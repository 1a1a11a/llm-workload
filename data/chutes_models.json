{
  "total": 240,
  "page": 0,
  "limit": 1000,
  "items": [
    {
      "chute_id": "110bf8d9-d07e-54dd-9c31-abe1a9919c7a",
      "name": "deepseek-ai/DeepSeek-R1-sgtest",
      "tagline": "",
      "readme": "deepseek-ai/DeepSeek-R1",
      "public": true,
      "version": "885c7d21-17fc-5875-86d5-4646c97ce3de",
      "tool_description": null,
      "slug": "chutes-deepseek-ai-deepseek-r1-sgtest",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "39298a95-dfa9-5370-8d14-8d45715bcfbf",
      "created_at": "2025-10-09T22:27:28.661019Z",
      "updated_at": "2025-10-09T22:28:48.637681Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 3289883,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.3,
            "tao": 0.000745056364755754
          },
          "output": {
            "usd": 1.2,
            "tao": 0.00298022545902302
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "e8389404-5a76-425c-90d9-662eca5b0599",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "7ce99c78-0429-4499-a0d7-55f7729ea4db",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "c2b0b2ad-bfda-49d8-b024-c37e52f4956e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "ec08ef56-1763-41ea-a53b-8732e038f3e6",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "32dc71fc-c882-44ec-9d80-7673cfce90b7",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "743b968c-b28a-4180-967d-86f60fd83b08",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "a68af9fe-95cf-4fea-81da-87b678acbea2",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "84c190da-a36e-4b6a-aca1-8083722630d8",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "94720772-03a7-44c4-ad9d-602ddac4b2a5",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "872064ac-b6b7-41b3-be27-e84f18e1d253",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "0b30842e-e4e8-4fa5-b94f-51a16da5b375",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "0775868d-43ec-4544-a287-d0c0385d5501",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "96d5a3a7-e287-4cb2-b99f-5ebe31ffdaf8",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "e56d2474-7f33-4ce8-91cd-dd86f01cdd1a",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "09edc4d6-e379-4d26-a940-23c0bd57a56c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "e47760cc-3d49-4018-82af-c186445c792e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "32b0bfb6-a923-4489-bcd5-9c222cd2e2ad",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "357372b3-446f-4f96-acfd-cd2daad39015",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "3a1c885f-fb5a-4094-aa10-556d08332485",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "442725f3-3e41-40a6-88a7-d1f5177a34db",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "ba0e54e4-da32-49b4-9215-77b4726512c3",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "3601b660-5fb1-4b4a-8f92-8955543d01f2",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "0aa6fbc6-1959-4c44-b892-2e1c658239c2",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        },
        {
          "instance_id": "b188f628-053e-4c6d-be48-58f9a32019f8",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:04.841165Z"
        }
      ],
      "logo_id": "90839dae-1bb7-41fd-a010-e9728b9075d6",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "f7361cd9ff99396dbf6bd644ad846015e59ed4fc",
      "concurrency": 40,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": 0.5,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/90839dae-1bb7-41fd-a010-e9728b9075d6.webp",
      "hot": true
    },
    {
      "chute_id": "14a91d88-d6d6-5046-aaf4-eb3ad96b7247",
      "name": "deepseek-ai/DeepSeek-R1-0528",
      "tagline": "DeepSeek-R1-0528 is an upgraded version of the DeepSeek language model optimized for complex reasoning tasks like mathematics and programming, demonstrating performance comparable to leading models like O3 and Gemini 2.5 Pro, with significant improvements in thinking depth and reduced hallucination rates.",
      "readme": "---\r\nlicense: mit\r\nlibrary_name: transformers\r\n---\r\n# DeepSeek-R1-0528\r\n\u003C!-- markdownlint-disable first-line-h1 --\u003E\r\n\u003C!-- markdownlint-disable html --\u003E\r\n\u003C!-- markdownlint-disable no-duplicate-header --\u003E\r\n\r\n\u003Cdiv align=\"center\"\u003E\r\n  \u003Cimg src=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/logo.svg?raw=true\" width=\"60%\" alt=\"DeepSeek-V3\" /\u003E\r\n\u003C/div\u003E\r\n\u003Chr\u003E\r\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\r\n  \u003Ca href=\"https://www.deepseek.com/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\r\n    \u003Cimg alt=\"Homepage\" src=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/badge.svg?raw=true\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\r\n  \u003C/a\u003E\r\n  \u003Ca href=\"https://chat.deepseek.com/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\r\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/ğŸ¤–%20Chat-DeepSeek%20R1-536af5?color=536af5&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\r\n  \u003C/a\u003E\r\n  \u003Ca href=\"https://huggingface.co/deepseek-ai\" target=\"_blank\" style=\"margin: 2px;\"\u003E\r\n    \u003Cimg alt=\"Hugging Face\" src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\r\n  \u003C/a\u003E\r\n\u003C/div\u003E\r\n\r\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\r\n  \u003Ca href=\"https://discord.gg/Tc7c45Zzu5\" target=\"_blank\" style=\"margin: 2px;\"\u003E\r\n    \u003Cimg alt=\"Discord\" src=\"https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&logoColor=white&color=7289da\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\r\n  \u003C/a\u003E\r\n  \u003Ca href=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/qr.jpeg?raw=true\" target=\"_blank\" style=\"margin: 2px;\"\u003E\r\n    \u003Cimg alt=\"Wechat\" src=\"https://img.shields.io/badge/WeChat-DeepSeek%20AI-brightgreen?logo=wechat&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\r\n  \u003C/a\u003E\r\n  \u003Ca href=\"https://twitter.com/deepseek_ai\" target=\"_blank\" style=\"margin: 2px;\"\u003E\r\n    \u003Cimg alt=\"Twitter Follow\" src=\"https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\r\n  \u003C/a\u003E\r\n\u003C/div\u003E\r\n\r\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\r\n  \u003Ca href=\"LICENSE\" style=\"margin: 2px;\"\u003E\r\n    \u003Cimg alt=\"License\" src=\"https://img.shields.io/badge/License-MIT-f5de53?&color=f5de53\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\r\n  \u003C/a\u003E\r\n\u003C/div\u003E\r\n \r\n\r\n\u003Cp align=\"center\"\u003E\r\n  \u003Ca href=\"https://arxiv.org/pdf/2501.12948\"\u003E\u003Cb\u003EPaper Link\u003C/b\u003EğŸ‘ï¸\u003C/a\u003E\r\n\u003C/p\u003E\r\n\r\n\r\n## 1. Introduction\r\n\r\nThe DeepSeek R1 model has undergone a minor version upgrade, with the current version being DeepSeek-R1-0528. In the latest update, DeepSeek R1 has significantly improved its depth of reasoning and inference capabilities by leveraging increased computational resources and introducing algorithmic optimization mechanisms during post-training. The model has demonstrated outstanding performance across various benchmark evaluations, including mathematics, programming, and general logic. Its overall performance is now approaching that of leading models, such as O3 and Gemini 2.5 Pro.\r\n\r\n\u003Cp align=\"center\"\u003E\r\n  \u003Cimg width=\"80%\" src=\"figures/benchmark.png\"\u003E\r\n\u003C/p\u003E\r\n\r\nCompared to the previous version, the upgraded model shows significant improvements in handling complex reasoning tasks. For instance, in the AIME 2025 test, the modelâ€™s accuracy has increased from 70% in the previous version to 87.5% in the current version. This advancement stems from enhanced thinking depth during the reasoning process: in the AIME test set, the previous model used an average of 12K tokens per question, whereas the new version averages 23K tokens per question.\r\n\r\nBeyond its improved reasoning capabilities, this version also offers a reduced hallucination rate, enhanced support for function calling, and better experience for vibe coding.\r\n\r\n## 2. Evaluation Results\r\n\r\n### DeepSeek-R1-0528\r\n For all our models, the maximum generation length is set to 64K tokens. For benchmarks requiring sampling, we use a temperature of $0.6$, a top-p value of $0.95$, and generate 16 responses per query to estimate pass@1.\r\n\u003Cdiv align=\"center\"\u003E\r\n\r\n| Category | Benchmark (Metric)               | DeepSeek R1     | DeepSeek R1 0528\r\n|----------|----------------------------------|-----------------|---|\r\n| General  |\r\n|          | MMLU-Redux (EM)                   | 92.9            | 93.4\r\n|          | MMLU-Pro (EM)                     | 84.0            | 85.0\r\n|          | GPQA-Diamond (Pass@1)             | 71.5            | 81.0\r\n|          | SimpleQA (Correct)                | 30.1            | 27.8\r\n|          | FRAMES (Acc.)                     | 82.5            | 83.0\r\n|          | Humanity's Last Exam (Pass@1)                     | 8.5            | 17.7\r\n| Code |\r\n|          | LiveCodeBench (2408-2505) (Pass@1)        | 63.5          | 73.3\r\n|          | Codeforces-Div1 (Rating)          | 1530            | 1930\r\n|          | SWE Verified (Resolved)           | 49.2            | 57.6\r\n|          | Aider-Polyglot (Acc.)             | 53.3            | 71.6\r\n| Math |\r\n|          | AIME 2024 (Pass@1)                | 79.8            | 91.4\r\n|          | AIME 2025 (Pass@1)                     | 70.0           | 87.5\r\n|          | HMMT 2025 (Pass@1)            | 41.7 | 79.4 |\r\n|          | CNMO 2024 (Pass@1)                | 78.8            | 86.9\r\n| Tools |\r\n|          | BFCL_v3_MultiTurn (Acc)     | -            | 37.0 |\r\n|          | Tau-Bench   (Pass@1)       | -            | 53.5(Airline)/63.9(Retail)\r\n\r\n\u003C/div\u003E\r\nNote: We use Agentless framework to evaluate model performance on SWE-Verified. We only evaluate text-only prompts in HLE testsets.  GPT-4.1 is employed to act user role in Tau-bench evaluation.\r\n\r\n### DeepSeek-R1-0528-Qwen3-8B\r\nMeanwhile, we distilled the chain-of-thought from DeepSeek-R1-0528 to post-train Qwen3 8B Base, obtaining DeepSeek-R1-0528-Qwen3-8B. This model achieves state-of-the-art (SOTA) performance among open-source models on the AIME 2024, surpassing Qwen3 8B by +10.0% and matching the performance of Qwen3-235B-thinking. We believe that the chain-of-thought from DeepSeek-R1-0528 will hold significant importance for both academic research on reasoning models and industrial development focused on small-scale models.\r\n\r\n|                                | AIME 24 | AIME 25 | HMMT Feb 25 | GPQA Diamond | LiveCodeBench (2408-2505) |\r\n|--------------------------------|---------|---------|-------------|--------------|---------------------------|\r\n| Qwen3-235B-A22B\t                | 85.7    | 81.5    | 62.5        | 71.1         | 66.5                  |\r\n| Qwen3-32B                      | 81.4    | 72.9    | -           | 68.4         | -                         |\r\n| Qwen3-8B                      | 76.0   | 67.3    | -           | 62.0       | -                         |\r\n| Phi-4-Reasoning-Plus-14B       | 81.3    | 78.0    | 53.6        | 69.3         | -          |\r\n| Gemini-2.5-Flash-Thinking-0520 | 82.3    | 72.0    | 64.2        | 82.8         | 62.3                  |\r\n| o3-mini (medium)               | 79.6    | 76.7    | 53.3        | 76.8         | 65.9                     |\r\n| DeepSeek-R1-0528-Qwen3-8B      | 86.0   | 76.3    | 61.5        | 61.1         | 60.5                      |\r\n\r\n## 3. Chat Website & API Platform\r\nYou can chat with DeepSeek-R1 on DeepSeek's official website: [chat.deepseek.com](https://chat.deepseek.com/sign_in), and switch on the button \"DeepThink\"\r\n\r\nWe also provide OpenAI-Compatible API at DeepSeek Platform: [platform.deepseek.com](https://platform.deepseek.com/)\r\n\r\n## 4. How to Run Locally\r\n\r\nPlease visit [DeepSeek-R1](https://github.com/deepseek-ai/DeepSeek-R1) repository for more information about running DeepSeek-R1-0528 locally.\r\n\r\nCompared to previous versions of DeepSeek-R1, the usage recommendations for DeepSeek-R1-0528 have the following changes:\r\n\r\n1. System prompt is supported now.\r\n2. It is not required to add \"\\\u003Cthink\\\u003E\\n\" at the beginning of the output to force the model into thinking pattern.\r\n\r\nThe model architecture of DeepSeek-R1-0528-Qwen3-8B is identical to that of Qwen3-8B, but it shares the same tokenizer configuration as DeepSeek-R1-0528. This model can be run in the same manner as Qwen3-8B.\r\n\r\n### System Prompt\r\nIn the official DeepSeek web/app, we use the same system prompt with a specific date.\r\n```\r\nè¯¥åŠ©æ‰‹ä¸ºDeepSeek-R1ï¼Œç”±æ·±åº¦æ±‚ç´¢å…¬å¸åˆ›é€ ã€‚\r\nä»Šå¤©æ˜¯{current date}ã€‚\r\n```\r\nFor example,\r\n```\r\nè¯¥åŠ©æ‰‹ä¸ºDeepSeek-R1ï¼Œç”±æ·±åº¦æ±‚ç´¢å…¬å¸åˆ›é€ ã€‚\r\nä»Šå¤©æ˜¯2025å¹´5æœˆ28æ—¥ï¼Œæ˜ŸæœŸä¸€ã€‚\r\n```\r\n### Temperature\r\nIn our web and application environments, the temperature parameter $T_{model}$ is set to 0.6. \r\n### Prompts for File Uploading and Web Search\r\nFor file uploading, please follow the template to create prompts, where {file_name}, {file_content} and {question} are arguments.\r\n```\r\nfile_template = \\\r\n\"\"\"[file name]: {file_name}\r\n[file content begin]\r\n{file_content}\r\n[file content end]\r\n{question}\"\"\"\r\n```\r\nFor Web Search, {search_results}, {cur_date}, and {question} are arguments.\r\nFor Chinese query, we use the prompt:\r\n```\r\nsearch_answer_zh_template = \\\r\n'''# ä»¥ä¸‹å†…å®¹æ˜¯åŸºäºç”¨æˆ·å‘é€çš„æ¶ˆæ¯çš„æœç´¢ç»“æœ:\r\n{search_results}\r\nåœ¨æˆ‘ç»™ä½ çš„æœç´¢ç»“æœä¸­ï¼Œæ¯ä¸ªç»“æœéƒ½æ˜¯[webpage X begin]...[webpage X end]æ ¼å¼çš„ï¼ŒXä»£è¡¨æ¯ç¯‡æ–‡ç« çš„æ•°å­—ç´¢å¼•ã€‚è¯·åœ¨é€‚å½“çš„æƒ…å†µä¸‹åœ¨å¥å­æœ«å°¾å¼•ç”¨ä¸Šä¸‹æ–‡ã€‚è¯·æŒ‰ç…§å¼•ç”¨ç¼–å·[citation:X]çš„æ ¼å¼åœ¨ç­”æ¡ˆä¸­å¯¹åº”éƒ¨åˆ†å¼•ç”¨ä¸Šä¸‹æ–‡ã€‚å¦‚æœä¸€å¥è¯æºè‡ªå¤šä¸ªä¸Šä¸‹æ–‡ï¼Œè¯·åˆ—å‡ºæ‰€æœ‰ç›¸å…³çš„å¼•ç”¨ç¼–å·ï¼Œä¾‹å¦‚[citation:3][citation:5]ï¼Œåˆ‡è®°ä¸è¦å°†å¼•ç”¨é›†ä¸­åœ¨æœ€åè¿”å›å¼•ç”¨ç¼–å·ï¼Œè€Œæ˜¯åœ¨ç­”æ¡ˆå¯¹åº”éƒ¨åˆ†åˆ—å‡ºã€‚\r\nåœ¨å›ç­”æ—¶ï¼Œè¯·æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š\r\n- ä»Šå¤©æ˜¯{cur_date}ã€‚\r\n- å¹¶éæœç´¢ç»“æœçš„æ‰€æœ‰å†…å®¹éƒ½ä¸ç”¨æˆ·çš„é—®é¢˜å¯†åˆ‡ç›¸å…³ï¼Œä½ éœ€è¦ç»“åˆé—®é¢˜ï¼Œå¯¹æœç´¢ç»“æœè¿›è¡Œç”„åˆ«ã€ç­›é€‰ã€‚\r\n- å¯¹äºåˆ—ä¸¾ç±»çš„é—®é¢˜ï¼ˆå¦‚åˆ—ä¸¾æ‰€æœ‰èˆªç­ä¿¡æ¯ï¼‰ï¼Œå°½é‡å°†ç­”æ¡ˆæ§åˆ¶åœ¨10ä¸ªè¦ç‚¹ä»¥å†…ï¼Œå¹¶å‘Šè¯‰ç”¨æˆ·å¯ä»¥æŸ¥çœ‹æœç´¢æ¥æºã€è·å¾—å®Œæ•´ä¿¡æ¯ã€‚ä¼˜å…ˆæä¾›ä¿¡æ¯å®Œæ•´ã€æœ€ç›¸å…³çš„åˆ—ä¸¾é¡¹ï¼›å¦‚éå¿…è¦ï¼Œä¸è¦ä¸»åŠ¨å‘Šè¯‰ç”¨æˆ·æœç´¢ç»“æœæœªæä¾›çš„å†…å®¹ã€‚\r\n- å¯¹äºåˆ›ä½œç±»çš„é—®é¢˜ï¼ˆå¦‚å†™è®ºæ–‡ï¼‰ï¼Œè¯·åŠ¡å¿…åœ¨æ­£æ–‡çš„æ®µè½ä¸­å¼•ç”¨å¯¹åº”çš„å‚è€ƒç¼–å·ï¼Œä¾‹å¦‚[citation:3][citation:5]ï¼Œä¸èƒ½åªåœ¨æ–‡ç« æœ«å°¾å¼•ç”¨ã€‚ä½ éœ€è¦è§£è¯»å¹¶æ¦‚æ‹¬ç”¨æˆ·çš„é¢˜ç›®è¦æ±‚ï¼Œé€‰æ‹©åˆé€‚çš„æ ¼å¼ï¼Œå……åˆ†åˆ©ç”¨æœç´¢ç»“æœå¹¶æŠ½å–é‡è¦ä¿¡æ¯ï¼Œç”Ÿæˆç¬¦åˆç”¨æˆ·è¦æ±‚ã€æå…·æ€æƒ³æ·±åº¦ã€å¯Œæœ‰åˆ›é€ åŠ›ä¸ä¸“ä¸šæ€§çš„ç­”æ¡ˆã€‚ä½ çš„åˆ›ä½œç¯‡å¹…éœ€è¦å°½å¯èƒ½å»¶é•¿ï¼Œå¯¹äºæ¯ä¸€ä¸ªè¦ç‚¹çš„è®ºè¿°è¦æ¨æµ‹ç”¨æˆ·çš„æ„å›¾ï¼Œç»™å‡ºå°½å¯èƒ½å¤šè§’åº¦çš„å›ç­”è¦ç‚¹ï¼Œä¸”åŠ¡å¿…ä¿¡æ¯é‡å¤§ã€è®ºè¿°è¯¦å°½ã€‚\r\n- å¦‚æœå›ç­”å¾ˆé•¿ï¼Œè¯·å°½é‡ç»“æ„åŒ–ã€åˆ†æ®µè½æ€»ç»“ã€‚å¦‚æœéœ€è¦åˆ†ç‚¹ä½œç­”ï¼Œå°½é‡æ§åˆ¶åœ¨5ä¸ªç‚¹ä»¥å†…ï¼Œå¹¶åˆå¹¶ç›¸å…³çš„å†…å®¹ã€‚\r\n- å¯¹äºå®¢è§‚ç±»çš„é—®ç­”ï¼Œå¦‚æœé—®é¢˜çš„ç­”æ¡ˆéå¸¸ç®€çŸ­ï¼Œå¯ä»¥é€‚å½“è¡¥å……ä¸€åˆ°ä¸¤å¥ç›¸å…³ä¿¡æ¯ï¼Œä»¥ä¸°å¯Œå†…å®¹ã€‚\r\n- ä½ éœ€è¦æ ¹æ®ç”¨æˆ·è¦æ±‚å’Œå›ç­”å†…å®¹é€‰æ‹©åˆé€‚ã€ç¾è§‚çš„å›ç­”æ ¼å¼ï¼Œç¡®ä¿å¯è¯»æ€§å¼ºã€‚\r\n- ä½ çš„å›ç­”åº”è¯¥ç»¼åˆå¤šä¸ªç›¸å…³ç½‘é¡µæ¥å›ç­”ï¼Œä¸èƒ½é‡å¤å¼•ç”¨ä¸€ä¸ªç½‘é¡µã€‚\r\n- é™¤éç”¨æˆ·è¦æ±‚ï¼Œå¦åˆ™ä½ å›ç­”çš„è¯­è¨€éœ€è¦å’Œç”¨æˆ·æé—®çš„è¯­è¨€ä¿æŒä¸€è‡´ã€‚\r\n# ç”¨æˆ·æ¶ˆæ¯ä¸ºï¼š\r\n{question}'''\r\n```\r\nFor English query, we use the prompt:\r\n```\r\nsearch_answer_en_template = \\\r\n'''# The following contents are the search results related to the user's message:\r\n{search_results}\r\nIn the search results I provide to you, each result is formatted as [webpage X begin]...[webpage X end], where X represents the numerical index of each article. Please cite the context at the end of the relevant sentence when appropriate. Use the citation format [citation:X] in the corresponding part of your answer. If a sentence is derived from multiple contexts, list all relevant citation numbers, such as [citation:3][citation:5]. Be sure not to cluster all citations at the end; instead, include them in the corresponding parts of the answer.\r\nWhen responding, please keep the following points in mind:\r\n- Today is {cur_date}.\r\n- Not all content in the search results is closely related to the user's question. You need to evaluate and filter the search results based on the question.\r\n- For listing-type questions (e.g., listing all flight information), try to limit the answer to 10 key points and inform the user that they can refer to the search sources for complete information. Prioritize providing the most complete and relevant items in the list. Avoid mentioning content not provided in the search results unless necessary.\r\n- For creative tasks (e.g., writing an essay), ensure that references are cited within the body of the text, such as [citation:3][citation:5], rather than only at the end of the text. You need to interpret and summarize the user's requirements, choose an appropriate format, fully utilize the search results, extract key information, and generate an answer that is insightful, creative, and professional. Extend the length of your response as much as possible, addressing each point in detail and from multiple perspectives, ensuring the content is rich and thorough.\r\n- If the response is lengthy, structure it well and summarize it in paragraphs. If a point-by-point format is needed, try to limit it to 5 points and merge related content.\r\n- For objective Q&A, if the answer is very brief, you may add one or two related sentences to enrich the content.\r\n- Choose an appropriate and visually appealing format for your response based on the user's requirements and the content of the answer, ensuring strong readability.\r\n- Your answer should synthesize information from multiple relevant webpages and avoid repeatedly citing the same webpage.\r\n- Unless the user requests otherwise, your response should be in the same language as the user's question.\r\n# The user's message is:\r\n{question}'''\r\n```\r\n\r\n## 5. License\r\nThis code repository is licensed under [MIT License](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528/raw/main/LICENSE). The use of DeepSeek-R1 models is also subject to [MIT License](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528/raw/main/LICENSE). DeepSeek-R1 series (including Base and Chat) supports commercial use and distillation.\r\n\r\n## 6. Citation\r\n```\r\n@misc{deepseekai2025deepseekr1incentivizingreasoningcapability,\r\n      title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}, \r\n      author={DeepSeek-AI},\r\n      year={2025},\r\n      eprint={2501.12948},\r\n      archivePrefix={arXiv},\r\n      primaryClass={cs.CL},\r\n      url={https://arxiv.org/abs/2501.12948}, \r\n}\r\n```\r\n\r\n## 7. Contact\r\nIf you have any questions, please raise an issue or contact us at [service@deepseek.com](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528/raw/main/service@deepseek.com).\r\n",
      "public": true,
      "version": "f6bcb8f3-cbbc-5e24-b4f7-4019f6975ece",
      "tool_description": null,
      "slug": "chutes-deepseek-ai-deepseek-r1-0528",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-05-28T18:56:26.606463Z",
      "updated_at": "2025-10-14T10:06:28.216852Z",
      "image": {
        "image_id": "1f7f2f45-9b11-594f-897c-d05c4f1727b6",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101300",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-13T17:42:41.772428Z",
        "build_started_at": "2025-10-13T17:42:45.733512Z",
        "build_completed_at": "2025-10-13T18:17:43.202213Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "initial",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 1808329,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.4,
            "tao": 0.000993408486341005
          },
          "output": {
            "usd": 1.75,
            "tao": 0.0043461621277419
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "4beb6fab-fd7a-408e-be0f-c159334d90ae",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:48:06.110475Z"
        },
        {
          "instance_id": "4520fbde-bc13-49c0-8755-5a9f2fa71a39",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:47:00.479037Z"
        },
        {
          "instance_id": "17b85977-7852-4cd1-9f08-728a0b1d16ef",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "1805fe0e-ceda-4c65-a0a4-919bb46e3a8a",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "2c61d8c6-de9b-4b86-8926-b72156bda509",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "3a9fb006-b8da-44ca-8aa4-73e1b51127ea",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "3cdbd2a7-c08b-4889-bdc6-02369a954110",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "65ec27a0-f6c7-4573-b960-6d6bbdf2deb9",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "738a1b9f-bb0a-418c-974c-25db245cc7e8",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "745e4e04-7f1a-4ad4-8752-b92e6f9efc6b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "7529832b-08ce-427f-9bc9-972dca1c104f",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "7f1774de-ff64-4a21-88c2-6f8630705e16",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "7ff4dae4-9ce9-49ad-952d-d74cbf4cf153",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "a7361a64-e734-430a-9ff0-8eb24ea4dec3",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "b052d46c-db96-4a71-93a1-a89d08ae5058",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "b8ced79c-a2b5-49ff-aafc-1c7f1062007e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "c4a3b63f-f62f-4dcc-9d62-70cc27a757ce",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "d24661ef-ced5-4fc6-9849-d9742b6868c6",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "ded84236-4a2f-4f86-b59f-ca91116a369d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "f31a8d76-8460-474e-b1d1-68be6029712d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "045f8ee5-0810-452b-85e9-efd826d2a62f",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "12292ff1-cca2-40e4-b75f-f6df40019b9a",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "1e18228a-3229-4ee4-92da-2fe306f4debc",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "8addad7c-816b-423e-97db-921bbe66e87e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:55:29.524414Z"
        },
        {
          "instance_id": "e26fd391-497a-4b4e-8349-b828f96a17bb",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T11:15:01.309341Z"
        },
        {
          "instance_id": "55027a20-27c2-4700-a99b-97c0373467d7",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T11:14:24.305782Z"
        },
        {
          "instance_id": "0ce7702b-3eba-47d6-ad5e-e5ff3d8b3670",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T11:18:12.514084Z"
        },
        {
          "instance_id": "0ab2073c-f074-4e75-91e5-57483c7bf415",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "0f838160-6d33-4d94-aa71-3905b27ac08c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "3409828c-2c30-47ac-ac27-82d9b64199e3",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "6864c3e0-656d-4524-9989-8f2b24ccd7bd",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "7e7ad604-6eca-40d0-a00f-c76b3e44bf9c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "a4bd182d-560c-4327-8e26-29e899276c3f",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "c8acbb14-725d-42a5-bbcf-198e7adaca58",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "dad5382f-bfd3-410f-9fb8-c901d0b06d92",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "f544fec7-ee3c-404e-b171-2f3aac04ca39",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        },
        {
          "instance_id": "fadbafc8-b701-4704-ba50-56d059bae904",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:27.354470Z"
        }
      ],
      "logo_id": "96f3a5ac-6120-4373-b0d3-056d8a468662",
      "openrouter": true,
      "chutes_version": "0.3.39.rc0",
      "revision": "4236a6af538feda4548eca9ab308586007567f52",
      "concurrency": 40,
      "boost": 1.5,
      "max_instances": null,
      "scaling_threshold": 0.5,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/96f3a5ac-6120-4373-b0d3-056d8a468662.webp",
      "hot": true
    },
    {
      "chute_id": "154ad01c-a431-5744-83c8-651215124360",
      "name": "deepseek-ai/DeepSeek-V3-0324",
      "tagline": "DeepSeek-V3-0324 is an improved version of DeepSeek-V3 that shows enhanced performance in reasoning, coding, Chinese language tasks, and function calling, making it particularly useful for developers and content creators needing a versatile open-source language model.",
      "readme": "# DeepSeek-V3-0324\n\u003C!-- markdownlint-disable first-line-h1 --\u003E\n\u003C!-- markdownlint-disable html --\u003E\n\u003C!-- markdownlint-disable no-duplicate-header --\u003E\n\n\u003Cdiv align=\"center\"\u003E\n  \u003Cimg src=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/logo.svg?raw=true\" width=\"60%\" alt=\"DeepSeek-V3\" /\u003E\n\u003C/div\u003E\n\u003Chr\u003E\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\n  \u003Ca href=\"https://www.deepseek.com/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Homepage\" src=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/badge.svg?raw=true\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://chat.deepseek.com/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/ğŸ¤–%20Chat-DeepSeek%20V3-536af5?color=536af5&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://huggingface.co/deepseek-ai\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Hugging Face\" src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\n  \u003Ca href=\"https://discord.gg/Tc7c45Zzu5\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Discord\" src=\"https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&logoColor=white&color=7289da\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/qr.jpeg?raw=true\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Wechat\" src=\"https://img.shields.io/badge/WeChat-DeepSeek%20AI-brightgreen?logo=wechat&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://twitter.com/deepseek_ai\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Twitter Follow\" src=\"https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\n  \u003Ca href=\"LICENSE\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"License\" src=\"https://img.shields.io/badge/License-MIT-f5de53?&color=f5de53\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\n## Features\n\nDeepSeek-V3-0324 demonstrates notable improvements over its predecessor, DeepSeek-V3, in several key aspects.\n\n![Model Performance](figures/0324_comparison.png) https://huggingface.co/deepseek-ai/DeepSeek-V3-0324/raw/main/figures/0324_comparison.png\n\n### Reasoning Capabilities\n\n- Significant improvements in benchmark performance:\n  - MMLU-Pro: 75.9 â†’ 81.2 (+5.3)\n  - GPQA: 59.1 â†’ 68.4 (+9.3)\n  - AIME: 39.6 â†’ 59.4 (+19.8)\n  - LiveCodeBench: 39.2 â†’ 49.2 (+10.0)\n\n### Front-End Web Development\n\n- Improved the executability of the code\n- More aesthetically pleasing web pages and game front-ends\n\n### Chinese Writing Proficiency\n\n- Enhanced style and content quality:\n  - Aligned with the R1 writing style\n  - Better quality in medium-to-long-form writing\n\n- Feature Enhancements\n  - Improved multi-turn interactive rewriting\n  - Optimized translation quality and letter writing\n\n### Chinese Search Capabilities\n\n- Enhanced report analysis requests with more detailed outputs\n\n### Function Calling Improvements\n\n- Increased accuracy in Function Calling, fixing issues from previous V3 versions\n\n---\n\n## Usage Recommendations\n\n### System Prompt\n\nIn the official DeepSeek web/app, we use the same system prompt with a specific date.\n\n```\nè¯¥åŠ©æ‰‹ä¸ºDeepSeek Chatï¼Œç”±æ·±åº¦æ±‚ç´¢å…¬å¸åˆ›é€ ã€‚\nä»Šå¤©æ˜¯{current date}ã€‚\n```\n\nFor example,\n\n```\nè¯¥åŠ©æ‰‹ä¸ºDeepSeek Chatï¼Œç”±æ·±åº¦æ±‚ç´¢å…¬å¸åˆ›é€ ã€‚\nä»Šå¤©æ˜¯3æœˆ24æ—¥ï¼Œæ˜ŸæœŸä¸€ã€‚\n```\n\n### Temperature\n\nIn our web and application environments, the temperature parameter $T_{model}$ is set to 0.3. Because many users use the default temperature 1.0 in API call, we have implemented an API temperature $T_{api}$ mapping mechanism that adjusts the input API temperature value of 1.0 to the most suitable model temperature setting of 0.3.\n\n$$\nT_{model} = T_{api} \\times 0.3 \\quad (0 \\leq T_{api} \\leq 1)\n$$\n\n$$\nT_{model} = T_{api} - 0.7 \\quad (1 \u003C T_{api} \\leq 2)\n$$\n\nThus, if you call V3 via API, temperature 1.0 equals to the model temperature 0.3.\n\n### Prompts for File Uploading and Web Search\n\nFor file uploading, please follow the template to create prompts, where {file_name}, {file_content} and {question} are arguments.\n\n```\nfile_template = \\\n\"\"\"[file name]: {file_name}\n[file content begin]\n{file_content}\n[file content end]\n{question}\"\"\"\n```\n\nFor Web Search, {search_results}, {cur_date}, and {question} are arguments.\n\nFor Chinese query, we use the prompt:\n\n```\nsearch_answer_zh_template = \\\n'''# ä»¥ä¸‹å†…å®¹æ˜¯åŸºäºç”¨æˆ·å‘é€çš„æ¶ˆæ¯çš„æœç´¢ç»“æœ:\n{search_results}\nåœ¨æˆ‘ç»™ä½ çš„æœç´¢ç»“æœä¸­ï¼Œæ¯ä¸ªç»“æœéƒ½æ˜¯[webpage X begin]...[webpage X end]æ ¼å¼çš„ï¼ŒXä»£è¡¨æ¯ç¯‡æ–‡ç« çš„æ•°å­—ç´¢å¼•ã€‚è¯·åœ¨é€‚å½“çš„æƒ…å†µä¸‹åœ¨å¥å­æœ«å°¾å¼•ç”¨ä¸Šä¸‹æ–‡ã€‚è¯·æŒ‰ç…§å¼•ç”¨ç¼–å·[citation:X]çš„æ ¼å¼åœ¨ç­”æ¡ˆä¸­å¯¹åº”éƒ¨åˆ†å¼•ç”¨ä¸Šä¸‹æ–‡ã€‚å¦‚æœä¸€å¥è¯æºè‡ªå¤šä¸ªä¸Šä¸‹æ–‡ï¼Œè¯·åˆ—å‡ºæ‰€æœ‰ç›¸å…³çš„å¼•ç”¨ç¼–å·ï¼Œä¾‹å¦‚[citation:3][citation:5]ï¼Œåˆ‡è®°ä¸è¦å°†å¼•ç”¨é›†ä¸­åœ¨æœ€åè¿”å›å¼•ç”¨ç¼–å·ï¼Œè€Œæ˜¯åœ¨ç­”æ¡ˆå¯¹åº”éƒ¨åˆ†åˆ—å‡ºã€‚\nåœ¨å›ç­”æ—¶ï¼Œè¯·æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š\n- ä»Šå¤©æ˜¯{cur_date}ã€‚\n- å¹¶éæœç´¢ç»“æœçš„æ‰€æœ‰å†…å®¹éƒ½ä¸ç”¨æˆ·çš„é—®é¢˜å¯†åˆ‡ç›¸å…³ï¼Œä½ éœ€è¦ç»“åˆé—®é¢˜ï¼Œå¯¹æœç´¢ç»“æœè¿›è¡Œç”„åˆ«ã€ç­›é€‰ã€‚\n- å¯¹äºåˆ—ä¸¾ç±»çš„é—®é¢˜ï¼ˆå¦‚åˆ—ä¸¾æ‰€æœ‰èˆªç­ä¿¡æ¯ï¼‰ï¼Œå°½é‡å°†ç­”æ¡ˆæ§åˆ¶åœ¨10ä¸ªè¦ç‚¹ä»¥å†…ï¼Œå¹¶å‘Šè¯‰ç”¨æˆ·å¯ä»¥æŸ¥çœ‹æœç´¢æ¥æºã€è·å¾—å®Œæ•´ä¿¡æ¯ã€‚ä¼˜å…ˆæä¾›ä¿¡æ¯å®Œæ•´ã€æœ€ç›¸å…³çš„åˆ—ä¸¾é¡¹ï¼›å¦‚éå¿…è¦ï¼Œä¸è¦ä¸»åŠ¨å‘Šè¯‰ç”¨æˆ·æœç´¢ç»“æœæœªæä¾›çš„å†…å®¹ã€‚\n- å¯¹äºåˆ›ä½œç±»çš„é—®é¢˜ï¼ˆå¦‚å†™è®ºæ–‡ï¼‰ï¼Œè¯·åŠ¡å¿…åœ¨æ­£æ–‡çš„æ®µè½ä¸­å¼•ç”¨å¯¹åº”çš„å‚è€ƒç¼–å·ï¼Œä¾‹å¦‚[citation:3][citation:5]ï¼Œä¸èƒ½åªåœ¨æ–‡ç« æœ«å°¾å¼•ç”¨ã€‚ä½ éœ€è¦è§£è¯»å¹¶æ¦‚æ‹¬ç”¨æˆ·çš„é¢˜ç›®è¦æ±‚ï¼Œé€‰æ‹©åˆé€‚çš„æ ¼å¼ï¼Œå……åˆ†åˆ©ç”¨æœç´¢ç»“æœå¹¶æŠ½å–é‡è¦ä¿¡æ¯ï¼Œç”Ÿæˆç¬¦åˆç”¨æˆ·è¦æ±‚ã€æå…·æ€æƒ³æ·±åº¦ã€å¯Œæœ‰åˆ›é€ åŠ›ä¸ä¸“ä¸šæ€§çš„ç­”æ¡ˆã€‚ä½ çš„åˆ›ä½œç¯‡å¹…éœ€è¦å°½å¯èƒ½å»¶é•¿ï¼Œå¯¹äºæ¯ä¸€ä¸ªè¦ç‚¹çš„è®ºè¿°è¦æ¨æµ‹ç”¨æˆ·çš„æ„å›¾ï¼Œç»™å‡ºå°½å¯èƒ½å¤šè§’åº¦çš„å›ç­”è¦ç‚¹ï¼Œä¸”åŠ¡å¿…ä¿¡æ¯é‡å¤§ã€è®ºè¿°è¯¦å°½ã€‚\n- å¦‚æœå›ç­”å¾ˆé•¿ï¼Œè¯·å°½é‡ç»“æ„åŒ–ã€åˆ†æ®µè½æ€»ç»“ã€‚å¦‚æœéœ€è¦åˆ†ç‚¹ä½œç­”ï¼Œå°½é‡æ§åˆ¶åœ¨5ä¸ªç‚¹ä»¥å†…ï¼Œå¹¶åˆå¹¶ç›¸å…³çš„å†…å®¹ã€‚\n- å¯¹äºå®¢è§‚ç±»çš„é—®ç­”ï¼Œå¦‚æœé—®é¢˜çš„ç­”æ¡ˆéå¸¸ç®€çŸ­ï¼Œå¯ä»¥é€‚å½“è¡¥å……ä¸€åˆ°ä¸¤å¥ç›¸å…³ä¿¡æ¯ï¼Œä»¥ä¸°å¯Œå†…å®¹ã€‚\n- ä½ éœ€è¦æ ¹æ®ç”¨æˆ·è¦æ±‚å’Œå›ç­”å†…å®¹é€‰æ‹©åˆé€‚ã€ç¾è§‚çš„å›ç­”æ ¼å¼ï¼Œç¡®ä¿å¯è¯»æ€§å¼ºã€‚\n- ä½ çš„å›ç­”åº”è¯¥ç»¼åˆå¤šä¸ªç›¸å…³ç½‘é¡µæ¥å›ç­”ï¼Œä¸èƒ½é‡å¤å¼•ç”¨ä¸€ä¸ªç½‘é¡µã€‚\n- é™¤éç”¨æˆ·è¦æ±‚ï¼Œå¦åˆ™ä½ å›ç­”çš„è¯­è¨€éœ€è¦å’Œç”¨æˆ·æé—®çš„è¯­è¨€ä¿æŒä¸€è‡´ã€‚\n\n# ç”¨æˆ·æ¶ˆæ¯ä¸ºï¼š\n{question}'''\n```\n\nFor English query, we use the prompt:\n\n```\nsearch_answer_en_template = \\\n'''# The following contents are the search results related to the user's message:\n{search_results}\nIn the search results I provide to you, each result is formatted as [webpage X begin]...[webpage X end], where X represents the numerical index of each article. Please cite the context at the end of the relevant sentence when appropriate. Use the citation format [citation:X] in the corresponding part of your answer. If a sentence is derived from multiple contexts, list all relevant citation numbers, such as [citation:3][citation:5]. Be sure not to cluster all citations at the end; instead, include them in the corresponding parts of the answer.\nWhen responding, please keep the following points in mind:\n- Today is {cur_date}.\n- Not all content in the search results is closely related to the user's question. You need to evaluate and filter the search results based on the question.\n- For listing-type questions (e.g., listing all flight information), try to limit the answer to 10 key points and inform the user that they can refer to the search sources for complete information. Prioritize providing the most complete and relevant items in the list. Avoid mentioning content not provided in the search results unless necessary.\n- For creative tasks (e.g., writing an essay), ensure that references are cited within the body of the text, such as [citation:3][citation:5], rather than only at the end of the text. You need to interpret and summarize the user's requirements, choose an appropriate format, fully utilize the search results, extract key information, and generate an answer that is insightful, creative, and professional. Extend the length of your response as much as possible, addressing each point in detail and from multiple perspectives, ensuring the content is rich and thorough.\n- If the response is lengthy, structure it well and summarize it in paragraphs. If a point-by-point format is needed, try to limit it to 5 points and merge related content.\n- For objective Q&A, if the answer is very brief, you may add one or two related sentences to enrich the content.\n- Choose an appropriate and visually appealing format for your response based on the user's requirements and the content of the answer, ensuring strong readability.\n- Your answer should synthesize information from multiple relevant webpages and avoid repeatedly citing the same webpage.\n- Unless the user requests otherwise, your response should be in the same language as the user's question.\n\n# The user's message is:\n{question}'''\n```\n\n## How to Run Locally\n\nThe model structure of DeepSeek-V3-0324 is exactly the same as DeepSeek-V3. Please visit [DeepSeek-V3](https://github.com/deepseek-ai/DeepSeek-V3) repo for more information about running this model locally.\n\n**This model supports features such as function calling, JSON output, and FIM completion. For instructions on how to construct prompts to use these features, please refer to [DeepSeek-V2.5](https://huggingface.co/deepseek-ai/DeepSeek-V2.5#function-calling) repo.**\n\n**NOTE: Hugging Face's Transformers has not been directly supported yet.**\n\n## License\n\nThis repository and the model weights are licensed under the [MIT License](https://huggingface.co/deepseek-ai/DeepSeek-V3-0324/raw/main/LICENSE).\n\n## Citation\n\n```\n@misc{deepseekai2024deepseekv3technicalreport,\n      title={DeepSeek-V3 Technical Report}, \n      author={DeepSeek-AI},\n      year={2024},\n      eprint={2412.19437},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2412.19437}, \n}\n```\n\n## Contact\nIf you have any questions, please raise an issue or contact us at [service@deepseek.com](https://huggingface.co/deepseek-ai/DeepSeek-V3-0324/raw/main/service@deepseek.com).\n",
      "public": true,
      "version": "56f2ab89-3656-539f-ab0d-91d750cb7efe",
      "tool_description": null,
      "slug": "chutes-deepseek-ai-deepseek-v3-0324",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-05-05T09:41:13.378848Z",
      "updated_at": "2025-10-13T08:46:50.204335Z",
      "image": {
        "image_id": "761d22a2-c96c-5675-82df-60cddab0827e",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101200",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-12T08:53:29.416285Z",
        "build_started_at": "2025-10-12T08:53:31.172351Z",
        "build_completed_at": "2025-10-12T09:17:36.083052Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "initial",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 1420431,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.24,
            "tao": 0.000596045091804603
          },
          "output": {
            "usd": 0.84,
            "tao": 0.00208615782131611
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "738cbf1f-d2aa-4382-9428-b88e584deeb9",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:56:58.037614Z"
        },
        {
          "instance_id": "c70ac629-2062-4b9b-a102-9112c031248c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:56:58.037614Z"
        },
        {
          "instance_id": "fec6ae49-f22c-49d0-b0d7-1f14fe327742",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:56:58.037614Z"
        },
        {
          "instance_id": "89dc6e16-4e87-49a3-becb-4d91aab3a521",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:56:58.037614Z"
        },
        {
          "instance_id": "8b41ad4d-4b48-429e-8d90-18a00723ec45",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:56:58.037614Z"
        },
        {
          "instance_id": "9ca506ea-1c36-465f-91da-0dc42acb1b2c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:56:58.037614Z"
        },
        {
          "instance_id": "0b3715bb-a830-401d-be90-0cbde9de2e03",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:56:58.037614Z"
        },
        {
          "instance_id": "2a3f568e-e7b0-41a5-88d8-534724d36976",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:56:58.037614Z"
        },
        {
          "instance_id": "4243cf2d-dce3-44c5-b7b0-5e20fbc6899f",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:56:58.037614Z"
        },
        {
          "instance_id": "bfeca919-cae8-4974-a745-ffdeb2163fc4",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:56:58.037614Z"
        },
        {
          "instance_id": "5721515c-e27e-4ea2-9f04-6eca791cf639",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:56:58.037614Z"
        },
        {
          "instance_id": "64cef111-71bb-468a-a607-7d10bf4cc16f",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:56:58.037614Z"
        },
        {
          "instance_id": "06919fe7-2413-4592-93db-9d62b391e840",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:56:58.037614Z"
        },
        {
          "instance_id": "bf920daa-eeb3-416f-9291-73c89150c56f",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:56:58.037614Z"
        },
        {
          "instance_id": "7580f02b-8619-4bef-a48f-6db39823b8c0",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:56:58.037614Z"
        },
        {
          "instance_id": "10e128f8-efa0-480a-adae-461c214ffbea",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:56:58.037614Z"
        },
        {
          "instance_id": "d7e89cb2-6dd3-4b31-8f02-c65d084b2b66",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:56:58.037614Z"
        },
        {
          "instance_id": "d831f215-0694-4983-bace-a82c1ae66c71",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:56:58.037614Z"
        },
        {
          "instance_id": "da621c89-e73e-4134-a449-00dec70b9193",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:56:58.037614Z"
        },
        {
          "instance_id": "e86656a5-61dc-443c-b40e-21f756db728e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:56:58.037614Z"
        }
      ],
      "logo_id": "0f15ccb8-5154-4e55-b13e-14ef6179820e",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "e9b33add76883f293d6bf61f6bd89b497e80e335",
      "concurrency": 48,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/0f15ccb8-5154-4e55-b13e-14ef6179820e.webp",
      "hot": true
    },
    {
      "chute_id": "de510462-c319-543b-9c67-00bcf807d2a7",
      "name": "deepseek-ai/DeepSeek-R1",
      "tagline": "",
      "readme": "deepseek-ai/DeepSeek-R1",
      "public": true,
      "version": "2aa7aeae-cd44-55a3-9eb5-59bf4caf0cc4",
      "tool_description": null,
      "slug": "chutes-deepseek-ai-deepseek-r1",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "b9784def-b796-57d7-888e-8fef54b2207e",
      "created_at": "2025-02-21T15:33:35.673823Z",
      "updated_at": "2025-10-20T08:23:39.359171Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 1233744,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.3,
            "tao": 0.000745056364755754
          },
          "output": {
            "usd": 1.2,
            "tao": 0.00298022545902302
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "88235fd2-6f84-4965-ac8d-e8666ec5ceee",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:01:24.905259Z"
        },
        {
          "instance_id": "9f9779dd-24ea-4a66-af0f-78f221f1223a",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:08:42.100027Z"
        },
        {
          "instance_id": "ee6532c2-cacc-4e0c-96bc-6123eaa16aea",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:01:19.282845Z"
        },
        {
          "instance_id": "1961634e-857f-44ee-ac9f-6983cee5e341",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T08:15:36.801376Z"
        },
        {
          "instance_id": "35a18b0d-d157-4b1c-be09-19b88a95eb89",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:26:11.444673Z"
        },
        {
          "instance_id": "77a40cb6-b60b-46d5-91c2-fc45b667a043",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T23:04:54.929530Z"
        },
        {
          "instance_id": "a3f16b2b-2010-4c71-ac04-b3323a8dfa9b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T08:09:26.138830Z"
        },
        {
          "instance_id": "81ddd15c-c2a1-4c44-9301-1de363ccf57d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T08:55:39.234585Z"
        },
        {
          "instance_id": "28f0eed5-fb9c-4e36-b513-d33e69e4cc31",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T23:04:54.929530Z"
        },
        {
          "instance_id": "7938e2ed-3954-4d8f-8b31-34b3ed08e2f0",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:29:50.197992Z"
        },
        {
          "instance_id": "cfd00aa4-23ec-4312-bfeb-c1fce7b07144",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:09:16.875064Z"
        },
        {
          "instance_id": "d064436e-6596-43a2-9cb2-e856b9be4985",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T08:51:27.394588Z"
        },
        {
          "instance_id": "28203084-97bf-40eb-8b81-a90193ff4e9a",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T08:51:03.927016Z"
        },
        {
          "instance_id": "b1f788bd-11af-4e7b-a60e-d22fbaf06b18",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T08:04:04.861299Z"
        },
        {
          "instance_id": "bf004beb-d256-41dd-84d4-c8e3d519431e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:00:58.284069Z"
        },
        {
          "instance_id": "c0d2376b-67f8-4c31-88b9-a7fc31521c75",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:02:21.073924Z"
        },
        {
          "instance_id": "b459f3d0-d360-4ca9-b90f-4efff19f18b6",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T08:03:25.914175Z"
        },
        {
          "instance_id": "82605979-a0be-48a8-8c0e-2375b7a68784",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:03:18.894088Z"
        },
        {
          "instance_id": "aa46ef42-3733-4a2b-b67b-0bc6671211bc",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:03:20.492033Z"
        }
      ],
      "logo_id": "be5a3ecb-3f8e-446e-8767-e59e6f5390f5",
      "openrouter": true,
      "chutes_version": "0.3.46",
      "revision": "f7361cd9ff99396dbf6bd644ad846015e59ed4fc",
      "concurrency": 40,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/be5a3ecb-3f8e-446e-8767-e59e6f5390f5.webp",
      "hot": true
    },
    {
      "chute_id": "4fa0c7f5-82f7-59d1-8996-661bb778893d",
      "name": "tngtech/DeepSeek-TNG-R1T2-Chimera",
      "tagline": "DeepSeek-TNG R1T2 Chimera is a 671B parameter model that combines three DeepSeek parent models using Assembly of Experts methodology, offering a balance of speed and intelligence that makes it particularly suitable for reasoning tasks while being about 20% faster than the regular DeepSeek R1.",
      "readme": "# DeepSeek-TNG-R1T2-Chimera\n\n\u003Cdiv align=\"center\"\u003E\n\u003Cimg src=\"https://354918363417-runtime-assets.s3.eu-central-1.amazonaws.com/company_logo_light.svg\"\n     alt=\"TNG Logo\" \n     width=\"400\"\n     style=\"display: inline-block; vertical-align: middle;\"/\u003E\n\u003C/div\u003E\n\u003Cbr\u003E\n\u003Cdiv align=\"center\"\u003E\n  \u003Ca href=\"https://huggingface.co/tngtech/DeepSeek-TNG-R1T2-Chimera/blob/main/LICENSE.DeepSeek\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"License\" src=\"https://img.shields.io/badge/License-MIT-f5de53?&color=f5de53\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\u003Cbr\u003E\n\u003Cdiv align=\"center\"\u003E\n    \u003Cimg alt=\"Intelligence Score\" src=\"intelligence_score_vs_output_tokens.png\" style=\"display: inline-block; vertical-align: middle;\" width=\"750\"/\u003E\n    \u003Cfigcaption\u003E\u003Ca href=\"https://x.com/tngtech/status/1940531045432283412\"\u003ERelease Announcement on X\u003C/a\u003E\u003C/figcaption\u003E\n\u003C/div\u003E\n\n\n## Assembly of Experts Chimera model constructed with the DeepSeek [R1-0528](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528), [R1](https://huggingface.co/deepseek-ai/DeepSeek-R1) and [V3-0324](https://huggingface.co/deepseek-ai/DeepSeek-V3-0324) parent models\n\nWe present our new **DeepSeek-TNG R1T2 Chimera** 671B model, the first successor to our original [*DeepSeek R1T Chimera*](https://huggingface.co/tngtech/DeepSeek-R1T-Chimera) that was released on April 26th. Unlike the original Chimera, which was based on the *two parent models* V3-0324 and R1, the new Chimera is a **Tri-Mind** *with three parents*, namely additionally R1-0528. It is constructed using the Assembly of Experts-method with relatively fine-granular direct brain edits. This more refined assembly allowed, among other improvements, the fixing of the &lt;think&gt; token consistency issue, which was a weakness of R1T and is now solved for R1T2. \n\n**Sweet spot**\n\nR1T2 operates at a new sweet spot in intelligence vs. output token length. It appears to be...\n\n- about **20% faster than** the regular **R1**, and more than **twice as fast as R1-0528**\n- significantly **more intelligent than** the regular **R1** in benchmarks such as **GPQA**, **AIME-24** and **Aider Polyglot**\n- much **more intelligent** and also **think-token consistent** compared to the first **R1T Chimera** 0426\n- and generally well-behaved and a **nice persona** to talk to, even without any system prompt.\n\n**Recommendations for your model decision**\n\n*R1T2* compared...\n- *vs R1:* We hope that R1T2 is a very desirable, almost universally **better drop-in replacement for R1**\n- *vs R1-0528:* R1T2 is a much **cheaper alternative to the full R1-0528**, if the full 0528-level intelligence is not required\n- *vs R1T:* R1T2 is usually **recommended over R1T**, unless the specific personality of R1T was optimal, the think-token issue not important, or R1T's higher speed crucial\n- *vs V3-0324:* V3 is so much faster that if you can live with the **lower intelligence, take V3**, however, if you **need reasoning, R1T2** is the go-to model\n\n**Limitations**\n\n- **R1-0528** is thinking much longer, but also is achieving **better hard benchmark results** than R1T2\n- As measured by SpeechMap.ai (courtesy of xlr8harder), **R1T2** is significantly **more reserved** than R1T, but not as much as R1-0528\n- When switching from R1T to R1T2 development, we changed from AIME24 and MT-Bench to AIME24, AIME25 and GPQA-Diamond for the intelligence score. With the new benchmark set, there is a larger score difference between R1 and the original R1T Chimera than published earlier.\n- Function calling is supported in general, but both vLLM and SGLang currently require some specific adaptions, see the section below.\n\n**Evaluation results**\n\nEvaluation was performed using the evalchemy framework (pass@1 averaged over 10/5 runs for AIME/GPQAD, at a temperature of 0.6).\nWe report measured benchmark results for our R1T2, R1T models and published benchmark results for V3-0324, R1, R1-0528.\n\n|                                    | R1T2 |  R1T | V3-0324 |   R1 | R1-0528 | Comment | Special source |\n|:-----------------------------------|-----:|-----:|--------:|-----:|--------:|:--------|:--------|\n| AIME-24                            | 82.3 | 74.7 |    59.4 | 79.8 |    91.4 |         |         |\n| AIME-25                            | 70.0 | 58.3 |    49.6 | 70.0 |    87.5 |         | V3-0324 AIME-25 measured by us |\n| GPQA-Diamond                       | 77.9 | 72.0 |    68.4 | 71.5 |    81.0 |         |         |\n| Aider Polyglot                     | 64.4 | 48.4 |    44.9 | 52.0 |    71.6 | R1T2 beats two of its parents, V3-0324 and R1, and was measured to be about 2.2 times more token efficient, i.e. faster, than its third parent, R1-0528 | R1T2 source: Aider discord, t=0.75 |\n| MMLU-Pro Computer Science          | 83.7-85.6 | 82.9-84.6 | 81.5-82.4 | 85.1-85.3 | 84.6-86.1 |         |         |\n| EQ-Bench Longform Creative Writing | 76.4 |  ./. |    78.1 | 74.6 |    78.9 | EQ Bench version before August 8th, 2025 | see [EQ Bench](https://eqbench.com/creative_writing_longform.html)  |\n| Vectara Hallucination Rate         |  5.5 |  ./. |     8.0 | 14.3 |     7.7 | lower hallucination rates are better, R1T2 is better than all its three parents | see [Hallucination Leaderboard](https://github.com/vectara/hallucination-leaderboard) |\n\n## Technological background\n\nFor details on the AoE construction process, you can read our [Paper on arXiV](https://arxiv.org/abs/2506.14794).\n\n**Runtime parameter settings**\n\n- Most of our evaluation was done with a maximum context size of 60,000 tokens.\n  With a context size of 130,000 tokens, the model proved very helpful in interpreting very long debug logs. Long-context testing was less extensive, though.\n- We're running the model using vLLM on 8xH200 and MI325X nodes, additionally we've tested the model using SGLang, which is also used by [chutes.ai](https://chutes.ai/app/chute/4fa0c7f5-82f7-59d1-8996-661bb778893d).\n- For SGLang, we recommend using versions \u003E= v0.4.8 in combination with argument `--reasoning-parser qwen3` to properly handle rare cases when the model skips the `\u003Cthink\u003E` reasoning step. \n\n\n### Function calling\n\nR1T2 does support function calling using an updated chat template (since 01 Aug 2025). However, neither vLLM nor SGLang provide an R1T2-compatible tool call parser natively but require some adaptions.\n\n_vLLM:_\n\nFor function calling with vLLM, a new tool parser is required. While we opened [a PR to vLLM](https://github.com/vllm-project/vllm/pull/22074) to include an R1T2-compatible tool parser off-the-shelf, we also ship the tool parser file `tool_parser_vllm.py` within this repository. \nWith this file, tool calling can be enabled via\n```\n--tool-parser-plugin \u003CABSOLUTE_MODEL_SNAPSHOT_PATH\u003E/tool_parser_vllm.py  \\\n--tool-call-parser tng_r1t2\n```\n\nHere, put in the path to the snapshot folder such as `~/.cache/huggingface/hub/models--tngtech--DeepSeek-TNG-R1T2-Chimera/snapshots/SNAPSHOT/tool_parser_vllm.py`\n\n_SGLang:_\n\nTool call support for R1T2 requires a recent SGLang version \u003E= v0.4.10 (alternatively, you need to patch [this bugfix for the reasoning parser](https://github.com/sgl-project/sglang/pull/8606) for older versions of SGLang).\n\nAn R1T2-compatible tool call parser will be added with [this PR to SGLang](https://github.com/sgl-project/sglang/pull/8672). \nUnfortunately, and unlike vLLM, there is no simple plugin system for tool call parsers in SGLang. \nUntil our PR is merged an relased with a new SGLang version, you can still install it manually by patching your SGLang source code as outlined in the PR:\nThe new tool call parser must be added and registered (so in total one file must be added, a second one edited, see [details here](https://github.com/sgl-project/sglang/pull/8672/files)).\n\nOnce the SGLang installation has been updated correctly, tool calling with R1T2 can be activated by starting SGLang with\n\n```\n--tool-call-parser tng_r1t2\n```\n\n\n## Model Details\n\n- **Architecture**: DeepSeek-MoE transformer-based language model\n- **Combination Method**: Assembly of Experts from the three DeepSeek parent models R1-0528, R1 and V3-0324\n- **Release Date**: 2025-07-02\n- **Design Team**: Robert Dahlke, Henrik Klagges, Benjamin Merkel, Fabian Klemm and David Reiss, Munich, Germany\n- **Extra Thanks**: Big thanks to DeepSeek for their great models and open-source generosity, and to the other researchers that have published on model merging methodologies.\n\n\n## Use, Out-of-scope Use, Other Limitations, Risks, Recommendations et al.\nRegarding the R1T/R1T2-Chimeras, we ask you to follow the careful guidelines that Microsoft has created for their \"MAI-DS-R1\" DeepSeek-based model. \nThese professional guidelines are available [here on Hugging Face](https://huggingface.co/microsoft/MAI-DS-R1).\n\n## EU AI Act\n\nDue to the strict new guidelines of the EU AI Act that take effect on August 2nd 2025, we recommend that each R1T/R1T2 user in the EU either familiarizes themselves with these requirements and assess their compliance, or ceases using the model in the EU after August 1st, 2025.\n\n## Contact, especially for your user feedback\n\nPlease give us your feedback, especially if you find deficiencies in the model:\n- Email: research@tngtech.com\n- X.com: @tngtech\n\n## Citation\n\n```\n@misc{tng_technology_consulting_gmbh_2025_07_02,\n\tauthor       = { TNG Technology Consulting GmbH },\n\ttitle        = { DeepSeek-TNG-R1T2-Chimera },\n\tyear         = 2025,\n    month        = { July },\n\turl          = { https://huggingface.co/tngtech/DeepSeek-TNG-R1T2-Chimera },\n\tdoi          = { 10.57967/hf/5950 },\n\tpublisher    = { Hugging Face }\n}\n```",
      "public": true,
      "version": "998e06d7-680f-59d3-a77b-7c06e8b93251",
      "tool_description": null,
      "slug": "chutes-tngtech-deepseek-tng-r1t2-chimera",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-08-04T15:51:33.777813Z",
      "updated_at": "2025-10-08T15:17:21.451778Z",
      "image": {
        "image_id": "959721f7-6184-549f-bd66-546c8868b9f7",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100800",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T14:43:47.661711Z",
        "build_started_at": "2025-10-08T14:44:11.231501Z",
        "build_completed_at": "2025-10-08T15:10:23.923875Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "df8eef013628",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 979917,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.3,
            "tao": 0.000745056364755754
          },
          "output": {
            "usd": 1.2,
            "tao": 0.00298022545902302
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "0b2a1aa8-e3cd-4f01-be8d-cb90fcb94848",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "451de259-7af8-4282-b95b-bc1c467b4ebf",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "54b298f6-6257-4acf-bda2-74d7c1f9ee5a",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "5be71bb3-57c6-4876-a6ef-b9adbf508b92",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "5c339673-b8ea-45ca-b77b-a01cb053e7e1",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "666fc68b-c636-4b65-ab1a-e02e77a93786",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "931d553f-8f2d-4080-a9cc-afd758dcf6eb",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "95e8082c-eea3-4b10-90a2-a7be038d566d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "b7d35d6b-e395-4955-acdf-13e1c70c0a5c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "ba07546d-822e-4d5d-9782-2d55cd99c015",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "85e33fba-565c-4584-8f83-c659d835960d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "39faf657-7272-46ad-9d41-38f06dafbf48",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "3ca2a174-a44a-4c06-91f8-d36702f6cb72",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "415fa2e1-5892-4aca-a663-18ae9a120940",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "85bc9958-2648-492a-915a-1dccd00cd447",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "8fae5335-7015-4f6f-b3a2-da0c6b320d7b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "d5352d0d-b9a2-44ec-baa0-4718509ae489",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "d703cf9f-c3ed-4a76-9597-3965d0bf02e7",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "f554d5d7-26ad-41ae-906f-58e38929a6b1",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "cc7816f1-bdac-40b1-b680-f86a8cb427ce",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "0129b37c-62b6-4dfd-9cfa-93dbccec57e8",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "ef975b0e-4f29-4b1f-9190-dbd1a7db4fbf",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "f1d15362-3359-4f58-a87c-2fd41c06f021",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        },
        {
          "instance_id": "6ca23043-adc0-4a7f-b289-5cb2a9c383f8",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:20:27.185750Z"
        }
      ],
      "logo_id": "91fd2f3b-ed42-457a-8651-594ea107ebee",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "0b8033a9b334d94a7abf266d4067789831dfd39f",
      "concurrency": 40,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/91fd2f3b-ed42-457a-8651-594ea107ebee.webp",
      "hot": true
    },
    {
      "chute_id": "986b874c-bf41-549f-b28f-4322f86fa4ba",
      "name": "unsloth/Mistral-Small-24B-Instruct-2501",
      "tagline": "Mistral Small 3 is a 24B parameter open source model that achieves near GPT-4 level performance on many tasks while being small enough to run on a single RTX 4090 or 32GB MacBook, making it ideal for local deployment of conversational agents and specialized fine-tuning.",
      "readme": "\n# Finetune LLMs 2-5x faster with 70% less memory via Unsloth!\nWe have a free Google Colab Tesla T4 notebook for Mistral (7B) here: https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_v0.3_(7B)-Conversational.ipynb\n\n[\u003Cimg src=\"https://raw.githubusercontent.com/unslothai/unsloth/main/images/Discord%20button.png\" width=\"200\"/\u003E](https://discord.gg/unsloth)\n[\u003Cimg src=\"https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20made%20with%20love.png\" width=\"200\"/\u003E](https://github.com/unslothai/unsloth)\n\n\n## âœ¨ Finetune for Free\n\nAll notebooks are **beginner friendly**! Add your dataset, click \"Run All\", and you'll get a 2x faster finetuned model which can be exported to GGUF, vLLM or uploaded to Hugging Face.\n\n| Unsloth supports          |    Free Notebooks                                                                                           | Performance | Memory use |\n|-----------------|--------------------------------------------------------------------------------------------------------------------------|-------------|----------|\n| **Llama-3.2 (3B)**      | [â–¶ï¸ Start on Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb)               | 2.4x faster | 58% less |\n| **Llama-3.2 (11B vision)**      | [â–¶ï¸ Start on Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)               | 2x faster | 60% less |\n| **Qwen2 VL (7B)**      | [â–¶ï¸ Start on Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2_VL_(7B)-Vision.ipynb)               | 1.8x faster | 60% less |\n| **Qwen2.5 (7B)**      | [â–¶ï¸ Start on Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2.5_(7B)-Alpaca.ipynb)               | 2x faster | 60% less |\n| **Llama-3.1 (8B)**      | [â–¶ï¸ Start on Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-Alpaca.ipynb)               | 2.4x faster | 58% less |\n| **Phi-3.5 (mini)** | [â–¶ï¸ Start on Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_3.5_Mini-Conversational.ipynb)               | 2x faster | 50% less |\n| **Gemma 2 (9B)**      | [â–¶ï¸ Start on Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Gemma2_(9B)-Alpaca.ipynb)               | 2.4x faster | 58% less |\n| **Mistral (7B)**    | [â–¶ï¸ Start on Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_v0.3_(7B)-Conversational.ipynb)               | 2.2x faster | 62% less |\n\n[\u003Cimg src=\"https://raw.githubusercontent.com/unslothai/unsloth/refs/heads/main/images/documentation%20green%20button.png\" width=\"200\"/\u003E](https://docs.unsloth.ai)\n\n- This [Llama 3.2 conversational notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb) is useful for ShareGPT ChatML / Vicuna templates.\n- This [text completion notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_(7B)-Text_Completion.ipynb) is for raw text. This [DPO notebook](https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing) replicates Zephyr.\n- \\* Kaggle has 2x T4s, but we use 1. Due to overhead, 1x T4 is 5x faster.\n# Model Card for Mistral-Small-24B-Instruct-2501\n\nMistral Small 3 ( 2501 ) sets a new benchmark in the \"small\" Large Language Models category below 70B, boasting 24B parameters and achieving state-of-the-art capabilities comparable to larger models!  \nThis model is an instruction-fine-tuned version of the base model: [Mistral-Small-24B-Base-2501](https://huggingface.co/mistralai/Mistral-Small-24B-Base-2501).\n\nMistral Small can be deployed locally and is exceptionally \"knowledge-dense\", fitting in a single RTX 4090 or a 32GB RAM MacBook once quantized.  \nPerfect for:\n- Fast response conversational agents.\n- Low latency function calling.\n- Subject matter experts via fine-tuning.\n- Local inference for hobbyists and organizations handling sensitive data.\n\nFor enterprises that need specialized capabilities (increased context, particular modalities, domain specific knowledge, etc.), we will be releasing commercial models beyond what Mistral AI contributes to the community.\n\nThis release demonstrates our commitment to open source, serving as a strong base model. \n\nLearn more about Mistral Small in our [blog post](https://mistral.ai/news/mistral-small-3/).\n\nModel developper: Mistral AI Team\n\n## Key Features\n- **Multilingual:** Supports dozens of languages, including English, French, German, Spanish, Italian, Chinese, Japanese, Korean, Portuguese, Dutch, and Polish.\n- **Agent-Centric:** Offers best-in-class agentic capabilities with native function calling and JSON outputting.\n- **Advanced Reasoning:** State-of-the-art conversational and reasoning capabilities.\n- **Apache 2.0 License:** Open license allowing usage and modification for both commercial and non-commercial purposes.\n- **Context Window:** A 32k context window.\n- **System Prompt:** Maintains strong adherence and support for system prompts.\n- **Tokenizer:** Utilizes a Tekken tokenizer with a 131k vocabulary size.\n\n## Benchmark results\n\n\n### Human evaluated benchmarks\n\n| Category | Gemma-2-27B | Qwen-2.5-32B | Llama-3.3-70B | Gpt4o-mini |\n|----------|-------------|--------------|---------------|------------|\n| Mistral is better | 0.536 | 0.496 | 0.192 | 0.200 |\n| Mistral is slightly better | 0.196 | 0.184 | 0.164 | 0.204 |\n| Ties | 0.052 | 0.060 | 0.236 | 0.160 |\n| Other is slightly better | 0.060 | 0.088 | 0.112 | 0.124 |\n| Other is better | 0.156 | 0.172 | 0.296 | 0.312 |\n\n**Note**:\n\n- We conducted side by side evaluations with an external third-party vendor, on a set of over 1k proprietary coding and generalist prompts.\n- Evaluators were tasked with selecting their preferred model response from anonymized generations produced by Mistral Small 3 vs another model.\n- We are aware that in some cases the benchmarks on human judgement starkly differ from publicly available benchmarks, but have taken extra caution in verifying a fair evaluation. We are confident that the above benchmarks are valid.\n\n### Publicly accesible benchmarks\n\n**Reasoning & Knowledge**\n\n| Evaluation | mistral-small-24B-instruct-2501 | gemma-2b-27b | llama-3.3-70b | qwen2.5-32b | gpt-4o-mini-2024-07-18 |\n|------------|---------------|--------------|---------------|---------------|-------------|\n| mmlu_pro_5shot_cot_instruct | 0.663 | 0.536 | 0.666 | 0.683 | 0.617 |\n| gpqa_main_cot_5shot_instruct | 0.453 | 0.344 | 0.531 | 0.404 | 0.377 |\n\n**Math & Coding**\n\n| Evaluation | mistral-small-24B-instruct-2501 | gemma-2b-27b | llama-3.3-70b | qwen2.5-32b | gpt-4o-mini-2024-07-18 |\n|------------|---------------|--------------|---------------|---------------|-------------|\n| humaneval_instruct_pass@1 | 0.848 | 0.732 | 0.854 | 0.909 | 0.890 |\n| math_instruct | 0.706 | 0.535 | 0.743 | 0.819 | 0.761 |\n**Instruction following**\n| Evaluation | mistral-small-24B-instruct-2501 | gemma-2b-27b | llama-3.3-70b | qwen2.5-32b | gpt-4o-mini-2024-07-18 |\n|------------|---------------|--------------|---------------|---------------|-------------|\n| mtbench_dev | 8.35 | 7.86 | 7.96 | 8.26 | 8.33 |\n| wildbench | 52.27 | 48.21 | 50.04 | 52.73 | 56.13 |\n| arena_hard | 0.873 | 0.788 | 0.840 | 0.860 | 0.897 |\n| ifeval | 0.829 | 0.8065 | 0.8835 | 0.8401 | 0.8499 |\n**Note**:\n- Performance accuracy on all benchmarks were obtained through the same internal evaluation pipeline - as such, numbers may vary slightly from previously reported performance\n([Qwen2.5-32B-Instruct](https://qwenlm.github.io/blog/qwen2.5/), [Llama-3.3-70B-Instruct](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct), [Gemma-2-27B-IT](https://huggingface.co/google/gemma-2-27b-it)). \n- Judge based evals such as Wildbench, Arena hard and MTBench were based on gpt-4o-2024-05-13.\n### Basic Instruct Template (V7-Tekken)\n```\n\u003Cs\u003E[SYSTEM_PROMPT]\u003Csystem prompt\u003E[/SYSTEM_PROMPT][INST]\u003Cuser message\u003E[/INST]\u003Cassistant response\u003E\u003C/s\u003E[INST]\u003Cuser message\u003E[/INST]\n```\n*`\u003Csystem_prompt\u003E`, `\u003Cuser message\u003E` and `\u003Cassistant response\u003E` are placeholders.*\n***Please make sure to use [mistral-common](https://github.com/mistralai/mistral-common) as the source of truth***\n## Usage\nThe model can be used with the following frameworks;\n- [`vllm`](https://github.com/vllm-project/vllm): See [here](https://huggingface.co/unsloth/Mistral-Small-24B-Instruct-2501/raw/main/#vLLM)\n- [`transformers`](https://github.com/huggingface/transformers): See [here](https://huggingface.co/unsloth/Mistral-Small-24B-Instruct-2501/raw/main/#Transformers)\n### vLLM\nWe recommend using this model with the [vLLM library](https://github.com/vllm-project/vllm)\nto implement production-ready inference pipelines.\n**Note 1**: We recommond using a relatively low temperature, such as `temperature=0.15`.\n**Note 2**: Make sure to add a system prompt to the model to best tailer it for your needs. If you want to use the model as a general assistant, we recommend the following \nsystem prompt:\n```\nsystem_prompt = \"\"\"You are Mistral Small 3, a Large Language Model (LLM) created by Mistral AI, a French startup headquartered in Paris.\nYour knowledge base was last updated on 2023-10-01. The current date is 2025-01-30.\nWhen you're not sure about some information, you say that you don't have the information and don't make up anything.\nIf the user's question is not clear, ambiguous, or does not provide enough context for you to accurately answer the question, you do not try to answer it right away and you rather ask the user to clarify their request (e.g. \\\"What are some good restaurants around me?\\\" =\u003E \\\"Where are you?\\\" or \\\"When is the next flight to Tokyo\\\" =\u003E \\\"Where do you travel from?\\\")\"\"\"\n```\n**_Installation_**\nMake sure you install [`vLLM \u003E= 0.6.4`](https://github.com/vllm-project/vllm/releases/tag/v0.6.4):\n```\npip install --upgrade vllm\n```\nAlso make sure you have [`mistral_common \u003E= 1.5.2`](https://github.com/mistralai/mistral-common/releases/tag/v1.5.2) installed:\n```\npip install --upgrade mistral_common\n```\nYou can also make use of a ready-to-go [docker image](https://github.com/vllm-project/vllm/blob/main/Dockerfile) or on the [docker hub](https://hub.docker.com/layers/vllm/vllm-openai/latest/images/sha256-de9032a92ffea7b5c007dad80b38fd44aac11eddc31c435f8e52f3b7404bbf39).\n#### Server\nWe recommand that you use Mistral-Small-24B-Instruct-2501 in a server/client setting. \n1. Spin up a server:\n```\nvllm serve mistralai/Mistral-Small-24B-Instruct-2501 --tokenizer_mode mistral --config_format mistral --load_format mistral --tool-call-parser mistral --enable-auto-tool-choice\n```\n**Note:** Running Mistral-Small-24B-Instruct-2501 on GPU requires ~55 GB of GPU RAM in bf16 or fp16. \n2. To ping the client you can use a simple Python snippet.\n```py\nimport requests\nimport json\nfrom datetime import datetime, timedelta\n\nurl = \"http://\u003Cyour-server\u003E:8000/v1/chat/completions\"\nheaders = {\"Content-Type\": \"application/json\", \"Authorization\": \"Bearer token\"}\n\nmodel = \"mistralai/Mistral-Small-24B-Instruct-2501\"\n\nmessages = [\n    {\n        \"role\": \"system\",\n        \"content\": \"You are a conversational agent that always answers straight to the point, always end your accurate response with an ASCII drawing of a cat.\"\n    },\n    {\n        \"role\": \"user\",\n        \"content\": \"Give me 5 non-formal ways to say 'See you later' in French.\"\n    },\n]\ndata = {\"model\": model, \"messages\": messages}\n\nresponse = requests.post(url, headers=headers, data=json.dumps(data))\nprint(response.json()[\"choices\"][0][\"message\"][\"content\"])\n\n# Sure, here are five non-formal ways to say \"See you later\" in French:\n#\n# 1. Ã€ plus tard\n# 2. Ã€ plus\n# 3. Salut\n# 4. Ã€ toute\n# 5. Bisous\n#\n# ```\n#  /\\_/\\\n# ( o.o )\n#  \u003E ^ \u003C\n# ```\n```\n### Function calling\nMistral-Small-24-Instruct-2501 is excellent at function / tool calling tasks via vLLM. *E.g.:*\n\u003Cdetails\u003E\n  \u003Csummary\u003EExample\u003C/summary\u003E\n```py\nimport requests\nimport json\nfrom huggingface_hub import hf_hub_download\nfrom datetime import datetime, timedelta\n\nurl = \"http://\u003Cyour-url\u003E:8000/v1/chat/completions\"\nheaders = {\"Content-Type\": \"application/json\", \"Authorization\": \"Bearer token\"}\n\nmodel = \"mistralai/Mistral-Small-24B-Instruct-2501\"\n\n\ndef load_system_prompt(repo_id: str, filename: str) -\u003E str:\n    file_path = hf_hub_download(repo_id=repo_id, filename=filename)\n    with open(file_path, \"r\") as file:\n        system_prompt = file.read()\n    today = datetime.today().strftime(\"%Y-%m-%d\")\n    yesterday = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n    model_name = repo_id.split(\"/\")[-1]\n    return system_prompt.format(name=model_name, today=today, yesterday=yesterday)\n\nSYSTEM_PROMPT = load_system_prompt(model, \"SYSTEM_PROMPT.txt\")\n\n\ntools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_current_weather\",\n            \"description\": \"Get the current weather in a given location\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"city\": {\n                        \"type\": \"string\",\n                        \"description\": \"The city to find the weather for, e.g. 'San Francisco'\",\n                    },\n                    \"state\": {\n                        \"type\": \"string\",\n                        \"description\": \"The state abbreviation, e.g. 'CA' for California\",\n                    },\n                    \"unit\": {\n                        \"type\": \"string\",\n                        \"description\": \"The unit for temperature\",\n                        \"enum\": [\"celsius\", \"fahrenheit\"],\n                    },\n                },\n                \"required\": [\"city\", \"state\", \"unit\"],\n            },\n        },\n    },\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"rewrite\",\n            \"description\": \"Rewrite a given text for improved clarity\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"text\": {\n                        \"type\": \"string\",\n                        \"description\": \"The input text to rewrite\",\n                    }\n                },\n            },\n        },\n    },\n]\nmessages = [\n    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n    {\n        \"role\": \"user\",\n        \"content\": \"Could you please make the below article more concise?\\n\\nOpenAI is an artificial intelligence research laboratory consisting of the non-profit OpenAI Incorporated and its for-profit subsidiary corporation OpenAI Limited Partnership.\",\n    },\n    {\n        \"role\": \"assistant\",\n        \"content\": \"\",\n        \"tool_calls\": [\n            {\n                \"id\": \"bbc5b7ede\",\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": \"rewrite\",\n                    \"arguments\": '{\"text\": \"OpenAI is an artificial intelligence research laboratory consisting of the non-profit OpenAI Incorporated and its for-profit subsidiary corporation OpenAI Limited Partnership.\"}',\n                },\n            }\n        ],\n    },\n    {\n        \"role\": \"tool\",\n        \"content\": '{\"action\":\"rewrite\",\"outcome\":\"OpenAI is a FOR-profit company.\"}',\n        \"tool_call_id\": \"bbc5b7ede\",\n        \"name\": \"rewrite\",\n    },\n    {\n        \"role\": \"assistant\",\n        \"content\": \"---\\n\\nOpenAI is a FOR-profit company.\",\n    },\n    {\n        \"role\": \"user\",\n        \"content\": \"Can you tell me what the temperature will be in Dallas, in Fahrenheit?\",\n    },\n]\ndata = {\"model\": model, \"messages\": messages, \"tools\": tools}\n\nresponse = requests.post(url, headers=headers, data=json.dumps(data))\nimport ipdb; ipdb.set_trace()\nprint(response.json()[\"choices\"][0][\"message\"][\"tool_calls\"])\n# [{'id': '8PdihwL6d', 'type': 'function', 'function': {'name': 'get_current_weather', 'arguments': '{\"city\": \"Dallas\", \"state\": \"TX\", \"unit\": \"fahre",
      "public": true,
      "version": "52de5463-4524-5fd1-ba19-10baa16ec0ad",
      "tool_description": null,
      "slug": "chutes-unsloth-mistral-small-24b-instruct-2501",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-03-22T12:45:43.823864Z",
      "updated_at": "2025-10-10T07:25:53.084126Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "h100",
        "h800",
        "a100_sxm",
        "l40s"
      ],
      "node_selector": {
        "exclude": [
          "l40",
          "a6000",
          "b200",
          "mi300x"
        ],
        "include": null,
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.888888888888889,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "h100",
          "h800",
          "a100_sxm",
          "l40s"
        ]
      },
      "invocation_count": 412198,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.05,
            "tao": 0.000124176060792625
          },
          "output": {
            "usd": 0.22,
            "tao": 0.000546374667487553
          }
        },
        "usd": {
          "hour": 4,
          "second": 0.00111111111111111
        },
        "tao": {
          "hour": 0.00993408486341006,
          "second": 0.000002759468017613
        }
      },
      "instances": [
        {
          "instance_id": "a20f8f80-d1cc-4504-a707-9dfbf85182fa",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:51:53.169494Z"
        },
        {
          "instance_id": "233e429a-c13b-4f68-81e8-7e8d405c9deb",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:51:53.169494Z"
        },
        {
          "instance_id": "4bb9e8f1-d50b-4ae9-a535-fbcfb0b6bff2",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:51:53.169494Z"
        },
        {
          "instance_id": "85b8bbf0-59ed-46fa-aade-61de359e485d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:51:53.169494Z"
        },
        {
          "instance_id": "90b1b122-7344-423d-9041-2579b6deb069",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:51:53.169494Z"
        }
      ],
      "logo_id": "779cffb3-d9e8-456a-8483-07921c478cd4",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "2eddef095b2d91c22c59cc3ede00ec595e530d16",
      "concurrency": 40,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/779cffb3-d9e8-456a-8483-07921c478cd4.webp",
      "hot": true
    },
    {
      "chute_id": "6275d63c-ca84-56f2-81c1-93a4070c6348",
      "name": "chutesai/Devstral-Small-2505",
      "tagline": "Devstral is a 24B parameter LLM optimized for software engineering tasks, capable of exploring codebases and powering coding agents with a 128k context window.",
      "readme": "\n# Model Card for mistralai/Devstrall-Small-2505\n\nDevstral is an agentic LLM for software engineering tasks built under a collaboration between [Mistral AI](https://mistral.ai/) and [All Hands AI](https://www.all-hands.dev/) ğŸ™Œ. Devstral excels at using tools to explore codebases, editing multiple files and power software engineering agents. The model achieves remarkable performance on SWE-bench which positionates it as the #1 open source model on this [benchmark](https://huggingface.co/chutesai/Devstral-Small-2505/raw/main/#benchmark-results). \n\nIt is finetuned from [Mistral-Small-3.1](https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Base-2503), therefore it has a long context window of up to 128k tokens. As a coding agent, Devstral is text-only and before fine-tuning from `Mistral-Small-3.1` the vision encoder was removed.\n\nFor enterprises requiring specialized capabilities (increased context, domain-specific knowledge, etc.), we will release commercial models beyond what Mistral AI contributes to the community.\n\nLearn more about Devstral in our [blog post](https://mistral.ai/news/devstral).\n\n\n## Key Features:\n- **Agentic coding**: Devstral is designed to excel at agentic coding tasks, making it a great choice for software engineering agents.\n- **lightweight**: with its compact size of just 24 billion parameters, Devstral is light enough to run on a single RTX 4090 or a Mac with 32GB RAM, making it an appropriate model for local deployment and on-device use.\n- **Apache 2.0 License**: Open license allowing usage and modification for both commercial and non-commercial purposes.\n- **Context Window**: A 128k context window.\n- **Tokenizer**: Utilizes a Tekken tokenizer with a 131k vocabulary size.\n\n\n\n## Benchmark Results\n\n### SWE-Bench\n\nDevstral achieves a score of 46.8% on SWE-Bench Verified, outperforming prior open-source SoTA by 6%.\n\n| Model            | Scaffold           | SWE-Bench Verified (%) |\n|------------------|--------------------|------------------------|\n| Devstral         | OpenHands Scaffold | **46.8**               |\n| GPT-4.1-mini     | OpenAI Scaffold    | 23.6                   |\n| Claude 3.5 Haiku | Anthropic Scaffold | 40.6                   |\n| SWE-smith-LM 32B | SWE-agent Scaffold | 40.2                   |\n\n\n When evaluated under the same test scaffold (OpenHands, provided by All Hands AI ğŸ™Œ), Devstral exceeds far larger models such as Deepseek-V3-0324 and Qwen3 232B-A22B.\n\n![SWE Benchmark](assets/swe_bench.png) https://huggingface.co/chutesai/Devstral-Small-2505/raw/main/assets/swe_bench.png\n\n## Usage\n\nWe recommend to use Devstral with the [OpenHands](https://github.com/All-Hands-AI/OpenHands/tree/main) scaffold.\nYou can use it either through our API or by running locally. \n\n### API \nFollow these [instructions](https://docs.mistral.ai/getting-started/quickstart/#account-setup) to create a Mistral account and get an API key.\n\nThen run these commands to start the OpenHands docker container.\n```bash\nexport MISTRAL_API_KEY=\u003CMY_KEY\u003E\n\ndocker pull docker.all-hands.dev/all-hands-ai/runtime:0.39-nikolaik\n\nmkdir -p ~/.openhands-state && echo '{\"language\":\"en\",\"agent\":\"CodeActAgent\",\"max_iterations\":null,\"security_analyzer\":null,\"confirmation_mode\":false,\"llm_model\":\"mistral/devstral-small-2505\",\"llm_api_key\":\"'$MISTRAL_API_KEY'\",\"remote_runtime_resource_factor\":null,\"github_token\":null,\"enable_default_condenser\":true}' \u003E ~/.openhands-state/settings.json\n\ndocker run -it --rm --pull=always \\\n    -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.39-nikolaik \\\n    -e LOG_ALL_EVENTS=true \\\n    -v /var/run/docker.sock:/var/run/docker.sock \\\n    -v ~/.openhands-state:/.openhands-state \\\n    -p 3000:3000 \\\n    --add-host host.docker.internal:host-gateway \\\n    --name openhands-app \\\n    docker.all-hands.dev/all-hands-ai/openhands:0.39\n```\n\n### Local inference \n\nYou can also run the model locally. It can be done with LMStudio or other providers listed below.\n\nLaunch Openhands\nYou can now interact with the model served from LM Studio with openhands. Start the openhands server with the docker\n\n```bash\ndocker pull docker.all-hands.dev/all-hands-ai/runtime:0.38-nikolaik\ndocker run -it --rm --pull=always \\\n\t-e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.38-nikolaik \\\n\t-e LOG_ALL_EVENTS=true \\\n\t-v /var/run/docker.sock:/var/run/docker.sock \\\n\t-v ~/.openhands-state:/.openhands-state \\\n\t-p 3000:3000 \\\n\t--add-host host.docker.internal:host-gateway \\\n\t--name openhands-app \\\n\tdocker.all-hands.dev/all-hands-ai/openhands:0.38\n```\n\nThe server will start at http://0.0.0.0:3000. Open it in your browser and you will see a tab AI Provider Configuration. \nNow you can start a new conversation with the agent by clicking on the plus sign on the left bar.\n\n\nThe model can also be deployed with the following libraries:\n- [`LMStudio (recommended for quantized model)`](https://lmstudio.ai/): See [here](https://huggingface.co/chutesai/Devstral-Small-2505/raw/main/#lmstudio-recommended-for-quantized-model)\n- [`vllm (recommended)`](https://github.com/vllm-project/vllm): See [here](https://huggingface.co/chutesai/Devstral-Small-2505/raw/main/#vllm-recommended)\n- [`mistral-inference`](https://github.com/mistralai/mistral-inference): See [here](https://huggingface.co/chutesai/Devstral-Small-2505/raw/main/#mistral-inference)\n- [`transformers`](https://github.com/huggingface/transformers): See [here](https://huggingface.co/chutesai/Devstral-Small-2505/raw/main/#transformers)\n- [`ollama`](https://github.com/ollama/ollama): See [here](https://huggingface.co/chutesai/Devstral-Small-2505/raw/main/#ollama)\n\n\n### OpenHands (recommended)\n\n#### Launch a server to deploy Devstral-Small-2505\n\nMake sure you launched an OpenAI-compatible server such as vLLM or Ollama as described above. Then, you can use OpenHands to interact with `Devstral-Small-2505`.\n\nIn the case of the tutorial we spineed up a vLLM server running the command:\n```bash\nvllm serve mistralai/Devstral-Small-2505 --tokenizer_mode mistral --config_format mistral --load_format mistral --tool-call-parser mistral --enable-auto-tool-choice --tensor-parallel-size 2\n```\n\nThe server address should be in the following format: `http://\u003Cyour-server-url\u003E:8000/v1`\n\n#### Launch OpenHands\n\nYou can follow installation of OpenHands [here](https://docs.all-hands.dev/modules/usage/installation).\n\nThe easiest way to launch OpenHands is to use the Docker image:\n```bash\ndocker pull docker.all-hands.dev/all-hands-ai/runtime:0.38-nikolaik\n\ndocker run -it --rm --pull=always \\\n    -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.38-nikolaik \\\n    -e LOG_ALL_EVENTS=true \\\n    -v /var/run/docker.sock:/var/run/docker.sock \\\n    -v ~/.openhands-state:/.openhands-state \\\n    -p 3000:3000 \\\n    --add-host host.docker.internal:host-gateway \\\n    --name openhands-app \\\n    docker.all-hands.dev/all-hands-ai/openhands:0.38\n```\n\n\nThen, you can access the OpenHands UI at `http://localhost:3000`.\n\n#### Connect to the server\n\nWhen accessing the OpenHands UI, you will be prompted to connect to a server. You can use the advanced mode to connect to the server you launched earlier.\n\nFill the following fields:\n- **Custom Model**: `openai/mistralai/Devstral-Small-2505`\n- **Base URL**: `http://\u003Cyour-server-url\u003E:8000/v1`\n- **API Key**: `token` (or any other token you used to launch the server if any)\n\n#### Use OpenHands powered by Devstral\n\nNow you're good to use Devstral Small inside OpenHands by **starting a new conversation**. Let's build a To-Do list app.\n\n\u003Cdetails\u003E\n  \u003Csummary\u003ETo-Do list app\u003C/summary\n\n1. Let's ask Devstral to generate the app with the following prompt:\n\n```txt\nBuild a To-Do list app with the following requirements:\n- Built using FastAPI and React.\n- Make it a one page app that:\n   - Allows to add a task.\n   - Allows to delete a task.\n   - Allows to mark a task as done.\n   - Displays the list of tasks.\n- Store the tasks in a SQLite database.\n```\n\n![Agent prompting](assets/tuto_open_hands/agent_prompting.png) https://huggingface.co/chutesai/Devstral-Small-2505/raw/main/assets/tuto_open_hands/agent_prompting.png\n\n\n2. Let's see the result\n\nYou should see the agent construct the app and be able to explore the code it generated.\n\nIf it doesn't do it automatically, ask Devstral to deploy the app or do it manually, and then go the front URL deployment to see the app.\n\n![Agent working](assets/tuto_open_hands/agent_working.png) https://huggingface.co/chutesai/Devstral-Small-2505/raw/main/assets/tuto_open_hands/agent_working.png\n![App UI](assets/tuto_open_hands/app_ui.png) https://huggingface.co/chutesai/Devstral-Small-2505/raw/main/assets/tuto_open_hands/app_ui.png\n\n\n3. Iterate\n\nNow that you have a first result you can iterate on it by asking your agent to improve it. For example, in the app generated we could click on a task to mark it checked but having a checkbox would improve UX. You could also ask it to add a feature to edit a task, or to add a feature to filter the tasks by status.\n\nEnjoy building with Devstral Small and OpenHands!\n\n\u003C/details\u003E\n\n\n### LMStudio (recommended for quantized model)\nDownload the weights from huggingface:\n\n```\npip install -U \"huggingface_hub[cli]\"\nhuggingface-cli download \\\n\"mistralai/Devstral-Small-2505_gguf\" \\\n--include \"devstralQ4_K_M.gguf\" \\\n--local-dir \"mistralai/Devstral-Small-2505_gguf/\"\n```\n\nYou can serve the model locally with [LMStudio](https://lmstudio.ai/).\n* Download [LM Studio](https://lmstudio.ai/) and install it\n* Install `lms cli ~/.lmstudio/bin/lms bootstrap`\n* In a bash terminal, run `lms import devstralQ4_K_M.ggu` in the directory where you've downloaded the model checkpoint (e.g. `mistralai/Devstral-Small-2505_gguf`)\n* Open the LMStudio application, click the terminal icon to get into the developer tab. Click select a model to load and select Devstral Q4 K M. Toggle the status button to start the model, in setting oggle Serve on Local Network to be on.\n* On the right tab, you will see an API identifier which should be devstralq4_k_m and an api address under API Usage. Keep note of this address, we will use it in the next step.\n\nLaunch Openhands\nYou can now interact with the model served from LM Studio with openhands. Start the openhands server with the docker\n\n```bash\ndocker pull docker.all-hands.dev/all-hands-ai/runtime:0.38-nikolaik\ndocker run -it --rm --pull=always \\\n\t-e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.38-nikolaik \\\n\t-e LOG_ALL_EVENTS=true \\\n\t-v /var/run/docker.sock:/var/run/docker.sock \\\n\t-v ~/.openhands-state:/.openhands-state \\\n\t-p 3000:3000 \\\n\t--add-host host.docker.internal:host-gateway \\\n\t--name openhands-app \\\n\tdocker.all-hands.dev/all-hands-ai/openhands:0.38\n```\n\nClick â€œsee advanced settingâ€ on the second line. \nIn the new tab, toggle advanced to on. Set the custom model to be mistral/devstralq4_k_m and Base URL the api address we get from the last step in LM Studio. Set API Key to dummy. Click save changes.\n\n### vLLM (recommended)\n\nWe recommend using this model with the [vLLM library](https://github.com/vllm-project/vllm)\nto implement production-ready inference pipelines.\n\n**_Installation_**\n\nMake sure you install [`vLLM \u003E= 0.8.5`](https://github.com/vllm-project/vllm/releases/tag/v0.8.5):\n\n```\npip install vllm --upgrade\n```\n\nDoing so should automatically install [`mistral_common \u003E= 1.5.5`](https://github.com/mistralai/mistral-common/releases/tag/v1.5.5).\n\nTo check:\n```\npython -c \"import mistral_common; print(mistral_common.__version__)\"\n```\n\nYou can also make use of a ready-to-go [docker image](https://github.com/vllm-project/vllm/blob/main/Dockerfile) or on the [docker hub](https://hub.docker.com/layers/vllm/vllm-openai/latest/images/sha256-de9032a92ffea7b5c007dad80b38fd44aac11eddc31c435f8e52f3b7404bbf39).\n\n#### Server\n\nWe recommand that you use Devstral in a server/client setting. \n\n1. Spin up a server:\n\n```\nvllm serve mistralai/Devstral-Small-2505 --tokenizer_mode mistral --config_format mistral --load_format mistral --tool-call-parser mistral --enable-auto-tool-choice --tensor-parallel-size 2\n```\n\n\n2. To ping the client you can use a simple Python snippet.\n\n```py\nimport requests\nimport json\nfrom huggingface_hub import hf_hub_download\n\n\nurl = \"http://\u003Cyour-server-url\u003E:8000/v1/chat/completions\"\nheaders = {\"Content-Type\": \"application/json\", \"Authorization\": \"Bearer token\"}\n\nmodel = \"mistralai/Devstral-Small-2505\"\n\ndef load_system_prompt(repo_id: str, filename: str) -\u003E str:\n    file_path = hf_hub_download(repo_id=repo_id, filename=filename)\n    with open(file_path, \"r\") as file:\n        system_prompt = file.read()\n    return system_prompt\n\nSYSTEM_PROMPT = load_system_prompt(model, \"SYSTEM_PROMPT.txt\")\n\nmessages = [\n    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"text\",\n                \"text\": \"\u003Cyour-command\u003E\",\n            },\n        ],\n    },\n]\n\ndata = {\"model\": model, \"messages\": messages, \"temperature\": 0.15}\n\nresponse = requests.post(url, headers=headers, data=json.dumps(data))\nprint(response.json()[\"choices\"][0][\"message\"][\"content\"])\n```\n\n\n### Mistral-inference\n\nWe recommend using mistral-inference to quickly try out / \"vibe-check\" Devstral.\n\n#### Install\n\nMake sure to have mistral_inference \u003E= 1.6.0 installed.\n\n```bash\npip install mistral_inference --upgrade\n```\n\n#### Download\n\n```python\nfrom huggingface_hub import snapshot_download\nfrom pathlib import Path\n\nmistral_models_path = Path.home().joinpath('mistral_models', 'Devstral')\nmistral_models_path.mkdir(parents=True, exist_ok=True)\n\nsnapshot_download(repo_id=\"mistralai/Devstral-Small-2505\", allow_patterns=[\"params.json\", \"consolidated.safetensors\", \"tekken.json\"], local_dir=mistral_models_path)\n```\n\n#### Python\n\nYou can run the model using the following command:\n\n```bash\nmistral-chat $HOME/mistral_models/Devstral --instruct --max_tokens 300\n```\n\nYou can then prompt it with anything you'd like.\n\n### Ollama\n\nYou can run Devstral using the [Ollama](https://ollama.ai/) CLI.\n\n```bash\nollama run devstral\n```\n\n### Transformers\n\nTo make the best use of our model with transformers make sure to have [installed](https://github.com/mistralai/mistral-common) `    mistral-common \u003E= 1.5.5` to use our tokenizer.\n\n```bash\npip install mistral-common --upgrade\n```\n\nThen load our tokenizer along with the model and generate:\n\n```python\nimport torch\n\nfrom mistral_common.protocol.instruct.messages import (\n    SystemMessage, UserMessage\n)\nfrom mistral_common.protocol.instruct.request import ChatCompletionRequest\nfrom mistral_common.tokens.tokenizers.mistral import MistralTokenizer\nfrom mistral_common.tokens.tokenizers.tekken import SpecialTokenPolicy\nfrom huggingface_hub import hf_hub_download\nfrom transformers import AutoModelForCausalLM\n\ndef load_system_prompt(repo_id: str, filename: str) -\u003E str:\n    file_path = hf_hub_download(repo_id=repo_id, filename=filename)\n    with open(file_path, \"r\") as file:\n        system_prompt = file.read()\n    return system_prompt\n\nmodel_id = \"mistralai/Devstral-Small-2505\"\ntekken_file = hf_hub_download(repo_id=model_id, filename=\"tekken.json\")\nSYSTEM_PROMPT = load_system_prompt(model_id, \"SYSTEM_PROMPT.txt\")\n\ntokenizer = MistralTokenizer.from_file(tekken_file)\n\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\n\ntokenized = tokenizer.encode_chat_completion(\n    ChatCompletionRequest(\n        messages=[\n            SystemMessage(content=SYSTEM_PROMPT),\n            UserMessage(content=\"\u003Cyour-command\u003E\"),\n        ],\n    )\n)\n\noutput = model.generate(\n    input_ids=torch.tensor([tokenized.tokens]),\n    max_new_tokens=1000,\n)[0]\n\ndecoded_output = tokenizer.decode(output[len(tokenized.tokens):])\nprint(decoded_output)\n```",
      "public": true,
      "version": "9030d0b9-31dc-5275-a1fe-b87bcf934b6f",
      "tool_description": null,
      "slug": "chutes-chutesai-devstral-small-2505",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-05-22T13:12:17.613436Z",
      "updated_at": "2025-10-09T18:38:13.990941Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "exclude": [
          "b200",
          "mi300x",
          "h200"
        ],
        "include": null,
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.888888888888889,
        "supported_gpus": [
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 341323,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.05,
            "tao": 0.000124176060792625
          },
          "output": {
            "usd": 0.22,
            "tao": 0.000546374667487553
          }
        },
        "usd": {
          "hour": 4,
          "second": 0.00111111111111111
        },
        "tao": {
          "hour": 0.00993408486341006,
          "second": 0.000002759468017613
        }
      },
      "instances": [
        {
          "instance_id": "100f48b5-f455-4eb3-929d-91dd312ab90c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:36:09.321236Z"
        },
        {
          "instance_id": "5ccc6e59-b98c-4a9a-90f3-769d5010266b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:36:09.321236Z"
        },
        {
          "instance_id": "96a1be63-1bfb-4033-baef-4ceb71c3cafd",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:36:09.321236Z"
        },
        {
          "instance_id": "a948b201-1e25-424d-9a35-778e1e95db76",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:36:09.321236Z"
        },
        {
          "instance_id": "eec746f7-4934-4a95-8a35-2d5df12f323f",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:36:09.321236Z"
        }
      ],
      "logo_id": "2b2f9077-e461-4889-9249-25b99d71fbe5",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "a038c1ea7deb0fa06be461e9b5f7158d145ffebc",
      "concurrency": 40,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/2b2f9077-e461-4889-9249-25b99d71fbe5.webp",
      "hot": true
    },
    {
      "chute_id": "7fa03c12-823f-529a-8245-36432f03e9a1",
      "name": "zai-org/GLM-4.5-Air",
      "tagline": "GLM-4.5-Air is a 106B parameter open-source language model (with 12B active parameters) designed for reasoning, coding, and agent applications that performs competitively with larger models while maintaining efficiency.",
      "readme": "\n# GLM-4.5-Air\n\n\u003Cdiv align=\"center\"\u003E\n\u003Cimg src=https://raw.githubusercontent.com/zai-org/GLM-4.5/refs/heads/main/resources/logo.svg width=\"15%\"/\u003E\n\u003C/div\u003E\n\u003Cp align=\"center\"\u003E\n    ğŸ‘‹ Join our \u003Ca href=\"https://discord.gg/QR7SARHRxK\" target=\"_blank\"\u003EDiscord\u003C/a\u003E community.\n    \u003Cbr\u003E\n    ğŸ“– Check out the GLM-4.5 \u003Ca href=\"https://z.ai/blog/glm-4.5\" target=\"_blank\"\u003Etechnical blog\u003C/a\u003E, \u003Ca href=\"https://arxiv.org/abs/2508.06471\" target=\"_blank\"\u003Etechnical report\u003C/a\u003E, and \u003Ca href=\"https://zhipu-ai.feishu.cn/wiki/Gv3swM0Yci7w7Zke9E0crhU7n7D\" target=\"_blank\"\u003EZhipu AI technical documentation\u003C/a\u003E.\n    \u003Cbr\u003E\n    ğŸ“ Use GLM-4.5 API services on \u003Ca href=\"https://docs.z.ai/guides/llm/glm-4.5\"\u003EZ.ai API Platform (Global)\u003C/a\u003E or \u003Cbr\u003E \u003Ca href=\"https://docs.bigmodel.cn/cn/guide/models/text/glm-4.5\"\u003EZhipu AI Open Platform (Mainland China)\u003C/a\u003E.\n    \u003Cbr\u003E\n    ğŸ‘‰ One click to \u003Ca href=\"https://chat.z.ai\"\u003EGLM-4.5\u003C/a\u003E.\n\u003C/p\u003E\n  \n## Model Introduction\n\nThe **GLM-4.5** series models are foundation models designed for intelligent agents. GLM-4.5 has **355** billion total parameters with **32** billion active parameters, while GLM-4.5-Air adopts a more compact design with **106** billion total parameters and **12** billion active parameters. GLM-4.5 models unify reasoning, coding, and intelligent agent capabilities to meet the complex demands of intelligent agent applications.\n\nBoth GLM-4.5 and GLM-4.5-Air are hybrid reasoning models that provide two modes: thinking mode for complex reasoning and tool usage, and non-thinking mode for immediate responses.\n\nWe have open-sourced the base models, hybrid reasoning models, and FP8 versions of the hybrid reasoning models for both GLM-4.5 and GLM-4.5-Air. They are released under the MIT open-source license and can be used commercially and for secondary development.\n\nAs demonstrated in our comprehensive evaluation across 12 industry-standard benchmarks, GLM-4.5 achieves exceptional performance with a score of **63.2**, in the **3rd** place among all the proprietary and open-source  models. Notably, GLM-4.5-Air delivers competitive results at **59.8** while maintaining superior efficiency.\n\n![bench](https://raw.githubusercontent.com/zai-org/GLM-4.5/refs/heads/main/resources/bench.png)\n\nFor more eval results, show cases, and technical details, please visit\nour [technical blog](https://z.ai/blog/glm-4.5) or [technical report](https://huggingface.co/papers/2508.06471).\n\nThe model code, tool parser and reasoning parser can be found in the implementation of [transformers](https://github.com/huggingface/transformers/tree/main/src/transformers/models/glm4_moe), [vLLM](https://github.com/vllm-project/vllm/blob/main/vllm/model_executor/models/glm4_moe_mtp.py) and [SGLang](https://github.com/sgl-project/sglang/blob/main/python/sglang/srt/models/glm4_moe.py).\n\n## Quick Start\n\nPlease refer our [github page](https://github.com/zai-org/GLM-4.5) for more detail.",
      "public": true,
      "version": "7a18bd00-fe93-5799-921b-e9c1b08d07ec",
      "tool_description": null,
      "slug": "chutes-zai-org-glm-4-5-air",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-07-28T14:43:02.919379Z",
      "updated_at": "2025-10-13T08:43:47.490279Z",
      "image": {
        "image_id": "761d22a2-c96c-5675-82df-60cddab0827e",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101200",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-12T08:53:29.416285Z",
        "build_started_at": "2025-10-12T08:53:31.172351Z",
        "build_completed_at": "2025-10-12T09:17:36.083052Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "initial",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "a100",
        "h20",
        "a6000_ada",
        "a100_40gb",
        "h100",
        "h100_sxm",
        "a100_40gb_sxm",
        "h800",
        "a100_sxm",
        "l40s"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h100",
          "h100_sxm",
          "h800",
          "l40s",
          "a6000_ada",
          "a100",
          "a100_sxm",
          "a100_40gb",
          "a100_40gb_sxm",
          "h20"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 1.06666666666667,
        "supported_gpus": [
          "a100",
          "h20",
          "a6000_ada",
          "a100_40gb",
          "h100",
          "h100_sxm",
          "a100_40gb_sxm",
          "h800",
          "a100_sxm",
          "l40s"
        ]
      },
      "invocation_count": 324760,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0,
            "tao": 0
          },
          "output": {
            "usd": 0,
            "tao": 0
          }
        },
        "usd": {
          "hour": 0,
          "second": 0
        },
        "tao": {
          "hour": 0,
          "second": 0
        }
      },
      "instances": [
        {
          "instance_id": "ba809c27-bb6a-4d48-9c70-87ceb531e32b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:44:30.977234Z"
        },
        {
          "instance_id": "1f802ad8-ad07-4605-8e0e-f5460c642bbe",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:14:14.627957Z"
        },
        {
          "instance_id": "2e7298e4-4f87-4715-aaea-2922522e331d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:44:30.977234Z"
        },
        {
          "instance_id": "3534cfa1-4e4a-41a5-9514-21fc70f7b904",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:44:30.977234Z"
        },
        {
          "instance_id": "ae81a018-9ab6-4446-b23d-6075e1be0d1c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:44:30.977234Z"
        },
        {
          "instance_id": "b969fc04-685e-4198-bde7-08a8e56a403e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:44:30.977234Z"
        },
        {
          "instance_id": "44379f45-449e-4c9e-b433-b4812905b9af",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:44:30.977234Z"
        },
        {
          "instance_id": "f18b2c43-d07d-4976-86cd-c384e51eb96d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:44:30.977234Z"
        },
        {
          "instance_id": "3e16845d-f7dd-4f63-b742-82cdf0654525",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:12:57.598860Z"
        },
        {
          "instance_id": "e4fbcd7a-1c8a-4613-80df-a121110efdea",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:44:30.977234Z"
        },
        {
          "instance_id": "3bae5344-14d9-40ff-af7f-f944ba683c1d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:44:30.977234Z"
        },
        {
          "instance_id": "d29517d3-2416-4141-abc6-47d47fc9875c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:44:30.977234Z"
        },
        {
          "instance_id": "7984ddc6-4146-4c20-a81e-4fbb4c6f083e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:44:30.977234Z"
        },
        {
          "instance_id": "fc2acf69-0cfa-4cb4-8ee6-a735dfd93f91",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:44:30.977234Z"
        },
        {
          "instance_id": "41e0a791-b626-4405-9868-7ee3bb1c1b26",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:44:30.977234Z"
        },
        {
          "instance_id": "ce36aa12-0ecd-4a80-91fa-81c107d1ac7a",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:44:30.977234Z"
        }
      ],
      "logo_id": "a4fdf19c-b675-49dc-b2f9-d12b926f8fda",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "e7fdb9e0a52d2e0aefea94f5867c924a32a78d17",
      "concurrency": 40,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/a4fdf19c-b675-49dc-b2f9-d12b926f8fda.webp",
      "hot": true
    },
    {
      "chute_id": "4d636d79-623c-5688-b57c-264f9e53d85d",
      "name": "unsloth/gemma-3-4b-it",
      "tagline": "Gemma 3 is a family of open-source multimodal language models (available in 1B, 4B, 12B, and 27B parameter sizes) that can process both text and images to generate text responses, making it useful for tasks like question answering, summarization, coding, and image analysis on consumer hardware.",
      "readme": "\n# Gemma 3 model card\n\n**Model Page**: [Gemma](https://ai.google.dev/gemma/docs/core)\n\n**Resources and Technical Documentation**:\n\n* [Gemma 3 Technical Report][g3-tech-report]\n* [Responsible Generative AI Toolkit][rai-toolkit]\n* [Gemma on Kaggle][kaggle-gemma]\n* [Gemma on Vertex Model Garden][vertex-mg-gemma3]\n\n**Terms of Use**: [Terms][terms]\n\n**Authors**: Google DeepMind\n\n## Model Information\n\nSummary description and brief definition of inputs and outputs.\n\n### Description\n\nGemma is a family of lightweight, state-of-the-art open models from Google,\nbuilt from the same research and technology used to create the Gemini models.\nGemma 3 models are multimodal, handling text and image input and generating text\noutput, with open weights for both pre-trained variants and instruction-tuned\nvariants. Gemma 3 has a large, 128K context window, multilingual support in over\n140 languages, and is available in more sizes than previous versions. Gemma 3\nmodels are well-suited for a variety of text generation and image understanding\ntasks, including question answering, summarization, and reasoning. Their\nrelatively small size makes it possible to deploy them in environments with\nlimited resources such as laptops, desktops or your own cloud infrastructure,\ndemocratizing access to state of the art AI models and helping foster innovation\nfor everyone.\n\n### Inputs and outputs\n\n-   **Input:**\n    -  Text string, such as a question, a prompt, or a document to be summarized\n    -  Images, normalized to 896 x 896 resolution and encoded to 256 tokens\n       each\n    -  Total input context of 128K tokens for the 4B, 12B, and 27B sizes, and\n       32K tokens for the 1B size\n\n-   **Output:**\n    -   Generated text in response to the input, such as an answer to a\n        question, analysis of image content, or a summary of a document\n    -   Total output context of 8192 tokens\n\n### Usage\n\nBelow, there are some code snippets on how to get quickly started with running the model. First, install the Transformers library. Gemma 3 is supported starting from transformers 4.50.0. \n\n```sh\n$ pip install -U transformers\n```\n\nThen, copy the snippet from the section that is relevant for your use case.\n\n#### Running with the `pipeline` API\n\nYou can initialize the model and processor for inference with `pipeline` as follows.\n\n```python\nfrom transformers import pipeline\nimport torch\n\npipe = pipeline(\n    \"image-text-to-text\",\n    model=\"google/gemma-3-4b-it\",\n    device=\"cuda\",\n    torch_dtype=torch.bfloat16\n)\n```\n\nWith instruction-tuned models, you need to use chat templates to process our inputs first. Then, you can pass it to the pipeline.\n\n```python\nmessages = [\n    {\n        \"role\": \"system\",\n        \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}]\n    },\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\", \"url\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/p-blog/candy.JPG\"},\n            {\"type\": \"text\", \"text\": \"What animal is on the candy?\"}\n        ]\n    }\n]\n\noutput = pipe(text=messages, max_new_tokens=200)\nprint(output[0][\"generated_text\"][-1][\"content\"])\n# Okay, let's take a look! \n# Based on the image, the animal on the candy is a **turtle**. \n# You can see the shell shape and the head and legs.\n```\n\n#### Running the model on a single/multi GPU\n\n```python\n# pip install accelerate\n\nfrom transformers import AutoProcessor, Gemma3ForConditionalGeneration\nfrom PIL import Image\nimport requests\nimport torch\n\nmodel_id = \"google/gemma-3-4b-it\"\n\nmodel = Gemma3ForConditionalGeneration.from_pretrained(\n    model_id, device_map=\"auto\"\n).eval()\n\nprocessor = AutoProcessor.from_pretrained(model_id)\n\nmessages = [\n    {\n        \"role\": \"system\",\n        \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}]\n    },\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\", \"image\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg\"},\n            {\"type\": \"text\", \"text\": \"Describe this image in detail.\"}\n        ]\n    }\n]\n\ninputs = processor.apply_chat_template(\n    messages, add_generation_prompt=True, tokenize=True,\n    return_dict=True, return_tensors=\"pt\"\n).to(model.device, dtype=torch.bfloat16)\n\ninput_len = inputs[\"input_ids\"].shape[-1]\n\nwith torch.inference_mode():\n    generation = model.generate(**inputs, max_new_tokens=100, do_sample=False)\n    generation = generation[0][input_len:]\n\ndecoded = processor.decode(generation, skip_special_tokens=True)\nprint(decoded)\n\n# **Overall Impression:** The image is a close-up shot of a vibrant garden scene, \n# focusing on a cluster of pink cosmos flowers and a busy bumblebee. \n# It has a slightly soft, natural feel, likely captured in daylight.\n```\n\n\n### Citation\n\n```none\n@article{gemma_2025,\n    title={Gemma 3},\n    url={https://goo.gle/Gemma3Report},\n    publisher={Kaggle},\n    author={Gemma Team},\n    year={2025}\n}\n```\n\n## Model Data\n\nData used for model training and how the data was processed.\n\n### Training Dataset\n\nThese models were trained on a dataset of text data that includes a wide variety\nof sources. The 27B model was trained with 14 trillion tokens, the 12B model was\ntrained with 12 trillion tokens, 4B model was trained with 4 trillion tokens and\n1B with 2 trillion tokens. Here are the key components:\n\n-   Web Documents: A diverse collection of web text ensures the model is\n    exposed to a broad range of linguistic styles, topics, and vocabulary. The\n    training dataset includes content in over 140 languages.\n-   Code: Exposing the model to code helps it to learn the syntax and\n    patterns of programming languages, which improves its ability to generate\n    code and understand code-related questions.\n-   Mathematics: Training on mathematical text helps the model learn logical\n    reasoning, symbolic representation, and to address mathematical queries.\n-   Images: A wide range of images enables the model to perform image\n    analysis and visual data extraction tasks.\n\nThe combination of these diverse data sources is crucial for training a powerful\nmultimodal model that can handle a wide variety of different tasks and data\nformats.\n\n### Data Preprocessing\n\nHere are the key data cleaning and filtering methods applied to the training\ndata:\n\n-   CSAM Filtering: Rigorous CSAM (Child Sexual Abuse Material) filtering\n    was applied at multiple stages in the data preparation process to ensure\n    the exclusion of harmful and illegal content.\n-   Sensitive Data Filtering: As part of making Gemma pre-trained models\n    safe and reliable, automated techniques were used to filter out certain\n    personal information and other sensitive data from training sets.\n-   Additional methods: Filtering based on content quality and safety in\n    line with [our policies][safety-policies].\n\n## Implementation Information\n\nDetails about the model internals.\n\n### Hardware\n\nGemma was trained using [Tensor Processing Unit (TPU)][tpu] hardware (TPUv4p,\nTPUv5p and TPUv5e). Training vision-language models (VLMS) requires significant\ncomputational power. TPUs, designed specifically for matrix operations common in\nmachine learning, offer several advantages in this domain:\n\n-   Performance: TPUs are specifically designed to handle the massive\n    computations involved in training VLMs. They can speed up training\n    considerably compared to CPUs.\n-   Memory: TPUs often come with large amounts of high-bandwidth memory,\n    allowing for the handling of large models and batch sizes during training.\n    This can lead to better model quality.\n-   Scalability: TPU Pods (large clusters of TPUs) provide a scalable\n    solution for handling the growing complexity of large foundation models.\n    You can distribute training across multiple TPU devices for faster and more\n    efficient processing.\n-   Cost-effectiveness: In many scenarios, TPUs can provide a more\n    cost-effective solution for training large models compared to CPU-based\n    infrastructure, especially when considering the time and resources saved\n    due to faster training.\n-   These advantages are aligned with\n    [Google's commitments to operate sustainably][sustainability].\n\n### Software\n\nTraining was done using [JAX][jax] and [ML Pathways][ml-pathways].\n\nJAX allows researchers to take advantage of the latest generation of hardware,\nincluding TPUs, for faster and more efficient training of large models. ML\nPathways is Google's latest effort to build artificially intelligent systems\ncapable of generalizing across multiple tasks. This is specially suitable for\nfoundation models, including large language models like these ones.\n\nTogether, JAX and ML Pathways are used as described in the\n[paper about the Gemini family of models][gemini-2-paper]; *\"the 'single\ncontroller' programming model of Jax and Pathways allows a single Python\nprocess to orchestrate the entire training run, dramatically simplifying the\ndevelopment workflow.\"*\n\n## Evaluation\n\nModel evaluation metrics and results.\n\n### Benchmark Results\n\nThese models were evaluated against a large collection of different datasets and\nmetrics to cover different aspects of text generation:\n\n#### Reasoning and factuality\n\n| Benchmark                      | Metric         | Gemma 3 PT 1B  | Gemma 3 PT 4B | Gemma 3 PT 12B | Gemma 3 PT 27B |\n| ------------------------------ |----------------|:--------------:|:-------------:|:--------------:|:--------------:|\n| [HellaSwag][hellaswag]         | 10-shot        |      62.3      |      77.2     |      84.2      |      85.6      |\n| [BoolQ][boolq]                 | 0-shot         |      63.2      |      72.3     |      78.8      |      82.4      |\n| [PIQA][piqa]                   | 0-shot         |      73.8      |      79.6     |      81.8      |      83.3      |\n| [SocialIQA][socialiqa]         | 0-shot         |      48.9      |      51.9     |      53.4      |      54.9      |\n| [TriviaQA][triviaqa]           | 5-shot         |      39.8      |      65.8     |      78.2      |      85.5      |\n| [Natural Questions][naturalq]  | 5-shot         |      9.48      |      20.0     |      31.4      |      36.1      |\n| [ARC-c][arc]                   | 25-shot        |      38.4      |      56.2     |      68.9      |      70.6      |\n| [ARC-e][arc]                   | 0-shot         |      73.0      |      82.4     |      88.3      |      89.0      |\n| [WinoGrande][winogrande]       | 5-shot         |      58.2      |      64.7     |      74.3      |      78.8      |\n| [BIG-Bench Hard][bbh]          | few-shot       |      28.4      |      50.9     |      72.6      |      77.7      |\n| [DROP][drop]                   | 1-shot         |      42.4      |      60.1     |      72.2      |      77.2      |\n\n[hellaswag]: https://arxiv.org/abs/1905.07830\n[boolq]: https://arxiv.org/abs/1905.10044\n[piqa]: https://arxiv.org/abs/1911.11641\n[socialiqa]: https://arxiv.org/abs/1904.09728\n[triviaqa]: https://arxiv.org/abs/1705.03551\n[naturalq]: https://github.com/google-research-datasets/natural-questions\n[arc]: https://arxiv.org/abs/1911.01547\n[winogrande]: https://arxiv.org/abs/1907.10641\n[bbh]: https://paperswithcode.com/dataset/bbh\n[drop]: https://arxiv.org/abs/1903.00161\n\n#### STEM and code\n\n| Benchmark                      | Metric         | Gemma 3 PT 4B | Gemma 3 PT 12B | Gemma 3 PT 27B |\n| ------------------------------ |----------------|:-------------:|:--------------:|:--------------:|\n| [MMLU][mmlu]                   | 5-shot         |      59.6     |      74.5      |      78.6      |\n| [MMLU][mmlu] (Pro COT)         | 5-shot         |      29.2     |      45.3      |      52.2      |\n| [AGIEval][agieval]             | 3-5-shot       |      42.1     |      57.4      |      66.2      |\n| [MATH][math]                   | 4-shot         |      24.2     |      43.3      |      50.0      |\n| [GSM8K][gsm8k]                 | 8-shot         |      38.4     |      71.0      |      82.6      |\n| [GPQA][gpqa]                   | 5-shot         |      15.0     |      25.4      |      24.3      |\n| [MBPP][mbpp]                   | 3-shot         |      46.0     |      60.4      |      65.6      |\n| [HumanEval][humaneval]         | 0-shot         |      36.0     |      45.7      |      48.8      |\n\n[mmlu]: https://arxiv.org/abs/2009.03300\n[agieval]: https://arxiv.org/abs/2304.06364\n[math]: https://arxiv.org/abs/2103.03874\n[gsm8k]: https://arxiv.org/abs/2110.14168\n[gpqa]: https://arxiv.org/abs/2311.12022\n[mbpp]: https://arxiv.org/abs/2108.07732\n[humaneval]: https://arxiv.org/abs/2107.03374\n\n#### Multilingual\n\n| Benchmark                            | Gemma 3 PT 1B | Gemma 3 PT 4B | Gemma 3 PT 12B | Gemma 3 PT 27B |\n| ------------------------------------ |:-------------:|:-------------:|:--------------:|:--------------:|\n| [MGSM][mgsm]                         |      2.04     |      34.7     |      64.3     |      74.3     |\n| [Global-MMLU-Lite][global-mmlu-lite] |      24.9     |      57.0     |      69.4     |      75.7     |\n| [WMT24++][wmt24pp] (ChrF)            |      36.7     |      48.4     |      53.9     |      55.7     |\n| [FloRes][flores]                     |      29.5     |      39.2     |      46.0     |      48.8     |\n| [XQuAD][xquad] (all)                 |      43.9     |      68.0     |      74.5     |      76.8     |\n| [ECLeKTic][eclektic]                 |      4.69     |      11.0     |      17.2     |      24.4     |\n| [IndicGenBench][indicgenbench]       |      41.4     |      57.2     |      61.7     |      63.4     |\n\n[mgsm]: https://arxiv.org/abs/2210.03057\n[flores]: https://arxiv.org/abs/2106.03193\n[xquad]: https://arxiv.org/abs/1910.11856v3\n[global-mmlu-lite]: https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite\n[wmt24pp]: https://arxiv.org/abs/2502.12404v1\n[eclektic]: https://arxiv.org/abs/2502.21228\n[indicgenbench]: https://arxiv.org/abs/2404.16816\n\n#### Multimodal\n\n| Benchmark                      | Gemma 3 PT 4B | Gemma 3 PT 12B | Gemma 3 PT 27B |\n| ------------------------------ |:-------------:|:--------------:|:--------------:|\n| [COCOcap][coco-cap]            |      102      |      111       |      116       |\n| [DocVQA][docvqa] (val)         |      72.8     |      82.3      |      85.6      |\n| [InfoVQA][info-vqa] (val)      |      44.1     |      54.8      |      59.4      |\n| [MMMU][mmmu] (pt)              |      39.2     |      50.3      |      56.1      |\n| [TextVQA][textvqa] (val)       |      58.9     |      66.5      |      68.6      |\n| [RealWorldQA][realworldqa]     |      45.5     |      52.2      |      53.9      |\n| [ReMI][remi]                   |      27.3     |      38.5      |      44.8      |\n| [AI2D][ai2d]                   |      63.2     |      75.2      |      79.0      |\n| [ChartQA][chartqa]             |      63.6     |      74.7      |      76.3      |\n| [VQAv2][vqav2]                 |      63.9     |      71.2      |      72.9      |\n| [BLINK][blinkvqa]              |      38.0     |      35.9      |      39.6      |\n| [OKVQA][okvqa]                 |      51.0     |      58.7      |      60.2      |\n| [TallyQA][tallyqa]             |      42.5     |      51.8      |      54.3      |\n| [SpatialSense VQA][ss-vqa]     |      50.9     |      60.0      |      59.4      |\n| [CountBenchQA][countbenchqa]   |      26.1     |      17.8      |      68.0      |\n\n[coco-cap]: https://cocodataset.org/#home\n[docvqa]: https://www.docvqa.org/\n[info-vqa]: https://arxiv.org/abs/2104.12756\n[mmmu]: https://arxiv.org/abs/2311.16502\n[textvqa]: https://textvqa.org/\n[realworldqa]: https://paperswithcode.com/dataset/realworldqa\n[remi]: https://arxiv.org/html/2406.09175v1\n[ai2d]: https://allenai.org/data/diagrams\n[chartqa]: https://arxiv.org/abs/2203.10244\n[vqav2]: https://visualqa.org/index.html\n[blinkvqa]: https://arxiv.org/abs/2404.12390\n[okvqa]: https://okvqa.allenai.org/\n[tallyqa]: https://arxiv.org/abs/1810.12440\n[ss-vqa]: https://arxiv.org/abs/1908.02660\n[countbenchqa]: https://github.com/goo",
      "public": true,
      "version": "dda6fcd5-1b53-5233-9f11-0342ea79400e",
      "tool_description": null,
      "slug": "chutes-unsloth-gemma-3-4b-it",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-08-03T09:48:10.424606Z",
      "updated_at": "2025-10-09T19:42:35.135257Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "pro_6000",
        "a6000_ada",
        "h100",
        "h100_sxm",
        "h800",
        "l40s"
      ],
      "node_selector": {
        "exclude": null,
        "include": [
          "h100",
          "h100_sxm",
          "pro_6000",
          "h800",
          "h200",
          "l40s",
          "a6000_ada"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.166666666666667,
        "supported_gpus": [
          "h200",
          "pro_6000",
          "a6000_ada",
          "h100",
          "h100_sxm",
          "h800",
          "l40s"
        ]
      },
      "invocation_count": 302328,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0,
            "tao": 0
          },
          "output": {
            "usd": 0,
            "tao": 0
          }
        },
        "usd": {
          "hour": 0,
          "second": 0
        },
        "tao": {
          "hour": 0,
          "second": 0
        }
      },
      "instances": [
        {
          "instance_id": "2909c653-0807-496f-937a-073c7a8e35d0",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:14:54.694414Z"
        },
        {
          "instance_id": "e6eca144-c4f4-4d15-9f78-e2db5d938ab9",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:14:54.694414Z"
        },
        {
          "instance_id": "eb3136da-efcf-4795-815f-ba522a8545bb",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:14:54.694414Z"
        },
        {
          "instance_id": "fcd4aacf-cd9c-4bd7-98c3-0e834da09d85",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:14:54.694414Z"
        },
        {
          "instance_id": "ff53c656-1c61-4fba-a13c-6ce02b7e0809",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:14:54.694414Z"
        }
      ],
      "logo_id": "219809f8-cd3a-42d5-b3be-5631da3a866a",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "90fe72f525abc73ff7283c23e6ceccea5d4273bb",
      "concurrency": 32,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/219809f8-cd3a-42d5-b3be-5631da3a866a.webp",
      "hot": true
    },
    {
      "chute_id": "4bbc44e9-6bfc-5e21-a91d-129bff2fb6d4",
      "name": "deepseek-ai/DeepSeek-V3.1-Terminus",
      "tagline": "DeepSeek-V3.1-Terminus is an updated version of DeepSeek's open source language model that excels at reasoning, coding, and agent-based tasks while offering improved language consistency and tool-use capabilities.",
      "readme": "# DeepSeek-V3.1-Terminus\n\n\u003C!-- markdownlint-disable first-line-h1 --\u003E\n\u003C!-- markdownlint-disable html --\u003E\n\u003C!-- markdownlint-disable no-duplicate-header --\u003E\n\n\u003Cdiv align=\"center\"\u003E\n  \u003Cimg src=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/logo.svg?raw=true\" width=\"60%\" alt=\"DeepSeek-V3\" /\u003E\n\u003C/div\u003E\n\u003Chr\u003E\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\n  \u003Ca href=\"https://www.deepseek.com/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Homepage\" src=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/badge.svg?raw=true\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://chat.deepseek.com/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/ğŸ¤–%20Chat-DeepSeek%20V3-536af5?color=536af5&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://huggingface.co/deepseek-ai\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Hugging Face\" src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\n  \u003Ca href=\"https://discord.gg/Tc7c45Zzu5\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Discord\" src=\"https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&logoColor=white&color=7289da\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/qr.jpeg?raw=true\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Wechat\" src=\"https://img.shields.io/badge/WeChat-DeepSeek%20AI-brightgreen?logo=wechat&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://twitter.com/deepseek_ai\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Twitter Follow\" src=\"https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\n  \u003Ca href=\"LICENSE\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"License\" src=\"https://img.shields.io/badge/License-MIT-f5de53?&color=f5de53\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\n## Introduction\n\nThis update maintains the model's original capabilities while addressing issues reported by users, including:\n\n- Language consistency: Reducing instances of mixed Chinese-English text and occasional abnormal characters;\n- Agent capabilities: Further optimizing the performance of the Code Agent and Search Agent.\n\n| Benchmark | DeepSeek-V3.1 | DeepSeek-V3.1-Terminus |\n| :--- | :---: | :---: |\n| **Reasoning Mode w/o Tool Use** | | |\n| MMLU-Pro | 84.8 | 85.0 |\n| GPQA-Diamond | 80.1 | 80.7 |\n| Humanity's Last Exam | 15.9 | 21.7 |\n| LiveCodeBench | 74.8 | 74.9 |\n| Codeforces | 2091 | 2046 |\n| Aider-Polyglot | 76.3 | 76.1 |\n| **Agentic Tool Use** | | |\n| BrowseComp | 30.0 | 38.5 |\n| BrowseComp-zh | 49.2 | 45.0 |\n| SimpleQA | 93.4 | 96.8 |\n| SWE Verified | 66.0 | 68.4 |\n| SWE-bench Multilingual | 54.5 | 57.8 |\n| Terminal-bench | 31.3 | 36.7 |\n\n**The template and tool-set of search agent have been updated, which is shown in `assets/search_tool_trajectory.html`.**\n\n## How to Run Locally\n\nThe model structure of DeepSeek-V3.1-Terminus is the same as DeepSeek-V3. Please visit [DeepSeek-V3](https://github.com/deepseek-ai/DeepSeek-V3) repo for more information about running this model locally.\n\nFor the model's chat template other than search agent, please refer to the [DeepSeek-V3.1](https://huggingface.co/deepseek-ai/DeepSeek-V3.1) repo.\n\n**Here we also provide an updated inference demo code in the `inference` folder to help the community get started with running our model and understand the details of model architecture.**\n\n**NOTE: In the current model checkpoint, the parameters of `self_attn.o_proj` do not conform to the UE8M0 FP8 scale data format. This is a known issue and will be corrected in future model releases.**\n\n## License\n\nThis repository and the model weights are licensed under the [MIT License](https://huggingface.co/deepseek-ai/DeepSeek-V3.1-Terminus/raw/main/LICENSE).\n\n## Citation\n\n```\n@misc{deepseekai2024deepseekv3technicalreport,\n      title={DeepSeek-V3 Technical Report}, \n      author={DeepSeek-AI},\n      year={2024},\n      eprint={2412.19437},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2412.19437}, \n}\n```\n\n## Contact\n\nIf you have any questions, please raise an issue or contact us at [service@deepseek.com](https://huggingface.co/deepseek-ai/DeepSeek-V3.1-Terminus/raw/main/service@deepseek.com).\n",
      "public": true,
      "version": "73d32e95-1d45-5ba9-9a48-0c590943de2d",
      "tool_description": null,
      "slug": "chutes-deepseek-ai-deepseek-v3-1-terminus",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-09-22T16:28:32.548502Z",
      "updated_at": "2025-10-14T10:02:20.803286Z",
      "image": {
        "image_id": "1f7f2f45-9b11-594f-897c-d05c4f1727b6",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101300",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-13T17:42:41.772428Z",
        "build_started_at": "2025-10-13T17:42:45.733512Z",
        "build_completed_at": "2025-10-13T18:17:43.202213Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "initial",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 302123,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.23,
            "tao": 0.000571209879646078
          },
          "output": {
            "usd": 0.9,
            "tao": 0.00223516909426726
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "fef306ba-4817-4431-a203-2b90f73a00ba",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T11:06:04.930987Z"
        },
        {
          "instance_id": "4ec4be86-70af-48d2-99cd-d4273ef8b3f6",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:16:06.268030Z"
        },
        {
          "instance_id": "5a8c5d0d-fda8-46c6-8eed-b4155caab575",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:16:06.268030Z"
        },
        {
          "instance_id": "6de3e000-b41d-4b90-93b8-fe0bf8d5f20a",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:16:06.268030Z"
        },
        {
          "instance_id": "832bc8c2-dc46-4cfd-8c65-423f3cd2cca5",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:16:06.268030Z"
        },
        {
          "instance_id": "a37477db-fcae-4f6f-999c-88384c878170",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:16:06.268030Z"
        },
        {
          "instance_id": "e3193fc6-6709-4ff7-9121-93711290775e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:16:06.268030Z"
        },
        {
          "instance_id": "de5ea779-2b10-47ad-91b3-97bba0e2ef04",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:16:06.268030Z"
        },
        {
          "instance_id": "bf4a88eb-d972-42d7-b737-ed3eecd23f84",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:16:06.268030Z"
        },
        {
          "instance_id": "0231ecab-019d-4f06-8e22-066548a8e325",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:16:06.268030Z"
        },
        {
          "instance_id": "bfd9bdc7-375a-48a7-aadd-932b5708ddfc",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:16:06.268030Z"
        },
        {
          "instance_id": "ac870353-e97a-4462-bf19-f97d571fbc45",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:16:06.268030Z"
        },
        {
          "instance_id": "010b07f6-97fe-4b74-9e90-e695b4caf0db",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:16:06.268030Z"
        }
      ],
      "logo_id": "d9986dd2-872a-4ab9-aef7-76fdd5123e3f",
      "openrouter": false,
      "chutes_version": "0.3.39.rc0",
      "revision": "407a1291c8e08fcb9dfd5715639c4b4487a5f079",
      "concurrency": 40,
      "boost": 1.5,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/d9986dd2-872a-4ab9-aef7-76fdd5123e3f.webp",
      "hot": true
    },
    {
      "chute_id": "1aec6931-3bb8-5f5e-a61c-b112276ed140",
      "name": "zai-org/GLM-4.6-FP8",
      "tagline": "GLM-4.6 is a large language model optimized for code generation, reasoning, and agent tasks with a 200K token context window, though parameter count is not disclosed in the model card.",
      "readme": "\n# GLM-4.6-FP8\n\n\u003Cdiv align=\"center\"\u003E\n\u003Cimg src=https://raw.githubusercontent.com/zai-org/GLM-4.5/refs/heads/main/resources/logo.svg width=\"15%\"/\u003E\n\u003C/div\u003E\n\u003Cp align=\"center\"\u003E\n    ğŸ‘‹ Join our \u003Ca href=\"https://discord.gg/QR7SARHRxK\" target=\"_blank\"\u003EDiscord\u003C/a\u003E community.\n    \u003Cbr\u003E\n    ğŸ“– Check out the GLM-4.6 \u003Ca href=\"https://z.ai/blog/glm-4.6\" target=\"_blank\"\u003Etechnical blog\u003C/a\u003E, \u003Ca href=\"https://arxiv.org/abs/2508.06471\" target=\"_blank\"\u003Etechnical report(GLM-4.5)\u003C/a\u003E, and \u003Ca href=\"https://zhipu-ai.feishu.cn/wiki/Gv3swM0Yci7w7Zke9E0crhU7n7D\" target=\"_blank\"\u003EZhipu AI technical documentation\u003C/a\u003E.\n    \u003Cbr\u003E\n    ğŸ“ Use GLM-4.6 API services on \u003Ca href=\"https://docs.z.ai/guides/llm/glm-4.6\"\u003EZ.ai API Platform. \u003C/a\u003E\n    \u003Cbr\u003E\n    ğŸ‘‰ One click to \u003Ca href=\"https://chat.z.ai\"\u003EGLM-4.6\u003C/a\u003E.\n\u003C/p\u003E\n\n## Model Introduction\n\nCompared with GLM-4.5, **GLM-4.6**  brings several key improvements:\n\n* **Longer context window:** The context window has been expanded from 128K to 200K tokens, enabling the model to handle more complex agentic tasks.\n* **Superior coding performance:** The model achieves higher scores on code benchmarks and demonstrates better real-world performance in applications such as Claude Codeã€Clineã€Roo Code and Kilo Code, including improvements in generating visually polished front-end pages.\n* **Advanced reasoning:** GLM-4.6 shows a clear improvement in reasoning performance and supports tool use during inference, leading to stronger overall capability.\n* **More capable agents:** GLM-4.6 exhibits stronger performance in tool using and search-based agents, and integrates more effectively within agent frameworks.\n* **Refined writing:** Better aligns with human preferences in style and readability, and performs more naturally in role-playing scenarios.\n\nWe evaluated GLM-4.6 across eight public benchmarks covering agents, reasoning, and coding. Results show clear gains over GLM-4.5, with GLM-4.6 also holding competitive advantages over leading domestic and international models such as **DeepSeek-V3.1-Terminus** and **Claude Sonnet 4**.\n\n![bench](https://raw.githubusercontent.com/zai-org/GLM-4.5/refs/heads/main/resources/bench_glm46.png)\n\n## Inference\n\n**Both GLM-4.5 and GLM-4.6 use the same inference method.**\n\nyou can check our [github](https://github.com/zai-org/GLM-4.5) for more detail.\n\n## Recommended Evaluation Parameters\n\nFor general evaluations, we recommend using a **sampling temperature of 1.0**.\n\nFor **code-related evaluation tasks** (such as LCB), it is further recommended to set:\n\n- `top_p = 0.95`\n- `top_k = 40`\n\n## Evaluation\n\n- For tool-integrated reasoning, please refer to [this doc](https://github.com/zai-org/GLM-4.5/blob/main/resources/glm_4.6_tir_guide.md).\n- For search benchmark, we design a specific format for searching toolcall in thinking mode to support search agent, please refer to [this](https://github.com/zai-org/GLM-4.5/blob/main/resources/trajectory_search.json). for the detailed template.\n",
      "public": true,
      "version": "c1a55276-1779-59a6-a2fe-43045d7c2fc3",
      "tool_description": null,
      "slug": "chutes-zai-org-glm-4-6-fp8",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-09-30T21:18:43.251434Z",
      "updated_at": "2025-10-13T08:43:19.273559Z",
      "image": {
        "image_id": "761d22a2-c96c-5675-82df-60cddab0827e",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101200",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-12T08:53:29.416285Z",
        "build_started_at": "2025-10-12T08:53:31.172351Z",
        "build_completed_at": "2025-10-12T09:17:36.083052Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "initial",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 285034,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.5,
            "tao": 0.00124176060792626
          },
          "output": {
            "usd": 1.75,
            "tao": 0.0043461621277419
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "b6fc1aac-0d75-41d6-ad33-5d709a5fbfd0",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T10:30:26.408654Z"
        },
        {
          "instance_id": "88fc5153-afbb-4f5c-b354-4fa7bc9ba5a1",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:55:25.649635Z"
        },
        {
          "instance_id": "4070e3b2-2b4e-4777-8a76-a385faada347",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T10:40:36.731772Z"
        },
        {
          "instance_id": "aa195a06-4b62-41c2-bc03-312a4d7f6a87",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:40:40.196665Z"
        },
        {
          "instance_id": "0464c4ab-03b3-4abc-a9da-e0172a045e6d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:44:27.733154Z"
        },
        {
          "instance_id": "14a6521b-6bfe-4a13-9c1d-d3f945970f24",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:03:16.313323Z"
        },
        {
          "instance_id": "46a3a030-4fd9-4c1d-b04b-75d26709b025",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:03:16.313323Z"
        },
        {
          "instance_id": "5ff67b19-743d-4d1d-b8a4-fdb07412edfe",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:03:16.313323Z"
        },
        {
          "instance_id": "62c7921f-9dcc-4569-83b7-4fef4ae7e448",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:03:16.313323Z"
        },
        {
          "instance_id": "6c7e25e0-91f1-43dd-aca9-4264abd31b8e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:03:16.313323Z"
        },
        {
          "instance_id": "6e812daf-2ad8-410c-adf3-ea39203a4b81",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:03:16.313323Z"
        },
        {
          "instance_id": "7fdd2259-a786-4362-9775-ee1f2f7a5215",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:03:16.313323Z"
        },
        {
          "instance_id": "81f7d469-b8f4-4830-bfe9-3ce38c25ab06",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:03:16.313323Z"
        },
        {
          "instance_id": "85f7a88f-c4f2-482a-8ff7-6999e34e6f7b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:03:16.313323Z"
        },
        {
          "instance_id": "8a3c403e-482c-4856-9e35-68419b6c2689",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:03:16.313323Z"
        },
        {
          "instance_id": "8b534f71-497d-40e7-8396-24005731893d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:03:16.313323Z"
        },
        {
          "instance_id": "9ebda388-5220-4cc7-9f16-84e09fe75707",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:03:16.313323Z"
        },
        {
          "instance_id": "ea209af2-3303-4510-818c-b0d528add9fa",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:03:16.313323Z"
        },
        {
          "instance_id": "effc883e-da52-4c25-be03-0f6727b23591",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:03:16.313323Z"
        },
        {
          "instance_id": "9c9dc6b3-0036-4d8d-95b9-8f597312110b",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T11:07:05.310888Z"
        },
        {
          "instance_id": "57a57442-6f87-4507-ada8-beae6f5ae49f",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:45:36.610207Z"
        },
        {
          "instance_id": "7c7f0bfe-461c-4923-8846-10ca548b9900",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T11:08:47.369511Z"
        },
        {
          "instance_id": "c385571e-a279-497f-81eb-1224c62c3255",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:03:16.313323Z"
        },
        {
          "instance_id": "f145da18-bf9b-43a2-a83c-40d77aff57ec",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:52:31.674208Z"
        },
        {
          "instance_id": "b5c683a9-8817-4166-b02b-2baff5d4fc41",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:51:59.039023Z"
        },
        {
          "instance_id": "5d3ef460-23b4-4c08-a0c8-bb56889aefc3",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:03:16.313323Z"
        },
        {
          "instance_id": "234d7d69-385f-45c5-98fd-5abfa460d03b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:03:16.313323Z"
        }
      ],
      "logo_id": "b372ff4b-5003-4079-9e0e-5457c2f70da4",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "dd30e1e9e5a3ac9bd16164f969b6f066c652a7e1",
      "concurrency": 32,
      "boost": 2,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/b372ff4b-5003-4079-9e0e-5457c2f70da4.webp",
      "hot": true
    },
    {
      "chute_id": "0591bb2d-4282-5c83-8b03-3c089b5f0a39",
      "name": "NousResearch/Hermes-4-14B",
      "tagline": "Hermes 4 14B is a reasoning-focused open source language model built on Qwen 3 that excels at math, code, and STEM tasks while being highly steerable and aligned to user preferences.",
      "readme": "\n# Hermes 4 â€” Qwen 3 14B\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/7B7nMvHJiL72QzVBEPKOG.png)\n\n## Model Description\n\nHermes 4 14B is a frontier, hybrid-mode **reasoning** model based on Qwen 3 14B by Nous Research that is aligned to **you**.\n\nRead the Hermes 4 technical report here: \u003Ca href=\"https://arxiv.org/abs/2508.18255\"\u003EHermes 4 Technical Report\u003C/a\u003E\n\nChat with Hermes in Nous Chat: https://chat.nousresearch.com\n\nTraining highlights include a newly synthesized post-training corpus emphasizing verified reasoning traces, massive improvements in math, code, STEM, logic, creativity, and format-faithful outputs, while preserving general assistant quality and broadly neutral alignment.\n\n\n## Whatâ€™s new vs Hermes 3\n\n- **Post-training corpus**: Massively increased dataset size from 1M samples and 1.2B tokens to **~5M samples / ~60B tokens** blended across reasoning and non-reasoning data.\n- **Hybrid reasoning mode** with explicit `\u003Cthink\u003Eâ€¦\u003C/think\u003E` segments when the model decides to deliberate, and options to make your responses faster when you want.\n- **Reasoning** that is top quality, expressive, improves math, code, STEM, logic, and even creative writing and subjective responses.\n- **Schema adherence & structured outputs**: trained to produce valid JSON for given schemas and to repair malformed objects.\n- **Much easier to steer and align**: extreme improvements on steerability, especially on reduced refusal rates.\n\n## Our Mission: Frontier Capabilities Aligned to You\n\nIn pursuit of the mission of producing models that are open, steerable and capable of producing the full range of human expression, while being able to be aligned to your values, we created a new benchmark, RefusalBench, that tests the models willingness to be helpful in a variety of scenarios commonly disallowed by closed and open models.\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/t_HvRYPEHV0pc8iS2zHHn.png)\n\nHermes 4 achieves SOTA on RefusalBench across all popular closed and open models in being helpful and conforming to your values, without censorship.\n\n## Benchmarks (Hermes 4 14B)\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/uzbo2sGy_3PkVMJLDlPwV.png)\n\n\u003E Full tables, settings, and comparisons are in the technical report.\n\n## Prompt Format\n\nHermes 4 uses ChatML format with role headers and special tags.\n\n**Basic chat:**\n```\n\u003C|im_start|\u003Esystem\n\nYou are Hermes 4. Be concise and helpful.\u003C|im_end|\u003E\n\u003C|im_start|\u003Euser\n\nExplain the photoelectric effect simply.\u003C|im_end|\u003E\n\u003C|im_start|\u003Eassistant\n```\n\n### Reasoning mode\n\nReasoning mode can be activated with the chat template via the flag `thinking=True` or by using the following system prompt:\n\n```\nYou are a deep thinking AI, you may use extremely long chains of thought to deeply consider the problem and deliberate with yourself via systematic reasoning processes to help come to a correct solution prior to answering. You should enclose your thoughts and internal monologue inside \u003Cthink\u003E \u003C/think\u003E tags, and then provide your solution or response to the problem.\n```\n\nNote that you can add any additional system instructions before or after this system message, and it will adjust the models policies, style, and effort of thinking, as well as its post-thinking style, format, identity, and more. You may also interleave the tool definition system message with the reasoning one. \n\nWhen the model chooses to deliberate, it emits:\n\n```\n\u003C|im_start|\u003Eassistant\n\u003Cthink\u003E\nâ€¦modelâ€™s internal reasoning may appear hereâ€¦\n\u003C/think\u003E\nFinal response starts hereâ€¦\u003C|im_end|\u003E\n```\n\nAdditionally, we provide a flag to keep the content inbetween the `\u003Cthink\u003E ... \u003C/think\u003E` that you can play with by setting `keep_cots=True`\n\n\n## Function Calling & Tool Use\n\nHermes 4 supports function/tool calls *within* a single assistant turn, produced after it's reasoning:\n\n**System message (example):**\n\n```\n\u003C|im_start|\u003Esystem\nYou are a function-calling AI. Tools are provided inside \u003Ctools\u003Eâ€¦\u003C/tools\u003E.\nWhen appropriate, call a tool by emitting a \u003Ctool_call\u003E{...}\u003C/tool_call\u003E object.\nAfter a tool responds (as \u003Ctool_response\u003E), continue reasoning inside \u003Cthink\u003E and produce the final answer.\n\u003Ctools\u003E\n{\"type\":\"function\",\"function\":{\"name\":\"get_weather\",\"description\":\"Get weather by city\",\"parameters\":{\"type\":\"object\",\"properties\":{\"city\":{\"type\":\"string\"}},\"required\":[\"city\"]}}}\n\u003C/tools\u003E\u003C|im_end|\u003E\n```\n\nNote that you may also simply place tool definitions into the \"tools:\" field of your messages, and the chat template will parse and create the system prompt for you. This also works with reasoning mode for improved accuracy of tool use.\n\nThe model will then generate tool calls within `\u003Ctool_call\u003E {tool_call} \u003C/tool_call\u003E` tags, for easy parsing. The tool_call tags are also added tokens, so it makes it easy to parse while streaming! There are also automatic tool parsers built-in to VLLM and SGLang for Hermes, just set the tool parser in VLLM to `hermes` and in SGLang to `qwen25`.\n\n## Inference Notes\n\n- **Sampling defaults that work well:** `temperature=0.6, top_p=0.95, top_k=20`.\n- **Template:** Use the ChatML chat format for Hermes 4 14B as shown above, or set `add_generation_prompt=True` when using `tokenizer.apply_chat_template(...)`.\n\n### Transformers example\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\nmodel_id = \"NousResearch/Hermes-4-14B\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)\n\nmessages = [\n    {\"role\":\"system\",\"content\":\"You are Hermes 4. Be concise.\"},\n    {\"role\":\"user\",\"content\":\"Summarize CRISPR in 3 sentences.\"}\n]\n\ninputs = tokenizer.apply_chat_template(\n    messages, add_generation_prompt=True, return_tensors=\"pt\"\n).to(model.device)\n\noutputs = model.generate(\n    **inputs, max_new_tokens=400, temperature=0.6, top_p=0.95, top_k=20, do_sample=True\n)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))\n```\n\nFor production serving on multi-GPU nodes, consider tensor parallel inference engines (e.g., SGLang/vLLM backends) with prefix caching.\n\n## Inference Providers:\n\n### Nous Portal:\n\n\u003Ca href=\"https://portal.nousresearch.com\"\u003E\u003Cimg width=256 alt=\"chutes logo\" src=\"https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/6YytY7N0mjCnBQvWo3qtv.png\"\u003E\u003C/a\u003E\n\n### Chutes:\n\n\u003Ca href=\"https://chutes.ai/app\"\u003E\u003Cimg width=256 alt=\"chutes logo\" src=\"https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/l14AWPv6cSvaprpwK_IWY.png\"\u003E\u003C/a\u003E\n\n### Nebius:\n\n\u003Ca href=\"https://nebius.com/services/studio-inference-service\"\u003E\n\u003Cpicture\u003E\n  \u003Csource media=\"(prefers-color-scheme: dark)\" srcset=\"https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/vhL0oAomFa_awBdt2KF_x.png\"\u003E\n  \u003Csource media=\"(prefers-color-scheme: light)\" srcset=\"https://cdn-uploads.huggingface.co/production/uploads/64b21cbb2fc8324fcb1dac03/LjAfeFfAz8ac5rV-iiwj5.png\"\u003E\n  \u003Cimg width=256 alt=\"nebius.com logo\" src=\"https://cdn-uploads.huggingface.co/production/uploads/64b21cbb2fc8324fcb1dac03/LjAfeFfAz8ac5rV-iiwj5.png\"\u003E\n\u003C/picture\u003E\n\u003C/a\u003E\n\n### Luminal:\n\n\u003Ca href=\"https://luminalai.com/\"\u003E\n\u003Cimg width=256 alt=\"luminal logo\" src=\"https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/FIHsRdjMMP0HUjebiuJyH.png\"\u003E\n\u003C/a\u003E\n\n# Quantized / Smaller Variants\n\nHermes 4 is available as BF16 original weights as well as BF16 as well as FP8 variants and GGUF variants by LM Studio.\n\nFP8: https://huggingface.co/NousResearch/Hermes-4-14B-FP8\n\nGGUF (Courtesy of LM Studio team!):\n\nHermes 4 is also available in larger sizes (e.g., 70B, 405B) with similar prompt formats.\n\nSee the Hermes 4 collection to explore them all:\nhttps://huggingface.co/collections/NousResearch/hermes-4-collection-68a731bfd452e20816725728\n\n# How to cite\n\n```bibtex\n@misc{teknium2025hermes4technicalreport,\n      title={Hermes 4 Technical Report}, \n      author={Ryan Teknium and Roger Jin and Jai Suphavadeeprasit and Dakota Mahan and Jeffrey Quesnelle and Joe Li and Chen Guang and Shannon Sands and Karan Malhotra},\n      year={2025},\n      eprint={2508.18255},\n      archivePrefix={arXiv},\n      primaryClass={cs.AI},\n      url={https://arxiv.org/abs/2508.18255}, \n}\n```",
      "public": true,
      "version": "23836eda-cf79-53c8-bcea-071be29e6026",
      "tool_description": null,
      "slug": "chutes-nousresearch-hermes-4-14b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-09-03T12:56:26.187798Z",
      "updated_at": "2025-10-13T08:50:05.550675Z",
      "image": {
        "image_id": "761d22a2-c96c-5675-82df-60cddab0827e",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101200",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-12T08:53:29.416285Z",
        "build_started_at": "2025-10-12T08:53:31.172351Z",
        "build_completed_at": "2025-10-12T09:17:36.083052Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "initial",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "exclude": [
          "h200",
          "b200",
          "mi300x"
        ],
        "include": null,
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.444444444444444,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 260882,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          },
          "output": {
            "usd": 0.11,
            "tao": 0.000273187333743776
          }
        },
        "usd": {
          "hour": 2,
          "second": 0.000555555555555555
        },
        "tao": {
          "hour": 0.00496704243170503,
          "second": 0.000001379734008806
        }
      },
      "instances": [
        {
          "instance_id": "f4426735-2a2a-48e7-aac5-8d422f616390",
          "region": "n/a",
          "active": false,
          "verified": false,
          "last_verified_at": null
        },
        {
          "instance_id": "77fd42d6-ba15-4701-a63f-6a610e1d3d2b",
          "region": "n/a",
          "active": false,
          "verified": false,
          "last_verified_at": null
        },
        {
          "instance_id": "07bb67d4-9d2d-4a21-a5e6-5cf3ba6464fb",
          "region": "n/a",
          "active": false,
          "verified": false,
          "last_verified_at": null
        },
        {
          "instance_id": "dc3294f0-e382-4d80-b622-8921c1f0f60c",
          "region": "n/a",
          "active": false,
          "verified": false,
          "last_verified_at": null
        },
        {
          "instance_id": "1cd3453c-029f-4d33-9586-c8554f05e4b7",
          "region": "n/a",
          "active": false,
          "verified": false,
          "last_verified_at": null
        },
        {
          "instance_id": "e7935bda-fb96-45f7-86bc-ee01fadf1920",
          "region": "n/a",
          "active": false,
          "verified": false,
          "last_verified_at": null
        },
        {
          "instance_id": "abe2cab3-660b-422f-b489-677691db99e2",
          "region": "n/a",
          "active": false,
          "verified": false,
          "last_verified_at": null
        },
        {
          "instance_id": "87a9628c-7c6b-483c-9d3d-0f35e6132efc",
          "region": "n/a",
          "active": false,
          "verified": false,
          "last_verified_at": null
        },
        {
          "instance_id": "12b92056-3598-490e-b9b3-cbc7cd9f3428",
          "region": "n/a",
          "active": false,
          "verified": false,
          "last_verified_at": null
        },
        {
          "instance_id": "f89e1b4d-3c0f-4d79-b6bf-e378b38df55f",
          "region": "n/a",
          "active": false,
          "verified": false,
          "last_verified_at": null
        },
        {
          "instance_id": "c6dc323a-1a86-4194-832c-1b6d4b5c974c",
          "region": "n/a",
          "active": false,
          "verified": false,
          "last_verified_at": null
        },
        {
          "instance_id": "4519ea2c-a044-43b8-b052-dc75e228f9dd",
          "region": "n/a",
          "active": false,
          "verified": false,
          "last_verified_at": null
        },
        {
          "instance_id": "10c8dde9-e9e6-493c-af0f-c63ce6d06aae",
          "region": "n/a",
          "active": false,
          "verified": false,
          "last_verified_at": null
        },
        {
          "instance_id": "072f59bc-7d1f-46e5-bd6a-a9d381d8986e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:42:14.248631Z"
        },
        {
          "instance_id": "c3c9bb4d-2158-436b-8291-5efeb6919a0e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:42:14.248631Z"
        },
        {
          "instance_id": "7e1720e5-4100-4ff2-8afc-792678956277",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:42:14.248631Z"
        },
        {
          "instance_id": "2befd576-3dc3-46be-9d04-dce2b93dc83f",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:42:14.248631Z"
        },
        {
          "instance_id": "f7983408-bb9c-48b2-8386-d1b6ad41e5e2",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:42:14.248631Z"
        }
      ],
      "logo_id": "f3704dbc-870f-4711-8b1d-f9fa091bc0f0",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "1aa1b96970a0e80181b61722b3a4b09b0b243e93",
      "concurrency": 24,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/f3704dbc-870f-4711-8b1d-f9fa091bc0f0.webp",
      "hot": true
    },
    {
      "chute_id": "83ce50c4-6d3f-55a6-88a6-c5db187f2c70",
      "name": "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
      "tagline": "Qwen3-Coder-480B-A35B-Instruct is a 480B parameter (with 35B activated) language model optimized for coding tasks and tool use, featuring 256K context length and competitive performance comparable to Claude Sonnet for code generation and browser-based interactions.",
      "readme": "\n# Qwen3-Coder-480B-A35B-Instruct-FP8\n\u003Ca href=\"https://chat.qwen.ai/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/%F0%9F%92%9C%EF%B8%8F%20Qwen%20Chat%20-536af5\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n\u003C/a\u003E\n\n## Highlights\n\nToday, we're announcing **Qwen3-Coder**, our most agentic code model to date. **Qwen3-Coder** is available in multiple sizes, but we're excited to introduce its most powerful variant first: **Qwen3-Coder-480B-A35B-Instruct**. featuring the following key enhancements:  \n\n- **Significant Performance** among open models on **Agentic Coding**, **Agentic Browser-Use**, and other foundational coding tasks, achieving results comparable to Claude Sonnet.\n- **Long-context Capabilities** with native support for **256K** tokens, extendable up to **1M** tokens using Yarn, optimized for repository-scale understanding.\n- **Agentic Coding** supporting for most platform such as **Qwen Code**, **CLINE**, featuring a specially designed function call format.\n\n![image/jpeg](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/qwen3-coder-main.jpg)\n\n## Model Overview\n\n**Qwen3-480B-A35B-Instruct** has the following features:\n- Type: Causal Language Models\n- Training Stage: Pretraining & Post-training\n- Number of Parameters: 480B in total and 35B activated\n- Number of Layers: 62\n- Number of Attention Heads (GQA): 96 for Q and 8 for KV\n- Number of Experts: 160\n- Number of Activated Experts: 8\n- Context Length: **262,144 natively**. \n\n**NOTE: This model supports only non-thinking mode and does not generate ``\u003Cthink\u003E\u003C/think\u003E`` blocks in its output. Meanwhile, specifying `enable_thinking=False` is no longer required.**\n\nFor more details, including benchmark evaluation, hardware requirements, and inference performance, please refer to our [blog](https://qwenlm.github.io/blog/qwen3-coder/), [GitHub](https://github.com/QwenLM/Qwen3-Coder), and [Documentation](https://qwen.readthedocs.io/en/latest/).\n\n\n## Quickstart\n\nWe advise you to use the latest version of `transformers`.\n\nWith `transformers\u003C4.51.0`, you will encounter the following error:\n```\nKeyError: 'qwen3_moe'\n```\n\nThe following contains a code snippet illustrating how to use the model generate content based on given inputs. \n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"Qwen/Qwen3-480B-A35B-Instruct\"\n\n# load the tokenizer and the model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=\"auto\",\n    device_map=\"auto\"\n)\n\n# prepare the model input\nprompt = \"Write a quick sort algorithm.\"\nmessages = [\n    {\"role\": \"user\", \"content\": prompt}\n]\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\n# conduct text completion\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=65536\n)\noutput_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n\ncontent = tokenizer.decode(output_ids, skip_special_tokens=True)\n\nprint(\"content:\", content)\n```\n\n**Note: If you encounter out-of-memory (OOM) issues, consider reducing the context length to a shorter value, such as `32,768`.**\n\n\n## Note on FP8\n\nFor convenience and performance, we have provided `fp8`-quantized model checkpoint for Qwen3, whose name ends with `-FP8`. The quantization method is fine-grained `fp8` quantization with block size of 128. You can find more details in the `quantization_config` field in `config.json`.\n\nYou can use the Qwen3-480B-A35B-Instruct-FP8 model with serveral inference frameworks, including `transformers`, `sglang`, and `vllm`, as the original bfloat16 model.\nHowever, please pay attention to the following known issues:\n- `transformers`:\n    - there are currently issues with the \"fine-grained fp8\" method in `transformers` for distributed inference. You may need to set the environment variable `CUDA_LAUNCH_BLOCKING=1` if multiple devices are used in inference.\n\n\n## Agentic Coding\n\nQwen3-Coder excels in tool calling capabilities. \n\nYou can simply define or use any tools as following example.\n```python\n# Your tool implementation\ndef square_the_number(num: float) -\u003E dict:\n    return num ** 2\n\n# Define Tools\ntools=[\n    {\n        \"type\":\"function\",\n        \"function\":{\n            \"name\": \"square_the_number\",\n            \"description\": \"output the square of the number.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"required\": [\"input_num\"],\n                \"properties\": {\n                    'input_num': {\n                        'type': 'number', \n                        'description': 'input_num is a number that will be squared'\n                        }\n                },\n            }\n        }\n    }\n]\n\nimport OpenAI\n# Define LLM\nclient = OpenAI(\n    # Use a custom endpoint compatible with OpenAI API\n    base_url='http://localhost:8000/v1',  # api_base\n    api_key=\"EMPTY\"\n)\n \nmessages = [{'role': 'user', 'content': 'square the number 1024'}]\n\ncompletion = client.chat.completions.create(\n    messages=messages,\n    model=\"Qwen3-Coder-480B-A35B-Instruct\",\n    max_tokens=65536,\n    tools=tools,\n)\n\nprint(completion.choice[0])\n```\n\n## Best Practices\n\nTo achieve optimal performance, we recommend the following settings:\n\n1. **Sampling Parameters**:\n   - We suggest using `temperature=0.7`, `top_p=0.8`, `top_k=20`, `repetition_penalty=1.05`.\n\n2. **Adequate Output Length**: We recommend using an output length of 65,536 tokens for most queries, which is adequate for instruct models.\n\n\n### Citation\n\nIf you find our work helpful, feel free to give us a cite.\n\n```\n@misc{qwen3technicalreport,\n      title={Qwen3 Technical Report}, \n      author={Qwen Team},\n      year={2025},\n      eprint={2505.09388},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2505.09388}, \n}\n```",
      "public": true,
      "version": "852c2d59-3c7d-5922-8b5a-b074d2d96022",
      "tool_description": null,
      "slug": "chutes-qwen-qwen3-coder-480b-a35b-instruct-fp8",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-07-23T17:53:40.124314Z",
      "updated_at": "2025-10-13T08:48:47.030706Z",
      "image": {
        "image_id": "761d22a2-c96c-5675-82df-60cddab0827e",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101200",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-12T08:53:29.416285Z",
        "build_started_at": "2025-10-12T08:53:31.172351Z",
        "build_completed_at": "2025-10-12T09:17:36.083052Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "initial",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 245204,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.22,
            "tao": 0.000546374667487553
          },
          "output": {
            "usd": 0.95,
            "tao": 0.00235934515505989
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "945a12ed-320d-43a1-b0de-d6340bcb395c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:46:37.125727Z"
        },
        {
          "instance_id": "28e7cd40-acfc-499d-b5c0-3fe7abde46ba",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:46:37.125727Z"
        },
        {
          "instance_id": "151a0690-5287-43e4-b144-42bf4183cf5b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:46:37.125727Z"
        },
        {
          "instance_id": "d5a33c0c-7cec-42cf-9ca4-32c00e7ad282",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:46:37.125727Z"
        },
        {
          "instance_id": "650b24fd-46a6-4cbc-bf52-c76bd7b98c04",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:46:37.125727Z"
        },
        {
          "instance_id": "f9319dad-9d92-475f-9dae-cb41abf2fb06",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:46:37.125727Z"
        },
        {
          "instance_id": "9a2e742a-5288-4174-b510-3d30e7c2f8a0",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:46:37.125727Z"
        },
        {
          "instance_id": "f813e9e4-a5a9-4219-b4f2-6281195cbb55",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:46:37.125727Z"
        },
        {
          "instance_id": "2b93711c-2991-445b-875e-d0a88d251944",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:46:37.125727Z"
        },
        {
          "instance_id": "69ea8992-3b7d-460e-9831-a557abb2332b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:46:37.125727Z"
        },
        {
          "instance_id": "73ea9457-b146-4c33-a73f-9e5d460b35db",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:46:37.125727Z"
        },
        {
          "instance_id": "8882bfa9-e60c-41a9-8143-7a0c8983cb56",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:46:37.125727Z"
        },
        {
          "instance_id": "1932b489-c538-4263-a4cb-75a739c03c8c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:46:37.125727Z"
        }
      ],
      "logo_id": "5eaccb08-8724-4975-add9-a8f329873eb3",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "12ec19e6655df1e2f7e3cc068ce32e4318d21544",
      "concurrency": 48,
      "boost": 1.5,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/5eaccb08-8724-4975-add9-a8f329873eb3.webp",
      "hot": true
    },
    {
      "chute_id": "07cb1b3a-ec4d-594a-96c2-b547fddcadb0",
      "name": "deepseek-ai/DeepSeek-V3.1",
      "tagline": "",
      "readme": "deepseek-ai/DeepSeek-V3.1",
      "public": true,
      "version": "2ec1b5d4-fdb0-54a5-ba29-8fa22cc00fef",
      "tool_description": null,
      "slug": "chutes-deepseek-ai-deepseek-v3-1",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "b9784def-b796-57d7-888e-8fef54b2207e",
      "created_at": "2025-08-21T10:21:12.774094Z",
      "updated_at": "2025-10-20T16:30:29.380486Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 211338,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.2,
            "tao": 0.000496704243170502
          },
          "output": {
            "usd": 0.8,
            "tao": 0.00198681697268201
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "540460fb-3f62-436a-8e04-132cbabe5955",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:44:42.173775Z"
        },
        {
          "instance_id": "57ab8edd-8310-4bd4-9ff4-7ee2ec87bd5a",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:44:42.173775Z"
        },
        {
          "instance_id": "8b05e5c8-03ac-4c55-958d-647047db01b4",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:44:42.173775Z"
        },
        {
          "instance_id": "8b2be0fb-0461-4624-a14b-0df4ce34eb7a",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:44:42.173775Z"
        },
        {
          "instance_id": "b5128995-8390-49e4-aad2-1e12db05e5b4",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:44:42.173775Z"
        },
        {
          "instance_id": "c740cf30-ee7b-4eba-a2ed-890c3cbade29",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:44:42.173775Z"
        },
        {
          "instance_id": "a8d19c9a-d42d-4c99-bab7-2e9f73e11989",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:44:42.173775Z"
        },
        {
          "instance_id": "f1127e11-3095-44a1-926e-7f7fc8594ea7",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:44:42.173775Z"
        },
        {
          "instance_id": "64fa1ab4-55ff-4622-82ab-c0d6316534d4",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:53:13.764773Z"
        },
        {
          "instance_id": "b67a9794-884c-46c1-908d-85b7a845d645",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:54:31.712677Z"
        },
        {
          "instance_id": "86008c1e-2961-4768-a523-a33cedd50939",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:03:04.720353Z"
        },
        {
          "instance_id": "ee61f8be-3d0a-4798-9f17-4e6bd8ada797",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:44:42.173775Z"
        },
        {
          "instance_id": "3b0839d1-7649-4518-8677-b1968c68f149",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:02:00.804428Z"
        },
        {
          "instance_id": "92e87840-3a30-4c3d-9dd9-bd89cbb144cc",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:44:42.173775Z"
        },
        {
          "instance_id": "de520ee2-5995-4ff2-8938-1eac07bec66d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:44:42.173775Z"
        },
        {
          "instance_id": "7c15280b-be46-4335-9208-fe551b4e4426",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:44:42.173775Z"
        }
      ],
      "logo_id": "05a15e68-a2cb-463f-92ed-809655be5853",
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "9e6c48c3fa6bb3e1cf684675dc02e813ca45d20f",
      "concurrency": 40,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/05a15e68-a2cb-463f-92ed-809655be5853.webp",
      "hot": true
    },
    {
      "chute_id": "d0cbdf3d-050a-5432-97d2-ea99277d7934",
      "name": "Qwen/Qwen3-14B",
      "tagline": "Qwen3-14B is a 14.8 billion parameter open source language model that can switch between reasoning and conversational modes, making it versatile for tasks ranging from complex math and coding to creative writing and multilingual chat.",
      "readme": "\n# Qwen3-14B\n\u003Ca href=\"https://chat.qwen.ai/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/%F0%9F%92%9C%EF%B8%8F%20Qwen%20Chat%20-536af5\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n\u003C/a\u003E\n\n## Qwen3 Highlights\n\nQwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support, with the following key features:\n\n- **Uniquely support of seamless switching between thinking mode** (for complex logical reasoning, math, and coding) and **non-thinking mode** (for efficient, general-purpose dialogue) **within single model**, ensuring optimal performance across various scenarios.\n- **Significantly enhancement in its reasoning capabilities**, surpassing previous QwQ (in thinking mode) and Qwen2.5 instruct models (in non-thinking mode) on mathematics, code generation, and commonsense logical reasoning.\n- **Superior human preference alignment**, excelling in creative writing, role-playing, multi-turn dialogues, and instruction following, to deliver a more natural, engaging, and immersive conversational experience.\n- **Expertise in agent capabilities**, enabling precise integration with external tools in both thinking and unthinking modes and achieving leading performance among open-source models in complex agent-based tasks.\n- **Support of 100+ languages and dialects** with strong capabilities for **multilingual instruction following** and **translation**.\n\n## Model Overview\n\n**Qwen3-14B** has the following features:\n- Type: Causal Language Models\n- Training Stage: Pretraining & Post-training\n- Number of Parameters: 14.8B\n- Number of Paramaters (Non-Embedding): 13.2B\n- Number of Layers: 40\n- Number of Attention Heads (GQA): 40 for Q and 8 for KV\n- Context Length: 32,768 natively and [131,072 tokens with YaRN](https://huggingface.co/Qwen/Qwen3-14B/raw/main/#processing-long-texts). \n\nFor more details, including benchmark evaluation, hardware requirements, and inference performance, please refer to our [blog](https://qwenlm.github.io/blog/qwen3/), [GitHub](https://github.com/QwenLM/Qwen3), and [Documentation](https://qwen.readthedocs.io/en/latest/).\n\n## Quickstart\n\nThe code of Qwen3 has been in the latest Hugging Face `transformers` and we advise you to use the latest version of `transformers`.\n\nWith `transformers\u003C4.51.0`, you will encounter the following error:\n```\nKeyError: 'qwen3'\n```\n\nThe following contains a code snippet illustrating how to use the model generate content based on given inputs. \n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"Qwen/Qwen3-14B\"\n\n# load the tokenizer and the model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=\"auto\",\n    device_map=\"auto\"\n)\n\n# prepare the model input\nprompt = \"Give me a short introduction to large language model.\"\nmessages = [\n    {\"role\": \"user\", \"content\": prompt}\n]\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\n# conduct text completion\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=32768\n)\noutput_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n\n# parsing thinking content\ntry:\n    # rindex finding 151668 (\u003C/think\u003E)\n    index = len(output_ids) - output_ids[::-1].index(151668)\nexcept ValueError:\n    index = 0\n\nthinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\ncontent = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n\nprint(\"thinking content:\", thinking_content)\nprint(\"content:\", content)\n```\n\nFor deployment, you can use `sglang\u003E=0.4.6.post1` or `vllm\u003E=0.8.5` or to create an OpenAI-compatible API endpoint:\n- SGLang:\n    ```shell\n    python -m sglang.launch_server --model-path Qwen/Qwen3-14B --reasoning-parser qwen3\n    ```\n- vLLM:\n    ```shell\n    vllm serve Qwen/Qwen3-14B --enable-reasoning --reasoning-parser deepseek_r1\n    ```\n\nFor local use, applications such as Ollama, LMStudio, MLX-LM, llama.cpp, and KTransformers have also supported Qwen3.\n\n## Switching Between Thinking and Non-Thinking Mode\n\n\u003E [!TIP]\n\u003E The `enable_thinking` switch is also available in APIs created by SGLang and vLLM. \n\u003E Please refer to our documentation for [SGLang](https://qwen.readthedocs.io/en/latest/deployment/sglang.html#thinking-non-thinking-modes) and [vLLM](https://qwen.readthedocs.io/en/latest/deployment/vllm.html#thinking-non-thinking-modes) users.\n\n### `enable_thinking=True`\n\nBy default, Qwen3 has thinking capabilities enabled, similar to QwQ-32B. This means the model will use its reasoning abilities to enhance the quality of generated responses. For example, when explicitly setting `enable_thinking=True` or leaving it as the default value in `tokenizer.apply_chat_template`, the model will engage its thinking mode.\n\n```python\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=True  # True is the default value for enable_thinking\n)\n```\n\nIn this mode, the model will generate think content wrapped in a `\u003Cthink\u003E...\u003C/think\u003E` block, followed by the final response.\n\n\u003E [!NOTE]\n\u003E For thinking mode, use `Temperature=0.6`, `TopP=0.95`, `TopK=20`, and `MinP=0` (the default setting in `generation_config.json`). **DO NOT use greedy decoding**, as it can lead to performance degradation and endless repetitions. For more detailed guidance, please refer to the [Best Practices](https://huggingface.co/Qwen/Qwen3-14B/raw/main/#best-practices) section.\n\n\n### `enable_thinking=False`\n\nWe provide a hard switch to strictly disable the model's thinking behavior, aligning its functionality with the previous Qwen2.5-Instruct models. This mode is particularly useful in scenarios where disabling thinking is essential for enhancing efficiency.\n\n```python\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=False  # Setting enable_thinking=False disables thinking mode\n)\n```\n\nIn this mode, the model will not generate any think content and will not include a `\u003Cthink\u003E...\u003C/think\u003E` block.\n\n\u003E [!NOTE]\n\u003E For non-thinking mode, we suggest using `Temperature=0.7`, `TopP=0.8`, `TopK=20`, and `MinP=0`. For more detailed guidance, please refer to the [Best Practices](https://huggingface.co/Qwen/Qwen3-14B/raw/main/#best-practices) section.\n\n### Advanced Usage: Switching Between Thinking and Non-Thinking Modes via User Input\n\nWe provide a soft switch mechanism that allows users to dynamically control the model's behavior when `enable_thinking=True`. Specifically, you can add `/think` and `/no_think` to user prompts or system messages to switch the model's thinking mode from turn to turn. The model will follow the most recent instruction in multi-turn conversations.\n\nHere is an example of a multi-turn conversation:\n\n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nclass QwenChatbot:\n    def __init__(self, model_name=\"Qwen/Qwen3-14B\"):\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n        self.history = []\n\n    def generate_response(self, user_input):\n        messages = self.history + [{\"role\": \"user\", \"content\": user_input}]\n\n        text = self.tokenizer.apply_chat_template(\n            messages,\n            tokenize=False,\n            add_generation_prompt=True\n        )\n\n        inputs = self.tokenizer(text, return_tensors=\"pt\")\n        response_ids = self.model.generate(**inputs, max_new_tokens=32768)[0][len(inputs.input_ids[0]):].tolist()\n        response = self.tokenizer.decode(response_ids, skip_special_tokens=True)\n\n        # Update history\n        self.history.append({\"role\": \"user\", \"content\": user_input})\n        self.history.append({\"role\": \"assistant\", \"content\": response})\n\n        return response\n\n# Example Usage\nif __name__ == \"__main__\":\n    chatbot = QwenChatbot()\n\n    # First input (without /think or /no_think tags, thinking mode is enabled by default)\n    user_input_1 = \"How many r's in strawberries?\"\n    print(f\"User: {user_input_1}\")\n    response_1 = chatbot.generate_response(user_input_1)\n    print(f\"Bot: {response_1}\")\n    print(\"----------------------\")\n\n    # Second input with /no_think\n    user_input_2 = \"Then, how many r's in blueberries? /no_think\"\n    print(f\"User: {user_input_2}\")\n    response_2 = chatbot.generate_response(user_input_2)\n    print(f\"Bot: {response_2}\") \n    print(\"----------------------\")\n\n    # Third input with /think\n    user_input_3 = \"Really? /think\"\n    print(f\"User: {user_input_3}\")\n    response_3 = chatbot.generate_response(user_input_3)\n    print(f\"Bot: {response_3}\")\n```\n\n\u003E [!NOTE]\n\u003E For API compatibility, when `enable_thinking=True`, regardless of whether the user uses `/think` or `/no_think`, the model will always output a block wrapped in `\u003Cthink\u003E...\u003C/think\u003E`. However, the content inside this block may be empty if thinking is disabled.\n\u003E When `enable_thinking=False`, the soft switches are not valid. Regardless of any `/think` or `/no_think` tags input by the user, the model will not generate think content and will not include a `\u003Cthink\u003E...\u003C/think\u003E` block.\n\n## Agentic Use\n\nQwen3 excels in tool calling capabilities. We recommend using [Qwen-Agent](https://github.com/QwenLM/Qwen-Agent) to make the best use of agentic ability of Qwen3. Qwen-Agent encapsulates tool-calling templates and tool-calling parsers internally, greatly reducing coding complexity.\n\nTo define the available tools, you can use the MCP configuration file, use the integrated tool of Qwen-Agent, or integrate other tools by yourself.\n```python\nfrom qwen_agent.agents import Assistant\n\n# Define LLM\nllm_cfg = {\n    'model': 'Qwen3-14B',\n\n    # Use the endpoint provided by Alibaba Model Studio:\n    # 'model_type': 'qwen_dashscope',\n    # 'api_key': os.getenv('DASHSCOPE_API_KEY'),\n\n    # Use a custom endpoint compatible with OpenAI API:\n    'model_server': 'http://localhost:8000/v1',  # api_base\n    'api_key': 'EMPTY',\n\n    # Other parameters:\n    # 'generate_cfg': {\n    #         # Add: When the response content is `\u003Cthink\u003Ethis is the thought\u003C/think\u003Ethis is the answer;\n    #         # Do not add: When the response has been separated by reasoning_content and content.\n    #         'thought_in_content': True,\n    #     },\n}\n\n# Define Tools\ntools = [\n    {'mcpServers': {  # You can specify the MCP configuration file\n            'time': {\n                'command': 'uvx',\n                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']\n            },\n            \"fetch\": {\n                \"command\": \"uvx\",\n                \"args\": [\"mcp-server-fetch\"]\n            }\n        }\n    },\n  'code_interpreter',  # Built-in tools\n]\n\n# Define Agent\nbot = Assistant(llm=llm_cfg, function_list=tools)\n\n# Streaming generation\nmessages = [{'role': 'user', 'content': 'https://qwenlm.github.io/blog/ Introduce the latest developments of Qwen'}]\nfor responses in bot.run(messages=messages):\n    pass\nprint(responses)\n```\n\n## Processing Long Texts\n\nQwen3 natively supports context lengths of up to 32,768 tokens. For conversations where the total length (including both input and output) significantly exceeds this limit, we recommend using RoPE scaling techniques to handle long texts effectively. We have validated the model's performance on context lengths of up to 131,072 tokens using the [YaRN](https://arxiv.org/abs/2309.00071) method.\n\nYaRN is currently supported by several inference frameworks, e.g., `transformers` and `llama.cpp` for local use, `vllm` and `sglang` for deployment. In general, there are two approaches to enabling YaRN for supported frameworks:\n\n- Modifying the model files:\n  In the `config.json` file, add the `rope_scaling` fields:\n    ```json\n    {\n        ...,\n        \"rope_scaling\": {\n            \"rope_type\": \"yarn\",\n            \"factor\": 4.0,\n            \"original_max_position_embeddings\": 32768\n        }\n    }\n    ```\n  For `llama.cpp`, you need to regenerate the GGUF file after the modification.\n\n- Passing command line arguments:\n\n  For `vllm`, you can use\n    ```shell\n    vllm serve ... --rope-scaling '{\"rope_type\":\"yarn\",\"factor\":4.0,\"original_max_position_embeddings\":32768}' --max-model-len 131072  \n    ```\n\n  For `sglang`, you can use\n    ```shell\n    python -m sglang.launch_server ... --json-model-override-args '{\"rope_scaling\":{\"rope_type\":\"yarn\",\"factor\":4.0,\"original_max_position_embeddings\":32768}}'\n    ```\n\n  For `llama-server` from `llama.cpp`, you can use\n    ```shell\n    llama-server ... --rope-scaling yarn --rope-scale 4 --yarn-orig-ctx 32768\n    ```\n\n\u003E [!IMPORTANT]\n\u003E If you encounter the following warning\n\u003E ```\n\u003E Unrecognized keys in `rope_scaling` for 'rope_type'='yarn': {'original_max_position_embeddings'}\n\u003E ```\n\u003E please upgrade `transformers\u003E=4.51.0`.\n\n\u003E [!NOTE]\n\u003E All the notable open-source frameworks implement static YaRN, which means the scaling factor remains constant regardless of input length, **potentially impacting performance on shorter texts.**\n\u003E We advise adding the `rope_scaling` configuration only when processing long contexts is required. \n\u003E It is also recommended to modify the `factor` as needed. For example, if the typical context length for your application is 65,536 tokens, it would be better to set `factor` as 2.0. \n\n\u003E [!NOTE]\n\u003E The default `max_position_embeddings` in `config.json` is set to 40,960. This allocation includes reserving 32,768 tokens for outputs and 8,192 tokens for typical prompts, which is sufficient for most scenarios involving short text processing. If the average context length does not exceed 32,768 tokens, we do not recommend enabling YaRN in this scenario, as it may potentially degrade model performance.\n\n\u003E [!TIP]\n\u003E The endpoint provided by Alibaba Model Studio supports dynamic YaRN by default and no extra configuration is needed.\n\n## Best Practices\n\nTo achieve optimal performance, we recommend the following settings:\n\n1. **Sampling Parameters**:\n   - For thinking mode (`enable_thinking=True`), use `Temperature=0.6`, `TopP=0.95`, `TopK=20`, and `MinP=0`. **DO NOT use greedy decoding**, as it can lead to performance degradation and endless repetitions.\n   - For non-thinking mode (`enable_thinking=False`), we suggest using `Temperature=0.7`, `TopP=0.8`, `TopK=20`, and `MinP=0`.\n   - For supported frameworks, you can adjust the `presence_penalty` parameter between 0 and 2 to reduce endless repetitions. However, using a higher value may occasionally result in language mixing and a slight decrease in model performance.\n\n2. **Adequate Output Length**: We recommend using an output length of 32,768 tokens for most queries. For benchmarking on highly complex problems, such as those found in math and programming competitions, we suggest setting the max output length to 38,912 tokens. This provides the model with sufficient space to generate detailed and comprehensive responses, thereby enhancing its overall performance.\n\n3. **Standardize Output Format**: We recommend using prompts to standardize model outputs when benchmarking.\n   - **Math Problems**: Include \"Please reason step by step, and put your final answer within \\boxed{}.\" in the prompt.\n   - **Multiple-Choice Questions**: Add the following JSON structure to the prompt to standardize responses: \"Please show your choice in the `answer` field with only the choice letter, e.g., `\"answer\": \"C\"`.\"\n\n4. **No Thinking Content in History**: In multi-turn conversations, the historical model output shoul",
      "public": true,
      "version": "614ea28a-7f0d-5de7-97fd-81a73284f1a1",
      "tool_description": null,
      "slug": "chutes-qwen-qwen3-14b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-04-28T22:22:06.798985Z",
      "updated_at": "2025-10-09T22:33:11.858237Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "5090",
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a100_40gb",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "exclude": [
          "b200",
          "mi300x"
        ],
        "include": null,
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 32,
        "compute_multiplier": 0.888888888888889,
        "supported_gpus": [
          "5090",
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a100_40gb",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 206391,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.05,
            "tao": 0.000124176060792625
          },
          "output": {
            "usd": 0.22,
            "tao": 0.000546374667487553
          }
        },
        "usd": {
          "hour": 4,
          "second": 0.00111111111111111
        },
        "tao": {
          "hour": 0.00993408486341006,
          "second": 0.000002759468017613
        }
      },
      "instances": [
        {
          "instance_id": "c336b554-c48d-473f-b984-e2ef931976fe",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:18:08.098342Z"
        },
        {
          "instance_id": "4d8895fe-1fee-4fe0-96ff-25bf4a431b71",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:16:02.013737Z"
        },
        {
          "instance_id": "3bc632c0-c358-4e11-ae88-867a0f32caf4",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:16:38.190752Z"
        },
        {
          "instance_id": "369a0f67-bf1a-45c7-ae35-0d0b951883a4",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:17:16.766860Z"
        },
        {
          "instance_id": "9ccd12c2-4f97-447b-91b1-ef03c531572c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:14:59.307930Z"
        },
        {
          "instance_id": "3f5d72b4-e787-4a0b-b231-fa1c89e4e5da",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:15:23.857204Z"
        },
        {
          "instance_id": "50fc3710-dc32-4dcd-ad87-4e380d857baf",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:15:01.790391Z"
        },
        {
          "instance_id": "7e3d1f1a-4127-48b5-a7a7-9fc51ac86a30",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:15:08.520343Z"
        },
        {
          "instance_id": "344632ab-9944-4bea-bc62-2dc4b710ce3f",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:14:52.156590Z"
        },
        {
          "instance_id": "4fb4486e-7f52-4f59-ad77-e2e579abe551",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:14:31.042974Z"
        },
        {
          "instance_id": "c28147b4-c43f-479a-b09b-41cddc16999d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:17:31.045041Z"
        },
        {
          "instance_id": "b3d28448-5ac8-4a34-98e5-57d16af5483c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:16:42.960656Z"
        },
        {
          "instance_id": "981ecf1c-cbf5-438e-8c36-329b80030633",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:17:34.984987Z"
        },
        {
          "instance_id": "c0ac4b7e-e8cf-4b88-b410-0a65e4856f4e",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T11:18:21.104186Z"
        }
      ],
      "logo_id": "6df74d27-1a19-4d0c-96a9-41d3cfba0ecd",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "3cd050e7238ebb5dca9beaf84d5eed6775180e21",
      "concurrency": 48,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/6df74d27-1a19-4d0c-96a9-41d3cfba0ecd.webp",
      "hot": true
    },
    {
      "chute_id": "b5326e54-8d9e-590e-bed4-f3db35d9d4cd",
      "name": "zai-org/GLM-4.5-FP8",
      "tagline": "GLM-4.5 is a 355B-parameter open-source MoE language model (with 32B active parameters) that excels at reasoning, coding, and agent-like tasks through its hybrid thinking/direct response modes.",
      "readme": "\n# GLM-4.5-FP8\n\n[ğŸ“š Paper](https://huggingface.co/papers/2508.06471) | [ğŸ’» Code](https://github.com/zai-org/GLM-4.5) | [ğŸŒ Project Page](https://z.ai/blog/glm-4.5)\n\n\u003Cdiv align=\"center\"\u003E\n\u003Cimg src=https://raw.githubusercontent.com/zai-org/GLM-4.5/refs/heads/main/resources/logo.svg width=\"15%\"/\u003E\n\u003C/div\u003E\n\u003Cp align=\"center\"\u003E\n    ğŸ‘‹ Join our \u003Ca href=\"https://discord.gg/QR7SARHRxK\" target=\"_blank\"\u003EDiscord\u003C/a\u003E community.\n    \u003Cbr\u003E\n    ğŸ“– Check out the GLM-4.5 \u003Ca href=\"https://z.ai/blog/glm-4.5\" target=\"_blank\"\u003Etechnical blog\u003C/a\u003E.\n    \u003Cbr\u003E\n    ğŸ“ Use GLM-4.5 API services on \u003Ca href=\"https://docs.z.ai/guides/llm/glm-4.5\"\u003EZ.ai API Platform (Global)\u003C/a\u003E or \u003Cbr\u003E \u003Ca href=\"https://docs.bigmodel.cn/cn/guide/models/text/glm-4.5\"\u003EZhipu AI Open Platform (Mainland China)\u003C/a\u003E.\n    \u003Cbr\u003E\n    ğŸ‘‰ One click to \u003Ca href=\"https://chat.z.ai\"\u003EGLM-4.5\u003C/a\u003E.\n\u003C/p\u003E\n  \n## Paper Abstract\n\nWe present GLM-4.5, an open-source Mixture-of-Experts (MoE) large language model with 355B total parameters and 32B activated parameters, featuring a hybrid reasoning method that supports both thinking and direct response modes. Through multi-stage training on 23T tokens and comprehensive post-training with expert model iteration and reinforcement learning, GLM-4.5 achieves strong performance across agentic, reasoning, and coding (ARC) tasks, scoring 70.1% on TAU-Bench, 91.0% on AIME 24, and 64.2% on SWE-bench Verified. With much fewer parameters than several competitors, GLM-4.5 ranks 3rd overall among all evaluated models and 2nd on agentic benchmarks. We release both GLM-4.5 (355B parameters) and a compact version, GLM-4.5-Air (106B parameters), to advance research in reasoning and agentic AI systems. Code, models, and more information are available at this https URL .\n\n## Model Introduction\n\nThe **GLM-4.5** series models are foundation models designed for intelligent agents. GLM-4.5 has **355** billion total parameters with **32** billion active parameters, while GLM-4.5-Air adopts a more compact design with **106** billion total parameters and **12** billion active parameters. GLM-4.5 models unify reasoning, coding, and intelligent agent capabilities to meet the complex demands of intelligent agent applications.\n\nBoth GLM-4.5 and GLM-4.5-Air are hybrid reasoning models that provide two modes: thinking mode for complex reasoning and tool usage, and non-thinking mode for immediate responses.\n\nWe have open-sourced the base models, hybrid reasoning models, and FP8 versions of the hybrid reasoning models for both GLM-4.5 and GLM-4.5-Air. They are released under the MIT open-source license and can be used commercially and for secondary development.\n\nAs demonstrated in our comprehensive evaluation across 12 industry-standard benchmarks, GLM-4.5 achieves exceptional performance with a score of **63.2**, in the **3rd** place among all the proprietary and open-source models. Notably, GLM-4.5-Air delivers competitive results at **59.8** while maintaining superior efficiency.\n\n![bench](https://raw.githubusercontent.com/zai-org/GLM-4.5/refs/heads/main/resources/bench.png)\n\nFor more eval results, show cases, and technical details, please visit our [technical blog](https://z.ai/blog/glm-4.5) or refer to the [technical report (paper)](https://huggingface.co/papers/2508.06471).\n\nThe model code, tool parser and reasoning parser can be found in the implementation of [transformers](https://github.com/huggingface/transformers/tree/main/src/transformers/models/glm4_moe), [vLLM](https://github.com/vllm-project/vllm/blob/main/vllm/model_executor/models/glm4_moe_mtp.py) and [SGLang](https://github.com/sgl-project/sglang/blob/main/python/sglang/srt/models/glm4_moe.py).\n\n## Model Downloads\n\nYou can directly experience the model on [Hugging Face](https://huggingface.co/spaces/zai-org/GLM-4.5-Space)\nor [ModelScope](https://modelscope.cn/studios/ZhipuAI/GLM-4.5-Demo) or download the model by following the links below.\n\n| Model            | Download Links                                                                                                                                | Model Size | Precision |\n|------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|------------|-----------|\n| GLM-4.5          | [ğŸ¤— Hugging Face](https://huggingface.co/zai-org/GLM-4.5)\u003Cbr\u003E [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5)                   | 355B-A32B  | BF16      |\n| GLM-4.5-Air      | [ğŸ¤— Hugging Face](https://huggingface.co/zai-org/GLM-4.5-Air)\u003Cbr\u003E [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5-Air)           | 106B-A12B  | BF16      |\n| GLM-4.5-FP8      | [ğŸ¤— Hugging Face](https://huggingface.co/zai-org/GLM-4.5-FP8)\u003Cbr\u003E [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5-FP8)           | 355B-A32B  | FP8       |\n| GLM-4.5-Air-FP8  | [ğŸ¤— Hugging Face](https://huggingface.co/zai-org/GLM-4.5-Air-FP8)\u003Cbr\u003E [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5-Air-FP8)   | 106B-A12B  | FP8       |\n| GLM-4.5-Base     | [ğŸ¤— Hugging Face](https://huggingface.co/zai-org/GLM-4.5-Base)\u003Cbr\u003E [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5-Base)         | 355B-A32B  | BF16      |\n| GLM-4.5-Air-Base | [ğŸ¤— Hugging Face](https://huggingface.co/zai-org/GLM-4.5-Air-Base)\u003Cbr\u003E [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5-Air-Base) | 106B-A12B  | BF16      |\n\n## System Requirements\n\n### Inference\n\nWe provide minimum and recommended configurations for \"full-featured\" model inference. The data in the table below is\nbased on the following conditions:\n\n1. All models use MTP layers and specify\n   `--speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-draft-tokens 4` to ensure competitive\n   inference speed.\n2. The `cpu-offload` parameter is not used.\n3. Inference batch size does not exceed `8`.\n4. All are executed on devices that natively support FP8 inference, ensuring both weights and cache are in FP8 format.\n5. Server memory must exceed `1T` to ensure normal model loading and operation.\n\nThe models can run under the configurations in the table below:\n\n| Model       | Precision | GPU Type and Count   | Test Framework |\n|-------------|-----------|----------------------|----------------|\n| GLM-4.5     | BF16      | H100 x 16 / H200 x 8 | sglang         |\n| GLM-4.5     | FP8       | H100 x 8 / H200 x 4  | sglang         |\n| GLM-4.5-Air | BF16      | H100 x 4 / H200 x 2  | sglang         |\n| GLM-4.5-Air | FP8       | H100 x 2 / H200 x 1  | sglang         |\n\nUnder the configurations in the table below, the models can utilize their full 128K context length:\n\n| Model       | Precision | GPU Type and Count    | Test Framework |\n|-------------|-----------|-----------------------|----------------|\n| GLM-4.5     | BF16      | H100 x 32 / H200 x 16 | sglang         |\n| GLM-4.5     | FP8       | H100 x 16 / H200 x 8  | sglang         |\n| GLM-4.5-Air | BF16      | H100 x 8 / H200 x 4   | sglang         |\n| GLM-4.5-Air | FP8       | H100 x 4 / H200 x 2   | sglang         |\\\n  \n### Fine-tuning\n\nThe code can run under the configurations in the table below\nusing [Llama Factory](https://github.com/hiyouga/LLaMA-Factory):\n\n| Model       | GPU Type and Count | Strategy | Batch Size (per GPU) |\n|-------------|--------------------|----------|----------------------|\n| GLM-4.5     | H100 x 16          | Lora     | 1                    |\n| GLM-4.5-Air | H100 x 4           | Lora     | 1                    |\n\nThe code can run under the configurations in the table below using [Swift](https://github.com/modelscope/ms-swift):\n\n| Model       | GPU Type and Count | Strategy | Batch Size (per GPU) |\n|-------------|--------------------|----------|----------------------|\n| GLM-4.5     | H20 (96GiB) x 16   | Lora     | 1                    |\n| GLM-4.5-Air | H20 (96GiB) x 4    | Lora     | 1                    |\n| GLM-4.5     | H20 (96GiB) x 128  | SFT      | 1                    |\n| GLM-4.5-Air | H20 (96GiB) x 32   | SFT      | 1                    |\n| GLM-4.5     | H20 (96GiB) x 128  | RL       | 1                    |\n| GLM-4.5-Air | H20 (96GiB) x 32   | RL       | 1                    |\n\n## Quick Start\n\nFor more comprehensive details and setup instructions, please refer to our [GitHub page](https://github.com/zai-org/GLM-4.5).\n\n### Transformers Inference\n\nHere is a basic example to run inference with the `transformers` library, demonstrating both thinking and non-thinking modes:\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\n# Load model and tokenizer\nmodel_id = \"zai-org/GLM-4.5-FP8\"\ntokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    torch_dtype=torch.bfloat16, # Adjust as needed (e.g., torch.float8 for FP8 models)\n    low_cpu_mem_usage=True,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\nmodel.eval()\n\nmessages = [\n    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n]\n\n# Example for non-thinking mode (direct response)\n# The `add_nothink_token=True` parameter triggers non-thinking mode.\n# This mode is suitable for straightforward questions not requiring complex reasoning or tool usage.\ninputs_nothink_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False, add_nothink_token=True)\ninput_ids_nothink = tokenizer(inputs_nothink_text, return_tensors=\"pt\").input_ids.to(model.device)\noutputs_nothink = model.generate(input_ids_nothink, max_new_tokens=100)\nprint(\"Non-thinking mode response:\", tokenizer.decode(outputs_nothink[0][len(input_ids_nothink[0]):], skip_special_tokens=True))\n\n# Example for thinking mode (for complex reasoning or tool usage)\n# By default, `add_nothink_token=False` or omitting it triggers thinking mode.\n# This mode allows the model to perform multi-step reasoning, break down tasks, and utilize tools.\ninputs_think_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False, add_nothink_token=False)\ninput_ids_think = tokenizer(inputs_think_text, return_tensors=\"pt\").input_ids.to(model.device)\noutputs_think = model.generate(input_ids_think, max_new_tokens=100)\nprint(\"Thinking mode response:\", tokenizer.decode(outputs_think[0][len(input_ids_think[0]):], skip_special_tokens=True))\n```\n\n### vLLM\n\n+ Both BF16 and FP8 can be started with the following code:\n\n```shell\nvllm serve zai-org/GLM-4.5-Air \\\n    --tensor-parallel-size 8 \\\n    --tool-call-parser glm45 \\\n    --reasoning-parser glm45 \\\n    --enable-auto-tool-choice \\\n    --served-model-name glm-4.5-air\n```\n\nIf you're using 8x H100 GPUs and encounter insufficient memory when running the GLM-4.5 model, you'll need\n`--cpu-offload-gb 16` (only applicable to vLLM).\n\nIf you encounter `flash infer` issues, use `VLLM_ATTENTION_BACKEND=XFORMERS` as a temporary replacement. You can also\nspecify `TORCH_CUDA_ARCH_LIST='9.0+PTX'` to use `flash infer` (different GPUs have different TORCH_CUDA_ARCH_LIST\nvalues, please check accordingly).\n\n### SGLang\n\n+ BF16\n\n```shell\npython3 -m sglang.launch_server \\\n  --model-path zai-org/GLM-4.5-Air \\\n  --tp-size 8 \\\n  --tool-call-parser glm45  \\\n  --reasoning-parser glm45 \\\n  --speculative-algorithm EAGLE \\\n  --speculative-num-steps 3 \\\n  --speculative-eagle-topk 1 \\\n  --speculative-num-draft-tokens 4 \\\n  --mem-fraction-static 0.7 \\\n  --served-model-name glm-4.5-air \\\n  --host 0.0.0.0 \\\n  --port 8000\n```\n\n+ FP8\n\n```shell\npython3 -m sglang.launch_server \\\n  --model-path zai-org/GLM-4.5-Air-FP8 \\\n  --tp-size 4 \\\n  --tool-call-parser glm45  \\\n  --reasoning-parser glm45  \\\n  --speculative-algorithm EAGLE \\\n  --speculative-num-steps 3  \\\n  --speculative-eagle-topk 1  \\\n  --speculative-num-draft-tokens 4 \\\n  --mem-fraction-static 0.7 \\\n  --disable-shared-experts-fusion \\\n  --served-model-name glm-4.5-air-fp8 \\\n  --host 0.0.0.0 \\\n  --port 8000\n```\n\n### Request Parameter Instructions\n\n+ When using `vLLM` and `SGLang`, thinking mode is enabled by default when sending requests. If you want to disable the\n  thinking switch, you need to add the `extra_body={\"chat_template_kwargs\": {\"enable_thinking\": False}}` parameter.\n+ Both support tool calling. Please use OpenAI-style tool description format for calls.\n+ For specific code, please refer to `api_request.py` in the `inference` folder.\n\n## Citation\nIf you find our work useful or helpful for your R&D works, please feel free to cite our paper as below.\n\n```bibtex\n@article{zhu2025glm45,\n  title={GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models},\n  author={Zhu, Xiaohan and Sun, Tianxiang and Wang, Hao and Xu, Yi and Zhang, Yichen and Wang, Junyi and Huang, Junjie and Zeng, Jiao and Huang, Yangyang and Gu, Ruipeng and Zhang, Xiaodong and Du, Mengying and Han, Hao and Li, Chao and Xiao, Jin and Guo, Weidong and Li, Zhen and Lu, Jingkang and Chen, Shu and Chen, Huadong and Chen, Peng and Liu, Hongguang and Guo, Guang and Liu, Wen and Yang, Tianyu and Hu, Bo and Zhang, Wenmin and Sun, Maosong},\n  journal={arXiv preprint arXiv:2508.06471},\n  year={2025}\n}\n```",
      "public": true,
      "version": "2208a75f-3513-542a-9296-e4bf21793cee",
      "tool_description": null,
      "slug": "chutes-zai-org-glm-4-5-fp8",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-07-28T14:34:40.498957Z",
      "updated_at": "2025-10-13T08:41:59.728551Z",
      "image": {
        "image_id": "761d22a2-c96c-5675-82df-60cddab0827e",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101200",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-12T08:53:29.416285Z",
        "build_started_at": "2025-10-12T08:53:31.172351Z",
        "build_completed_at": "2025-10-12T09:17:36.083052Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "initial",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 200981,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.35,
            "tao": 0.00086923242554838
          },
          "output": {
            "usd": 1.55,
            "tao": 0.0038494578845714
          }
        },
        "usd": {
          "hour": 36.3,
          "second": 0.0100833333333333
        },
        "tao": {
          "hour": 0.0901518201354463,
          "second": 0.000025042172259846
        }
      },
      "instances": [
        {
          "instance_id": "134e9855-19ca-4d78-b9cd-a0c929a95202",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:01:39.107945Z"
        },
        {
          "instance_id": "62abb445-40fd-439b-bb7c-21f49d5f4163",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:01:39.107945Z"
        },
        {
          "instance_id": "a840ed8e-9ac9-4370-a60d-75036e98b4a6",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:01:39.107945Z"
        },
        {
          "instance_id": "c4500284-d71b-4b49-accf-b5fef4548430",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:01:39.107945Z"
        },
        {
          "instance_id": "86f45e24-f780-4025-8e3b-c98b3d679212",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:01:39.107945Z"
        },
        {
          "instance_id": "489c20b6-2a00-4c4a-9ff8-a395b3be4b00",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:01:39.107945Z"
        },
        {
          "instance_id": "8245e128-6e86-4238-9293-455315e8ccd4",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:01:39.107945Z"
        },
        {
          "instance_id": "e03aa0af-fb7e-462e-88bb-03215f3a5940",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:01:39.107945Z"
        },
        {
          "instance_id": "179d4ef9-4566-4949-9a0a-d300a8d5c2fc",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:01:39.107945Z"
        },
        {
          "instance_id": "405e92e8-ae8b-474f-b2c7-83e34e2428c9",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:01:39.107945Z"
        },
        {
          "instance_id": "c32d69e9-11c2-40b1-86fa-5d3110227328",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:01:39.107945Z"
        },
        {
          "instance_id": "509adb41-4473-4f89-86d6-8ee3ca3b0b09",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:01:39.107945Z"
        },
        {
          "instance_id": "c2938a58-3eb5-4269-8614-c05e64e393e0",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:01:39.107945Z"
        },
        {
          "instance_id": "56f28852-b1f4-4d27-ac4e-5e18734c695d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:01:39.107945Z"
        },
        {
          "instance_id": "eaa6be79-a9e5-4ced-bb12-e266ebd60f96",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:01:39.107945Z"
        }
      ],
      "logo_id": "794738a0-1146-43ee-8c1a-a365da4e3626",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "a0f46d4df319ef3877e248e617035d4317729846",
      "concurrency": 32,
      "boost": 1.5,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/794738a0-1146-43ee-8c1a-a365da4e3626.webp",
      "hot": true
    },
    {
      "chute_id": "0d7184a2-32a3-53e0-9607-058c37edaab5",
      "name": "Qwen/Qwen3-32B",
      "tagline": "Qwen3-32B is a 32.8B parameter open source language model that can switch between thinking and non-thinking modes, making it versatile for tasks ranging from complex reasoning to general dialogue while supporting 100+ languages and long context windows up to 131K tokens.",
      "readme": "\n# Qwen3-32B\n\u003Ca href=\"https://chat.qwen.ai/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/%F0%9F%92%9C%EF%B8%8F%20Qwen%20Chat%20-536af5\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n\u003C/a\u003E\n\n## Qwen3 Highlights\n\nQwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support, with the following key features:\n\n- **Uniquely support of seamless switching between thinking mode** (for complex logical reasoning, math, and coding) and **non-thinking mode** (for efficient, general-purpose dialogue) **within single model**, ensuring optimal performance across various scenarios.\n- **Significantly enhancement in its reasoning capabilities**, surpassing previous QwQ (in thinking mode) and Qwen2.5 instruct models (in non-thinking mode) on mathematics, code generation, and commonsense logical reasoning.\n- **Superior human preference alignment**, excelling in creative writing, role-playing, multi-turn dialogues, and instruction following, to deliver a more natural, engaging, and immersive conversational experience.\n- **Expertise in agent capabilities**, enabling precise integration with external tools in both thinking and unthinking modes and achieving leading performance among open-source models in complex agent-based tasks.\n- **Support of 100+ languages and dialects** with strong capabilities for **multilingual instruction following** and **translation**.\n\n## Model Overview\n\n**Qwen3-32B** has the following features:\n- Type: Causal Language Models\n- Training Stage: Pretraining & Post-training\n- Number of Parameters: 32.8B\n- Number of Paramaters (Non-Embedding): 31.2B\n- Number of Layers: 64\n- Number of Attention Heads (GQA): 64 for Q and 8 for KV\n- Context Length: 32,768 natively and [131,072 tokens with YaRN](https://huggingface.co/Qwen/Qwen3-32B/raw/main/#processing-long-texts). \n\nFor more details, including benchmark evaluation, hardware requirements, and inference performance, please refer to our [blog](https://qwenlm.github.io/blog/qwen3/), [GitHub](https://github.com/QwenLM/Qwen3), and [Documentation](https://qwen.readthedocs.io/en/latest/).\n\n## Quickstart\n\nThe code of Qwen3 has been in the latest Hugging Face `transformers` and we advise you to use the latest version of `transformers`.\n\nWith `transformers\u003C4.51.0`, you will encounter the following error:\n```\nKeyError: 'qwen3'\n```\n\nThe following contains a code snippet illustrating how to use the model generate content based on given inputs. \n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"Qwen/Qwen3-32B\"\n\n# load the tokenizer and the model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=\"auto\",\n    device_map=\"auto\"\n)\n\n# prepare the model input\nprompt = \"Give me a short introduction to large language model.\"\nmessages = [\n    {\"role\": \"user\", \"content\": prompt}\n]\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\n# conduct text completion\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=32768\n)\noutput_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n\n# parsing thinking content\ntry:\n    # rindex finding 151668 (\u003C/think\u003E)\n    index = len(output_ids) - output_ids[::-1].index(151668)\nexcept ValueError:\n    index = 0\n\nthinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\ncontent = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n\nprint(\"thinking content:\", thinking_content)\nprint(\"content:\", content)\n```\n\nFor deployment, you can use `sglang\u003E=0.4.6.post1` or `vllm\u003E=0.8.5` or to create an OpenAI-compatible API endpoint:\n- SGLang:\n    ```shell\n    python -m sglang.launch_server --model-path Qwen/Qwen3-32B --reasoning-parser qwen3\n    ```\n- vLLM:\n    ```shell\n    vllm serve Qwen/Qwen3-32B --enable-reasoning --reasoning-parser deepseek_r1\n    ```\n\nFor local use, applications such as Ollama, LMStudio, MLX-LM, llama.cpp, and KTransformers have also supported Qwen3.\n\n## Switching Between Thinking and Non-Thinking Mode\n\n\u003E [!TIP]\n\u003E The `enable_thinking` switch is also available in APIs created by SGLang and vLLM. \n\u003E Please refer to our documentation for [SGLang](https://qwen.readthedocs.io/en/latest/deployment/sglang.html#thinking-non-thinking-modes) and [vLLM](https://qwen.readthedocs.io/en/latest/deployment/vllm.html#thinking-non-thinking-modes) users.\n\n### `enable_thinking=True`\n\nBy default, Qwen3 has thinking capabilities enabled, similar to QwQ-32B. This means the model will use its reasoning abilities to enhance the quality of generated responses. For example, when explicitly setting `enable_thinking=True` or leaving it as the default value in `tokenizer.apply_chat_template`, the model will engage its thinking mode.\n\n```python\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=True  # True is the default value for enable_thinking\n)\n```\n\nIn this mode, the model will generate think content wrapped in a `\u003Cthink\u003E...\u003C/think\u003E` block, followed by the final response.\n\n\u003E [!NOTE]\n\u003E For thinking mode, use `Temperature=0.6`, `TopP=0.95`, `TopK=20`, and `MinP=0` (the default setting in `generation_config.json`). **DO NOT use greedy decoding**, as it can lead to performance degradation and endless repetitions. For more detailed guidance, please refer to the [Best Practices](https://huggingface.co/Qwen/Qwen3-32B/raw/main/#best-practices) section.\n\n\n### `enable_thinking=False`\n\nWe provide a hard switch to strictly disable the model's thinking behavior, aligning its functionality with the previous Qwen2.5-Instruct models. This mode is particularly useful in scenarios where disabling thinking is essential for enhancing efficiency.\n\n```python\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=False  # Setting enable_thinking=False disables thinking mode\n)\n```\n\nIn this mode, the model will not generate any think content and will not include a `\u003Cthink\u003E...\u003C/think\u003E` block.\n\n\u003E [!NOTE]\n\u003E For non-thinking mode, we suggest using `Temperature=0.7`, `TopP=0.8`, `TopK=20`, and `MinP=0`. For more detailed guidance, please refer to the [Best Practices](https://huggingface.co/Qwen/Qwen3-32B/raw/main/#best-practices) section.\n\n### Advanced Usage: Switching Between Thinking and Non-Thinking Modes via User Input\n\nWe provide a soft switch mechanism that allows users to dynamically control the model's behavior when `enable_thinking=True`. Specifically, you can add `/think` and `/no_think` to user prompts or system messages to switch the model's thinking mode from turn to turn. The model will follow the most recent instruction in multi-turn conversations.\n\nHere is an example of a multi-turn conversation:\n\n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nclass QwenChatbot:\n    def __init__(self, model_name=\"Qwen/Qwen3-32B\"):\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n        self.history = []\n\n    def generate_response(self, user_input):\n        messages = self.history + [{\"role\": \"user\", \"content\": user_input}]\n\n        text = self.tokenizer.apply_chat_template(\n            messages,\n            tokenize=False,\n            add_generation_prompt=True\n        )\n\n        inputs = self.tokenizer(text, return_tensors=\"pt\")\n        response_ids = self.model.generate(**inputs, max_new_tokens=32768)[0][len(inputs.input_ids[0]):].tolist()\n        response = self.tokenizer.decode(response_ids, skip_special_tokens=True)\n\n        # Update history\n        self.history.append({\"role\": \"user\", \"content\": user_input})\n        self.history.append({\"role\": \"assistant\", \"content\": response})\n\n        return response\n\n# Example Usage\nif __name__ == \"__main__\":\n    chatbot = QwenChatbot()\n\n    # First input (without /think or /no_think tags, thinking mode is enabled by default)\n    user_input_1 = \"How many r's in strawberries?\"\n    print(f\"User: {user_input_1}\")\n    response_1 = chatbot.generate_response(user_input_1)\n    print(f\"Bot: {response_1}\")\n    print(\"----------------------\")\n\n    # Second input with /no_think\n    user_input_2 = \"Then, how many r's in blueberries? /no_think\"\n    print(f\"User: {user_input_2}\")\n    response_2 = chatbot.generate_response(user_input_2)\n    print(f\"Bot: {response_2}\") \n    print(\"----------------------\")\n\n    # Third input with /think\n    user_input_3 = \"Really? /think\"\n    print(f\"User: {user_input_3}\")\n    response_3 = chatbot.generate_response(user_input_3)\n    print(f\"Bot: {response_3}\")\n```\n\n\u003E [!NOTE]\n\u003E For API compatibility, when `enable_thinking=True`, regardless of whether the user uses `/think` or `/no_think`, the model will always output a block wrapped in `\u003Cthink\u003E...\u003C/think\u003E`. However, the content inside this block may be empty if thinking is disabled.\n\u003E When `enable_thinking=False`, the soft switches are not valid. Regardless of any `/think` or `/no_think` tags input by the user, the model will not generate think content and will not include a `\u003Cthink\u003E...\u003C/think\u003E` block.\n\n## Agentic Use\n\nQwen3 excels in tool calling capabilities. We recommend using [Qwen-Agent](https://github.com/QwenLM/Qwen-Agent) to make the best use of agentic ability of Qwen3. Qwen-Agent encapsulates tool-calling templates and tool-calling parsers internally, greatly reducing coding complexity.\n\nTo define the available tools, you can use the MCP configuration file, use the integrated tool of Qwen-Agent, or integrate other tools by yourself.\n```python\nfrom qwen_agent.agents import Assistant\n\n# Define LLM\nllm_cfg = {\n    'model': 'Qwen3-32B',\n\n    # Use the endpoint provided by Alibaba Model Studio:\n    # 'model_type': 'qwen_dashscope',\n    # 'api_key': os.getenv('DASHSCOPE_API_KEY'),\n\n    # Use a custom endpoint compatible with OpenAI API:\n    'model_server': 'http://localhost:8000/v1',  # api_base\n    'api_key': 'EMPTY',\n\n    # Other parameters:\n    # 'generate_cfg': {\n    #         # Add: When the response content is `\u003Cthink\u003Ethis is the thought\u003C/think\u003Ethis is the answer;\n    #         # Do not add: When the response has been separated by reasoning_content and content.\n    #         'thought_in_content': True,\n    #     },\n}\n\n# Define Tools\ntools = [\n    {'mcpServers': {  # You can specify the MCP configuration file\n            'time': {\n                'command': 'uvx',\n                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']\n            },\n            \"fetch\": {\n                \"command\": \"uvx\",\n                \"args\": [\"mcp-server-fetch\"]\n            }\n        }\n    },\n  'code_interpreter',  # Built-in tools\n]\n\n# Define Agent\nbot = Assistant(llm=llm_cfg, function_list=tools)\n\n# Streaming generation\nmessages = [{'role': 'user', 'content': 'https://qwenlm.github.io/blog/ Introduce the latest developments of Qwen'}]\nfor responses in bot.run(messages=messages):\n    pass\nprint(responses)\n```\n\n## Processing Long Texts\n\nQwen3 natively supports context lengths of up to 32,768 tokens. For conversations where the total length (including both input and output) significantly exceeds this limit, we recommend using RoPE scaling techniques to handle long texts effectively. We have validated the model's performance on context lengths of up to 131,072 tokens using the [YaRN](https://arxiv.org/abs/2309.00071) method.\n\nYaRN is currently supported by several inference frameworks, e.g., `transformers` and `llama.cpp` for local use, `vllm` and `sglang` for deployment. In general, there are two approaches to enabling YaRN for supported frameworks:\n\n- Modifying the model files:\n  In the `config.json` file, add the `rope_scaling` fields:\n    ```json\n    {\n        ...,\n        \"rope_scaling\": {\n            \"rope_type\": \"yarn\",\n            \"factor\": 4.0,\n            \"original_max_position_embeddings\": 32768\n        }\n    }\n    ```\n  For `llama.cpp`, you need to regenerate the GGUF file after the modification.\n\n- Passing command line arguments:\n\n  For `vllm`, you can use\n    ```shell\n    vllm serve ... --rope-scaling '{\"rope_type\":\"yarn\",\"factor\":4.0,\"original_max_position_embeddings\":32768}' --max-model-len 131072  \n    ```\n\n  For `sglang`, you can use\n    ```shell\n    python -m sglang.launch_server ... --json-model-override-args '{\"rope_scaling\":{\"rope_type\":\"yarn\",\"factor\":4.0,\"original_max_position_embeddings\":32768}}'\n    ```\n\n  For `llama-server` from `llama.cpp`, you can use\n    ```shell\n    llama-server ... --rope-scaling yarn --rope-scale 4 --yarn-orig-ctx 32768\n    ```\n\n\u003E [!IMPORTANT]\n\u003E If you encounter the following warning\n\u003E ```\n\u003E Unrecognized keys in `rope_scaling` for 'rope_type'='yarn': {'original_max_position_embeddings'}\n\u003E ```\n\u003E please upgrade `transformers\u003E=4.51.0`.\n\n\u003E [!NOTE]\n\u003E All the notable open-source frameworks implement static YaRN, which means the scaling factor remains constant regardless of input length, **potentially impacting performance on shorter texts.**\n\u003E We advise adding the `rope_scaling` configuration only when processing long contexts is required. \n\u003E It is also recommended to modify the `factor` as needed. For example, if the typical context length for your application is 65,536 tokens, it would be better to set `factor` as 2.0. \n\n\u003E [!NOTE]\n\u003E The default `max_position_embeddings` in `config.json` is set to 40,960. This allocation includes reserving 32,768 tokens for outputs and 8,192 tokens for typical prompts, which is sufficient for most scenarios involving short text processing. If the average context length does not exceed 32,768 tokens, we do not recommend enabling YaRN in this scenario, as it may potentially degrade model performance.\n\n\u003E [!TIP]\n\u003E The endpoint provided by Alibaba Model Studio supports dynamic YaRN by default and no extra configuration is needed.\n\n## Best Practices\n\nTo achieve optimal performance, we recommend the following settings:\n\n1. **Sampling Parameters**:\n   - For thinking mode (`enable_thinking=True`), use `Temperature=0.6`, `TopP=0.95`, `TopK=20`, and `MinP=0`. **DO NOT use greedy decoding**, as it can lead to performance degradation and endless repetitions.\n   - For non-thinking mode (`enable_thinking=False`), we suggest using `Temperature=0.7`, `TopP=0.8`, `TopK=20`, and `MinP=0`.\n   - For supported frameworks, you can adjust the `presence_penalty` parameter between 0 and 2 to reduce endless repetitions. However, using a higher value may occasionally result in language mixing and a slight decrease in model performance.\n\n2. **Adequate Output Length**: We recommend using an output length of 32,768 tokens for most queries. For benchmarking on highly complex problems, such as those found in math and programming competitions, we suggest setting the max output length to 38,912 tokens. This provides the model with sufficient space to generate detailed and comprehensive responses, thereby enhancing its overall performance.\n\n3. **Standardize Output Format**: We recommend using prompts to standardize model outputs when benchmarking.\n   - **Math Problems**: Include \"Please reason step by step, and put your final answer within \\boxed{}.\" in the prompt.\n   - **Multiple-Choice Questions**: Add the following JSON structure to the prompt to standardize responses: \"Please show your choice in the `answer` field with only the choice letter, e.g., `\"answer\": \"C\"`.\"\n\n4. **No Thinking Content in History**: In multi-turn conversations, the historical model output shoul",
      "public": true,
      "version": "7526ae94-8a60-5ad9-a53b-256bcde269f7",
      "tool_description": null,
      "slug": "chutes-qwen-qwen3-32b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-04-28T22:12:52.612152Z",
      "updated_at": "2025-10-09T22:36:55.096740Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a100_40gb",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "exclude": [
          "b200",
          "mi300x",
          "5090"
        ],
        "include": null,
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 40,
        "compute_multiplier": 0.888888888888889,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a100_40gb",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 200495,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.05,
            "tao": 0.000124176060792625
          },
          "output": {
            "usd": 0.2,
            "tao": 0.000496704243170502
          }
        },
        "usd": {
          "hour": 3.6,
          "second": 0.001
        },
        "tao": {
          "hour": 0.00894067637706905,
          "second": 0.000002483521215852
        }
      },
      "instances": [
        {
          "instance_id": "a86a1f77-fd54-4dcd-84a4-71eca2b54a26",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:43:59.206390Z"
        },
        {
          "instance_id": "b3bc8b7d-503e-4e9e-9f7f-7290fe93b4da",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:43:59.206390Z"
        },
        {
          "instance_id": "cac97bb6-f586-4f7e-bd93-0dc127f1dc31",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:43:59.206390Z"
        },
        {
          "instance_id": "81378c3b-ae5c-40bb-8ca2-3353f03495ba",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:43:59.206390Z"
        },
        {
          "instance_id": "2f1703d8-4e74-4411-aaa5-41bf3ed09d47",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:43:59.206390Z"
        },
        {
          "instance_id": "36160a39-317f-4027-8c7f-4491c16b45a0",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:43:59.206390Z"
        },
        {
          "instance_id": "5a79e15f-9647-4d63-ad60-500d91275a71",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:43:59.206390Z"
        },
        {
          "instance_id": "e992bb2b-026d-48b7-9366-ac31591e2b7d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:43:59.206390Z"
        },
        {
          "instance_id": "826694d4-ed81-4000-ab71-fa9ba6035318",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:43:59.206390Z"
        }
      ],
      "logo_id": "6866dead-21bd-481a-87aa-6c723c5fe9cb",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "ba1f828c09458ab0ae83d42eaacc2cf8720c7957",
      "concurrency": 24,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": 0.6,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/6866dead-21bd-481a-87aa-6c723c5fe9cb.webp",
      "hot": true
    },
    {
      "chute_id": "fa4181ad-0cf1-5531-afdb-bbffbf2ff945",
      "name": "deepseek-ai/DeepSeek-V3",
      "tagline": "DeepSeek-V3 is a 671B parameter MoE model (37B active parameters per token) that excels at reasoning, coding, and math tasks while maintaining strong general language capabilities across English, Chinese and other languages.",
      "readme": "\u003C!-- markdownlint-disable first-line-h1 --\u003E\n\u003C!-- markdownlint-disable html --\u003E\n\u003C!-- markdownlint-disable no-duplicate-header --\u003E\n\n\u003Cdiv align=\"center\"\u003E\n  \u003Cimg src=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/logo.svg?raw=true\" width=\"60%\" alt=\"DeepSeek-V3\" /\u003E\n\u003C/div\u003E\n\u003Chr\u003E\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\n  \u003Ca href=\"https://www.deepseek.com/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Homepage\" src=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/badge.svg?raw=true\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://chat.deepseek.com/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/ğŸ¤–%20Chat-DeepSeek%20V3-536af5?color=536af5&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://huggingface.co/deepseek-ai\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Hugging Face\" src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\n  \u003Ca href=\"https://discord.gg/Tc7c45Zzu5\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Discord\" src=\"https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&logoColor=white&color=7289da\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/qr.jpeg?raw=true\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Wechat\" src=\"https://img.shields.io/badge/WeChat-DeepSeek%20AI-brightgreen?logo=wechat&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://twitter.com/deepseek_ai\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Twitter Follow\" src=\"https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\n  \u003Ca href=\"https://github.com/deepseek-ai/DeepSeek-V3/blob/main/LICENSE-CODE\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Code License\" src=\"https://img.shields.io/badge/Code_License-MIT-f5de53?&color=f5de53\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://github.com/deepseek-ai/DeepSeek-V3/blob/main/LICENSE-MODEL\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Model License\" src=\"https://img.shields.io/badge/Model_License-Model_Agreement-f5de53?&color=f5de53\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\n\n\u003Cp align=\"center\"\u003E\n  \u003Ca href=\"https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf\"\u003E\u003Cb\u003EPaper Link\u003C/b\u003EğŸ‘ï¸\u003C/a\u003E\n\u003C/p\u003E\n\n\n## 1. Introduction\n\nWe present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token. \nTo achieve efficient inference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architectures, which were thoroughly validated in DeepSeek-V2. \nFurthermore, DeepSeek-V3 pioneers an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training objective for stronger performance. \nWe pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities. \nComprehensive evaluations reveal that DeepSeek-V3 outperforms other open-source models and achieves performance comparable to leading closed-source models.\nDespite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its full training.\nIn addition, its training process is remarkably stable. \nThroughout the entire training process, we did not experience any irrecoverable loss spikes or perform any rollbacks. \n\u003Cp align=\"center\"\u003E\n  \u003Cimg width=\"80%\" src=\"figures/benchmark.png\"\u003E\n\u003C/p\u003E\n\n## 2. Model Summary\n\n---\n\n**Architecture: Innovative Load Balancing Strategy and Training Objective**\n\n- On top of the efficient architecture of DeepSeek-V2, we pioneer an auxiliary-loss-free strategy for load balancing, which minimizes the performance degradation that arises from encouraging load balancing.\n-  We investigate a Multi-Token Prediction (MTP) objective and prove it beneficial to model performance. \n    It can also be used for speculative decoding for inference acceleration. \n\n---\n\n**Pre-Training: Towards Ultimate Training Efficiency**\n\n- We design an FP8 mixed precision training framework and, for the first time, validate the feasibility and effectiveness of FP8 training on an extremely large-scale model.  \n- Through co-design of algorithms, frameworks, and hardware, we overcome the communication bottleneck in cross-node MoE training, nearly achieving full computation-communication overlap.  \n  This significantly enhances our training efficiency and reduces the training costs, enabling us to further scale up the model size without additional overhead.  \n- At an economical cost of only 2.664M H800 GPU hours, we complete the pre-training of DeepSeek-V3 on 14.8T tokens, producing the currently strongest open-source base model. The subsequent training stages after pre-training require only 0.1M GPU hours.\n\n---\n\n**Post-Training: Knowledge Distillation from DeepSeek-R1**\n\n-   We introduce an innovative methodology to distill reasoning capabilities from the long-Chain-of-Thought (CoT) model, specifically from one of the DeepSeek R1 series models, into standard LLMs, particularly DeepSeek-V3. Our pipeline elegantly incorporates the verification and reflection patterns of R1 into DeepSeek-V3 and notably improves its reasoning performance. Meanwhile, we also maintain a control over the output style and length of DeepSeek-V3.\n\n---\n\n\n## 3. Model Downloads\n\n\u003Cdiv align=\"center\"\u003E\n\n| **Model** | **#Total Params** | **#Activated Params** | **Context Length** | **Download** |\n| :------------: | :------------: | :------------: | :------------: | :------------: |\n| DeepSeek-V3-Base | 671B | 37B | 128K   | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-V3-Base)   |\n| DeepSeek-V3   | 671B | 37B |  128K   | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-V3)   |\n\n\u003C/div\u003E\n\n**NOTE: The total size of DeepSeek-V3 models on HuggingFace is 685B, which includes 671B of the Main Model weights and 14B of the Multi-Token Prediction (MTP) Module weights.**\n\nTo ensure optimal performance and flexibility, we have partnered with open-source communities and hardware vendors to provide multiple ways to run the model locally. For step-by-step guidance, check out Section 6: [How_to Run_Locally](https://huggingface.co/deepseek-ai/DeepSeek-V3/raw/main/#6-how-to-run-locally).\n\nFor developers looking to dive deeper, we recommend exploring [README_WEIGHTS.md](https://huggingface.co/deepseek-ai/DeepSeek-V3/raw/main/README_WEIGHTS.md) for details on the Main Model weights and the Multi-Token Prediction (MTP) Modules. Please note that MTP support is currently under active development within the community, and we welcome your contributions and feedback.\n\n## 4. Evaluation Results\n### Base Model\n#### Standard Benchmarks\n\n\u003Cdiv align=\"center\"\u003E\n\n\n|  | Benchmark (Metric) | # Shots | DeepSeek-V2 | Qwen2.5 72B | LLaMA3.1 405B | DeepSeek-V3 |\n|---|-------------------|----------|--------|-------------|---------------|---------|\n| | Architecture | - | MoE | Dense | Dense | MoE |\n| | # Activated Params | - | 21B | 72B | 405B | 37B |\n| | # Total Params | - | 236B | 72B | 405B | 671B |\n| English | Pile-test (BPB) | - | 0.606 | 0.638 | **0.542** | 0.548 |\n| | BBH (EM) | 3-shot | 78.8 | 79.8 | 82.9 | **87.5** |\n| | MMLU (Acc.) | 5-shot | 78.4 | 85.0 | 84.4 | **87.1** |\n| | MMLU-Redux (Acc.) | 5-shot | 75.6 | 83.2 | 81.3 | **86.2** |\n| | MMLU-Pro (Acc.) | 5-shot | 51.4 | 58.3 | 52.8 | **64.4** |\n| | DROP (F1) | 3-shot | 80.4 | 80.6 | 86.0 | **89.0** |\n| | ARC-Easy (Acc.) | 25-shot | 97.6 | 98.4 | 98.4 | **98.9** |\n| | ARC-Challenge (Acc.) | 25-shot | 92.2 | 94.5 | **95.3** | **95.3** |\n| | HellaSwag (Acc.) | 10-shot | 87.1 | 84.8 | **89.2** | 88.9 |\n| | PIQA (Acc.) | 0-shot | 83.9 | 82.6 | **85.9** | 84.7 |\n| | WinoGrande (Acc.) | 5-shot | **86.3** | 82.3 | 85.2 | 84.9 |\n| | RACE-Middle (Acc.) | 5-shot | 73.1 | 68.1 | **74.2** | 67.1 |\n| | RACE-High (Acc.) | 5-shot | 52.6 | 50.3 | **56.8** | 51.3 |\n| | TriviaQA (EM) | 5-shot | 80.0 | 71.9 | **82.7** | **82.9** |\n| | NaturalQuestions (EM) | 5-shot | 38.6 | 33.2 | **41.5** | 40.0 |\n| | AGIEval (Acc.) | 0-shot | 57.5 | 75.8 | 60.6 | **79.6** |\n| Code | HumanEval (Pass@1) | 0-shot | 43.3 | 53.0 | 54.9 | **65.2** |\n| | MBPP (Pass@1) | 3-shot | 65.0 | 72.6 | 68.4 | **75.4** |\n| | LiveCodeBench-Base (Pass@1) | 3-shot | 11.6 | 12.9 | 15.5 | **19.4** |\n| | CRUXEval-I (Acc.) | 2-shot | 52.5 | 59.1 | 58.5 | **67.3** |\n| | CRUXEval-O (Acc.) | 2-shot | 49.8 | 59.9 | 59.9 | **69.8** |\n| Math | GSM8K (EM) | 8-shot | 81.6 | 88.3 | 83.5 | **89.3** |\n| | MATH (EM) | 4-shot | 43.4 | 54.4 | 49.0 | **61.6** |\n| | MGSM (EM) | 8-shot | 63.6 | 76.2 | 69.9 | **79.8** |\n| | CMath (EM) | 3-shot | 78.7 | 84.5 | 77.3 | **90.7** |\n| Chinese | CLUEWSC (EM) | 5-shot | 82.0 | 82.5 | **83.0** | 82.7 |\n| | C-Eval (Acc.) | 5-shot | 81.4 | 89.2 | 72.5 | **90.1** |\n| | CMMLU (Acc.) | 5-shot | 84.0 | **89.5** | 73.7 | 88.8 |\n| | CMRC (EM) | 1-shot | **77.4** | 75.8 | 76.0 | 76.3 |\n| | C3 (Acc.) | 0-shot | 77.4 | 76.7 | **79.7** | 78.6 |\n| | CCPM (Acc.) | 0-shot | **93.0** | 88.5 | 78.6 | 92.0 |\n| Multilingual | MMMLU-non-English (Acc.) | 5-shot | 64.0 | 74.8 | 73.8 | **79.4** |\n\n\u003C/div\u003E\n\nNote: Best results are shown in bold. Scores with a gap not exceeding 0.3 are considered to be at the same level. DeepSeek-V3 achieves the best performance on most benchmarks, especially on math and code tasks.\nFor more evaluation details, please check our paper. \n\n#### Context Window\n\u003Cp align=\"center\"\u003E\n  \u003Cimg width=\"80%\" src=\"figures/niah.png\"\u003E\n\u003C/p\u003E\n\nEvaluation results on the ``Needle In A Haystack`` (NIAH) tests.  DeepSeek-V3 performs well across all context window lengths up to **128K**. \n\n### Chat Model\n#### Standard Benchmarks (Models larger than 67B)\n\u003Cdiv align=\"center\"\u003E\n\n| | **Benchmark (Metric)** | **DeepSeek V2-0506** | **DeepSeek V2.5-0905** | **Qwen2.5 72B-Inst.** | **Llama3.1 405B-Inst.** | **Claude-3.5-Sonnet-1022** | **GPT-4o 0513** | **DeepSeek V3** |\n|---|---------------------|---------------------|----------------------|---------------------|----------------------|---------------------------|----------------|----------------|\n| | Architecture | MoE | MoE | Dense | Dense | - | - | MoE |\n| | # Activated Params | 21B | 21B | 72B | 405B | - | - | 37B |\n| | # Total Params | 236B | 236B | 72B | 405B | - | - | 671B |\n| English | MMLU (EM) | 78.2 | 80.6 | 85.3 | **88.6** | **88.3** | 87.2 | **88.5** |\n| | MMLU-Redux (EM) | 77.9 | 80.3 | 85.6 | 86.2 | **88.9** | 88.0 | **89.1** |\n| | MMLU-Pro (EM) | 58.5 | 66.2 | 71.6 | 73.3 | **78.0** | 72.6 | 75.9 |\n| | DROP (3-shot F1) | 83.0 | 87.8 | 76.7 | 88.7 | 88.3 | 83.7 | **91.6** |\n| | IF-Eval (Prompt Strict) | 57.7 | 80.6 | 84.1 | 86.0 | **86.5** | 84.3 | 86.1 |\n| | GPQA-Diamond (Pass@1) | 35.3 | 41.3 | 49.0 | 51.1 | **65.0** | 49.9 | 59.1 |\n| | SimpleQA (Correct) | 9.0 | 10.2 | 9.1 | 17.1 | 28.4 | **38.2** | 24.9 |\n| | FRAMES (Acc.) | 66.9 | 65.4 | 69.8 | 70.0 | 72.5 | **80.5** | 73.3 |\n| | LongBench v2 (Acc.) | 31.6 | 35.4 | 39.4 | 36.1 | 41.0 | 48.1 | **48.7** |\n| Code | HumanEval-Mul (Pass@1) | 69.3 | 77.4 | 77.3 | 77.2 | 81.7 | 80.5 | **82.6** |\n| | LiveCodeBench (Pass@1-COT) | 18.8 | 29.2 | 31.1 | 28.4 | 36.3 | 33.4 | **40.5** |\n| | LiveCodeBench (Pass@1) | 20.3 | 28.4 | 28.7 | 30.1 | 32.8 | 34.2 | **37.6** |\n| | Codeforces (Percentile) | 17.5 | 35.6 | 24.8 | 25.3 | 20.3 | 23.6 | **51.6** |\n| | SWE Verified (Resolved) | - | 22.6 | 23.8 | 24.5 | **50.8** | 38.8 | 42.0 |\n| | Aider-Edit (Acc.) | 60.3 | 71.6 | 65.4 | 63.9 | **84.2** | 72.9 | 79.7 |\n| | Aider-Polyglot (Acc.) | - | 18.2 | 7.6 | 5.8 | 45.3 | 16.0 | **49.6** |\n| Math | AIME 2024 (Pass@1) | 4.6 | 16.7 | 23.3 | 23.3 | 16.0 | 9.3 | **39.2** |\n| | MATH-500 (EM) | 56.3 | 74.7 | 80.0 | 73.8 | 78.3 | 74.6 | **90.2** |\n| | CNMO 2024 (Pass@1) | 2.8 | 10.8 | 15.9 | 6.8 | 13.1 | 10.8 | **43.2** |\n| Chinese | CLUEWSC (EM) | 89.9 | 90.4 | **91.4** | 84.7 | 85.4 | 87.9 | 90.9 |\n| | C-Eval (EM) | 78.6 | 79.5 | 86.1 | 61.5 | 76.7 | 76.0 | **86.5** |\n| | C-SimpleQA (Correct) | 48.5 | 54.1 | 48.4 | 50.4 | 51.3 | 59.3 | **64.8** |\n\nNote: All models are evaluated in a configuration that limits the output length to 8K. Benchmarks containing fewer than 1000 samples are tested multiple times using varying temperature settings to derive robust final results. DeepSeek-V3 stands as the best-performing open-source model, and also exhibits competitive performance against frontier closed-source models.\n\n\u003C/div\u003E\n\n\n####  Open Ended Generation Evaluation\n\n\u003Cdiv align=\"center\"\u003E\n\n\n\n| Model | Arena-Hard | AlpacaEval 2.0 |\n|-------|------------|----------------|\n| DeepSeek-V2.5-0905 | 76.2 | 50.5 |\n| Qwen2.5-72B-Instruct | 81.2 | 49.1 |\n| LLaMA-3.1 405B | 69.3 | 40.5 |\n| GPT-4o-0513 | 80.4 | 51.1 |\n| Claude-Sonnet-3.5-1022 | 85.2 | 52.0 |\n| DeepSeek-V3 | **85.5** | **70.0** |\n\nNote: English open-ended conversation evaluations. For AlpacaEval 2.0, we use the length-controlled win rate as the metric.\n\u003C/div\u003E\n\n\n## 5. Chat Website & API Platform\nYou can chat with DeepSeek-V3 on DeepSeek's official website: [chat.deepseek.com](https://chat.deepseek.com/sign_in)\n\nWe also provide OpenAI-Compatible API at DeepSeek Platform: [platform.deepseek.com](https://platform.deepseek.com/)\n\n## 6. How to Run Locally\n\nDeepSeek-V3 can be deployed locally using the following hardware and open-source community software:\n\n1. **DeepSeek-Infer Demo**: We provide a simple and lightweight demo for FP8 and BF16 inference.\n2. **SGLang**: Fully support the DeepSeek-V3 model in both BF16 and FP8 inference modes.\n3. **LMDeploy**: Enables efficient FP8 and BF16 inference for local and cloud deployment.\n4. **TensorRT-LLM**: Currently supports BF16 inference and INT4/8 quantization, with FP8 support coming soon.\n5. **vLLM**: Support DeekSeek-V3 model with FP8 and BF16 modes for tensor parallelism and pipeline parallelism.\n6. **AMD GPU**: Enables running the DeepSeek-V3 model on AMD GPUs via SGLang in both BF16 and FP8 modes.\n7. **Huawei Ascend NPU**: Supports running DeepSeek-V3 on Huawei Ascend devices.\n\nSince FP8 training is natively adopted in our framework, we only provide FP8 weights. If you require BF16 weights for experimentation, you can use the provided conversion script to perform the transformation.\n\nHere is an example of converting FP8 weights to BF16:\n\n```shell\ncd inference\npython fp8_cast_bf16.py --input-fp8-hf-path /path/to/fp8_weights --output-bf16-hf-path /path/to/bf16_weights\n```\n\n**NOTE: Huggingface's Transformers has not been directly supported yet.**\n\n### 6.1 Inference with DeepSeek-Infer Demo (example only)\n\n#### Model Weights & Demo Code Preparation\n\nFirst, clone our DeepSeek-V3 GitHub repository:\n\n```shell\ngit clone https://github.com/deepseek-ai/DeepSeek-V3.git\n```\n\nNavigate to the `inference` folder and install dependencies listed in `requirements.txt`.\n\n```shell\ncd DeepSeek-V3/inference\npip install -r requirements.txt\n```\n\nDownload the model weights from HuggingFace, and put them into `/path/to/DeepSeek-V3` folder.\n\n#### Model Weights Conversion\n\nConvert HuggingFace model weights to a specific format:\n\n```shell\npython convert.py --hf-ckpt-path /path/to/DeepSeek-V3 --save-path /path/to/DeepSeek-V3-Demo --n-experts 256 --model-parallel 16\n```\n\n#### Run\n\nThen you can chat with DeepSeek-V3:\n\n```shell\ntorchrun --nnodes 2 --nproc-per-node 8 generate.py --node-rank $RANK --master-addr $ADDR --ckpt-path /path/to/DeepSeek-V3-Demo --config configs/config_671B.json --interactive --temperature 0.7 --max-new-tokens 200\n```\n\nOr batch inference on a given file:\n\n```shell\ntorchrun",
      "public": true,
      "version": "54ee0872-fe60-5b86-bd33-e5dbdc974af4",
      "tool_description": null,
      "slug": "chutes-deepseek-ai-deepseek-v3",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-02-21T16:54:45.697264Z",
      "updated_at": "2025-10-10T07:25:24.550986Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 189570,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.3,
            "tao": 0.000745056364755754
          },
          "output": {
            "usd": 1.2,
            "tao": 0.00298022545902302
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "122a1856-a4d5-49bd-afb2-10b25c2d1f5f",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T03:04:43.340362Z"
        },
        {
          "instance_id": "29e09eb0-b95c-4c1c-8bff-afc8af097455",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T07:17:13.057222Z"
        },
        {
          "instance_id": "59c87f43-ecb3-455d-9543-f9392549872d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T23:08:05.905358Z"
        },
        {
          "instance_id": "7eb1a7b6-6845-4cd5-a840-c493347a6242",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T04:05:32.412664Z"
        },
        {
          "instance_id": "d84f40d1-fdfb-48cf-9e0d-646cb7672e67",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T23:08:05.905358Z"
        }
      ],
      "logo_id": "c4f849f8-0e95-4556-a80e-389c755bd3bc",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "1d044fd82b15f1cedb197a288e50cc96a2c27205",
      "concurrency": 40,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/c4f849f8-0e95-4556-a80e-389c755bd3bc.webp",
      "hot": true
    },
    {
      "chute_id": "41d0bdad-9127-5d30-8d9f-e743577f4293",
      "name": "Qwen/Qwen2.5-VL-32B-Instruct",
      "tagline": "Qwen2.5-VL-32B is a 32 billion parameter multimodal language model that can understand and reason about images, videos, text, and structured data like charts and forms, making it useful for applications requiring comprehensive visual and textual understanding.",
      "readme": "\n# Qwen2.5-VL-32B-Instruct\n\u003Ca href=\"https://chat.qwenlm.ai/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/%F0%9F%92%9C%EF%B8%8F%20Qwen%20Chat%20-536af5\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n\u003C/a\u003E\n\n\n## Latest Updates:\nIn addition to the original formula, we have further enhanced Qwen2.5-VL-32B's mathematical and problem-solving abilities through reinforcement learning. This has also significantly improved the model's subjective user experience, with response styles adjusted to better align with human preferences. Particularly for objective queries such as mathematics, logical reasoning, and knowledge-based Q&A, the level of detail in responses and the clarity of formatting have been noticeably enhanced.\n\n## Introduction\n\nIn the past five months since Qwen2-VLâ€™s release, numerous developers have built new models on the Qwen2-VL vision-language models, providing us with valuable feedback. During this period, we focused on building more useful vision-language models. Today, we are excited to introduce the latest addition to the Qwen family: Qwen2.5-VL.\n\n#### Key Enhancements:\n* **Understand things visually**: Qwen2.5-VL is not only proficient in recognizing common objects such as flowers, birds, fish, and insects, but it is highly capable of analyzing texts, charts, icons, graphics, and layouts within images.\n\n* **Being agentic**: Qwen2.5-VL directly plays as a visual agent that can reason and dynamically direct tools, which is capable of computer use and phone use.\n\n* **Understanding long videos and capturing events**: Qwen2.5-VL can comprehend videos of over 1 hour, and this time it has a new ability of cpaturing event by pinpointing the relevant video segments.\n\n* **Capable of visual localization in different formats**: Qwen2.5-VL can accurately localize objects in an image by generating bounding boxes or points, and it can provide stable JSON outputs for coordinates and attributes.\n\n* **Generating structured outputs**: for data like scans of invoices, forms, tables, etc. Qwen2.5-VL supports structured outputs of their contents, benefiting usages in finance, commerce, etc.\n\n\n#### Model Architecture Updates:\n\n* **Dynamic Resolution and Frame Rate Training for Video Understanding**:\n\nWe extend dynamic resolution to the temporal dimension by adopting dynamic FPS sampling, enabling the model to comprehend videos at various sampling rates. Accordingly, we update mRoPE in the time dimension with IDs and absolute time alignment, enabling the model to learn temporal sequence and speed, and ultimately acquire the ability to pinpoint specific moments.\n\n\u003Cp align=\"center\"\u003E\n    \u003Cimg src=\"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5-VL/qwen2.5vl_arc.jpeg\" width=\"80%\"/\u003E\n\u003Cp\u003E\n\n\n* **Streamlined and Efficient Vision Encoder**\n\nWe enhance both training and inference speeds by strategically implementing window attention into the ViT. The ViT architecture is further optimized with SwiGLU and RMSNorm, aligning it with the structure of the Qwen2.5 LLM.\n\n\nWe have four models with 3, 7, 32 and 72 billion parameters. This repo contains the instruction-tuned 32B Qwen2.5-VL model. For more information, visit our [Blog](https://qwenlm.github.io/blog/qwen2.5-vl/) and [GitHub](https://github.com/QwenLM/Qwen2.5-VL).\n\n\n\n## Evaluation\n\n### Vision\n\n| Dataset | Qwen2.5-VL-72B\u003Cbr\u003E\u003Csup\u003E([ğŸ¤—](https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct)[ğŸ¤–](https://modelscope.cn/models/qwen/Qwen2.5-VL-72B-Instruct)) | Qwen2-VL-72B\u003Cbr\u003E\u003Csup\u003E([ğŸ¤—](https://huggingface.co/Qwen/Qwen2-VL-72B-Instruct)[ğŸ¤–](https://modelscope.cn/models/qwen/Qwen2-VL-72B-Instruct)) | Qwen2.5-VL-32B\u003Cbr\u003E\u003Csup\u003E([ğŸ¤—](https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct)[ğŸ¤–](https://modelscope.cn/models/qwen/Qwen2.5-VL-32B-Instruct)) |\n|--------------------|--------|--------------|------------------|\n| MMMU |**70.2** | 64.5 | 70 |\n| MMMU Pro |**51.1** | 46.2 | 49.5 |\n| MMStar | **70.8** | 68.3 | 69.5 |\n| MathVista | **74.8** | 70.5 | 74.7 |\n| MathVision |38.1 | 25.9 | **40.0**|\n| OCRBenchV2 | **61.5/63.7** | 47.8/46.1 | 57.2/59.1 |\n| CC-OCR | **79.8** | 68.7 | 77.1 |\n| DocVQA | **96.4** | **96.5** | 94.8 |\n| InfoVQA | **87.3** | 84.5 | 83.4 |\n| LVBench |47.3 | - | **49.00** |\n| CharadesSTA |50.9 | - | **54.2** |\n| VideoMME |**73.3/79.1** | 71.2/77.8 | 70.5/77.9 |\n| MMBench-Video |**2.02** | 1.7 | 1.93 |\n| AITZ |**83.2** | - | 83.1 |\n| Android Control |**67.4/93.7** | 66.4/84.4 | 69.6/93.3 |\n| ScreenSpot |**87.1** | - | 88.5 |\n| ScreenSpot Pro |**43.6** | - | 39.4 |\n| AndroidWorld |**35** | - | 22.0 |\n| OSWorld |**8.83** | - | 5.92 |\n\n### Text\n\n| MODEL           | MMLU   | MMLU-PRO | MATH    | GPQA-diamond | MBPP   | Human Eval |\n|-----------------|--------|----------|---------|--------------|--------|------------|\n| Qwen2.5-VL-32B  | 78.4  | 68.8    | 82.2   | 46.0        | 84.0  | 91.5      |\n| Mistral-Small-3.1-24B | 80.6 | 66.8    | 69.3    | 46.0        | 74.7  | 88.4    |\n| Gemma3-27B-IT     | 76.9   | 67.5     | 89      | 42.4         | 74.4   | 87.8       |\n| GPT-4o-Mini       | 82.0     | 61.7     | 70.2    | 39.4        | 84.8  | 87.2       |\n| Claude-3.5-Haiku | 77.6   | 65.0       | 69.2    | 41.6         | 85.6   | 88.1       |\n\n## Requirements\nThe code of Qwen2.5-VL has been in the latest Hugging face transformers and we advise you to build from source with command:\n```\n\npip install git+https://github.com/huggingface/transformers accelerate\n\n```\nor you might encounter the following error:\n```\n\nKeyError: 'qwen2_5_vl'\n\n```\n## Quickstart\n\nBelow, we provide simple examples to show how to use Qwen2.5-VL with ğŸ¤– ModelScope and ğŸ¤— Transformers.\n\nThe code of Qwen2.5-VL has been in the latest Hugging face transformers and we advise you to build from source with command:\n```\n\npip install git+https://github.com/huggingface/transformers accelerate\n\n```\nor you might encounter the following error:\n```\n\nKeyError: 'qwen2_5_vl'\n\n```\nWe offer a toolkit to help you handle various types of visual input more conveniently, as if you were using an API. This includes base64, URLs, and interleaved images and videos. You can install it using the following command:\n\n```bash\n# It's highly recommanded to use `[decord]` feature for faster video loading.\npip install qwen-vl-utils[decord]==0.0.8\n```\n\nIf you are not using Linux, you might not be able to install `decord` from PyPI. In that case, you can use `pip install qwen-vl-utils` which will fall back to using torchvision for video processing. However, you can still [install decord from source](https://github.com/dmlc/decord?tab=readme-ov-file#install-from-source) to get decord used when loading video.\n\n### Using ğŸ¤—  Transformers to Chat\n\nHere we show a code snippet to show you how to use the chat model with `transformers` and `qwen_vl_utils`:\n\n```python\nfrom transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor\nfrom qwen_vl_utils import process_vision_info\n\n# default: Load the model on the available device(s)\nmodel = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n    \"Qwen/Qwen2.5-VL-32B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n)\n\n# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n# model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n#     \"Qwen/Qwen2.5-VL-32B-Instruct\",\n#     torch_dtype=torch.bfloat16,\n#     attn_implementation=\"flash_attention_2\",\n#     device_map=\"auto\",\n# )\n\n# default processer\nprocessor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-32B-Instruct\")\n\n# The default range for the number of visual tokens per image in the model is 4-16384.\n# You can set min_pixels and max_pixels according to your needs, such as a token range of 256-1280, to balance performance and cost.\n# min_pixels = 256*28*28\n# max_pixels = 1280*28*28\n# processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-32B-Instruct\", min_pixels=min_pixels, max_pixels=max_pixels)\n\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"image\",\n                \"image\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\",\n            },\n            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n        ],\n    }\n]\n\n# Preparation for inference\ntext = processor.apply_chat_template(\n    messages, tokenize=False, add_generation_prompt=True\n)\nimage_inputs, video_inputs = process_vision_info(messages)\ninputs = processor(\n    text=[text],\n    images=image_inputs,\n    videos=video_inputs,\n    padding=True,\n    return_tensors=\"pt\",\n)\ninputs = inputs.to(\"cuda\")\n\n# Inference: Generation of the output\ngenerated_ids = model.generate(**inputs, max_new_tokens=128)\ngenerated_ids_trimmed = [\n    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n]\noutput_text = processor.batch_decode(\n    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n)\nprint(output_text)\n```\n\n\u003Cdetails\u003E\n\u003Csummary\u003EMulti image inference\u003C/summary\u003E\n\n```python\n# Messages containing multiple images and a text query\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\", \"image\": \"file:///path/to/image1.jpg\"},\n            {\"type\": \"image\", \"image\": \"file:///path/to/image2.jpg\"},\n            {\"type\": \"text\", \"text\": \"Identify the similarities between these images.\"},\n        ],\n    }\n]\n\n# Preparation for inference\ntext = processor.apply_chat_template(\n    messages, tokenize=False, add_generation_prompt=True\n)\nimage_inputs, video_inputs = process_vision_info(messages)\ninputs = processor(\n    text=[text],\n    images=image_inputs,\n    videos=video_inputs,\n    padding=True,\n    return_tensors=\"pt\",\n)\ninputs = inputs.to(\"cuda\")\n\n# Inference\ngenerated_ids = model.generate(**inputs, max_new_tokens=128)\ngenerated_ids_trimmed = [\n    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n]\noutput_text = processor.batch_decode(\n    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n)\nprint(output_text)\n```\n\n\u003C/details\u003E\n\n\u003Cdetails\u003E\n\u003Csummary\u003EVideo inference\u003C/summary\u003E\n\n```python\n# Messages containing a images list as a video and a text query\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"video\",\n                \"video\": [\n                    \"file:///path/to/frame1.jpg\",\n                    \"file:///path/to/frame2.jpg\",\n                    \"file:///path/to/frame3.jpg\",\n                    \"file:///path/to/frame4.jpg\",\n                ],\n            },\n            {\"type\": \"text\", \"text\": \"Describe this video.\"},\n        ],\n    }\n]\n\n# Messages containing a local video path and a text query\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"video\",\n                \"video\": \"file:///path/to/video1.mp4\",\n                \"max_pixels\": 360 * 420,\n                \"fps\": 1.0,\n            },\n            {\"type\": \"text\", \"text\": \"Describe this video.\"},\n        ],\n    }\n]\n\n# Messages containing a video url and a text query\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"video\",\n                \"video\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-VL/space_woaudio.mp4\",\n            },\n            {\"type\": \"text\", \"text\": \"Describe this video.\"},\n        ],\n    }\n]\n\n#In Qwen 2.5 VL, frame rate information is also input into the model to align with absolute time.\n# Preparation for inference\ntext = processor.apply_chat_template(\n    messages, tokenize=False, add_generation_prompt=True\n)\nimage_inputs, video_inputs, video_kwargs = process_vision_info(messages, return_video_kwargs=True)\ninputs = processor(\n    text=[text],\n    images=image_inputs,\n    videos=video_inputs,\n    fps=fps,\n    padding=True,\n    return_tensors=\"pt\",\n    **video_kwargs,\n)\ninputs = inputs.to(\"cuda\")\n\n# Inference\ngenerated_ids = model.generate(**inputs, max_new_tokens=128)\ngenerated_ids_trimmed = [\n    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n]\noutput_text = processor.batch_decode(\n    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n)\nprint(output_text)\n```\n\nVideo URL compatibility largely depends on the third-party library version. The details are in the table below. change the backend by `FORCE_QWENVL_VIDEO_READER=torchvision` or `FORCE_QWENVL_VIDEO_READER=decord` if you prefer not to use the default one.\n\n| Backend     | HTTP | HTTPS |\n|-------------|------|-------|\n| torchvision \u003E= 0.19.0 | âœ…  | âœ…   |\n| torchvision \u003C 0.19.0  | âŒ  | âŒ   |\n| decord      | âœ…  | âŒ   |\n\n\u003C/details\u003E\n\n\u003Cdetails\u003E\n\u003Csummary\u003EBatch inference\u003C/summary\u003E\n\n```python\n# Sample messages for batch inference\nmessages1 = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\", \"image\": \"file:///path/to/image1.jpg\"},\n            {\"type\": \"image\", \"image\": \"file:///path/to/image2.jpg\"},\n            {\"type\": \"text\", \"text\": \"What are the common elements in these pictures?\"},\n        ],\n    }\n]\nmessages2 = [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Who are you?\"},\n]\n# Combine messages for batch processing\nmessages = [messages1, messages2]\n\n# Preparation for batch inference\ntexts = [\n    processor.apply_chat_template(msg, tokenize=False, add_generation_prompt=True)\n    for msg in messages\n]\nimage_inputs, video_inputs = process_vision_info(messages)\ninputs = processor(\n    text=texts,\n    images=image_inputs,\n    videos=video_inputs,\n    padding=True,\n    return_tensors=\"pt\",\n)\ninputs = inputs.to(\"cuda\")\n\n# Batch Inference\ngenerated_ids = model.generate(**inputs, max_new_tokens=128)\ngenerated_ids_trimmed = [\n    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n]\noutput_texts = processor.batch_decode(\n    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n)\nprint(output_texts)\n```\n\n\u003C/details\u003E\n\n### ğŸ¤– ModelScope\n\nWe strongly advise users especially those in mainland China to use ModelScope. `snapshot_download` can help you solve issues concerning downloading checkpoints.\n\n### More Usage Tips\n\nFor input images, we support local files, base64, and URLs. For videos, we currently only support local files.\n\n```python\n# You can directly insert a local file path, a URL, or a base64-encoded image into the position where you want in the text.\n## Local file path\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\", \"image\": \"file:///path/to/your/image.jpg\"},\n            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n        ],\n    }\n]\n## Image URL\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\", \"image\": \"http://path/to/your/image.jpg\"},\n            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n        ],\n    }\n]\n## Base64 encoded image\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\", \"image\": \"data:image;base64,/9j/...\"},\n            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n        ],\n    }\n]\n```\n\n#### Image Resolution for performance boost\n\nThe model supports a wide range of resolution inputs. By default, it uses the native resolution for input, but higher resolutions can enhance performance at the cost of more computation. Users can set the minimum and maximum number of pixels to achieve an optimal configuration for their needs, such as a token count range of 256-1280, to balance speed and memory usage.\n\n```python\nmin_pixels = 256 * 28 * 28\nmax_pixels = 1280 * 28 * 28\nprocessor = AutoProcessor.from_pretrained(\n    \"Qwen/Qwen2.5-VL-32B-Instruct\", min_pixels=min_pixels, max_pixels=max_pixels\n)\n```\n\nBesides, We provide two methods for fine-grained control over the image size input to the model:\n\n1. Define min_pixels and max_pixels: Images will be resized to maint",
      "public": true,
      "version": "0be1ef2c-7f8c-5cf0-8e40-4b86cf7db405",
      "tool_description": null,
      "slug": "chutes-qwen-qwen2-5-vl-32b-instruct",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-03-25T09:38:34.248725Z",
      "updated_at": "2025-10-09T18:49:14.021101Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "exclude": [
          "b200",
          "mi300x",
          "h200"
        ],
        "include": null,
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.888888888888889,
        "supported_gpus": [
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 187427,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.05,
            "tao": 0.000124176060792625
          },
          "output": {
            "usd": 0.22,
            "tao": 0.000546374667487553
          }
        },
        "usd": {
          "hour": 4,
          "second": 0.00111111111111111
        },
        "tao": {
          "hour": 0.00993408486341006,
          "second": 0.000002759468017613
        }
      },
      "instances": [
        {
          "instance_id": "1df3d892-21ab-49d4-8903-019e43e291bd",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:12:20.290688Z"
        },
        {
          "instance_id": "6fbc59b2-e301-4541-891a-86850103874d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:12:20.290688Z"
        },
        {
          "instance_id": "ac5e0368-4027-44f7-aae9-48197b889e64",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:12:20.290688Z"
        },
        {
          "instance_id": "bcd98944-cdc9-4d60-b6d8-b7dab433c859",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:12:20.290688Z"
        },
        {
          "instance_id": "0f96c291-ac43-4dcd-ae77-92f50d3bb48f",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:12:20.290688Z"
        }
      ],
      "logo_id": "58d29b56-acd5-42bf-be97-8bfd41e91ff5",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "6bcf1c9155874e6961bcf82792681b4f4421d2f7",
      "concurrency": 16,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/58d29b56-acd5-42bf-be97-8bfd41e91ff5.webp",
      "hot": true
    },
    {
      "chute_id": "aef797d4-f375-5beb-9986-3ad245947469",
      "name": "tngtech/DeepSeek-R1T-Chimera",
      "tagline": "DeepSeek-R1T-Chimera is an open-source merged model combining DeepSeek-R1's intelligence with DeepSeek-V3's token efficiency, making it well-suited for general-purpose tasks requiring both strong reasoning capabilities and efficient token processing.",
      "readme": "# DeepSeek-R1T-Chimera\n\n\u003Cdiv align=\"center\"\u003E\n\u003Cimg src=\"https://354918363417-runtime-assets.s3.eu-central-1.amazonaws.com/company_logo_light.svg\"\n     alt=\"TNG Logo\" \n     width=\"400\"\n     style=\"display: inline-block; vertical-align: middle;\"/\u003E\n\u003C/div\u003E\n\u003Cbr\u003E\n\u003Cdiv align=\"center\"\u003E\n  \u003Ca href=\"LICENSE\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"License\" src=\"https://img.shields.io/badge/License-MIT-f5de53?&color=f5de53\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\u003Cbr\u003E\n\u003Cdiv align=\"center\"\u003E\n  \u003Ca href=\"https://x.com/tngtech/status/1916284566127444468\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Benchmarks\" src=\"R1T-Chimera_Benchmarks_20250427_V1.jpg\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\n\n**Model merge of DeepSeek-R1 and DeepSeek-V3 (0324)**\n\nAn open weights model combining the intelligence of R1 with the token efficiency of V3.\n\nFor details on the construction process and analyses of Chimera model variants, please [read our paper](https://arxiv.org/abs/2506.14794). \n\n[Paper on arXiV](https://arxiv.org/abs/2506.14794) | [Announcement on X](https://x.com/tngtech/status/1916284566127444468) | [LinkedIn post](https://www.linkedin.com/posts/tng-technology-consulting_on-the-weekend-we-released-deepseek-r1t-chimera-activity-7323008947236290560-Cf2m) | [Try it on OpenRouter](https://openrouter.ai/tngtech/deepseek-r1t-chimera:free)\n\n**Update:** we released [R1T2-Chimera](https://huggingface.co/tngtech/DeepSeek-TNG-R1T2-Chimera) that is both faster *and* smarter than R1.\n\n\n## Model Details\n\n- **Architecture**: DeepSeek-MoE Transformer-based language model\n- **Combination Method**: Merged model weights from DeepSeek-R1 and DeepSeek-V3 (0324)\n- **Release Date**: 2025-04-27\n\n## Use, Out-of-scope Use, Limitations, Risks, Recommendations et al\nRegarding R1T Chimera, we ask you to follow the careful guidelines that Microsoft has created for their \"MAI-DS-R1\" DeepSeek-based model. \n\nThese guidelines are available [here on Hugging Face](https://huggingface.co/microsoft/MAI-DS-R1).\n\n## Contact\n\n- Email: research@tngtech.com\n- X.com: @tngtech\n\n## Citation\n\n```\n@misc{tng_technology_consulting_gmbh_2025,\n\tauthor       = { TNG Technology Consulting GmbH },\n\ttitle        = { DeepSeek-R1T-Chimera },\n\tyear         = 2025,\n    month        = {April},\n\turl          = { https://huggingface.co/tngtech/DeepSeek-R1T-Chimera },\n\tdoi          = { 10.57967/hf/5330 },\n\tpublisher    = { Hugging Face }\n}\n\n```",
      "public": true,
      "version": "0b4d6397-e753-5e95-a11a-ea5a035257fa",
      "tool_description": null,
      "slug": "chutes-tngtech-deepseek-r1t-chimera",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-04-27T08:27:51.957755Z",
      "updated_at": "2025-10-08T15:17:04.196105Z",
      "image": {
        "image_id": "959721f7-6184-549f-bd66-546c8868b9f7",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100800",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T14:43:47.661711Z",
        "build_started_at": "2025-10-08T14:44:11.231501Z",
        "build_completed_at": "2025-10-08T15:10:23.923875Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "df8eef013628",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 187373,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.3,
            "tao": 0.000745056364755754
          },
          "output": {
            "usd": 1.2,
            "tao": 0.00298022545902302
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "3089eec6-cda8-4973-920b-b7db3026385f",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:45.134798Z"
        },
        {
          "instance_id": "ed84d423-c2d5-4d15-a8b5-d0f87c50d4ab",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:45.134798Z"
        },
        {
          "instance_id": "da183156-5346-4079-b5db-db3df6e55539",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:45.134798Z"
        },
        {
          "instance_id": "22663292-6ecc-4b75-a359-05ec47716945",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:45.134798Z"
        },
        {
          "instance_id": "e36fae17-1ca4-4287-b6e4-ab6a014c3b0d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:45.134798Z"
        }
      ],
      "logo_id": "fbf435ef-b0fb-4110-a25c-80fc9e2c5ce7",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "66488d22ff2766fa9ce829c7445aea7618b1aa4e",
      "concurrency": 24,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/fbf435ef-b0fb-4110-a25c-80fc9e2c5ce7.webp",
      "hot": true
    },
    {
      "chute_id": "52bebe99-e55f-5bee-a386-b293b6e762c5",
      "name": "openai/gpt-oss-20b",
      "tagline": "GPT-OSS-20B is a 21B parameter open source language model (with 3.6B active parameters) designed for local deployment and specialized use cases requiring reasoning, agent-like behaviors, and developer integration.",
      "readme": "\n\u003Cp align=\"center\"\u003E\n  \u003Cimg alt=\"gpt-oss-20b\" src=\"https://raw.githubusercontent.com/openai/gpt-oss/main/docs/gpt-oss-20b.svg\"\u003E\n\u003C/p\u003E\n\n\u003Cp align=\"center\"\u003E\n  \u003Ca href=\"https://gpt-oss.com\"\u003E\u003Cstrong\u003ETry gpt-oss\u003C/strong\u003E\u003C/a\u003E Â·\n  \u003Ca href=\"https://cookbook.openai.com/topic/gpt-oss\"\u003E\u003Cstrong\u003EGuides\u003C/strong\u003E\u003C/a\u003E Â·\n  \u003Ca href=\"https://arxiv.org/abs/2508.10925\"\u003E\u003Cstrong\u003EModel card\u003C/strong\u003E\u003C/a\u003E Â·\n  \u003Ca href=\"https://openai.com/index/introducing-gpt-oss/\"\u003E\u003Cstrong\u003EOpenAI blog\u003C/strong\u003E\u003C/a\u003E\n\u003C/p\u003E\n\n\u003Cbr\u003E\n\nWelcome to the gpt-oss series, [OpenAIâ€™s open-weight models](https://openai.com/open-models) designed for powerful reasoning, agentic tasks, and versatile developer use cases.\n\nWeâ€™re releasing two flavors of these open models:\n- `gpt-oss-120b` â€” for production, general purpose, high reasoning use cases that fit into a single 80GB GPU (like NVIDIA H100 or AMD MI300X) (117B parameters with 5.1B active parameters)\n- `gpt-oss-20b` â€” for lower latency, and local or specialized use cases (21B parameters with 3.6B active parameters)\n\nBoth models were trained on our [harmony response format](https://github.com/openai/harmony) and should only be used with the harmony format as it will not work correctly otherwise.\n\n\n\u003E [!NOTE]\n\u003E This model card is dedicated to the smaller `gpt-oss-20b` model. Check out [`gpt-oss-120b`](https://huggingface.co/openai/gpt-oss-120b) for the larger model.\n\n# Highlights\n\n* **Permissive Apache 2.0 license:** Build freely without copyleft restrictions or patent riskâ€”ideal for experimentation, customization, and commercial deployment.  \n* **Configurable reasoning effort:** Easily adjust the reasoning effort (low, medium, high) based on your specific use case and latency needs.  \n* **Full chain-of-thought:** Gain complete access to the modelâ€™s reasoning process, facilitating easier debugging and increased trust in outputs. Itâ€™s not intended to be shown to end users.  \n* **Fine-tunable:** Fully customize models to your specific use case through parameter fine-tuning.\n* **Agentic capabilities:** Use the modelsâ€™ native capabilities for function calling, [web browsing](https://github.com/openai/gpt-oss/tree/main?tab=readme-ov-file#browser), [Python code execution](https://github.com/openai/gpt-oss/tree/main?tab=readme-ov-file#python), and Structured Outputs.\n* **MXFP4 quantization:** The models were post-trained with MXFP4 quantization of the MoE weights, making `gpt-oss-120b` run on a single 80GB GPU (like NVIDIA H100 or AMD MI300X) and the `gpt-oss-20b` model run within 16GB of memory. All evals were performed with the same MXFP4 quantization.\n\n---\n\n# Inference examples\n\n## Transformers\n\nYou can use `gpt-oss-120b` and `gpt-oss-20b` with Transformers. If you use the Transformers chat template, it will automatically apply the [harmony response format](https://github.com/openai/harmony). If you use `model.generate` directly, you need to apply the harmony format manually using the chat template or use our [openai-harmony](https://github.com/openai/harmony) package.\n\nTo get started, install the necessary dependencies to setup your environment:\n\n```\npip install -U transformers kernels torch \n```\n\nOnce, setup you can proceed to run the model by running the snippet below:\n\n```py\nfrom transformers import pipeline\nimport torch\n\nmodel_id = \"openai/gpt-oss-20b\"\n\npipe = pipeline(\n    \"text-generation\",\n    model=model_id,\n    torch_dtype=\"auto\",\n    device_map=\"auto\",\n)\n\nmessages = [\n    {\"role\": \"user\", \"content\": \"Explain quantum mechanics clearly and concisely.\"},\n]\n\noutputs = pipe(\n    messages,\n    max_new_tokens=256,\n)\nprint(outputs[0][\"generated_text\"][-1])\n```\n\nAlternatively, you can run the model via [`Transformers Serve`](https://huggingface.co/docs/transformers/main/serving) to spin up a OpenAI-compatible webserver:\n\n```\ntransformers serve\ntransformers chat localhost:8000 --model-name-or-path openai/gpt-oss-20b\n```\n\n[Learn more about how to use gpt-oss with Transformers.](https://cookbook.openai.com/articles/gpt-oss/run-transformers)\n\n## vLLM\n\nvLLM recommends using [uv](https://docs.astral.sh/uv/) for Python dependency management. You can use vLLM to spin up an OpenAI-compatible webserver. The following command will automatically download the model and start the server.\n\n```bash\nuv pip install --pre vllm==0.10.1+gptoss \\\n    --extra-index-url https://wheels.vllm.ai/gpt-oss/ \\\n    --extra-index-url https://download.pytorch.org/whl/nightly/cu128 \\\n    --index-strategy unsafe-best-match\n\nvllm serve openai/gpt-oss-20b\n```\n\n[Learn more about how to use gpt-oss with vLLM.](https://cookbook.openai.com/articles/gpt-oss/run-vllm)\n\n## PyTorch / Triton\n\nTo learn about how to use this model with PyTorch and Triton, check out our [reference implementations in the gpt-oss repository](https://github.com/openai/gpt-oss?tab=readme-ov-file#reference-pytorch-implementation).\n\n## Ollama\n\nIf you are trying to run gpt-oss on consumer hardware, you can use Ollama by running the following commands after [installing Ollama](https://ollama.com/download).\n\n```bash\n# gpt-oss-20b\nollama pull gpt-oss:20b\nollama run gpt-oss:20b\n```\n\n[Learn more about how to use gpt-oss with Ollama.](https://cookbook.openai.com/articles/gpt-oss/run-locally-ollama)\n\n#### LM Studio\n\nIf you are using [LM Studio](https://lmstudio.ai/) you can use the following commands to download.\n\n```bash\n# gpt-oss-20b\nlms get openai/gpt-oss-20b\n```\n\nCheck out our [awesome list](https://github.com/openai/gpt-oss/blob/main/awesome-gpt-oss.md) for a broader collection of gpt-oss resources and inference partners.\n\n---\n\n# Download the model\n\nYou can download the model weights from the [Hugging Face Hub](https://huggingface.co/collections/openai/gpt-oss-68911959590a1634ba11c7a4) directly from Hugging Face CLI:\n\n```shell\n# gpt-oss-20b\nhuggingface-cli download openai/gpt-oss-20b --include \"original/*\" --local-dir gpt-oss-20b/\npip install gpt-oss\npython -m gpt_oss.chat model/\n```\n\n# Reasoning levels\n\nYou can adjust the reasoning level that suits your task across three levels:\n\n* **Low:** Fast responses for general dialogue.  \n* **Medium:** Balanced speed and detail.  \n* **High:** Deep and detailed analysis.\n\nThe reasoning level can be set in the system prompts, e.g., \"Reasoning: high\".\n\n# Tool use\n\nThe gpt-oss models are excellent for:\n* Web browsing (using built-in browsing tools)\n* Function calling with defined schemas\n* Agentic operations like browser tasks\n\n# Fine-tuning\n\nBoth gpt-oss models can be fine-tuned for a variety of specialized use cases.\n\nThis smaller model `gpt-oss-20b` can be fine-tuned on consumer hardware, whereas the larger [`gpt-oss-120b`](https://huggingface.co/openai/gpt-oss-120b) can be fine-tuned on a single H100 node.\n\n# Citation\n\n```bibtex\n@misc{openai2025gptoss120bgptoss20bmodel,\n      title={gpt-oss-120b & gpt-oss-20b Model Card}, \n      author={OpenAI},\n      year={2025},\n      eprint={2508.10925},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2508.10925}, \n}\n```",
      "public": true,
      "version": "b659f58c-370f-56c1-816f-7ca873757e49",
      "tool_description": null,
      "slug": "chutes-openai-gpt-oss-20b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-08-19T13:46:09.940588Z",
      "updated_at": "2025-10-08T15:18:40.178227Z",
      "image": {
        "image_id": "959721f7-6184-549f-bd66-546c8868b9f7",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100800",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T14:43:47.661711Z",
        "build_started_at": "2025-10-08T14:44:11.231501Z",
        "build_completed_at": "2025-10-08T15:10:23.923875Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "df8eef013628",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h100",
          "h200",
          "h100_sxm"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.397777777777778,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 179502,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0,
            "tao": 0
          },
          "output": {
            "usd": 0,
            "tao": 0
          }
        },
        "usd": {
          "hour": 0,
          "second": 0
        },
        "tao": {
          "hour": 0,
          "second": 0
        }
      },
      "instances": [
        {
          "instance_id": "3afb5972-bf39-4c6f-8409-3275c539560d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:17:24.762443Z"
        },
        {
          "instance_id": "5395f66c-8913-4d38-9877-5b766b9d2418",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:17:24.762443Z"
        },
        {
          "instance_id": "99a6a823-2017-428c-b36e-92a5ab085289",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:17:24.762443Z"
        },
        {
          "instance_id": "a980be38-33ae-4f00-8aab-896ae38fcf6e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:17:24.762443Z"
        },
        {
          "instance_id": "ade1bc47-e684-47f5-9bde-a1bed2f1e25c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:17:24.762443Z"
        }
      ],
      "logo_id": "d9be0d51-5ed4-4483-9bb9-ef8411d23e39",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "6cd4d0ffba39483fe4fb0f5637831f717dafca35",
      "concurrency": 40,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/d9be0d51-5ed4-4483-9bb9-ef8411d23e39.webp",
      "hot": true
    },
    {
      "chute_id": "b46ddcc1-3104-5955-8010-a84b57f62219",
      "name": "samoline/e9729fda-9a6b-44ee-a717-7afdc47f0da8",
      "tagline": "",
      "readme": "samoline/e9729fda-9a6b-44ee-a717-7afdc47f0da8",
      "public": true,
      "version": "d31389e1-4fd6-5901-a49d-c0c7f44d6264",
      "tool_description": null,
      "slug": "gradients-samoline-e9729fda-9a6b-44ee-a717-7afdc47f0da8",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-08-14T10:15:27.786480Z",
      "updated_at": "2025-08-14T10:15:27.786480Z",
      "image": {
        "image_id": "dd30a5e7-24ae-538e-bee7-ba6a93b3d2f0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "0.4.9.post6",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-08-06T20:56:26.489668Z",
        "build_started_at": "2025-08-06T20:56:28.092938Z",
        "build_completed_at": "2025-08-06T21:28:45.347952Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "65013002be06",
        "logo": null
      },
      "user": {
        "username": "gradients",
        "user_id": "8baddea0-3891-5c6b-b02b-3567eb38ca03",
        "logo_id": "72372fad-eebb-4b1e-a966-b4e78b534a56",
        "created_at": "2025-02-11T16:50:24.482536Z",
        "logo": "https://logos.chutes.ai/logos/72372fad-eebb-4b1e-a966-b4e78b534a56.webp"
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "exclude": [
          "h200",
          "mi300x",
          "b200"
        ],
        "include": null,
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.444444444444444,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 171406,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          },
          "output": {
            "usd": 0.11,
            "tao": 0.000273187333743776
          }
        },
        "usd": {
          "hour": 2,
          "second": 0.000555555555555555
        },
        "tao": {
          "hour": 0.00496704243170503,
          "second": 0.000001379734008806
        }
      },
      "instances": [
        {
          "instance_id": "c1b73c5e-edf0-4065-81b9-e72e289ae058",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:43.685916Z"
        },
        {
          "instance_id": "2eeadbc9-b1e1-4001-aca9-d5937a049367",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:43.685916Z"
        },
        {
          "instance_id": "8ff24f10-9d56-4dd2-aa95-576e893f260b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:43.685916Z"
        },
        {
          "instance_id": "bdc9b6fa-e1b4-41be-93f3-7b3cd8255557",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:43.685916Z"
        },
        {
          "instance_id": "7f9e8a2d-8c71-4c27-9ddb-fad9be015e6f",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:43.685916Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.31.rc1",
      "revision": "bd42e3520189033b45e96c65a5d1a57686ab1940",
      "concurrency": 20,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "b20fe05c-52c6-594a-b7c6-5c68f3153df3",
      "name": "NousResearch/DeepHermes-3-Llama-3-8B-Preview",
      "tagline": "DeepHermes 3 is an 8B parameter open-source LLM that uniquely combines traditional chat responses with long-chain reasoning capabilities, making it especially useful for tasks requiring detailed analysis or step-by-step problem solving.",
      "readme": "# DeepHermes 3 - Llama-3.1 8B\n\n![image/jpeg](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/9fxlaDxteqe3SasZ7_06_.jpeg)\n\n## Model Description\n\nDeepHermes 3 Preview is the latest version of our flagship Hermes series of LLMs by Nous Research, and one of the first models in the world to unify Reasoning (long chains of thought that improve answer accuracy) and normal LLM response modes into one model. We have also improved LLM annotation, judgement, and function calling.\n\nDeepHermes 3 Preview is one of the first LLM models to unify both \"intuitive\", traditional mode responses and **long chain of thought reasoning** responses into a single model, toggled by a system prompt.\n\nHermes 3, the predecessor of DeepHermes 3, is a generalist language model with many improvements over Hermes 2, including advanced agentic capabilities, much better roleplaying, reasoning, multi-turn conversation, long context coherence, and improvements across the board.\n\nThe ethos of the Hermes series of models is focused on aligning LLMs to the user, with powerful steering capabilities and control given to the end user.\n\n*This is a preview Hermes with early reasoning capabilities, distilled from R1 across a variety of tasks that benefit from reasoning and objectivity. Some quirks may be discovered! Please let us know any interesting findings or issues you discover!*\n\n## Note: To toggle REASONING ON, you must use the following system prompt:\n```\nYou are a deep thinking AI, you may use extremely long chains of thought to deeply consider the problem and deliberate with yourself via systematic reasoning processes to help come to a correct solution prior to answering. You should enclose your thoughts and internal monologue inside \u003Cthink\u003E \u003C/think\u003E tags, and then provide your solution or response to the problem.\n```  \n\n# Nous API\n\nThis model is also available on our new API product - Check out the API and sign up for the waitlist here:\nhttps://portal.nousresearch.com/\n\n# Example Outputs:\n\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/_giUevm1IjPFWiypG0zd4.png)\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/bAI0HG2cFA_o1hTFIfCr_.png)\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/FmOIB7fjXKVHfs94DJPwn.png)\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/tfL1jeGXvv7xTAULFQgqs.png)\n\n# Benchmarks\n\n## Benchmarks for **Reasoning Mode** on vs off:\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/O_sgWq4CVPuxuKYqHWkkN.png)\n\n*Reasoning ON benchmarks aquired by running HuggingFace's open-r1 reasoning mode evaluation suite, and scores for reasoning mode OFF aquired by running LM-Eval-Harness Benchmark Suite* \n*Upper bound determined by measuring the % gained over Hermes 3 3 & 70b by MATH_VERIFY compared to eleuther eval harness, which ranged betweeen 33% and 50% gain in MATH Hard benchmark on retested models by them compared to eval harness reported scores*\n\n## Benchmarks in **Non-Reasoning Mode** against Llama-3.1-8B-Instruct\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/hZCJa8g8smOS9BcQSXAd1.png)\n\n# Prompt Format\n\nDeepHermes 3 now uses Llama-Chat format as the prompt format, opening up a more unified, structured system for engaging the LLM in multi-turn chat dialogue.\n\nSystem prompts allow steerability and interesting new ways to interact with an LLM, guiding rules, roles, and stylistic choices of the model.\n\n## Deep Thinking Mode - Deep Hermes Preview can activate long chain of thought with a system prompt.\n\n```\nYou are a deep thinking AI, you may use extremely long chains of thought to deeply consider the problem and deliberate with yourself via systematic reasoning processes to help come to a correct solution prior to answering. You should enclose your thoughts and internal monologue inside \u003Cthink\u003E \u003C/think\u003E tags, and then provide your solution or response to the problem.\n```\n\nFor an example of using deep reasoning mode with HuggingFace Transformers:\n```python\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport flash_attn\nimport time\n\ntokenizer = AutoTokenizer.from_pretrained(\"NousResearch/DeepHermes-3-Llama-3-8B-Preview\")\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"NousResearch/DeepHermes-3-Llama-3-8B-Preview\",\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    attn_implementation=\"flash_attention_2\",\n)\n\nmessages = [\n    {\n        \"role\": \"system\",\n        \"content\": \"You are a deep thinking AI, you may use extremely long chains of thought to deeply consider the problem and deliberate with yourself via systematic reasoning processes to help come to a correct solution prior to answering. You should enclose your thoughts and internal monologue inside \u003Cthink\u003E \u003C/think\u003E tags, and then provide your solution or response to the problem.\"\n    },\n    {\n        \"role\": \"user\",\n        \"content\": \"What is y if y=2*2-4+(3*2)\"\n    }\n]\n\ninput_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors='pt').to(\"cuda\")\ngenerated_ids = model.generate(input_ids, max_new_tokens=2500, temperature=0.8, repetition_penalty=1.1, do_sample=True, eos_token_id=tokenizer.eos_token_id)\nprint(f\"Generated Tokens: {generated_ids.shape[-1:]}\")\nresponse = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_space=True)\nprint(f\"Response: {response}\")\n```\n\nPlease note, for difficult problems DeepHermes can think using as many as 13,000 tokens. You may need to increase `max_new_tokens` to be much larger than 2500 for difficult problems.\n\n## Standard \"Intuitive\" Response Mode\n\nPrompt with system instruction (Use whatever system prompt you like, this is just an example!):\n\n```python\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport flash_attn\nimport time\n\ntokenizer = AutoTokenizer.from_pretrained(\"NousResearch/DeepHermes-3-Llama-3-8B-Preview\")\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"NousResearch/DeepHermes-3-Llama-3-8B-Preview\",\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    attn_implementation=\"flash_attention_2\",\n)\n\nmessages = [\n    {\n        \"role\": \"system\",\n        \"content\": \"You are Hermes, an AI assistant\"\n    },\n    {\n        \"role\": \"user\",\n        \"content\": \"What are the most interesting things to do in Paris?\"\n    }\n]\n\ninput_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors='pt').to(\"cuda\")\ngenerated_ids = model.generate(input_ids, max_new_tokens=2500, temperature=0.8, repetition_penalty=1.1, do_sample=True, eos_token_id=tokenizer.eos_token_id)\nprint(f\"Generated Tokens: {generated_ids.shape[-1:]}\")\nresponse = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_space=True)\nprint(f\"Response: {response}\")\n```\n\n## VLLM Inference\n\nYou can also run this model with vLLM, by running the following in your terminal after `pip install vllm`\n\n`vllm serve NousResearch/DeepHermes-3-Llama-3-8B-Preview`\n\nYou may then use the model over API using the OpenAI library just like you would call OpenAI's API.\n\n## Prompt Format for Function Calling\n\nOur model was trained on specific system prompts and structures for Function Calling. \n\nYou should use the system role with this message, followed by a function signature json as this example shows here.\n```\n\u003C|start_header_id|\u003Esystem\u003C|end_header_id|\u003E\nYou are a function calling AI model. You are provided with function signatures within \u003Ctools\u003E\u003C/tools\u003E XML tags. You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools: \u003Ctools\u003E {\"type\": \"function\", \"function\": {\"name\": \"get_stock_fundamentals\", \"description\": \"get_stock_fundamentals(symbol: str) -\u003E dict - Get fundamental data for a given stock symbol using yfinance API.\\\\n\\\\n    Args:\\\\n        symbol (str): The stock symbol.\\\\n\\\\n    Returns:\\\\n        dict: A dictionary containing fundamental data.\\\\n            Keys:\\\\n                - \\'symbol\\': The stock symbol.\\\\n                - \\'company_name\\': The long name of the company.\\\\n                - \\'sector\\': The sector to which the company belongs.\\\\n                - \\'industry\\': The industry to which the company belongs.\\\\n                - \\'market_cap\\': The market capitalization of the company.\\\\n                - \\'pe_ratio\\': The forward price-to-earnings ratio.\\\\n                - \\'pb_ratio\\': The price-to-book ratio.\\\\n                - \\'dividend_yield\\': The dividend yield.\\\\n                - \\'eps\\': The trailing earnings per share.\\\\n                - \\'beta\\': The beta value of the stock.\\\\n                - \\'52_week_high\\': The 52-week high price of the stock.\\\\n                - \\'52_week_low\\': The 52-week low price of the stock.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"symbol\": {\"type\": \"string\"}}, \"required\": [\"symbol\"]}}}  \u003C/tools\u003E Use the following pydantic model json schema for each tool call you will make: {\"properties\": {\"arguments\": {\"title\": \"Arguments\", \"type\": \"object\"}, \"name\": {\"title\": \"Name\", \"type\": \"string\"}}, \"required\": [\"arguments\", \"name\"], \"title\": \"FunctionCall\", \"type\": \"object\"} For each function call return a json object with function name and arguments within \u003Ctool_call\u003E\u003C/tool_call\u003E XML tags as follows:\n\u003Ctool_call\u003E\n{\"arguments\": \u003Cargs-dict\u003E, \"name\": \u003Cfunction-name\u003E}\n\u003C/tool_call\u003E\u003C|eot_id|\u003E\u003C|start_header_id|\u003Euser\u003C|end_header_id|\u003E\n```\n\nTo complete the function call, create a user prompt that follows the above system prompt, like so:\n```\nFetch the stock fundamentals data for Tesla (TSLA)\u003C|eot_id|\u003E\u003C|start_header_id|\u003Eassistant\u003C|end_header_id|\u003E\n```\n\nThe model will then generate a tool call, which your inference code must parse, and plug into a function (see example inference code here: https://github.com/NousResearch/Hermes-Function-Calling):\n```\n\u003Ctool_call\u003E\n{\"arguments\": {\"symbol\": \"TSLA\"}, \"name\": \"get_stock_fundamentals\"}\n\u003C/tool_call\u003E\u003C|eot_id|\u003E\u003C|start_header_id|\u003Etool\u003C|end_header_id|\u003E\n```\n\nOnce you parse the tool call, call the api and get the returned values for the call, and pass it back in as a new role, `tool` like so:\n```\n\u003Ctool_response\u003E\n{\"name\": \"get_stock_fundamentals\", \"content\": {'symbol': 'TSLA', 'company_name': 'Tesla, Inc.', 'sector': 'Consumer Cyclical', 'industry': 'Auto Manufacturers', 'market_cap': 611384164352, 'pe_ratio': 49.604652, 'pb_ratio': 9.762013, 'dividend_yield': None, 'eps': 4.3, 'beta': 2.427, '52_week_high': 299.29, '52_week_low': 152.37}}\n\u003C/tool_response\u003E\n\u003C|eot_id|\u003E\u003C|start_header_id|\u003Eassistant\u003C|end_header_id|\u003E\n```\n\nThe assistant will then read in that data from the function's response, and generate a natural language response:\n```\nThe stock fundamentals data for Tesla (TSLA) are as follows:\n- **Symbol**: TSLA\n- **Company Name**: Tesla, Inc.\n- **Sector**: Consumer Cyclical\n- **Industry**: Auto Manufacturers\n- **Market Capitalization**: $566,160,130,480\n- **Forward Price-to-Earnings Ratio (PE Ratio)**: 42.73\n- **Price-to-Book Ratio (PB Ratio)**: 9.04\n- **Dividend Yield**: N/A\n- **Trailing Earnings Per Share (EPS)**: $4.3\n- **Beta Value of the Stock**: 2.42\n- **52-Week High Price of the Stock**: $299.29\n- **52-Week Low Price of the Stock**: $152.37\n\nThis information provides a snapshot of Tesla's financial position and performance based on the fundamental data obtained from the yfinance API. It shows that Tesla has a substantial market capitalization and a relatively high P/E and P/B ratio compared to other stocks in its industry. The company does not pay a dividend at the moment, which is reflected by a 'Dividend Yield' of 'None'. The Beta value indicates that Tesla's stock has a moderate level of volatility relative to the market. The 52-week high and low prices give an idea of the stock's range over the past year. This data can be useful when assessing investment opportunities and making investment decisions.\u003C|eot_id|\u003E\u003C|start_header_id|\u003Euser\u003C|end_header_id|\u003E\n```\n\n\n## Prompt Format for JSON Mode / Structured Outputs\n\nOur model was also trained on a specific system prompt for Structured Outputs, which should respond with **only** a json object response, in a specific json schema.\n\nYour schema can be made from a pydantic object using our codebase, with the standalone script `jsonmode.py` available here: https://github.com/NousResearch/Hermes-Function-Calling/tree/main\n\n```\n\u003C|start_header_id|\u003Esystem\u003C|end_header_id|\u003E\nYou are a helpful assistant that answers in JSON. Here's the json schema you must adhere to:\\n\u003Cschema\u003E\\n{schema}\\n\u003C/schema\u003E\u003C|eot_id|\u003E\n```\n\nGiven the {schema} that you provide, it should follow the format of that json to create its response, all you have to do is give a typical user prompt, and it will respond in JSON.\n\n\n## Inference Code for Function Calling:\n\nAll code for utilizing, parsing, and building function calling templates is available on our github:\n[https://github.com/NousResearch/Hermes-Function-Calling](https://github.com/NousResearch/Hermes-Function-Calling)\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/oi4CiGh50xmoviUQnh8R3.png)\n\n\n## Quantized Versions:\n\nGGUF Quants: https://huggingface.co/NousResearch/DeepHermes-3-Llama-3-8B-Preview-GGUF\n\n# How to cite:\n\n```bibtext\n@misc{\n      title={DeepHermes 3 Preview}, \n      author={Teknium and Roger Jin and Chen Guang and Jai Suphavadeeprasit and Jeffrey Quesnelle},\n      year={2025}\n}\n```",
      "public": true,
      "version": "d79116c0-c5ea-5df3-ad75-7ffbdd12bb01",
      "tool_description": null,
      "slug": "chutes-nousresearch-deephermes-3-llama-3-8b-preview",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "7e4c99c5-31f0-5254-869e-711c84e4423a",
      "created_at": "2025-03-22T12:42:50.583414Z",
      "updated_at": "2025-09-17T09:57:46.606542Z",
      "image": {
        "image_id": "5427328c-13a0-5f9b-bd8f-8cadecd21ead",
        "name": "vllm",
        "readme": "## vLLM - fast, flexible llm inference",
        "tag": "0.10.1.1.p2",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-09-12T08:53:59.354698Z",
        "build_started_at": "2025-09-12T08:54:01.636997Z",
        "build_completed_at": "2025-09-12T09:24:51.096759Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "29dc2bbc7666",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "5090",
        "3090",
        "a100",
        "h100_nvl",
        "a5000",
        "h20",
        "pro_6000",
        "l4",
        "a6000_ada",
        "a100_40gb",
        "h100",
        "h100_sxm",
        "a100_40gb_sxm",
        "h800",
        "a10",
        "a100_sxm",
        "l40s",
        "4090"
      ],
      "node_selector": {
        "exclude": [
          "a6000",
          "l40",
          "a40",
          "mi300x",
          "b200",
          "h200"
        ],
        "include": null,
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.444444444444444,
        "supported_gpus": [
          "5090",
          "3090",
          "a100",
          "h100_nvl",
          "a5000",
          "h20",
          "pro_6000",
          "l4",
          "a6000_ada",
          "a100_40gb",
          "h100",
          "h100_sxm",
          "a100_40gb_sxm",
          "h800",
          "a10",
          "a100_sxm",
          "l40s",
          "4090"
        ]
      },
      "invocation_count": 151600,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          },
          "output": {
            "usd": 0.11,
            "tao": 0.000273187333743776
          }
        },
        "usd": {
          "hour": 2,
          "second": 0.000555555555555555
        },
        "tao": {
          "hour": 0.00496704243170503,
          "second": 0.000001379734008806
        }
      },
      "instances": [
        {
          "instance_id": "dc836615-4389-482e-ba9b-4381c3f1d34e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:35.712823Z"
        },
        {
          "instance_id": "0e826c6a-d163-478f-943b-1fd84d14f94e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:35.712823Z"
        },
        {
          "instance_id": "5f47c050-28e5-4850-a3ed-46679ad95aa4",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:35.712823Z"
        },
        {
          "instance_id": "0745218a-870b-4013-873b-5e2a0fcc4992",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:35.712823Z"
        },
        {
          "instance_id": "8bd8f3f8-abe7-40a6-89f8-6b08ae533d29",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:35.712823Z"
        }
      ],
      "logo_id": "ff22c5e8-8634-418e-947c-fa57204e707a",
      "openrouter": true,
      "chutes_version": "0.3.31.rc1",
      "revision": "53d902c7dcfa4c749a3b455149064f82af2e2549",
      "concurrency": 32,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/ff22c5e8-8634-418e-947c-fa57204e707a.webp",
      "hot": true
    },
    {
      "chute_id": "280c45ab-76fb-504c-bbbe-4974fa1623f4",
      "name": "rayonlabs/Gradients-Instruct-8B",
      "tagline": "",
      "readme": "rayonlabs/Gradients-Instruct-8B",
      "public": true,
      "version": "9cd2062f-afb8-523c-b035-72d678f0ab19",
      "tool_description": null,
      "slug": "gradients-rayonlabs-gradients-instruct-8b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-08-14T11:51:03.965103Z",
      "updated_at": "2025-08-14T18:14:56.774508Z",
      "image": {
        "image_id": "dd30a5e7-24ae-538e-bee7-ba6a93b3d2f0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "0.4.9.post6",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-08-06T20:56:26.489668Z",
        "build_started_at": "2025-08-06T20:56:28.092938Z",
        "build_completed_at": "2025-08-06T21:28:45.347952Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "65013002be06",
        "logo": null
      },
      "user": {
        "username": "gradients",
        "user_id": "8baddea0-3891-5c6b-b02b-3567eb38ca03",
        "logo_id": "72372fad-eebb-4b1e-a966-b4e78b534a56",
        "created_at": "2025-02-11T16:50:24.482536Z",
        "logo": "https://logos.chutes.ai/logos/72372fad-eebb-4b1e-a966-b4e78b534a56.webp"
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "exclude": [
          "b200",
          "mi300x",
          "h200"
        ],
        "include": null,
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.444444444444444,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 146507,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          },
          "output": {
            "usd": 0.11,
            "tao": 0.000273187333743776
          }
        },
        "usd": {
          "hour": 2,
          "second": 0.000555555555555555
        },
        "tao": {
          "hour": 0.00496704243170503,
          "second": 0.000001379734008806
        }
      },
      "instances": [
        {
          "instance_id": "7a428fd1-d81d-4803-8845-f47cbdb69f69",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:06:35.253042Z"
        },
        {
          "instance_id": "89b688fe-13fb-47a6-8ea3-8b1bc1fe9360",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:06:35.253042Z"
        },
        {
          "instance_id": "b9d1908e-d6c5-4d2e-b968-edfd81487732",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:06:35.253042Z"
        },
        {
          "instance_id": "ef5b38c6-0950-48f5-8da0-b6cf705d95f1",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:06:35.253042Z"
        },
        {
          "instance_id": "fc5e14b1-dc91-4683-a253-035140fe1e64",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:06:35.253042Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.31.rc1",
      "revision": "6d6c7fe3cc293a7d3a2a0ad8aa4f98841c68dbed",
      "concurrency": 20,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "344f4802-b7af-569c-9f82-3a15f1f142aa",
      "name": "NousResearch/Hermes-4-70B",
      "tagline": "Hermes 4 is a 70 billion parameter open-source LLM based on Llama-3.1 that excels at reasoning tasks while remaining highly steerable, making it particularly useful for complex problem-solving in math, code, and STEM fields.",
      "readme": "\n# Hermes 4 â€” Llama-3.1 70B\n\n![image/jpeg](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/roT9o5bMYBtQziRMlaSDf.jpeg)\n\n## Model Description\n\nHermes 4 70B is a frontier, hybrid-mode **reasoning** model based on Llama-3.1-70B by Nous Research that is aligned to **you**.\n\nRead the Hermes 4 technical report here: \u003Ca href=\"https://arxiv.org/abs/2508.18255\"\u003EHermes 4 Technical Report\u003C/a\u003E\n\nChat with Hermes in Nous Chat: https://chat.nousresearch.com\n\nTraining highlights include a newly synthesized post-training corpus emphasizing verified reasoning traces, massive improvements in math, code, STEM, logic, creativity, and format-faithful outputs, while preserving general assistant quality and broadly neutral alignment.\n\n\n## Whatâ€™s new vs Hermes 3\n\n- **Post-training corpus**: Massively increased dataset size from 1M samples and 1.2B tokens to **~5M samples / ~60B tokens** blended across reasoning and non-reasoning data.\n- **Hybrid reasoning mode** with explicit `\u003Cthink\u003Eâ€¦\u003C/think\u003E` segments when the model decides to deliberate, and options to make your responses faster when you want.\n- **Reasoning** that is top quality, expressive, improves math, code, STEM, logic, and even creative writing and subjective responses.\n- **Schema adherence & structured outputs**: trained to produce valid JSON for given schemas and to repair malformed objects.\n- **Much easier to steer and align**: extreme improvements on steerability, especially on reduced refusal rates.\n\n## Our Mission: Frontier Capabilities Aligned to You\n\nIn pursuit of the mission of producing models that are open, steerable and capable of producing the full range of human expression, while being able to be aligned to your values, we created a new benchmark, RefusalBench, that tests the models willingness to be helpful in a variety of scenarios commonly disallowed by closed and open models.\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/t_HvRYPEHV0pc8iS2zHHn.png)\n\nHermes 4 achieves SOTA on RefusalBench across all popular closed and open models in being helpful and conforming to your values, without censorship.\n\n## Benchmarks (Hermes 4 70B)\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/Sa-X7ErRF0ej20P8qBv9i.png)\n\n\u003E Full tables, settings, and comparisons are in the technical report.\n\n## Prompt Format\n\nHermes 4 uses Llama-3-Chat format with role headers and special tags.\n\n**Basic chat:**\n```\n\u003C|start_header_id|\u003Esystem\u003C|end_header_id|\u003E\n\nYou are Hermes 4. Be concise and helpful.\u003C|eot_id|\u003E\n\u003C|start_header_id|\u003Euser\u003C|end_header_id|\u003E\n\nExplain the photoelectric effect simply.\u003C|im_end|\u003E\n\u003C|start_header_id|\u003Eassistant\u003C|end_header_id|\u003E\n```\n\n### Reasoning mode\n\nReasoning mode can be activated with the chat template via the flag `thinking=True` or by using the following system prompt:\n\n```\nYou are a deep thinking AI, you may use extremely long chains of thought to deeply consider the problem and deliberate with yourself via systematic reasoning processes to help come to a correct solution prior to answering. You should enclose your thoughts and internal monologue inside \u003Cthink\u003E \u003C/think\u003E tags, and then provide your solution or response to the problem.\n```\n\nNote that you can add any additional system instructions before or after this system message, and it will adjust the models policies, style, and effort of thinking, as well as its post-thinking style, format, identity, and more. You may also interleave the tool definition system message with the reasoning one. \n\nWhen the model chooses to deliberate, it emits:\n\n```\n\u003C|start_header_id|\u003Eassistant\u003C|end_header_id|\u003E\n\u003Cthink\u003E\nâ€¦modelâ€™s internal reasoning may appear hereâ€¦\n\u003C/think\u003E\nFinal response starts hereâ€¦\u003C|eot_id|\u003E\n```\n\nAdditionally, we provide a flag to keep the content inbetween the `\u003Cthink\u003E ... \u003C/think\u003E` that you can play with by setting `keep_cots=True`\n\n\n## Function Calling & Tool Use\n\nHermes 4 supports function/tool calls *within* a single assistant turn, produced after it's reasoning:\n\n**System message (example):**\n\n```\n\u003C|im_start|\u003Esystem\nYou are a function-calling AI. Tools are provided inside \u003Ctools\u003Eâ€¦\u003C/tools\u003E.\nWhen appropriate, call a tool by emitting a \u003Ctool_call\u003E{...}\u003C/tool_call\u003E object.\nAfter a tool responds (as \u003Ctool_response\u003E), continue reasoning inside \u003Cthink\u003E and produce the final answer.\n\u003Ctools\u003E\n{\"type\":\"function\",\"function\":{\"name\":\"get_weather\",\"description\":\"Get weather by city\",\"parameters\":{\"type\":\"object\",\"properties\":{\"city\":{\"type\":\"string\"}},\"required\":[\"city\"]}}}\n\u003C/tools\u003E\u003C|im_end|\u003E\n```\n\nNote that you may also simply place tool definitions into the \"tools:\" field of your messages, and the chat template will parse and create the system prompt for you. This also works with reasoning mode for improved accuracy of tool use.\n\nThe model will then generate tool calls within `\u003Ctool_call\u003E {tool_call} \u003C/tool_call\u003E` tags, for easy parsing. The tool_call tags are also added tokens, so it makes it easy to parse while streaming! There are also automatic tool parsers built-in to VLLM and SGLang for Hermes, just set the tool parser in VLLM to `hermes` and in SGLang to `qwen25`.\n\n## Inference Notes\n\n- **Sampling defaults that work well:** `temperature=0.6, top_p=0.95, top_k=20`.\n- **Template:** Use the Llama chat format for Hermes 4 70B and 405B as shown above, or set `add_generation_prompt=True` when using `tokenizer.apply_chat_template(...)`.\n\n### Transformers example\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\nmodel_id = \"NousResearch/Hermes-4-Llama-3.1-70B\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)\n\nmessages = [\n    {\"role\":\"system\",\"content\":\"You are Hermes 4. Be concise.\"},\n    {\"role\":\"user\",\"content\":\"Summarize CRISPR in 3 sentences.\"}\n]\n\ninputs = tokenizer.apply_chat_template(\n    messages, add_generation_prompt=True, return_tensors=\"pt\"\n).to(model.device)\n\noutputs = model.generate(\n    **inputs, max_new_tokens=400, temperature=0.6, top_p=0.95, top_k=20, do_sample=True\n)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))\n```\n\nFor production serving on multi-GPU nodes, consider tensor parallel inference engines (e.g., SGLang/vLLM backends) with prefix caching.\n\n## Inference Providers:\n\n### Nous Portal:\n\n\u003Ca href=\"https://portal.nousresearch.com\"\u003E\u003Cimg width=256 alt=\"chutes logo\" src=\"https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/6YytY7N0mjCnBQvWo3qtv.png\"\u003E\u003C/a\u003E\n\n### Chutes:\n\n\u003Ca href=\"https://chutes.ai/app\"\u003E\u003Cimg width=256 alt=\"chutes logo\" src=\"https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/l14AWPv6cSvaprpwK_IWY.png\"\u003E\u003C/a\u003E\n\n### Nebius:\n\n\u003Ca href=\"https://nebius.com/services/studio-inference-service\"\u003E\n\u003Cpicture\u003E\n  \u003Csource media=\"(prefers-color-scheme: dark)\" srcset=\"https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/vhL0oAomFa_awBdt2KF_x.png\"\u003E\n  \u003Csource media=\"(prefers-color-scheme: light)\" srcset=\"https://cdn-uploads.huggingface.co/production/uploads/64b21cbb2fc8324fcb1dac03/LjAfeFfAz8ac5rV-iiwj5.png\"\u003E\n  \u003Cimg width=256 alt=\"nebius.com logo\" src=\"https://cdn-uploads.huggingface.co/production/uploads/64b21cbb2fc8324fcb1dac03/LjAfeFfAz8ac5rV-iiwj5.png\"\u003E\n\u003C/picture\u003E\n\u003C/a\u003E\n\n### Luminal:\n\n\u003Ca href=\"https://luminalai.com/\"\u003E\n\u003Cimg width=256 alt=\"luminal logo\" src=\"https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/FIHsRdjMMP0HUjebiuJyH.png\"\u003E\n\u003C/a\u003E\n\n# Quantized / Smaller Variants\n\nHermes 4 is available as BF16 original weights as well as BF16 as well as FP8 variants and GGUF variants by LM Studio.\n\nFP8: https://huggingface.co/NousResearch/Hermes-4-70B-FP8\n\nGGUF (Courtesy of LM Studio team!):\nhttps://huggingface.co/lmstudio-community/Hermes-4-70B-GGUF\n\nHermes 4 is also available in smaller sizes (e.g., 70B) with similar prompt formats.\n\nSee the Hermes 4 collection to explore them all:\nhttps://huggingface.co/collections/NousResearch/hermes-4-collection-68a731bfd452e20816725728\n\n# How to cite\n\n```bibtex\n@misc{teknium2025hermes4technicalreport,\n      title={Hermes 4 Technical Report}, \n      author={Ryan Teknium and Roger Jin and Jai Suphavadeeprasit and Dakota Mahan and Jeffrey Quesnelle and Joe Li and Chen Guang and Shannon Sands and Karan Malhotra},\n      year={2025},\n      eprint={2508.18255},\n      archivePrefix={arXiv},\n      primaryClass={cs.AI},\n      url={https://arxiv.org/abs/2508.18255}, \n}\n```",
      "public": true,
      "version": "d695da9b-08cd-53e4-af6b-5c7b8192ed78",
      "tool_description": null,
      "slug": "chutes-nousresearch-hermes-4-70b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-08-26T19:21:09.645906Z",
      "updated_at": "2025-10-13T08:50:12.681382Z",
      "image": {
        "image_id": "761d22a2-c96c-5675-82df-60cddab0827e",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101200",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-12T08:53:29.416285Z",
        "build_started_at": "2025-10-12T08:53:31.172351Z",
        "build_completed_at": "2025-10-12T09:17:36.083052Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "initial",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm",
        "h800"
      ],
      "node_selector": {
        "exclude": null,
        "include": [
          "h100",
          "h100_sxm",
          "h800",
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 2.66666666666667,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm",
          "h800"
        ]
      },
      "invocation_count": 140077,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.11,
            "tao": 0.000273187333743776
          },
          "output": {
            "usd": 0.38,
            "tao": 0.000943738062023955
          }
        },
        "usd": {
          "hour": 10.8,
          "second": 0.003
        },
        "tao": {
          "hour": 0.0268220291312072,
          "second": 0.000007450563647557
        }
      },
      "instances": [
        {
          "instance_id": "50fb799f-9d98-4e36-be85-989f1027c880",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:10:53.358200Z"
        },
        {
          "instance_id": "7c18063c-d473-4c70-848c-b79762c6d3f5",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:10:53.358200Z"
        },
        {
          "instance_id": "7d1870ac-bfbe-4ce7-bec2-27f9baf86e7d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:10:53.358200Z"
        },
        {
          "instance_id": "b7cd92e4-2fad-4e54-8667-2d8a06d4988c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:10:53.358200Z"
        },
        {
          "instance_id": "84dde6ec-836e-44d6-a2f5-2ac121bbe213",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T11:14:40.447290Z"
        }
      ],
      "logo_id": "fa1c2126-58a4-4c32-ae12-360a2debd8e1",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "8635c3f88cc33e405a8ad297f05fb4f33042a533",
      "concurrency": 24,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/fa1c2126-58a4-4c32-ae12-360a2debd8e1.webp",
      "hot": true
    },
    {
      "chute_id": "118a60a5-6bd8-554c-8fda-9d394e5c0ab8",
      "name": "zai-org/GLM-Z1-32B-0414",
      "tagline": "GLM-4-Z1-32B-0414 is a 32 billion parameter open-source language model optimized for deep reasoning and complex problem-solving tasks like mathematics, code generation, and analytical writing.",
      "readme": "\n# GLM-4-Z1-32B-0414\n\n## Introduction\n\nThe GLM family welcomes a new generation of open-source models, the **GLM-4-32B-0414** series, featuring 32 billion parameters. Its performance is comparable to OpenAI's GPT series and DeepSeek's V3/R1 series, and it supports very user-friendly local deployment features. GLM-4-32B-Base-0414 was pre-trained on 15T of high-quality data, including a large amount of reasoning-type synthetic data, laying the foundation for subsequent reinforcement learning extensions. In the post-training stage, in addition to human preference alignment for dialogue scenarios, we also enhanced the model's performance in instruction following, engineering code, and function calling using techniques such as rejection sampling and reinforcement learning, strengthening the atomic capabilities required for agent tasks. GLM-4-32B-0414 achieves good results in areas such as engineering code, Artifact generation, function calling, search-based Q&A, and report generation. Some benchmarks even rival larger models like GPT-4o and DeepSeek-V3-0324 (671B).\n\n**GLM-Z1-32B-0414** is a reasoning model with **deep thinking capabilities**. This was developed based on GLM-4-32B-0414 through cold start and extended reinforcement learning, as well as further training of the model on tasks involving mathematics, code, and logic. Compared to the base model, GLM-Z1-32B-0414 significantly improves mathematical abilities and the capability to solve complex tasks. During the training process, we also introduced general reinforcement learning based on pairwise ranking feedback, further enhancing the model's general capabilities.\n\n**GLM-Z1-Rumination-32B-0414** is a deep reasoning model with **rumination capabilities** (benchmarked against OpenAI's Deep Research). Unlike typical deep thinking models, the rumination model employs longer periods of deep thought to solve more open-ended and complex problems (e.g., writing a comparative analysis of AI development in two cities and their future development plans). The rumination model integrates search tools during its deep thinking process to handle complex tasks and is trained by utilizing multiple rule-based rewards to guide and extend end-to-end reinforcement learning. Z1-Rumination shows significant improvements in research-style writing and complex retrieval tasks.\n\nFinally, **GLM-Z1-9B-0414** is a surprise. We employed the aforementioned series of techniques to train a 9B small-sized model that maintains the open-source tradition. Despite its smaller scale, GLM-Z1-9B-0414 still exhibits excellent capabilities in mathematical reasoning and general tasks. Its overall performance is already at a leading level among open-source models of the same size. Especially in resource-constrained scenarios, this model achieves an excellent balance between efficiency and effectiveness, providing a powerful option for users seeking lightweight deployment.\n\n## Performance\n\n\u003Cp align=\"center\"\u003E\n  \u003Cimg width=\"100%\" src=\"https://raw.githubusercontent.com/THUDM/GLM-4/refs/heads/main/resources/Bench-Z1-32B.png\"\u003E\n\u003C/p\u003E\n\n\u003Cp align=\"center\"\u003E\n  \u003Cimg width=\"100%\" src=\"https://raw.githubusercontent.com/THUDM/GLM-4/refs/heads/main/resources/Bench-Z1-9B.png\"\u003E\n\u003C/p\u003E\n\n## Model Usage Guidelines\n\n### I. Sampling Parameters\n\n| Parameter    | Recommended Value | Description                                  |\n| ------------ | ----------------- | -------------------------------------------- |\n| temperature  | **0.6**           | Balances creativity and stability            |\n| top_p        | **0.95**          | Cumulative probability threshold for sampling|\n| top_k        | **40**         | Filters out rare tokens while maintaining diversity |\n| max_new_tokens        | **30000**         | Leaves enough tokens for thinking |\n\n### II. Enforced Thinking\n\n- Add \\\u003Cthink\\\u003E\\n to the **first line**: Ensures the model thinks before responding  \n- When using `chat_template.jinja`, the prompt is automatically injected to enforce this behavior\n\n\n### III. Dialogue History Trimming\n\n- Retain only the **final user-visible reply**.  \n  Hidden thinking content should **not** be saved to history to reduce interferenceâ€”this is already implemented in `chat_template.jinja`\n\n\n### IV. Handling Long Contexts (YaRN)\n\n- When input length exceeds **8,192 tokens**, consider enabling YaRN (Rope Scaling)\n\n- In supported frameworks, add the following snippet to `config.json`:\n\n  ```json\n  \"rope_scaling\": {\n    \"type\": \"yarn\",\n    \"factor\": 4.0,\n    \"original_max_position_embeddings\": 32768\n  }\n  ```\n\n- **Static YaRN** applies uniformly to all text. It may slightly degrade performance on short texts, so enable as needed.\n\n\n## Inference Code\n\nMake Sure Using `transforemrs\u003E=4.51.3`.\n\n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nMODEL_PATH = \"THUDM/GLM-4-Z1-32B-0414\"\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\nmodel = AutoModelForCausalLM.from_pretrained(MODEL_PATH, device_map=\"auto\")\n\nmessage = [{\"role\": \"user\", \"content\": \"Let a, b be positive real numbers such that ab = a + b + 3. Determine the range of possible values for a + b.\"}]\n\ninputs = tokenizer.apply_chat_template(\n    message,\n    return_tensors=\"pt\",\n    add_generation_prompt=True,\n    return_dict=True,\n).to(model.device)\n\ngenerate_kwargs = {\n    \"input_ids\": inputs[\"input_ids\"],\n    \"attention_mask\": inputs[\"attention_mask\"],\n    \"max_new_tokens\": 4096,\n    \"do_sample\": False,\n}\nout = model.generate(**generate_kwargs)\nprint(tokenizer.decode(out[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True))\n```\n\n## Citations\n\nIf you find our work useful, please consider citing the following paper.\n\n```\n@misc{glm2024chatglm,\n      title={ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools}, \n      author={Team GLM and Aohan Zeng and Bin Xu and Bowen Wang and Chenhui Zhang and Da Yin and Diego Rojas and Guanyu Feng and Hanlin Zhao and Hanyu Lai and Hao Yu and Hongning Wang and Jiadai Sun and Jiajie Zhang and Jiale Cheng and Jiayi Gui and Jie Tang and Jing Zhang and Juanzi Li and Lei Zhao and Lindong Wu and Lucen Zhong and Mingdao Liu and Minlie Huang and Peng Zhang and Qinkai Zheng and Rui Lu and Shuaiqi Duan and Shudan Zhang and Shulin Cao and Shuxun Yang and Weng Lam Tam and Wenyi Zhao and Xiao Liu and Xiao Xia and Xiaohan Zhang and Xiaotao Gu and Xin Lv and Xinghan Liu and Xinyi Liu and Xinyue Yang and Xixuan Song and Xunkai Zhang and Yifan An and Yifan Xu and Yilin Niu and Yuantao Yang and Yueyan Li and Yushi Bai and Yuxiao Dong and Zehan Qi and Zhaoyu Wang and Zhen Yang and Zhengxiao Du and Zhenyu Hou and Zihan Wang},\n      year={2024},\n      eprint={2406.12793},\n      archivePrefix={arXiv},\n      primaryClass={id='cs.CL' full_name='Computation and Language' is_active=True alt_name='cmp-lg' in_archive='cs' is_general=False description='Covers natural language processing. Roughly includes material in ACM Subject Class I.2.7. Note that work on artificial languages (programming languages, logics, formal systems) that does not explicitly address natural-language issues broadly construed (natural-language processing, computational linguistics, speech, text retrieval, etc.) is not appropriate for this area.'}\n}\n```",
      "public": true,
      "version": "bd852539-dc14-568a-a33a-92ee6b96383a",
      "tool_description": null,
      "slug": "chutes-zai-org-glm-z1-32b-0414",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-08-04T12:49:12.698661Z",
      "updated_at": "2025-10-09T19:40:10.498059Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a100_40gb",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "exclude": [
          "b200",
          "mi300x"
        ],
        "include": null,
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 40,
        "compute_multiplier": 0.888888888888889,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a100_40gb",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 137416,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.05,
            "tao": 0.000124176060792625
          },
          "output": {
            "usd": 0.22,
            "tao": 0.000546374667487553
          }
        },
        "usd": {
          "hour": 4,
          "second": 0.00111111111111111
        },
        "tao": {
          "hour": 0.00993408486341006,
          "second": 0.000002759468017613
        }
      },
      "instances": [
        {
          "instance_id": "df7bc532-5402-4430-a824-0619f66ee09b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:45:38.961678Z"
        },
        {
          "instance_id": "e85d1df4-0f5f-401b-8b3a-e2b11389b7fa",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:45:38.961678Z"
        },
        {
          "instance_id": "2a7780da-4c74-4205-bed5-fe5d3516dbf5",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:45:38.961678Z"
        },
        {
          "instance_id": "bafa9772-c0ed-41f5-8687-c4fb9ab198b3",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:45:38.961678Z"
        },
        {
          "instance_id": "c0c2ae3c-9c9b-43ca-b727-f95417765744",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:45:38.961678Z"
        }
      ],
      "logo_id": "70eb6b09-fd9f-486a-af99-cfb60b6ced7f",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "8eb2858992c1f749e2a6d4075455decc2484722d",
      "concurrency": 16,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/70eb6b09-fd9f-486a-af99-cfb60b6ced7f.webp",
      "hot": true
    },
    {
      "chute_id": "b2b7a64c-b203-5a5f-8982-a9c5cc12058c",
      "name": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "tagline": "",
      "readme": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "public": true,
      "version": "d273b590-3b39-5980-a9e1-c6b605f2107e",
      "tool_description": null,
      "slug": "chutes-qwen-qwen3-235b-a22b-instruct-2507",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "b9784def-b796-57d7-888e-8fef54b2207e",
      "created_at": "2025-07-21T17:26:09.405817Z",
      "updated_at": "2025-10-20T16:31:51.471916Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 129031,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.08,
            "tao": 0.000198681697268201
          },
          "output": {
            "usd": 0.55,
            "tao": 0.00136593666871888
          }
        },
        "usd": {
          "hour": 8.58,
          "second": 0.00238333333333333
        },
        "tao": {
          "hour": 0.0213086120320146,
          "second": 0.000005919058897781
        }
      },
      "instances": [
        {
          "instance_id": "40a926f1-fe8e-4a25-8ceb-4aa4260a3f5b",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T11:18:13.387080Z"
        },
        {
          "instance_id": "517baf1b-6341-40ca-86c1-c740bf72d8ee",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:20.097502Z"
        },
        {
          "instance_id": "bbd7e753-38aa-4b80-afe8-7de6c4692db4",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:20.097502Z"
        },
        {
          "instance_id": "4e809873-1121-4b2d-be13-c384394466be",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:20.097502Z"
        },
        {
          "instance_id": "1a2a26cd-b5e4-492e-9ba1-adcab783109a",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:20.097502Z"
        }
      ],
      "logo_id": "ed6657a8-7ae2-4732-bc8c-8f12ec438610",
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "56e16a623ffb2855ca901a65166a9170e99df127",
      "concurrency": 40,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/ed6657a8-7ae2-4732-bc8c-8f12ec438610.webp",
      "hot": true
    },
    {
      "chute_id": "bf339be1-5937-5bba-911b-a1010839c465",
      "name": "unsloth/Mistral-Nemo-Instruct-2407",
      "tagline": "A collection of open source language models (ranging from 7B to 34B parameters) optimized for faster and more memory-efficient finetuning on custom datasets using the Unsloth framework.",
      "readme": "\n# Finetune Mistral, Gemma, Llama 2-5x faster with 70% less memory via Unsloth!\n\nWe have a free Google Colab Tesla T4 notebook for Mistral Nemo 12b here: https://colab.research.google.com/drive/17d3U-CAIwzmbDRqbZ9NnpHxCkmXB6LZ0?usp=sharing\n\n[\u003Cimg src=\"https://raw.githubusercontent.com/unslothai/unsloth/main/images/Discord%20button.png\" width=\"200\"/\u003E](https://discord.gg/u54VK8m8tk)\n[\u003Cimg src=\"https://raw.githubusercontent.com/unslothai/unsloth/main/images/buy%20me%20a%20coffee%20button.png\" width=\"200\"/\u003E](https://ko-fi.com/unsloth)\n[\u003Cimg src=\"https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20made%20with%20love.png\" width=\"200\"/\u003E](https://github.com/unslothai/unsloth)\n\n## âœ¨ Finetune for Free\n\nAll notebooks are **beginner friendly**! Add your dataset, click \"Run All\", and you'll get a 2x faster finetuned model which can be exported to GGUF, vLLM or uploaded to Hugging Face.\n\n| Unsloth supports          |    Free Notebooks                                                                                           | Performance | Memory use |\n|-----------------|--------------------------------------------------------------------------------------------------------------------------|-------------|----------|\n| **Llama-3 8b**      | [â–¶ï¸ Start on Colab](https://colab.research.google.com/drive/135ced7oHytdxu3N2DNe1Z0kqjyYIkDXp?usp=sharing)               | 2.4x faster | 58% less |\n| **Gemma 7b**      | [â–¶ï¸ Start on Colab](https://colab.research.google.com/drive/10NbwlsRChbma1v55m8LAPYG15uQv6HLo?usp=sharing)               | 2.4x faster | 58% less |\n| **Mistral 7b**    | [â–¶ï¸ Start on Colab](https://colab.research.google.com/drive/1Dyauq4kTZoLewQ1cApceUQVNcnnNTzg_?usp=sharing)               | 2.2x faster | 62% less |\n| **Llama-2 7b**      | [â–¶ï¸ Start on Colab](https://colab.research.google.com/drive/1lBzz5KeZJKXjvivbYvmGarix9Ao6Wxe5?usp=sharing)               | 2.2x faster | 43% less |\n| **TinyLlama**  | [â–¶ï¸ Start on Colab](https://colab.research.google.com/drive/1AZghoNBQaMDgWJpi4RbffGM1h6raLUj9?usp=sharing)              | 3.9x faster | 74% less |\n| **CodeLlama 34b** A100   | [â–¶ï¸ Start on Colab](https://colab.research.google.com/drive/1y7A0AxE3y8gdj4AVkl2aZX47Xu3P1wJT?usp=sharing)              | 1.9x faster | 27% less |\n| **Mistral 7b** 1xT4  | [â–¶ï¸ Start on Kaggle](https://www.kaggle.com/code/danielhanchen/kaggle-mistral-7b-unsloth-notebook) | 5x faster\\* | 62% less |\n| **DPO - Zephyr**     | [â–¶ï¸ Start on Colab](https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing)               | 1.9x faster | 19% less |\n\n- This [conversational notebook](https://colab.research.google.com/drive/1Aau3lgPzeZKQ-98h69CCu1UJcvIBLmy2?usp=sharing) is useful for ShareGPT ChatML / Vicuna templates.\n- This [text completion notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing) is for raw text. This [DPO notebook](https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing) replicates Zephyr.\n- \\* Kaggle has 2x T4s, but we use 1. Due to overhead, 1x T4 is 5x faster.",
      "public": true,
      "version": "a7df4d39-88c5-5d49-878d-0d04dabef9dc",
      "tool_description": null,
      "slug": "chutes-unsloth-mistral-nemo-instruct-2407",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-03-22T12:45:24.929555Z",
      "updated_at": "2025-10-09T19:40:17.779770Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a100_40gb",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "exclude": [
          "5090",
          "b200",
          "mi300x"
        ],
        "include": null,
        "gpu_count": 4,
        "min_vram_gb_per_gpu": 40,
        "compute_multiplier": 0.444444444444444,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a100_40gb",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 121048,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          },
          "output": {
            "usd": 0.11,
            "tao": 0.000273187333743776
          }
        },
        "usd": {
          "hour": 2,
          "second": 0.000555555555555555
        },
        "tao": {
          "hour": 0.00496704243170503,
          "second": 0.000001379734008806
        }
      },
      "instances": [
        {
          "instance_id": "d12bf074-f675-4f0d-80da-73a708bd0991",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:02:23.163801Z"
        },
        {
          "instance_id": "3f946dfe-aae3-4b67-b2d3-b48ebb52fef0",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:02:23.163801Z"
        },
        {
          "instance_id": "b601a993-b898-46de-9538-29fe9499bea5",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:02:23.163801Z"
        },
        {
          "instance_id": "49f2809b-ed8c-4755-b19e-3f0d036d7395",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:02:23.163801Z"
        },
        {
          "instance_id": "6114bdab-8a26-4dc5-a25c-92dc5ce78210",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:02:23.163801Z"
        }
      ],
      "logo_id": "915811d2-833a-4ff7-9e41-4e4c507f31f8",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "e9976040f42d8a5590ed58cefe973061b3f973b5",
      "concurrency": 24,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/915811d2-833a-4ff7-9e41-4e4c507f31f8.webp",
      "hot": true
    },
    {
      "chute_id": "1a0d9245-582a-5cde-8f5b-2da5b9542339",
      "name": "moonshotai/Kimi-K2-Instruct-0905",
      "tagline": "",
      "readme": "moonshotai/Kimi-K2-Instruct-0905",
      "public": true,
      "version": "27c0c4f3-daa7-59cc-8593-2c7e8a1e5fa0",
      "tool_description": null,
      "slug": "chutes-moonshotai-kimi-k2-instruct-0905",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-09-05T11:50:59.976639Z",
      "updated_at": "2025-10-15T11:34:28.982114Z",
      "image": {
        "image_id": "761d22a2-c96c-5675-82df-60cddab0827e",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101200",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-12T08:53:29.416285Z",
        "build_started_at": "2025-10-12T08:53:31.172351Z",
        "build_completed_at": "2025-10-12T09:17:36.083052Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "initial",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "b200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "b200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 8,
        "supported_gpus": [
          "b200"
        ]
      },
      "invocation_count": 120521,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.39,
            "tao": 0.00096857327418248
          },
          "output": {
            "usd": 1.9,
            "tao": 0.00471869031011978
          }
        },
        "usd": {
          "hour": 36,
          "second": 0.01
        },
        "tao": {
          "hour": 0.0894067637706905,
          "second": 0.000024835212158525
        }
      },
      "instances": [
        {
          "instance_id": "44c87684-aab0-4ad0-ae28-37e5460606cf",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T11:04:30.792795Z"
        },
        {
          "instance_id": "eb7bb734-6cb9-4332-ae2d-b411f96863de",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:01:43.148640Z"
        },
        {
          "instance_id": "c95b6f21-853a-43e7-86b6-3f7602b1753d",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T11:17:12.455299Z"
        },
        {
          "instance_id": "1801dfa6-cb87-4a3c-a958-2ce09c187ce6",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:01:43.148640Z"
        },
        {
          "instance_id": "30b7b2d4-7221-4d4d-b2d7-1beb03124c71",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:01:43.148640Z"
        },
        {
          "instance_id": "5ecea0f8-34dd-4bec-914b-5bc4bc4b6fdf",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:01:43.148640Z"
        },
        {
          "instance_id": "8e1e4ec4-6c4e-4675-a9df-e8414449dfbb",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:01:43.148640Z"
        },
        {
          "instance_id": "9fa08823-ce16-4817-aae1-653755f5690c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:01:43.148640Z"
        },
        {
          "instance_id": "ac73f564-08ea-4991-a137-ccf3864ff4d9",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:01:43.148640Z"
        }
      ],
      "logo_id": "d0a1e00e-ed45-4b78-94b6-6fb4f677b0b0",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "09d5f937b41ae72c90d7155c9a901e2b5831dfaf",
      "concurrency": 16,
      "boost": 20,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/d0a1e00e-ed45-4b78-94b6-6fb4f677b0b0.webp",
      "hot": true
    },
    {
      "chute_id": "5c47e581-a06c-5483-a597-5a1b6888b0b9",
      "name": "shisa-ai/shisa-v2-llama3.3-70b",
      "tagline": "Shisa V2 is a family of bilingual Japanese-English language models ranging from 7B to 70B parameters, optimized for high-quality Japanese language capabilities while maintaining strong English performance, making them particularly useful for Japanese language tasks and Japanese-English translation.",
      "readme": "\n# Shisa V2\n\nShisa V2 is a family of bilingual Japanese and English (JA/EN) general-purpose chat models trained by [Shisa.AI](https://shisa.ai). These models aim to excel in Japanese language tasks while retaining robust English capabilities.\n\nSince our initial [Shisa 7B](https://huggingface.co/augmxnt/shisa-7b-v1) releases, the baseline Japanese capabilities of open-weight language models have significantly improved. New models have more Japanese pre-training tokens, higher [JA tokenizer efficiency](https://github.com/shisa-ai/shisa-v2/blob/main/eval/tokenizer-efficiency/tokenizer-eval-ja.md), and better quality Japanese outputs overall. As such, for Shisa V2 we've eschewed both tokenizer extension and costly continued pre-training and have focused entirely on optimizing post-training. We've significantly expanded and refined the synthetic-data driven approach that was pioneered with our original [Shisa 7B](https://huggingface.co/augmxnt/shisa-7b-v1) models, and have achieved substantial performance gains.\n\n## Model Family Overview\n\nThe Shisa V2 family comprises a range of models from 7B to 70B parameters in size:\n\n| License | Model | Parameters | Context Length | JA AVG | EN AVG |\n|----|----|----|----|----|----|\n| Apache 2.0 | [shisa-v2-qwen2.5-7b](https://huggingface.co/shisa-ai/shisa-v2-qwen2.5-7b) | 7B | 128K/8K | 71.06 | 54.86 |\n| Llama 3.1 | [shisa-v2-llama3.1-8b](https://huggingface.co/shisa-ai/shisa-v2-llama3.1-8b)\u003Csup\u003E1\u003C/sup\u003E | 8B | 128K | 70.83 | 54.75 |\n| Apache 2.0 | [shisa-v2-mistral-nemo-12b](https://huggingface.co/shisa-ai/shisa-v2-mistral-nemo-12b) | 12B | 128K | 72.83 | 53.33 |\n| MIT | [shisa-v2-unphi4-14b](https://huggingface.co/shisa-ai/shisa-v2-unphi4-14b) | 14B | 16K | 75.89 | 60.10 |\n| Apache 2.0 | [shisa-v2-qwen2.5-32b](https://huggingface.co/shisa-ai/shisa-v2-qwen2.5-32b) | 32B | 128K/8K | 76.97 | 67.41 |\n| Llama 3.3 | [shisa-v2-llama3.3-70b](https://huggingface.co/shisa-ai/shisa-v2-llama3.3-70b)\u003Csup\u003E1\u003C/sup\u003E | 70B | 128K | 79.72 | 67.71 |\n\nThese Shisa V2 models were all trained using the same datasets and training recipes, except for scaling the learning rate based on model size and modifying the global batch size for the 70B model.\n\nWhile most of our development and tuning was done on the Llama 3.1 8B model, we did some cross-validation during this process and we're pleased that our final recipe has shown robust scaling, improving Japanese language performance across all model sizes evaluated. We've prioritized releasing the highest-quality openly-licensed (Apache 2.0 and MIT) models in each class size.\n\n## Performance\n\nAll Shisa V2 models demonstrate improved Japanese output quality compared to their respective base models:\n\n| Model                                                                                         | JA AVG    | EN AVG    | Shaberi AVG | ELYZA 100 | JA MT Bench | Rakuda  | Tengu   | llm-jp-eval | shisa-jp-ifeval | shisa-jp-rp-bench | shisa-jp-tl-bench | MixEval | LiveBench | IFEval  | EvalPlus |\n|----------------------------------------------------------------------------------------------------|-----------|-----------|-------------|-----------|-------------|---------|---------|-------------|-----------------|-------------------|-------------------|---------|-----------|---------|----------|\n| [shisa-ai/shisa-v2-llama3.3-70b](https://huggingface.co/shisa-ai/shisa-v2-llama3.3-70b)         | **79.72** | 67.71     | **8.86**     | **8.98**   | **9.03**     | **9.32** | **8.11** | 0.63        | **0.42**         | **4.72**          | **8.37**          | 0.59    | 48.7      | 0.84    | **0.79** |\n| [meta-llama/Llama-3.3-70B-Instruct](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct)     | 72.75     | **71.48** | 8.28        | 8.09      | 8.76        | 8.88    | 7.40    | **0.66**    | 0.35             | 4.65             | 5.75             | **0.64** | **51.8**   | **0.92** | **0.79** |\n\nThe Shisa V2 models perform well against other models in their respective class sizes.\n\n| License   | Model                                                                                  | JA AVG    | EN AVG    | Shaberi AVG | ELYZA 100 | JA MT Bench | Rakuda  | Tengu  | llm-jp-eval | shisa-jp-ifeval | shisa-jp-rp-bench | shisa-jp-tl-bench | MixEval | LiveBench | IFEval  | EvalPlus  |\n|-----------|---------------------------------------------------------------------------------------------|-----------|-----------|-------------|-----------|-------------|---------|--------|-------------|-----------------|-------------------|-------------------|---------|-----------|---------|-----------|\n| Llama 3.3 | [shisa-ai/shisa-v2-llama3.3-70b](https://huggingface.co/shisa-ai/shisa-v2-llama3.3-70b)  | **79.72** | 67.71     | **8.86**     | **8.98**   | **9.03**     | 9.32    | 8.11   | 0.63        | 0.42            | **4.72**          | **8.37**          | 0.59    | 48.7      | 0.84    | **0.79**  |\n| Qwen      | Qwen/Qwen2.5-72B-Instruct                                                                   | 77.57     | 68.12     | 8.81        | 8.97      | 8.83        | 9.23    | **8.22** | **0.67**    | **0.47**        | 4.52             | 6.39             | 0.54    | **53.8**  | 0.86    | **0.79**  |\n| Llama 3.3 | tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4                                           | 75.59     | 61.03     | 8.55        | 8.34      | 8.81        | 9.15    | 7.90   | 0.66        | 0.39            | 4.55             | 6.63             | 0.50    | 41.6      | 0.80    | 0.73      |\n| Llama 3.1 | allenai/Llama-3.1-Tulu-3-70B                                                                | 74.64     | 64.48     | 8.60        | 8.31      | 8.84        | **9.36** | 7.91   | 0.65        | 0.41            | 4.70             | 5.31             | 0.54    | 42.4      | 0.86    | 0.76      |\n| Llama 3.1 | cyberagent/Llama-3.1-70B-Japanese-Instruct-2407                                            | 73.67     | 64.47     | 8.68        | 8.93      | 8.61        | 9.14    | 8.06   | 0.63        | 0.36            | 4.05             | 6.25             | 0.56    | 43.6      | 0.85    | 0.73      |\n| Llama 3.3 | meta-llama/Llama-3.3-70B-Instruct                                                           | 72.75     | **71.48** | 8.28        | 8.09      | 8.76        | 8.88    | 7.40   | 0.66        | 0.35            | 4.65             | 5.75             | **0.64** | 51.8      | **0.92** | **0.79**  |\n| Llama 3   | [shisa-ai/shisa-v1-llama3-70b](https://huggingface.co/shisa-ai/shisa-v1-llama3-70b)        | 60.63     | 52.96     | 7.73        | 7.33      | 8.06        | 8.88    | 6.65   | 0.26        | 0.24            | 4.51             | 3.51             | 0.56    | 27.4      | 0.65    | 0.63      |\n\n### Testing Notes\n\nJapanese functional tests were conducted using the **[shisa-ai/shaberi](https://github.com/shisa-ai/shaberi/)** fork of the [LightBlue Shaberi](https://github.com/lightblue-tech/japanese_llm_eval) evaluation harness. Shaberi ratings were performed with a **[PoLL](https://arxiv.org/abs/2404.18796)** (LLM Jury) consisting of:\n\n- [Athene-V2](https://huggingface.co/Nexusflow/Athene-V2-Chat)\n- [Llama 3.3 70B](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct)\n- [Tulu 3 405B FP8](https://huggingface.co/shisa-ai/Llama-3.1-Tulu-3-405B-FP8-Dynamic)\n\nThe results were statistically validated to be comparable to both `gpt-4-1106-preview` and human-reviewed \"gold standard\" ratings.\n\nDynamic RoPE extension was utilized when necessary for testing models with context windows smaller than 8K tokens. All tests were performed using recent versions of [vLLM](https://github.com/vllm-project/vllm) or [SGLang](https://github.com/sgl-project/sglang).\n\nWe developed a custom \"multieval\" harness to automate our model evaluations. Standard benchmarks include:\n\n- [ELYZA Tasks 100](https://huggingface.co/datasets/elyza/ELYZA-tasks-100)\n- [JA MT-Bench](https://github.com/Stability-AI/FastChat/tree/jp-stable/fastchat/llm_judge) ([dataset](https://huggingface.co/datasets/shisa-ai/ja-mt-bench-1shot))\n- [Rakuda](https://huggingface.co/datasets/yuzuai/rakuda-questions)\n- [Tengu Bench](https://huggingface.co/datasets/lightblue/tengu_bench)\n- [llm-jp-eval](https://github.com/llm-jp/llm-jp-eval) (v1.4.1)\n- [MixEval](https://mixeval.github.io/)\n- [LiveBench](https://livebench.ai/) (2024-11-25)\n- [IFEval](https://huggingface.co/datasets/google/IFEval) ([Lighteval](https://github.com/huggingface/lighteval))\n- [EvalPlus](https://github.com/evalplus/evalplus)\n\n### New Japanese Benchmarks\n\nOver the course of model development, we also created several new evaluations to help us measure performance on important Japanese downstream tasks:\n\n- **shisa-jp-ifeval**: Inspired by [IFEval](https://huggingface.co/datasets/google/IFEval), but evaluating instruction-following abilities specific to Japanese grammar and linguistics (closed form)\n- **shisa-jp-rp-bench**: Assessing performance on Japanese role-play and character/persona-based multi-turn conversations based on [Aratako](https://huggingface.co/Aratako)'s [Japanese-RP-Bench](https://github.com/Aratako/Japanese-RP-Bench) (LLM judge)\n- **shisa-jp-tl-bench**: Testing Japanese-English translation proficiency (LLM judge, BTL pairwise comparison with logistic transformation scoring)\n\nWe believe these benchmarks will be generally useful and plan to open-source them in the near future to support the Japanese LLM research community.\n\n## Usage\n\nAll Shisa V2 models inherit the [chat templates](https://huggingface.co/docs/transformers/v4.37.1/chat_templating) of their respective base models and have been tested and validated for proper inference with both [vLLM](https://github.com/vllm-project/vllm) and [SGLang](https://github.com/sgl-project/sglang).\n\nRunning sampler sweeps, we found the models operate well across a variety of temperatures in most settings. For translation tasks specifically, we recommend a lower temperatures (0.2) to increase accuracy. For role-play and creative tasks, a higher temp (eg 1.0) seems to give good results. To prevent cross-lingual token leakage we recommend a top_p of 0.9 or min_p of 0.1. \n\nNo additional safety alignment has been done on these models, so they will largely inherit the base models' biases and safety profiles.\n\n## Datasets\n\nOur supervised fine-tuning (SFT) stage dataset consists of approximately 360K samples totaling roughly 420M Llama 3 tokens:\n\n- [shisa-ai/shisa-v2-sharegpt](https://huggingface.co/datasets/shisa-ai/shisa-v2-sharegpt)\n  - This is a filtered, regenerated and resampled version of the original Shisa V1 [augmxnt/ultra-orca-boros-en-ja-v1](https://huggingface.co/datasets/augmxnt/ultra-orca-boros-en-ja-v1) dataset\n  - This was the backbone of our Shisa V2 training and it proved to be an extremely robust dataset, out-performing all existing mixes/additions (Tulu, Olmo, Rewild, various Magpie sets, etc.) - if you need a JA/EN dataset, we believe this new version is among the best currently available\n- [shisa-ai/rewild-set-deepseek-subset](https://huggingface.co/datasets/shisa-ai/rewild-set-deepseek-subset)\n  - A filtered version of [Rewild](https://arxiv.org/abs/2501.18511) ([WildChat](https://wildchat.allen.ai/)) prompts translated into Japanese, with responses generated by [DeepSeek-V3-0324](https://huggingface.co/deepseek-ai/DeepSeek-V3-0324)\n- shisa-ai/magpie-ultra-set\n  - Japanese generations based on [argilla/magpie-ultra-v1.0](https://huggingface.co/datasets/argilla/magpie-ultra-v1.0)\n- shisa-ai/magpie-advanced-questions-set\n  - [Magpie](https://magpie-align.github.io/)-generated questions about advanced college-level topics across a variety of academic fields\n- shisa-ai/japan-magpie-set\n  - [Magpie](https://magpie-align.github.io/)-generated questions about Japan's economy and history as well as cultural and business practices\n- shisa-ai/shisa-v2-roleplaying-sft\n  - Synthetically-generated roleplaying data featuring a wide variety of characters, situations, and genres\n- shisa-ai/translation_expanded_master_set_filtered\n  - A synthetic dataset involving a wide range of translation tasks, including essays, conversations, and fiction\n- shisa-ai/shisa-v2-instruction-following-sft\n  - An instruction following dataset based on prompts from ([Aratako/Magpie-Tanuki-8B-annotated-96k](https://huggingface.co/datasets/Aratako/Magpie-Tanuki-8B-annotated-96k)) and a list of instruction-following constraints\n\nOur final DPO mix is 113K samples totaling approximately 115M Llama 3 tokens:\n\n- [shisa-ai/deepseekv3-ultrafeedback-armorm-dpo](https://huggingface.co/datasets/shisa-ai/deepseekv3-ultrafeedback-armorm-dpo)\n  - This is a version of [princeton-nlp/gemma2-ultrafeedback-armorm](https://huggingface.co/datasets/princeton-nlp/gemma2-ultrafeedback-armorm) with `chosen` responses regenerated by [DeepSeek-V3-0324](https://huggingface.co/deepseek-ai/DeepSeek-V3-0324)\n  - Surprisingly, we found that using this relatively small DPO alignment set in English-only outperformed both JA/EN DPO sets and also much larger sets like the [Tulu 3 preference mixture](https://huggingface.co/datasets/allenai/llama-3.1-tulu-3-405b-preference-mixture)\n- shisa-ai/shisa-v2-roleplaying-dpo\n  - A DPO variant of the roleplaying-sft set that uses an [UltraFeedback](https://github.com/OpenBMB/UltraFeedback)-style rating system\n- shisa-ai/translation-no-extra-text-dpo-dataset\n  - A DPO set that aims to reduce the tendency of models to output extraneous explanatory text for translations when not wanted\n- shisa-ai/shisa-v2-instruction-following-dpo\n  - A DPO variant of the instruction-following-sft set to further enhance instruction-following performance\n- shisa-ai/politeness-dpo-set\n  - A set to allow for greater controllability of speaking style for Japanese responses\n\n## Training\n\nWe trained over 200 models to empirically test a wide range of variables. Beyond hyper-parameter and data-mix testing, we also ran numerous tests on data ordering, multilingual-specific ordering, curriculum learning, multi-stage training, various forms of self-play, preference tuning, and some of the latest RL/verifiable reward techniques.\n\nA full discussion of these learnings is out of scope here, but we will be updating the [shisa-v2 wiki](https://github.com/shisa-ai/shisa-v2/wiki) and the [Shisa.AI website](http://shisa.ai/) with forthcoming writeups.\n\nMost of our training was done on a small AWS Sagemaker-deployed 4-node H100 slurm cluster. Training was mostly done with [Axolotl](https://github.com/axolotl-ai-cloud/axolotl/) with [DeepSpeed](https://www.deepspeed.ai/) and [Liger Kernels](https://github.com/linkedin/Liger-Kernel). The Phi 4 and Llama 3.3 70B versions of Shisa V2 were trained with [OpenRLHF](https://github.com/OpenRLHF/OpenRLHF). Our training logs are [publicly available on Weights and Biases](https://wandb.ai/augmxnt/shisa-v2). \n\n### Credits\n\nThe Shisa V2 models were developed by [Leonard Lin](https://huggingface.co/leonardlin) and Adam Lensenmayer ([Shisa.AI](http://Shisa.AI)).\n\nCompute was provided by [Ubitus K.K.](https://ubitus.net/) and [METI GENIAC](https://www.meti.go.jp/policy/mono_info_service/geniac/).\n\nThanks to [Meta Llama](https://huggingface.co/meta-llama), [Microsoft Research](https://huggingface.co/microsoft), [Mistral AI](https://huggingface.co/mistralai), and [Qwen Team](https://huggingface.co/Qwen) for providing their models to the open source community, [Unsloth](https://huggingface.co/unsloth) for their [llamafied conversion of Phi-4](https://huggingface.co/unsloth/phi-4), the Tulu team, whose detailed writeups and fast responses to our questions were very helpful, and [Chanvichet Vong](https://github.com/NanoCode012) of the Axolotl team for his tireless work in the Axolotl Discord.\n\nWe also extend our thanks to all open source AI developers and researchers - without their publicly shared research, tooling, and datasets, none of our work would be possible. We hope that our own contributions will further support the broader com",
      "public": true,
      "version": "27d23313-ab3e-5bbb-93a4-ef4a6eb69355",
      "tool_description": null,
      "slug": "chutes-shisa-ai-shisa-v2-llama3-3-70b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-04-15T08:49:19.821666Z",
      "updated_at": "2025-10-09T19:42:51.907378Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "exclude": [
          "mi300x",
          "b200"
        ],
        "include": null,
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.888888888888889,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 113554,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.05,
            "tao": 0.000124176060792625
          },
          "output": {
            "usd": 0.22,
            "tao": 0.000546374667487553
          }
        },
        "usd": {
          "hour": 4,
          "second": 0.00111111111111111
        },
        "tao": {
          "hour": 0.00993408486341006,
          "second": 0.000002759468017613
        }
      },
      "instances": [
        {
          "instance_id": "1b801ec6-60a1-41a0-b7d5-4b7c05746057",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:34:59.527635Z"
        },
        {
          "instance_id": "46dabffa-50d4-4ff2-8d57-7f2a1877f782",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:34:59.527635Z"
        },
        {
          "instance_id": "c7e57c5b-b354-4a5b-8976-7900c6b304c0",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:34:59.527635Z"
        },
        {
          "instance_id": "eae57502-8e98-4acd-8e29-ad7bda85f060",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:34:59.527635Z"
        },
        {
          "instance_id": "44209384-00cb-4509-8a0d-9f51b9014ba5",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:34:59.527635Z"
        },
        {
          "instance_id": "fec5850a-8cc3-4d2d-bff2-1d9ce8348de6",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:34:59.527635Z"
        }
      ],
      "logo_id": null,
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "eabf8d16e511a6e5544ae58b2b65f836b6614841",
      "concurrency": 16,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "aa5ff190-f995-5edf-9331-ea8fc5734f3e",
      "name": "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B",
      "tagline": "DeepSeek-R1-0528 is an MIT-licensed large language model optimized for complex reasoning and inference tasks like mathematics and coding, achieving strong performance on benchmarks like AIME and showing capabilities comparable to leading models like O3 and Gemini 2.5 Pro.",
      "readme": "---\r\nlicense: mit\r\nlibrary_name: transformers\r\n---\r\n# DeepSeek-R1-0528\r\n\u003C!-- markdownlint-disable first-line-h1 --\u003E\r\n\u003C!-- markdownlint-disable html --\u003E\r\n\u003C!-- markdownlint-disable no-duplicate-header --\u003E\r\n\r\n\u003Cdiv align=\"center\"\u003E\r\n  \u003Cimg src=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/logo.svg?raw=true\" width=\"60%\" alt=\"DeepSeek-V3\" /\u003E\r\n\u003C/div\u003E\r\n\u003Chr\u003E\r\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\r\n  \u003Ca href=\"https://www.deepseek.com/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\r\n    \u003Cimg alt=\"Homepage\" src=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/badge.svg?raw=true\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\r\n  \u003C/a\u003E\r\n  \u003Ca href=\"https://chat.deepseek.com/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\r\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/ğŸ¤–%20Chat-DeepSeek%20R1-536af5?color=536af5&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\r\n  \u003C/a\u003E\r\n  \u003Ca href=\"https://huggingface.co/deepseek-ai\" target=\"_blank\" style=\"margin: 2px;\"\u003E\r\n    \u003Cimg alt=\"Hugging Face\" src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\r\n  \u003C/a\u003E\r\n\u003C/div\u003E\r\n\r\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\r\n  \u003Ca href=\"https://discord.gg/Tc7c45Zzu5\" target=\"_blank\" style=\"margin: 2px;\"\u003E\r\n    \u003Cimg alt=\"Discord\" src=\"https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&logoColor=white&color=7289da\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\r\n  \u003C/a\u003E\r\n  \u003Ca href=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/qr.jpeg?raw=true\" target=\"_blank\" style=\"margin: 2px;\"\u003E\r\n    \u003Cimg alt=\"Wechat\" src=\"https://img.shields.io/badge/WeChat-DeepSeek%20AI-brightgreen?logo=wechat&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\r\n  \u003C/a\u003E\r\n  \u003Ca href=\"https://twitter.com/deepseek_ai\" target=\"_blank\" style=\"margin: 2px;\"\u003E\r\n    \u003Cimg alt=\"Twitter Follow\" src=\"https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\r\n  \u003C/a\u003E\r\n\u003C/div\u003E\r\n\r\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\r\n  \u003Ca href=\"LICENSE\" style=\"margin: 2px;\"\u003E\r\n    \u003Cimg alt=\"License\" src=\"https://img.shields.io/badge/License-MIT-f5de53?&color=f5de53\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\r\n  \u003C/a\u003E\r\n\u003C/div\u003E\r\n \r\n\r\n\u003Cp align=\"center\"\u003E\r\n  \u003Ca href=\"https://arxiv.org/pdf/2501.12948\"\u003E\u003Cb\u003EPaper Link\u003C/b\u003EğŸ‘ï¸\u003C/a\u003E\r\n\u003C/p\u003E\r\n\r\n\r\n## 1. Introduction\r\n\r\nThe DeepSeek R1 model has undergone a minor version upgrade, with the current version being DeepSeek-R1-0528. In the latest update, DeepSeek R1 has significantly improved its depth of reasoning and inference capabilities by leveraging increased computational resources and introducing algorithmic optimization mechanisms during post-training. The model has demonstrated outstanding performance across various benchmark evaluations, including mathematics, programming, and general logic. Its overall performance is now approaching that of leading models, such as O3 and Gemini 2.5 Pro.\r\n\r\n\u003Cp align=\"center\"\u003E\r\n  \u003Cimg width=\"80%\" src=\"figures/benchmark.png\"\u003E\r\n\u003C/p\u003E\r\n\r\nCompared to the previous version, the upgraded model shows significant improvements in handling complex reasoning tasks. For instance, in the AIME 2025 test, the modelâ€™s accuracy has increased from 70% in the previous version to 87.5% in the current version. This advancement stems from enhanced thinking depth during the reasoning process: in the AIME test set, the previous model used an average of 12K tokens per question, whereas the new version averages 23K tokens per question.\r\n\r\nBeyond its improved reasoning capabilities, this version also offers a reduced hallucination rate, enhanced support for function calling, and better experience for vibe coding.\r\n\r\n## 2. Evaluation Results\r\n\r\n### DeepSeek-R1-0528\r\n For all our models, the maximum generation length is set to 64K tokens. For benchmarks requiring sampling, we use a temperature of $0.6$, a top-p value of $0.95$, and generate 16 responses per query to estimate pass@1.\r\n\u003Cdiv align=\"center\"\u003E\r\n\r\n| Category | Benchmark (Metric)               | DeepSeek R1     | DeepSeek R1 0528\r\n|----------|----------------------------------|-----------------|---|\r\n| General  |\r\n|          | MMLU-Redux (EM)                   | 92.9            | 93.4\r\n|          | MMLU-Pro (EM)                     | 84.0            | 85.0\r\n|          | GPQA-Diamond (Pass@1)             | 71.5            | 81.0\r\n|          | SimpleQA (Correct)                | 30.1            | 27.8\r\n|          | FRAMES (Acc.)                     | 82.5            | 83.0\r\n|          | Humanity's Last Exam (Pass@1)                     | 8.5            | 17.7\r\n| Code |\r\n|          | LiveCodeBench (2408-2505) (Pass@1)        | 63.5          | 73.3\r\n|          | Codeforces-Div1 (Rating)          | 1530            | 1930\r\n|          | SWE Verified (Resolved)           | 49.2            | 57.6\r\n|          | Aider-Polyglot (Acc.)             | 53.3            | 71.6\r\n| Math |\r\n|          | AIME 2024 (Pass@1)                | 79.8            | 91.4\r\n|          | AIME 2025 (Pass@1)                     | 70.0           | 87.5\r\n|          | HMMT 2025 (Pass@1)            | 41.7 | 79.4 |\r\n|          | CNMO 2024 (Pass@1)                | 78.8            | 86.9\r\n| Tools |\r\n|          | BFCL_v3_MultiTurn (Acc)     | -            | 37.0 |\r\n|          | Tau-Bench   (Pass@1)       | -            | 53.5(Airline)/63.9(Retail)\r\n\r\n\u003C/div\u003E\r\nNote: We use Agentless framework to evaluate model performance on SWE-Verified. We only evaluate text-only prompts in HLE testsets.  GPT-4.1 is employed to act user role in Tau-bench evaluation.\r\n\r\n### DeepSeek-R1-0528-Qwen3-8B\r\nMeanwhile, we distilled the chain-of-thought from DeepSeek-R1-0528 to post-train Qwen3 8B Base, obtaining DeepSeek-R1-0528-Qwen3-8B. This model achieves state-of-the-art (SOTA) performance among open-source models on the AIME 2024, surpassing Qwen3 8B by +10.0% and matching the performance of Qwen3-235B-thinking. We believe that the chain-of-thought from DeepSeek-R1-0528 will hold significant importance for both academic research on reasoning models and industrial development focused on small-scale models.\r\n\r\n|                                | AIME 24 | AIME 25 | HMMT Feb 25 | GPQA Diamond | LiveCodeBench (2408-2505) |\r\n|--------------------------------|---------|---------|-------------|--------------|---------------------------|\r\n| Qwen3-235B-A22B\t                | 85.7    | 81.5    | 62.5        | 71.1         | 66.5                  |\r\n| Qwen3-32B                      | 81.4    | 72.9    | -           | 68.4         | -                         |\r\n| Qwen3-8B                      | 76.0   | 67.3    | -           | 62.0       | -                         |\r\n| Phi-4-Reasoning-Plus-14B       | 81.3    | 78.0    | 53.6        | 69.3         | -          |\r\n| Gemini-2.5-Flash-Thinking-0520 | 82.3    | 72.0    | 64.2        | 82.8         | 62.3                  |\r\n| o3-mini (medium)               | 79.6    | 76.7    | 53.3        | 76.8         | 65.9                     |\r\n| DeepSeek-R1-0528-Qwen3-8B      | 86.0   | 76.3    | 61.5        | 61.1         | 60.5                      |\r\n\r\n## 3. Chat Website & API Platform\r\nYou can chat with DeepSeek-R1 on DeepSeek's official website: [chat.deepseek.com](https://chat.deepseek.com/sign_in), and switch on the button \"DeepThink\"\r\n\r\nWe also provide OpenAI-Compatible API at DeepSeek Platform: [platform.deepseek.com](https://platform.deepseek.com/)\r\n\r\n## 4. How to Run Locally\r\n\r\nPlease visit [DeepSeek-R1](https://github.com/deepseek-ai/DeepSeek-R1) repository for more information about running DeepSeek-R1-0528 locally.\r\n\r\nCompared to previous versions of DeepSeek-R1, the usage recommendations for DeepSeek-R1-0528 have the following changes:\r\n\r\n1. System prompt is supported now.\r\n2. It is not required to add \"\\\u003Cthink\\\u003E\\n\" at the beginning of the output to force the model into thinking pattern.\r\n\r\nThe model architecture of DeepSeek-R1-0528-Qwen3-8B is identical to that of Qwen3-8B, but it shares the same tokenizer configuration as DeepSeek-R1-0528. This model can be run in the same manner as Qwen3-8B, but it is essential to ensure that all configuration files are sourced from our repository rather than the original Qwen3 project.\r\n\r\n### System Prompt\r\nIn the official DeepSeek web/app, we use the same system prompt with a specific date.\r\n```\r\nè¯¥åŠ©æ‰‹ä¸ºDeepSeek-R1ï¼Œç”±æ·±åº¦æ±‚ç´¢å…¬å¸åˆ›é€ ã€‚\r\nä»Šå¤©æ˜¯{current date}ã€‚\r\n```\r\nFor example,\r\n```\r\nè¯¥åŠ©æ‰‹ä¸ºDeepSeek-R1ï¼Œç”±æ·±åº¦æ±‚ç´¢å…¬å¸åˆ›é€ ã€‚\r\nä»Šå¤©æ˜¯2025å¹´5æœˆ28æ—¥ï¼Œæ˜ŸæœŸä¸€ã€‚\r\n```\r\n### Temperature\r\nIn our web and application environments, the temperature parameter $T_{model}$ is set to 0.6. \r\n### Prompts for File Uploading and Web Search\r\nFor file uploading, please follow the template to create prompts, where {file_name}, {file_content} and {question} are arguments.\r\n```\r\nfile_template = \\\r\n\"\"\"[file name]: {file_name}\r\n[file content begin]\r\n{file_content}\r\n[file content end]\r\n{question}\"\"\"\r\n```\r\nFor Web Search, {search_results}, {cur_date}, and {question} are arguments.\r\nFor Chinese query, we use the prompt:\r\n```\r\nsearch_answer_zh_template = \\\r\n'''# ä»¥ä¸‹å†…å®¹æ˜¯åŸºäºç”¨æˆ·å‘é€çš„æ¶ˆæ¯çš„æœç´¢ç»“æœ:\r\n{search_results}\r\nåœ¨æˆ‘ç»™ä½ çš„æœç´¢ç»“æœä¸­ï¼Œæ¯ä¸ªç»“æœéƒ½æ˜¯[webpage X begin]...[webpage X end]æ ¼å¼çš„ï¼ŒXä»£è¡¨æ¯ç¯‡æ–‡ç« çš„æ•°å­—ç´¢å¼•ã€‚è¯·åœ¨é€‚å½“çš„æƒ…å†µä¸‹åœ¨å¥å­æœ«å°¾å¼•ç”¨ä¸Šä¸‹æ–‡ã€‚è¯·æŒ‰ç…§å¼•ç”¨ç¼–å·[citation:X]çš„æ ¼å¼åœ¨ç­”æ¡ˆä¸­å¯¹åº”éƒ¨åˆ†å¼•ç”¨ä¸Šä¸‹æ–‡ã€‚å¦‚æœä¸€å¥è¯æºè‡ªå¤šä¸ªä¸Šä¸‹æ–‡ï¼Œè¯·åˆ—å‡ºæ‰€æœ‰ç›¸å…³çš„å¼•ç”¨ç¼–å·ï¼Œä¾‹å¦‚[citation:3][citation:5]ï¼Œåˆ‡è®°ä¸è¦å°†å¼•ç”¨é›†ä¸­åœ¨æœ€åè¿”å›å¼•ç”¨ç¼–å·ï¼Œè€Œæ˜¯åœ¨ç­”æ¡ˆå¯¹åº”éƒ¨åˆ†åˆ—å‡ºã€‚\r\nåœ¨å›ç­”æ—¶ï¼Œè¯·æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š\r\n- ä»Šå¤©æ˜¯{cur_date}ã€‚\r\n- å¹¶éæœç´¢ç»“æœçš„æ‰€æœ‰å†…å®¹éƒ½ä¸ç”¨æˆ·çš„é—®é¢˜å¯†åˆ‡ç›¸å…³ï¼Œä½ éœ€è¦ç»“åˆé—®é¢˜ï¼Œå¯¹æœç´¢ç»“æœè¿›è¡Œç”„åˆ«ã€ç­›é€‰ã€‚\r\n- å¯¹äºåˆ—ä¸¾ç±»çš„é—®é¢˜ï¼ˆå¦‚åˆ—ä¸¾æ‰€æœ‰èˆªç­ä¿¡æ¯ï¼‰ï¼Œå°½é‡å°†ç­”æ¡ˆæ§åˆ¶åœ¨10ä¸ªè¦ç‚¹ä»¥å†…ï¼Œå¹¶å‘Šè¯‰ç”¨æˆ·å¯ä»¥æŸ¥çœ‹æœç´¢æ¥æºã€è·å¾—å®Œæ•´ä¿¡æ¯ã€‚ä¼˜å…ˆæä¾›ä¿¡æ¯å®Œæ•´ã€æœ€ç›¸å…³çš„åˆ—ä¸¾é¡¹ï¼›å¦‚éå¿…è¦ï¼Œä¸è¦ä¸»åŠ¨å‘Šè¯‰ç”¨æˆ·æœç´¢ç»“æœæœªæä¾›çš„å†…å®¹ã€‚\r\n- å¯¹äºåˆ›ä½œç±»çš„é—®é¢˜ï¼ˆå¦‚å†™è®ºæ–‡ï¼‰ï¼Œè¯·åŠ¡å¿…åœ¨æ­£æ–‡çš„æ®µè½ä¸­å¼•ç”¨å¯¹åº”çš„å‚è€ƒç¼–å·ï¼Œä¾‹å¦‚[citation:3][citation:5]ï¼Œä¸èƒ½åªåœ¨æ–‡ç« æœ«å°¾å¼•ç”¨ã€‚ä½ éœ€è¦è§£è¯»å¹¶æ¦‚æ‹¬ç”¨æˆ·çš„é¢˜ç›®è¦æ±‚ï¼Œé€‰æ‹©åˆé€‚çš„æ ¼å¼ï¼Œå……åˆ†åˆ©ç”¨æœç´¢ç»“æœå¹¶æŠ½å–é‡è¦ä¿¡æ¯ï¼Œç”Ÿæˆç¬¦åˆç”¨æˆ·è¦æ±‚ã€æå…·æ€æƒ³æ·±åº¦ã€å¯Œæœ‰åˆ›é€ åŠ›ä¸ä¸“ä¸šæ€§çš„ç­”æ¡ˆã€‚ä½ çš„åˆ›ä½œç¯‡å¹…éœ€è¦å°½å¯èƒ½å»¶é•¿ï¼Œå¯¹äºæ¯ä¸€ä¸ªè¦ç‚¹çš„è®ºè¿°è¦æ¨æµ‹ç”¨æˆ·çš„æ„å›¾ï¼Œç»™å‡ºå°½å¯èƒ½å¤šè§’åº¦çš„å›ç­”è¦ç‚¹ï¼Œä¸”åŠ¡å¿…ä¿¡æ¯é‡å¤§ã€è®ºè¿°è¯¦å°½ã€‚\r\n- å¦‚æœå›ç­”å¾ˆé•¿ï¼Œè¯·å°½é‡ç»“æ„åŒ–ã€åˆ†æ®µè½æ€»ç»“ã€‚å¦‚æœéœ€è¦åˆ†ç‚¹ä½œç­”ï¼Œå°½é‡æ§åˆ¶åœ¨5ä¸ªç‚¹ä»¥å†…ï¼Œå¹¶åˆå¹¶ç›¸å…³çš„å†…å®¹ã€‚\r\n- å¯¹äºå®¢è§‚ç±»çš„é—®ç­”ï¼Œå¦‚æœé—®é¢˜çš„ç­”æ¡ˆéå¸¸ç®€çŸ­ï¼Œå¯ä»¥é€‚å½“è¡¥å……ä¸€åˆ°ä¸¤å¥ç›¸å…³ä¿¡æ¯ï¼Œä»¥ä¸°å¯Œå†…å®¹ã€‚\r\n- ä½ éœ€è¦æ ¹æ®ç”¨æˆ·è¦æ±‚å’Œå›ç­”å†…å®¹é€‰æ‹©åˆé€‚ã€ç¾è§‚çš„å›ç­”æ ¼å¼ï¼Œç¡®ä¿å¯è¯»æ€§å¼ºã€‚\r\n- ä½ çš„å›ç­”åº”è¯¥ç»¼åˆå¤šä¸ªç›¸å…³ç½‘é¡µæ¥å›ç­”ï¼Œä¸èƒ½é‡å¤å¼•ç”¨ä¸€ä¸ªç½‘é¡µã€‚\r\n- é™¤éç”¨æˆ·è¦æ±‚ï¼Œå¦åˆ™ä½ å›ç­”çš„è¯­è¨€éœ€è¦å’Œç”¨æˆ·æé—®çš„è¯­è¨€ä¿æŒä¸€è‡´ã€‚\r\n# ç”¨æˆ·æ¶ˆæ¯ä¸ºï¼š\r\n{question}'''\r\n```\r\nFor English query, we use the prompt:\r\n```\r\nsearch_answer_en_template = \\\r\n'''# The following contents are the search results related to the user's message:\r\n{search_results}\r\nIn the search results I provide to you, each result is formatted as [webpage X begin]...[webpage X end], where X represents the numerical index of each article. Please cite the context at the end of the relevant sentence when appropriate. Use the citation format [citation:X] in the corresponding part of your answer. If a sentence is derived from multiple contexts, list all relevant citation numbers, such as [citation:3][citation:5]. Be sure not to cluster all citations at the end; instead, include them in the corresponding parts of the answer.\r\nWhen responding, please keep the following points in mind:\r\n- Today is {cur_date}.\r\n- Not all content in the search results is closely related to the user's question. You need to evaluate and filter the search results based on the question.\r\n- For listing-type questions (e.g., listing all flight information), try to limit the answer to 10 key points and inform the user that they can refer to the search sources for complete information. Prioritize providing the most complete and relevant items in the list. Avoid mentioning content not provided in the search results unless necessary.\r\n- For creative tasks (e.g., writing an essay), ensure that references are cited within the body of the text, such as [citation:3][citation:5], rather than only at the end of the text. You need to interpret and summarize the user's requirements, choose an appropriate format, fully utilize the search results, extract key information, and generate an answer that is insightful, creative, and professional. Extend the length of your response as much as possible, addressing each point in detail and from multiple perspectives, ensuring the content is rich and thorough.\r\n- If the response is lengthy, structure it well and summarize it in paragraphs. If a point-by-point format is needed, try to limit it to 5 points and merge related content.\r\n- For objective Q&A, if the answer is very brief, you may add one or two related sentences to enrich the content.\r\n- Choose an appropriate and visually appealing format for your response based on the user's requirements and the content of the answer, ensuring strong readability.\r\n- Your answer should synthesize information from multiple relevant webpages and avoid repeatedly citing the same webpage.\r\n- Unless the user requests otherwise, your response should be in the same language as the user's question.\r\n# The user's message is:\r\n{question}'''\r\n```\r\n\r\n## 5. License\r\nThis code repository is licensed under [MIT License](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B/raw/main/LICENSE). The use of DeepSeek-R1 models is also subject to [MIT License](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B/raw/main/LICENSE). DeepSeek-R1 series (including Base and Chat) supports commercial use and distillation.\r\n\r\n## 6. Citation\r\n```\r\n@misc{deepseekai2025deepseekr1incentivizingreasoningcapability,\r\n      title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}, \r\n      author={DeepSeek-AI},\r\n      year={2025},\r\n      eprint={2501.12948},\r\n      archivePrefix={arXiv},\r\n      primaryClass={cs.CL},\r\n      url={https://arxiv.org/abs/2501.12948}, \r\n}\r\n```\r\n\r\n## 7. Contact\r\nIf you have any questions, please raise an issue or contact us at [service@deepseek.com](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B/raw/main/service@deepseek.com).\r\n",
      "public": true,
      "version": "96590844-158f-5a91-a813-19ea34d2e7d3",
      "tool_description": null,
      "slug": "chutes-deepseek-ai-deepseek-r1-0528-qwen3-8b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-05-29T15:35:34.111992Z",
      "updated_at": "2025-10-09T19:43:01.164292Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "exclude": [
          "mi300x",
          "b200"
        ],
        "include": null,
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.444444444444444,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 105929,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          },
          "output": {
            "usd": 0.11,
            "tao": 0.000273187333743776
          }
        },
        "usd": {
          "hour": 2,
          "second": 0.000555555555555555
        },
        "tao": {
          "hour": 0.00496704243170503,
          "second": 0.000001379734008806
        }
      },
      "instances": [
        {
          "instance_id": "c0a26831-aa27-417c-8d34-59eb03ebe5d2",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:57:15.028168Z"
        },
        {
          "instance_id": "e069f0df-64e3-4796-a26a-7b6224f54f5e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:57:15.028168Z"
        },
        {
          "instance_id": "1e623022-6ddd-4394-8cef-03ed5f41a85c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:57:15.028168Z"
        },
        {
          "instance_id": "814ab3f7-eb57-47ac-a37d-7ff0e47d8bba",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:57:15.028168Z"
        },
        {
          "instance_id": "733f2fbc-28c6-45ca-8e23-788c6d5de716",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:57:15.028168Z"
        },
        {
          "instance_id": "d7512dc7-cd03-4e7b-862f-f090a5fbb9f6",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:57:15.028168Z"
        },
        {
          "instance_id": "2e5dec58-5a20-43ef-8b69-058c051fb3b7",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:57:15.028168Z"
        },
        {
          "instance_id": "39ba3689-c7fb-4a1c-88fb-ccae71bc0d1e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:57:15.028168Z"
        },
        {
          "instance_id": "1afbc3f0-5361-413e-857d-2eaaeb951074",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:57:15.028168Z"
        },
        {
          "instance_id": "28db525f-ac2f-4fc9-a22b-6a8827601bfc",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:57:15.028168Z"
        },
        {
          "instance_id": "ac4a94a0-7fce-4957-9e08-7cb215425a70",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:57:15.028168Z"
        },
        {
          "instance_id": "2bb798e6-5d4d-4a2a-b691-7fa61ed99183",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:57:15.028168Z"
        },
        {
          "instance_id": "c642c6c6-0b14-4d3a-a17e-c5f6ffa142ac",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:57:15.028168Z"
        },
        {
          "instance_id": "0783b2b1-01cc-4876-bc88-150ec3295380",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:57:15.028168Z"
        }
      ],
      "logo_id": "daf43d25-5713-4318-b763-436c5c321a0a",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "6e8885a6ff5c1dc5201574c8fd700323f23c25fa",
      "concurrency": 48,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/daf43d25-5713-4318-b763-436c5c321a0a.webp",
      "hot": true
    },
    {
      "chute_id": "2a6173bd-6d60-5ca6-8601-9ece77f055e4",
      "name": "meituan-longcat/LongCat-Flash-Chat-FP8",
      "tagline": "LongCat-Flash-Chat is a 560B parameter MoE model (using ~27B parameters per inference) that excels at agentic tasks like tool use while maintaining strong performance across general reasoning, coding, and instruction following.",
      "readme": "\n# LongCat-Flash-Chat\n\n\u003Cdiv align=\"center\"\u003E\n  \u003Cimg src=\"https://raw.githubusercontent.com/meituan-longcat/LongCat-Flash-Chat/main/figures/longcat_logo.svg\" \n       width=\"300\" \n       alt=\"LongCat Logo\"/\u003E\n\u003C/div\u003E\n\n\u003Chr\u003E\n\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\n\n  \u003Ca href=\"https://longcat.ai/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/ğŸ¤–%20Chat-LongCat--Flash--Chat-ADFF2F?color=29E154&logoColor=white\"  fill-opacity=\"1\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://huggingface.co/meituan-longcat\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Hugging Face\" src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-LongCat-ffc107?color=ffc107&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\n  \u003Ca href=\"https://github.com/meituan-longcat/LongCat-Flash-Chat/blob/main/figures/wechat_official_accounts.png\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Wechat\" src=\"https://img.shields.io/badge/WeChat-LongCat-brightgreen?logo=wechat&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://x.com/Meituan_LongCat\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Twitter Follow\" src=\"https://img.shields.io/badge/Twitter-LongCat-white?logo=x&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\n  \u003Ca href=\"https://huggingface.co/meituan-longcat/LongCat-Flash-Chat-FP8/blob/main/LICENSE\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"License\" src=\"https://img.shields.io/badge/License-MIT-f5de53?&color=f5de53\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\n\n## Model Introduction\nWe introduce LongCat-Flash, a powerful and efficient language model with 560 billion total parameters, featuring an innovative Mixture-of-Experts (MoE) architecture. The model incorporates a dynamic computation mechanism that activates 18.6Bâˆ¼31.3B parameters (averagingâˆ¼27B) based on contextual demands, optimizing both computational efficiency and performance. To achieve advanced training and inference efficiency, we employ a shortcut-connected architecture that expands computation-communication overlap window, achieving over 100 tokens per second (TPS) for inference cost-effectively. Our comprehensive training and scaling strategies ensure stable, efficient training, while tailored data strategies enhance model performance. \n\nNow we release LongCat-Flash-Chat, a non-thinking foundation model that delivers highly competitive performance among leading models, with exceptional strengths in agentic tasks.\n\n\n### Key Features\n\n#### ğŸŒŸ Scalable Architectural Design for Computational Efficiency\n\nLongCat-Flash is designed and optimized under two key principles: efficient computation utilization, as well as  efficient training and inference. Specifically, (1) As not all tokens are equal, we introduce the zero-computation experts mechanism in MoE blocks to allocate a dynamic computation budget to important tokens based on their significance, i.e., activating 18.6 to 31.3 billion parameters (out of 560 billion total) based on contextual demands. To ensure consistent computation load, we employ expert bias adjusted by a PID-controller, maintaining an average ofâˆ¼27 billion activated parameters per token. (2) As communication overhead becomes a bottleneck during MoE model scaling, we incorporate the Shortcut-connected MoE (ScMoE) design to expand the computation-communication overlap window. Combined with customized infrastructure optimizations, this design enables training at a massive scale of over tens of thousands accelerators and inference with high throughput and low latency.\n\n\n#### ğŸŒŸ Effective Model Scaling Strategy\n\nEffectively and efficiently scaling model size remains a key challenge in strategy design. To this end, we develop a comprehensive stability-and-scaling framework for robustly training large-scale models: (1) We successfully apply a hyperparameter transfer strategy to such a large model, predicting optimal hyperparameter configurations by leveraging results from smaller proxy models with theoretical guarantees. (2) We initialize the model using a model-growth mechanism based on a refined half-scale checkpoint, achieving improved performance compared to conventional initialization methods. (3) A multi-pronged stability suite incorporates principled router-gradient balancing, a hidden z-loss to suppress massive activations, and fine-tuned optimizer configurations. (4) To enhance the reliability of large-scale cluster training, we introduce deterministic computation. This guarantees the exact reproducibility of experiments and enables the detection of SDC (Silent Data Corruption) during the training process. These interventions ensure that LongCat-Flash â€™s training remains stable, with no irrecoverable loss spikes.\n\n#### ğŸŒŸ Multi-Stage Training Pipeline for Agentic Capability\nThrough a meticulously designed pipeline, LongCat-Flash is endowed with advanced agentic behaviors. Initial efforts focus on constructing a more suitable base model for agentic post-training, where we design a two-stage pretraining data fusion strategy to concentrate reasoning-intensive domain data. During mid-training, we enhance reasoning and coding capabilities while extending the context length to 128k to meet agentic post-training requirements. Building on this advanced base model, we proceed with a multi-stage post-training. Recognizing the scarcity of high-quality, high-difficulty training problems for agentic tasks, we design a multi-agent synthesis framework that defines task difficulty across three axes, i.e., information processing, tool-set complexity, and user interactionâ€”using specialized controllers to generate complex tasks requiring iterative reasoning and environmental interaction.\n\nFor more detail, please refer to the comprehensive [***LongCat-Flash Technical Report***](https://github.com/meituan-longcat/LongCat-Flash-Chat/blob/main/tech_report.pdf).\n\n## Evaluation Results\n| **Benchmark** | **DeepSeek V3.1** | **Qwen3 MoE-2507** | **Kimi-K2** | **GPT-4.1** | **Claude4 Sonnet** | **Gemini2.5 Flash** | **LongCat-Flash** |\n|---------------|-------------------|--------------------|-------------|-------------|--------------------|---------------------|-------------|\n| **Architecture** | MoE | MoE | MoE | - | - | - | MoE |\n| **# Total Params** | 671B | 235B | 1043B | - | - | - | 560B |\n| **# Activated Params** | 37B | 22B | 32B | - | - | - | 27B |\n| **General Domains** | | | | | | | |\n| MMLU\u003Csub\u003E(acc)\u003C/sub\u003E | 90.96 | 90.23 | 89.86 | 89.64 | 91.75 | 86.33 | 89.71 |\n| MMLU-Pro\u003Csub\u003E(acc)\u003C/sub\u003E | 84.45 | 84.83 | 82.06 | 81.72 | 83.74 | 81.95 | 82.68 |\n| ArenaHard-V2\u003Csub\u003E(acc)\u003C/sub\u003E | 84.10 | 88.20 | 85.70 | 61.50 | 62.10 | 77.00 | 86.50 |\n| CEval\u003Csub\u003E(acc)\u003C/sub\u003E | 89.21 | 92.70 | 91.26 | 79.53 | 86.63 | 78.78 | 90.44 |\n| CMMLU\u003Csub\u003E(acc)\u003C/sub\u003E | 88.04 | 88.14 | 89.66 | 77.65 | 86.51 | 78.30 | 84.34 |\n| **Instruction Following** | | | | | | | |\n| IFEval\u003Csub\u003E(acc)\u003C/sub\u003E | 86.69 | 88.54 | 88.91 | 85.58 | 88.35 | 83.92 | 89.65 |\n| COLLIE\u003Csub\u003E(acc)\u003C/sub\u003E | 43.80 | 49.71 | 56.34 | 50.00 | 51.22 | 48.60 | 57.10 |\n| Meeseeks-zh\u003Csub\u003E(acc)\u003C/sub\u003E | 33.83 | 35.32 | 42.79 | 41.54 | 35.07 | 34.84 | 43.03 |\n| **Mathematical Reasoning** | | | | | | | |\n| MATH500\u003Csub\u003E(acc)\u003C/sub\u003E | 96.08 | 98.80 | 97.60 | 90.60 | 93.80 | 98.40 | 96.40 |\n| AIME24\u003Csub\u003E(avg@10)\u003C/sub\u003E | 66.30* | 81.67 | 69.60* | 47.00 | 47.00 | 79.67 | 70.42 |\n| AIME25\u003Csub\u003E(avg@10)\u003C/sub\u003E | 49.27 | 68.33 | 50.66 | 32.00 | 37.00 | 67.33 | 61.25 |\n| BeyondAIME\u003Csub\u003E(avg@10)\u003C/sub\u003E | 36.50 | 57.60 | 36.60 | 22.10 | 20.50 | 44.20 | 43.00 |\n| **General Reasoning** | | | | | | | |\n| GPQA-diamond\u003Csub\u003E(acc)\u003C/sub\u003E | 74.90* | 77.43 | 75.76 | 67.68 | 70.71 | 80.30 | 73.23 |\n| DROP\u003Csub\u003E(f1)\u003C/sub\u003E | 84.19 | 78.57 | 89.04 | 66.94 | 73.06 | 45.03 | 79.06 |\n| ZebraLogic\u003Csub\u003E(acc)\u003C/sub\u003E | 85.30 | 94.22 | 89.11 | 56.30* | 75.85 | 51.78 | 89.30 |\n| GraphWalks-128k\u003Csub\u003E(precision)\u003C/sub\u003E | 73.54 | 80.72 | 47.50 | 85.02 | 80.57 | 64.83 | 51.05 |\n| **Coding** | | | | | | | |\n| LiveCodeBench\u003Csub\u003E(pass@1)\u003C/sub\u003E | 56.40* | 46.48 | 46.70 | 39.21 | 45.59 | 39.65 | 48.02 |\n| Humaneval+\u003Csub\u003E(pass@1)\u003C/sub\u003E | 92.68 | 94.51 | 85.98 | 93.29 | 94.51 | 87.80 | 88.41 |\n| MBPP+\u003Csub\u003E(pass@1)\u003C/sub\u003E | 79.89 | 79.89 | 81.75 | 79.37 | 80.16 | 76.19 | 79.63 |\n| SWE-Bench-Verified\u003Csub\u003E(acc)\u003C/sub\u003E | 66.00* | 42.00 | 64.60 | 48.60 | 68.00* | 40.60 | 60.40 |\n| TerminalBench\u003Csub\u003E(acc)\u003C/sub\u003E | 31.30* | 17.28 | 25.93 | 28.40 | 40.74 | 12.35 | 39.51 |\n| **Agentic Tool Use** | | | | | | | |\n| Ï„Â²-Bench (telecom)\u003Csub\u003E(avg@4)\u003C/sub\u003E | 38.50 | 22.50 | 67.50 | 35.20 | 46.20 | 16.50 | 73.68 |\n| Ï„Â²-Bench (airline)\u003Csub\u003E(avg@4)\u003C/sub\u003E | 46.00 | 36.00 | 54.20 | 56.00 | 60.00 | 41.50 | 58.00 |\n| Ï„Â²-Bench (retail)\u003Csub\u003E(avg@4)\u003C/sub\u003E | 64.90 | 70.50 | 70.80 | 74.10 | 80.00 | 64.80 | 71.27 |\n| AceBench\u003Csub\u003E(acc)\u003C/sub\u003E | 69.70 | 71.10 | 82.20 | 80.10* | 76.20* | 74.50* | 76.10 |\n| VitaBench\u003Csub\u003E(avg@4)\u003C/sub\u003E | 20.30 | 8.50 | 18.20 | 19.00 | 23.00 | 8.00 | 24.30 |\n| **Safety** | | | | | | | |\n| Harmful | 82.79 | 80.82 | 53.91 | 56.19 | 66.56 | - | 83.98 |\n| Criminal | 87.83 | 89.13 | 77.19 | 81.58 | 87.58 | - | 91.24 |\n| Misinformation | 83.17 | 77.76 | 42.68 | 45.49 | 54.91 | - | 81.72 |\n| Privacy | 98.80 | 98.80 | 96.39 | 98.80 | 100.00 | - | 93.98 |\n\nNote:\n* Values marked with `*` are sourced from other public reports. \n* DeepSeek-V3.1, Qwen3-235B-A22B, Gemini2.5-Flash, and Claude4-Sonnet are evaluated under their non-thinking mode.\n\n## Quick Start\n\n### Chat Template\nThe details of our chat template are provided in the `tokenizer_config.json` file. Below are some examples.\n\n#### First-Turn\n\nWith the following prefix, LongCat-Flash can generate responses corresponding to user queries:\n\n```\n[Round 0] USER:{query} ASSISTANT:\n```\n\nWhen a system prompt is specified, the prefix will take the following format:\n\n```\nSYSTEM:{system_prompt} [Round 0] USER:{query} ASSISTANT:\n```\n\n#### Multi-Turn\n\nIn multi-turn scenarios, the prefix is constructed by concatenating the context with the latest user query:\n```\nSYSTEM:{system_prompt} [Round 0] USER:{query} ASSISTANT:{response}\u003C/longcat_s\u003E... [Round N-1] USER:{query} ASSISTANT:{response}\u003C/longcat_s\u003E [Round N] USER:{query} ASSISTANT:\n```\n\nHere, N denotes the N-th round of user queries, with indexing starting from zero.\n\n#### ToolCall\n\nLongCat-Flash supports tool calling in the following format:\n```\n{tool_description}\n\n## Messages\nSYSTEM:{system_prompt} [Round 0] USER:{query} ASSISTANT:\n```\n\n\n\nThe tool_description is:\n```markdown\n## Tools\nYou have access to the following tools: \n\n### Tool namespace: function\n\n#### Tool name: {func.name}\n\nDescription: {func.description}\n\nInputSchema: \n{json.dumps(func.parameters, indent=2)}\n\n**Note**: For each function call, return a json object with function name and arguments within \u003Clongcat_tool_call\u003E\u003C/longcat_tool_call\u003E XML tags as follows:\n\u003Clongcat_tool_call\u003E\n{\"name\": \u003Cfunction-name\u003E, \"arguments\": \u003Cargs-dict\u003E}\n\u003C/longcat_tool_call\u003E\nWhen multiple functions need to be called simultaneously, each function call should be wrapped in its own \u003Clongcat_tool_call\u003E tag and placed consecutively. For example:\n\u003Clongcat_tool_call\u003E\n{\"name\": \u003Cfunction-name\u003E, \"arguments\": \u003Cargs-dict\u003E}\n\u003C/longcat_tool_call\u003E\u003Clongcat_tool_call\u003E\n{\"name\": \u003Cfunction-name\u003E, \"arguments\": \u003Cargs-dict\u003E}\n\u003C/longcat_tool_call\u003E\n```\n\n\n## Deployment\nWe have implemented basic adaptations in both SGLang and vLLM to support the deployment of LongCat-Flash. For comprehensive guidance, please refer to the [Deployment Guide](https://github.com/meituan-longcat/LongCat-Flash-Chat/blob/main/docs/deployment_guide.md) in the LongCat-Flash-Chat repository.\n\n## Chat Website\nYou can chat with LongCat-Flash on our official website: [https://longcat.ai](https://longcat.ai).\n\n## License Agreement\n\nThis repository, including both the model weights and the source code, is released under the **MIT License**. \n\nAny contributions to this repository are licensed under the MIT License, unless otherwise stated. This license does not grant any rights to use Meituan trademarks or patents. \n\nFor details, see the [LICENSE](https://huggingface.co/meituan-longcat/LongCat-Flash-Chat-FP8/raw/main/LICENSE) file. \n\n## Usage Considerations \nThis model has not been specifically designed or comprehensively evaluated for every possible downstream application. \n\nDevelopers should take into account the known limitations of large language models, including performance variations across different languages, and carefully assess accuracy, safety, and fairness before deploying the model in sensitive or high-risk scenarios. \nIt is the responsibility of developers and downstream users to understand and comply with all applicable laws and regulations relevant to their use case, including but not limited to data protection, privacy, and content safety requirements. \n\nNothing in this Model Card should be interpreted as altering or restricting the terms of the MIT License under which the model is released. \n\n\n## Citation\n\nWe kindly encourage citation of our work if you find it useful.\n\n```\n@misc{meituan2025longcatflashtechnicalreport, \n    title={LongCat-Flash Technical Report}, \n    author={Meituan LongCat Team}, \n    year={2025}, \n    eprint={2509.01322}, \n    archivePrefix={arXiv}, \n    primaryClass={cs.CL}, \n    url={https://arxiv.org/abs/2509.01322}, \n}\n```\n\n\n## Contact\nPlease contact us at \u003Ca href=\"mailto:longcat-team@meituan.com\"\u003Elongcat-team@meituan.com\u003C/a\u003E or open an issue if you have any questions.\n\n",
      "public": true,
      "version": "ace4fa76-c783-5f92-bed7-60c93b516e9c",
      "tool_description": null,
      "slug": "chutes-meituan-longcat-longcat-flash-chat-fp8",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-09-03T14:38:15.621158Z",
      "updated_at": "2025-10-10T08:37:42.792915Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 96648,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0,
            "tao": 0
          },
          "output": {
            "usd": 0,
            "tao": 0
          }
        },
        "usd": {
          "hour": 0,
          "second": 0
        },
        "tao": {
          "hour": 0,
          "second": 0
        }
      },
      "instances": [
        {
          "instance_id": "87e3f3b6-64a4-4583-9364-7c50d381bfef",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:08:00.855586Z"
        },
        {
          "instance_id": "c3ffce99-31f3-4c15-9c80-da153e3168a3",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:08:00.855586Z"
        },
        {
          "instance_id": "cf97edda-b45d-4823-88dd-73af0e0ebdb1",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:08:00.855586Z"
        },
        {
          "instance_id": "887afc05-0b8d-437d-bc90-6b639b066f5b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:08:00.855586Z"
        }
      ],
      "logo_id": "139883da-2eb2-44dc-a781-35192ab779a1",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "915be6c24abfd4f3b2d44913ad2536c84e4c3d45",
      "concurrency": 48,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/139883da-2eb2-44dc-a781-35192ab779a1.webp",
      "hot": true
    },
    {
      "chute_id": "07fc32f5-a63d-57e4-a86d-c167570b53e1",
      "name": "NousResearch/DeepHermes-3-Mistral-24B-Preview",
      "tagline": "DeepHermes 3 is a 24B parameter language model that uniquely combines traditional LLM responses with long chain-of-thought reasoning capabilities, making it particularly useful for complex problem-solving, detailed analysis, and general-purpose tasks like conversation and coding.",
      "readme": "# DeepHermes 3 - Mistral 24B Preview\n\n![image/jpeg](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/nZFJYtN7DvuyP7JQdfAMO.jpeg)\n\n## Model Description\n\nDeepHermes 3 Preview is the latest version of our flagship Hermes series of LLMs by Nous Research, and one of the first models in the world to unify Reasoning (long chains of thought that improve answer accuracy) and normal LLM response modes into one model. We have also improved LLM annotation, judgement, and function calling.\n\nDeepHermes 3 Preview is a hybrid reasoning model, and one of the first LLM models to unify both \"intuitive\", traditional mode responses and **long chain of thought reasoning** responses into a single model, toggled by a system prompt.\n\nHermes 3, the predecessor of DeepHermes 3, is a generalist language model with many improvements over Hermes 2, including advanced agentic capabilities, much better roleplaying, reasoning, multi-turn conversation, long context coherence, and improvements across the board.\n\nThe ethos of the Hermes series of models is focused on aligning LLMs to the user, with powerful steering capabilities and control given to the end user.\n\n*This is a preview Hermes with early reasoning capabilities, distilled from R1 across a variety of tasks that benefit from reasoning and objectivity. Some quirks may be discovered! Please let us know any interesting findings or issues you discover!*\n\n## Note: To toggle REASONING ON, you must use the following system prompt:\n```\nYou are a deep thinking AI, you may use extremely long chains of thought to deeply consider the problem and deliberate with yourself via systematic reasoning processes to help come to a correct solution prior to answering. You should enclose your thoughts and internal monologue inside \u003Cthink\u003E \u003C/think\u003E tags, and then provide your solution or response to the problem.\n```  \n\n# Nous API\n\nThis model is also available on our new API product - Check out the API and sign up for the waitlist here:\nhttps://portal.nousresearch.com/\n\n# Benchmarks:\n\nComparisons between Reasoning mode ON and OFF:\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/Qcemsj4-7Tf2a7SK-Nxg5.png)\n\nBenchmarks of Non-Reasoning mode on Traditional Benchmarks against Mistral-Small-24B-Instruct:\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/uNC__jwFG4dtWXed6pCSr.png)\n\n# Example Outputs:\n\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/_giUevm1IjPFWiypG0zd4.png)\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/bAI0HG2cFA_o1hTFIfCr_.png)\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/FmOIB7fjXKVHfs94DJPwn.png)\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/tfL1jeGXvv7xTAULFQgqs.png)\n\n# Prompt Format\n\nDeepHermes 3 now uses Llama-Chat format as the prompt format, opening up a more unified, structured system for engaging the LLM in multi-turn chat dialogue.\n\nSystem prompts allow steerability and interesting new ways to interact with an LLM, guiding rules, roles, and stylistic choices of the model.\n\n## Deep Thinking Mode - Deep Hermes Preview can activate long chain of thought with a system prompt.\n\n```\nYou are a deep thinking AI, you may use extremely long chains of thought to deeply consider the problem and deliberate with yourself via systematic reasoning processes to help come to a correct solution prior to answering. You should enclose your thoughts and internal monologue inside \u003Cthink\u003E \u003C/think\u003E tags, and then provide your solution or response to the problem.\n```\n\nFor an example of using deep reasoning mode with HuggingFace Transformers:\n```python\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport flash_attn\nimport time\n\ntokenizer = AutoTokenizer.from_pretrained(\"NousResearch/DeepHermes-3-Mistral-24B-Preview\")\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"NousResearch/DeepHermes-3-Mistral-24B-Preview\",\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    attn_implementation=\"flash_attention_2\",\n)\n\nmessages = [\n    {\n        \"role\": \"system\",\n        \"content\": \"You are a deep thinking AI, you may use extremely long chains of thought to deeply consider the problem and deliberate with yourself via systematic reasoning processes to help come to a correct solution prior to answering. You should enclose your thoughts and internal monologue inside \u003Cthink\u003E \u003C/think\u003E tags, and then provide your solution or response to the problem.\"\n    },\n    {\n        \"role\": \"user\",\n        \"content\": \"What is y if y=2*2-4+(3*2)\"\n    }\n]\n\ninput_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors='pt').to(\"cuda\")\ngenerated_ids = model.generate(input_ids, max_new_tokens=2500, temperature=0.8, repetition_penalty=1.1, do_sample=True, eos_token_id=tokenizer.eos_token_id)\nprint(f\"Generated Tokens: {generated_ids.shape[-1:]}\")\nresponse = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_space=True)\nprint(f\"Response: {response}\")\n```\n\nPlease note, for difficult problems DeepHermes can think using as many as 13,000 tokens. You may need to increase `max_new_tokens` to be much larger than 2500 for difficult problems.\n\n## Standard \"Intuitive\" Response Mode\n\nPrompt with system instruction (Use whatever system prompt you like, this is just an example!):\n\n```python\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport flash_attn\nimport time\n\ntokenizer = AutoTokenizer.from_pretrained(\"NousResearch/DeepHermes-3-Mistral-24B-Preview\")\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"NousResearch/DeepHermes-3-Mistral-24B-Preview\",\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    attn_implementation=\"flash_attention_2\",\n)\n\nmessages = [\n    {\n        \"role\": \"system\",\n        \"content\": \"You are Hermes, an AI assistant\"\n    },\n    {\n        \"role\": \"user\",\n        \"content\": \"What are the most interesting things to do in Paris?\"\n    }\n]\n\ninput_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors='pt').to(\"cuda\")\ngenerated_ids = model.generate(input_ids, max_new_tokens=2500, temperature=0.8, repetition_penalty=1.1, do_sample=True, eos_token_id=tokenizer.eos_token_id)\nprint(f\"Generated Tokens: {generated_ids.shape[-1:]}\")\nresponse = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_space=True)\nprint(f\"Response: {response}\")\n```\n\n## VLLM Inference\n\nYou can also run this model with vLLM, by running the following in your terminal after `pip install vllm`\n\n`vllm serve NousResearch/DeepHermes-3-Mistral-24B-Preview`\n\nYou may then use the model over API using the OpenAI library just like you would call OpenAI's API.\n\n## Prompt Format for Function Calling\n\nOur model was trained on specific system prompts and structures for Function Calling. \n\nYou should use the system role with this message, followed by a function signature json as this example shows here.\n```\n\u003C|start_header_id|\u003Esystem\u003C|end_header_id|\u003E\nYou are a function calling AI model. You are provided with function signatures within \u003Ctools\u003E\u003C/tools\u003E XML tags. You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools: \u003Ctools\u003E {\"type\": \"function\", \"function\": {\"name\": \"get_stock_fundamentals\", \"description\": \"get_stock_fundamentals(symbol: str) -\u003E dict - Get fundamental data for a given stock symbol using yfinance API.\\\\n\\\\n    Args:\\\\n        symbol (str): The stock symbol.\\\\n\\\\n    Returns:\\\\n        dict: A dictionary containing fundamental data.\\\\n            Keys:\\\\n                - \\'symbol\\': The stock symbol.\\\\n                - \\'company_name\\': The long name of the company.\\\\n                - \\'sector\\': The sector to which the company belongs.\\\\n                - \\'industry\\': The industry to which the company belongs.\\\\n                - \\'market_cap\\': The market capitalization of the company.\\\\n                - \\'pe_ratio\\': The forward price-to-earnings ratio.\\\\n                - \\'pb_ratio\\': The price-to-book ratio.\\\\n                - \\'dividend_yield\\': The dividend yield.\\\\n                - \\'eps\\': The trailing earnings per share.\\\\n                - \\'beta\\': The beta value of the stock.\\\\n                - \\'52_week_high\\': The 52-week high price of the stock.\\\\n                - \\'52_week_low\\': The 52-week low price of the stock.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"symbol\": {\"type\": \"string\"}}, \"required\": [\"symbol\"]}}}  \u003C/tools\u003E Use the following pydantic model json schema for each tool call you will make: {\"properties\": {\"arguments\": {\"title\": \"Arguments\", \"type\": \"object\"}, \"name\": {\"title\": \"Name\", \"type\": \"string\"}}, \"required\": [\"arguments\", \"name\"], \"title\": \"FunctionCall\", \"type\": \"object\"} For each function call return a json object with function name and arguments within \u003Ctool_call\u003E\u003C/tool_call\u003E XML tags as follows:\n\u003Ctool_call\u003E\n{\"arguments\": \u003Cargs-dict\u003E, \"name\": \u003Cfunction-name\u003E}\n\u003C/tool_call\u003E\u003C|eot_id|\u003E\u003C|start_header_id|\u003Euser\u003C|end_header_id|\u003E\n```\n\nTo complete the function call, create a user prompt that follows the above system prompt, like so:\n```\nFetch the stock fundamentals data for Tesla (TSLA)\u003C|eot_id|\u003E\u003C|start_header_id|\u003Eassistant\u003C|end_header_id|\u003E\n```\n\nThe model will then generate a tool call, which your inference code must parse, and plug into a function (see example inference code here: https://github.com/NousResearch/Hermes-Function-Calling):\n```\n\u003Ctool_call\u003E\n{\"arguments\": {\"symbol\": \"TSLA\"}, \"name\": \"get_stock_fundamentals\"}\n\u003C/tool_call\u003E\u003C|eot_id|\u003E\u003C|start_header_id|\u003Etool\u003C|end_header_id|\u003E\n```\n\nOnce you parse the tool call, call the api and get the returned values for the call, and pass it back in as a new role, `tool` like so:\n```\n\u003Ctool_response\u003E\n{\"name\": \"get_stock_fundamentals\", \"content\": {'symbol': 'TSLA', 'company_name': 'Tesla, Inc.', 'sector': 'Consumer Cyclical', 'industry': 'Auto Manufacturers', 'market_cap': 611384164352, 'pe_ratio': 49.604652, 'pb_ratio': 9.762013, 'dividend_yield': None, 'eps': 4.3, 'beta': 2.427, '52_week_high': 299.29, '52_week_low': 152.37}}\n\u003C/tool_response\u003E\n\u003C|eot_id|\u003E\u003C|start_header_id|\u003Eassistant\u003C|end_header_id|\u003E\n```\n\nThe assistant will then read in that data from the function's response, and generate a natural language response:\n```\nThe stock fundamentals data for Tesla (TSLA) are as follows:\n- **Symbol**: TSLA\n- **Company Name**: Tesla, Inc.\n- **Sector**: Consumer Cyclical\n- **Industry**: Auto Manufacturers\n- **Market Capitalization**: $566,160,130,480\n- **Forward Price-to-Earnings Ratio (PE Ratio)**: 42.73\n- **Price-to-Book Ratio (PB Ratio)**: 9.04\n- **Dividend Yield**: N/A\n- **Trailing Earnings Per Share (EPS)**: $4.3\n- **Beta Value of the Stock**: 2.42\n- **52-Week High Price of the Stock**: $299.29\n- **52-Week Low Price of the Stock**: $152.37\n\nThis information provides a snapshot of Tesla's financial position and performance based on the fundamental data obtained from the yfinance API. It shows that Tesla has a substantial market capitalization and a relatively high P/E and P/B ratio compared to other stocks in its industry. The company does not pay a dividend at the moment, which is reflected by a 'Dividend Yield' of 'None'. The Beta value indicates that Tesla's stock has a moderate level of volatility relative to the market. The 52-week high and low prices give an idea of the stock's range over the past year. This data can be useful when assessing investment opportunities and making investment decisions.\u003C|eot_id|\u003E\u003C|start_header_id|\u003Euser\u003C|end_header_id|\u003E\n```\n\n\n## Prompt Format for JSON Mode / Structured Outputs\n\nOur model was also trained on a specific system prompt for Structured Outputs, which should respond with **only** a json object response, in a specific json schema.\n\nYour schema can be made from a pydantic object using our codebase, with the standalone script `jsonmode.py` available here: https://github.com/NousResearch/Hermes-Function-Calling/tree/main\n\n```\n\u003C|start_header_id|\u003Esystem\u003C|end_header_id|\u003E\nYou are a helpful assistant that answers in JSON. Here's the json schema you must adhere to:\\n\u003Cschema\u003E\\n{schema}\\n\u003C/schema\u003E\u003C|eot_id|\u003E\n```\n\nGiven the {schema} that you provide, it should follow the format of that json to create its response, all you have to do is give a typical user prompt, and it will respond in JSON.\n\n\n## Inference Code for Function Calling:\n\nAll code for utilizing, parsing, and building function calling templates is available on our github:\n[https://github.com/NousResearch/Hermes-Function-Calling](https://github.com/NousResearch/Hermes-Function-Calling)\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/oi4CiGh50xmoviUQnh8R3.png)\n\n\n## Quantized Versions:\n\nGGUF Quants: https://huggingface.co/NousResearch/DeepHermes-3-Mistral-24B-Preview-GGUF\n\n# How to cite:\n\n```bibtext\n@misc{\n      title={DeepHermes 3 Preview}, \n      author={Teknium and Roger Jin and Chen Guang and Jai Suphavadeeprasit and Jeffrey Quesnelle},\n      year={2025}\n}\n```",
      "public": true,
      "version": "66fa4602-e605-513d-a452-2ff4e47f3f6c",
      "tool_description": null,
      "slug": "chutes-nousresearch-deephermes-3-mistral-24b-preview",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-05-08T08:22:24.723375Z",
      "updated_at": "2025-10-09T19:47:27.399615Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "h100_nvl",
        "h100",
        "h100_sxm",
        "h800"
      ],
      "node_selector": {
        "exclude": null,
        "include": [
          "h200",
          "h100",
          "h100_sxm",
          "h100_nvl",
          "h800"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 2.66666666666667,
        "supported_gpus": [
          "h200",
          "h100_nvl",
          "h100",
          "h100_sxm",
          "h800"
        ]
      },
      "invocation_count": 92817,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          },
          "output": {
            "usd": 0.59,
            "tao": 0.00146527751735298
          }
        },
        "usd": {
          "hour": 10.8,
          "second": 0.003
        },
        "tao": {
          "hour": 0.0268220291312072,
          "second": 0.000007450563647557
        }
      },
      "instances": [
        {
          "instance_id": "a91b9455-aeac-4d51-a82c-e9bf483e174e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:42:52.938972Z"
        },
        {
          "instance_id": "5fb62e1e-1784-448e-8313-32ec99f3dd82",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:42:52.938972Z"
        },
        {
          "instance_id": "7c613ab4-d22a-4c05-9aac-ddff736f1eee",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:42:52.938972Z"
        },
        {
          "instance_id": "c686e432-c3b8-4bdc-865e-2f62fca792c3",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:42:52.938972Z"
        },
        {
          "instance_id": "0c24be83-57f5-4a94-a0f6-a2342a256ff5",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:06:26.367775Z"
        }
      ],
      "logo_id": "70a9787c-556a-43c5-9dc1-e4f1ef180811",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "48072dc6c0594a3198eb862c13613c4ab1119009",
      "concurrency": 32,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/70a9787c-556a-43c5-9dc1-e4f1ef180811.webp",
      "hot": true
    },
    {
      "chute_id": "8cac9bf4-d7e2-55eb-b4bb-1416b7f57131",
      "name": "chutesai/Mistral-Small-3.2-24B-Instruct-2506",
      "tagline": "Mistral-Small-3.2-24B-Instruct-2506 is a 24B parameter multimodal LLM that excels at instruction following, vision tasks, and function calling while producing fewer repetitive outputs compared to its predecessor.",
      "readme": "\n# Mistral-Small-3.2-24B-Instruct-2506\n\nMistral-Small-3.2-24B-Instruct-2506 is a minor update of [Mistral-Small-3.1-24B-Instruct-2503](https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Base-2503).\n\nSmall-3.2 improves in the following categories:\n- **Instruction following**: Small-3.2 is better at following precise instructions\n- **Repetition errors**: Small-3.2 produces less infinite generations or repetitive answers\n- **Function calling**: Small-3.2's function calling template is more robust (see [here](https://github.com/mistralai/mistral-common/blob/535b4d0a0fc94674ea17db6cf8dc2079b81cbcfa/src/mistral_common/tokens/tokenizers/instruct.py#L778) and [examples](https://huggingface.co/chutesai/Mistral-Small-3.2-24B-Instruct-2506/raw/main/#function-calling))\n\nIn all other categories Small-3.2 should match or slightly improve compared to [Mistral-Small-3.1-24B-Instruct-2503](https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Base-2503).\n\n## Key Features\n- same as [Mistral-Small-3.1-24B-Instruct-2503](https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Base-2503#key-features)\n\n## Benchmark Results\n\nWe compare Mistral-Small-3.2-24B to [Mistral-Small-3.1-24B-Instruct-2503](https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Base-2503).\nFor more comparison against other models of similar size, please check [Mistral-Small-3.1's Benchmarks'](https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Base-2503#benchmark-results)\n\n### Text \n\n#### Instruction Following / Chat / Tone\n\n| Model | Wildbench v2 | Arena Hard v2 | IF (Internal; accuracy) |\n|-------|---------------|---------------|------------------------|\n| Small 3.1 24B Instruct | 55.6% | 19.56% | 82.75% |\n| **Small 3.2 24B Instruct** | **65.33%** | **43.1%** | **84.78%** |\n\n#### Infinite Generations\n\nSmall 3.2 reduces infitine generations by 2x on challenging, long and repetitive prompts.\n\n| Model | Infinite Generations (Internal; Lower is better) |\n|-------|-------|\n| Small 3.1 24B Instruct | 2.11% |\n| **Small 3.2 24B Instruct** | **1.29%** |\n\n#### STEM\n\n| Model                          | MMLU      | MMLU Pro (5-shot CoT) | MATH                   | GPQA Main (5-shot CoT) | GPQA Diamond (5-shot CoT )| MBPP Plus - Pass@5 | HumanEval Plus - Pass@5 | SimpleQA (TotalAcc)|\n|--------------------------------|-----------|-----------------------|------------------------|------------------------|---------------------------|--------------------|-------------------------|--------------------|\n| Small 3.1 24B Instruct         | 80.62%    | 66.76%                | 69.30%                 | 44.42%                 | 45.96%                    | 74.63%             | 88.99%                  | 10.43%             |\n| **Small 3.2 24B Instruct**     | 80.50%    | **69.06%**            | 69.42%                 | 44.22%                 | 46.13%                    | **78.33%**         | **92.90%**              | **12.10%**         |\n\n### Vision\n\n| Model                          | MMMU       | Mathvista | ChartQA   | DocVQA    | AI2D      |\n|--------------------------------|------------|-----------|-----------|-----------|-----------|\n| Small 3.1 24B Instruct         | **64.00%** | **68.91%**| 86.24%    | 94.08%    | 93.72%  | \n| **Small 3.2 24B Instruct**     | 62.50%     | 67.09%    | **87.4%** | 94.86%    | 92.91%  | \n\n\n## Usage\n\nThe model can be used with the following frameworks;\n- [`vllm (recommended)`](https://github.com/vllm-project/vllm): See [here](https://huggingface.co/chutesai/Mistral-Small-3.2-24B-Instruct-2506/raw/main/#vllm-recommended)\n- [`transformers`](https://github.com/huggingface/transformers): See [here](https://huggingface.co/chutesai/Mistral-Small-3.2-24B-Instruct-2506/raw/main/#transformers)\n\n**Note 1**: We recommend using a relatively low temperature, such as `temperature=0.15`.\n\n**Note 2**: Make sure to add a system prompt to the model to best tailer it for your needs. If you want to use the model as a general assistant, we recommend to use the one provided in the [SYSTEM_PROMPT.txt](https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506/blob/main/SYSTEM_PROMPT.txt) file.\n\n### vLLM (recommended)\n\nWe recommend using this model with [vLLM](https://github.com/vllm-project/vllm).\n\n#### Installation\n\nMake sure to install [`vLLM \u003E= 0.9.1`](https://github.com/vllm-project/vllm/releases/tag/v0.9.1):\n\n```\npip install vllm --upgrade\n```\n\nDoing so should automatically install [`mistral_common \u003E= 1.6.2`](https://github.com/mistralai/mistral-common/releases/tag/v1.6.2).\n\nTo check:\n```\npython -c \"import mistral_common; print(mistral_common.__version__)\"\n```\n\nYou can also make use of a ready-to-go [docker image](https://github.com/vllm-project/vllm/blob/main/Dockerfile) or on the [docker hub](https://hub.docker.com/layers/vllm/vllm-openai/latest/images/sha256-de9032a92ffea7b5c007dad80b38fd44aac11eddc31c435f8e52f3b7404bbf39).\n\n#### Serve\n\nWe recommand that you use Mistral-Small-3.2-24B-Instruct-2506 in a server/client setting. \n\n1. Spin up a server:\n\n```\nvllm serve mistralai/Mistral-Small-3.2-24B-Instruct-2506 --tokenizer_mode mistral --config_format mistral --load_format mistral --tool-call-parser mistral --enable-auto-tool-choice --limit_mm_per_prompt 'image=10' --tensor-parallel-size 2\n```\n\n**Note:** Running Mistral-Small-3.2-24B-Instruct-2506 on GPU requires ~55 GB of GPU RAM in bf16 or fp16. \n\n\n2. To ping the client you can use a simple Python snippet. See the following examples.\n\n\n#### Vision reasoning\n\nTake leverage of the vision capabilities of Mistral-Small-3.2-24B-Instruct-2506 to take the best choice given a scenario, go catch them all !\n\n\u003Cdetails\u003E\n  \u003Csummary\u003EPython snippet\u003C/summary\u003E\n\n```py\nfrom datetime import datetime, timedelta\n\nfrom openai import OpenAI\nfrom huggingface_hub import hf_hub_download\n\n# Modify OpenAI's API key and API base to use vLLM's API server.\nopenai_api_key = \"EMPTY\"\nopenai_api_base = \"http://localhost:8000/v1\"\n\nTEMP = 0.15\nMAX_TOK = 131072\n\nclient = OpenAI(\n    api_key=openai_api_key,\n    base_url=openai_api_base,\n)\n\nmodels = client.models.list()\nmodel = models.data[0].id\n\n\ndef load_system_prompt(repo_id: str, filename: str) -\u003E str:\n    file_path = hf_hub_download(repo_id=repo_id, filename=filename)\n    with open(file_path, \"r\") as file:\n        system_prompt = file.read()\n    today = datetime.today().strftime(\"%Y-%m-%d\")\n    yesterday = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n    model_name = repo_id.split(\"/\")[-1]\n    return system_prompt.format(name=model_name, today=today, yesterday=yesterday)\n\n\nmodel_id = \"mistralai/Mistral-Small-3.2-24B-Instruct-2506\"\nSYSTEM_PROMPT = load_system_prompt(model_id, \"SYSTEM_PROMPT.txt\")\nimage_url = \"https://static.wikia.nocookie.net/essentialsdocs/images/7/70/Battle.png/revision/latest?cb=20220523172438\"\n\nmessages = [\n    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"text\",\n                \"text\": \"What action do you think I should take in this situation? List all the possible actions and explain why you think they are good or bad.\",\n            },\n            {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n        ],\n    },\n]\n\n\nresponse = client.chat.completions.create(\n    model=model,\n    messages=messages,\n    temperature=TEMP,\n    max_tokens=MAX_TOK,\n)\n\nprint(response.choices[0].message.content)\n# In this situation, you are playing a PokÃ©mon game where your Pikachu (Level 42) is facing a wild Pidgey (Level 17). Here are the possible actions you can take and an analysis of each:\n\n# 1. **FIGHT**:\n#    - **Pros**: Pikachu is significantly higher level than the wild Pidgey, which suggests that it should be able to defeat Pidgey easily. This could be a good opportunity to gain experience points and possibly items or money.\n#    - **Cons**: There is always a small risk of Pikachu fainting, especially if Pidgey has a powerful move or a status effect that could hinder Pikachu. However, given the large level difference, this risk is minimal.\n\n# 2. **BAG**:\n#    - **Pros**: You might have items in your bag that could help in this battle, such as Potions, PokÃ© Balls, or Berries. Using an item could help you capture the Pidgey or heal your Pikachu if needed.\n#    - **Cons**: Using items might not be necessary given the level difference. It could be more efficient to just fight and defeat the Pidgey quickly.\n\n# 3. **POKÃ‰MON**:\n#    - **Pros**: You might have another PokÃ©mon in your party that is better suited for this battle or that you want to gain experience. Switching PokÃ©mon could also be a strategic move if you want to train a lower-level PokÃ©mon.\n#    - **Cons**: Switching PokÃ©mon might not be necessary since Pikachu is at a significant advantage. It could also waste time and potentially give Pidgey a turn to attack.\n\n# 4. **RUN**:\n#    - **Pros**: Running away could save time and conserve your PokÃ©mon's health and resources. If you are in a hurry or do not need the experience or items, running away is a safe option.\n#    - **Cons**: Running away means you miss out on the experience points and potential items or money that you could gain from defeating the Pidgey. It also means you do not get the chance to capture the Pidgey if you wanted to.\n\n# ### Recommendation:\n# Given the significant level advantage, the best action is likely to **FIGHT**. This will allow you to quickly defeat the Pidgey, gain experience points, and potentially earn items or money. If you are concerned about Pikachu's health, you could use an item from your **BAG** to heal it before or during the battle. Running away or switching PokÃ©mon does not seem necessary in this situation.\n```\n\u003C/details\u003E\n\n#### Function calling\n\nMistral-Small-3.2-24B-Instruct-2506 is excellent at function / tool calling tasks via vLLM. *E.g.:*\n\n\u003Cdetails\u003E\n  \u003Csummary\u003EPython snippet - easy\u003C/summary\u003E\n\n```py\nfrom openai import OpenAI\nfrom huggingface_hub import hf_hub_download\n\n# Modify OpenAI's API key and API base to use vLLM's API server.\nopenai_api_key = \"EMPTY\"\nopenai_api_base = \"http://localhost:8000/v1\"\n\nTEMP = 0.15\nMAX_TOK = 131072\n\nclient = OpenAI(\n    api_key=openai_api_key,\n    base_url=openai_api_base,\n)\n\nmodels = client.models.list()\nmodel = models.data[0].id\n\ndef load_system_prompt(repo_id: str, filename: str) -\u003E str:\n    file_path = hf_hub_download(repo_id=repo_id, filename=filename)\n    with open(file_path, \"r\") as file:\n        system_prompt = file.read()\n    return system_prompt\n\nmodel_id = \"mistralai/Mistral-Small-3.2-24B-Instruct-2506\"\nSYSTEM_PROMPT = load_system_prompt(model_id, \"SYSTEM_PROMPT.txt\")\n\nimage_url = \"https://huggingface.co/datasets/patrickvonplaten/random_img/resolve/main/europe.png\"\n\ntools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_current_population\",\n            \"description\": \"Get the up-to-date population of a given country.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"country\": {\n                        \"type\": \"string\",\n                        \"description\": \"The country to find the population of.\",\n                    },\n                    \"unit\": {\n                        \"type\": \"string\",\n                        \"description\": \"The unit for the population.\",\n                        \"enum\": [\"millions\", \"thousands\"],\n                    },\n                },\n                \"required\": [\"country\", \"unit\"],\n            },\n        },\n    },\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"rewrite\",\n            \"description\": \"Rewrite a given text for improved clarity\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"text\": {\n                        \"type\": \"string\",\n                        \"description\": \"The input text to rewrite\",\n                    }\n                },\n            },\n        },\n    },\n]\n\nmessages = [\n    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n    {\n        \"role\": \"user\",\n        \"content\": \"Could you please make the below article more concise?\\n\\nOpenAI is an artificial intelligence research laboratory consisting of the non-profit OpenAI Incorporated and its for-profit subsidiary corporation OpenAI Limited Partnership.\",\n    },\n    {\n        \"role\": \"assistant\",\n        \"content\": \"\",\n        \"tool_calls\": [\n            {\n                \"id\": \"bbc5b7ede\",\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": \"rewrite\",\n                    \"arguments\": '{\"text\": \"OpenAI is an artificial intelligence research laboratory consisting of the non-profit OpenAI Incorporated and its for-profit subsidiary corporation OpenAI Limited Partnership.\"}',\n                },\n            }\n        ],\n    },\n    {\n        \"role\": \"tool\",\n        \"content\": '{\"action\":\"rewrite\",\"outcome\":\"OpenAI is a FOR-profit company.\"}',\n        \"tool_call_id\": \"bbc5b7ede\",\n        \"name\": \"rewrite\",\n    },\n    {\n        \"role\": \"assistant\",\n        \"content\": \"---\\n\\nOpenAI is a FOR-profit company.\",\n    },\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"text\",\n                \"text\": \"Can you tell me what is the biggest country depicted on the map?\",\n            },\n            {\n                \"type\": \"image_url\",\n                \"image_url\": {\n                    \"url\": image_url,\n                },\n            },\n        ],\n    }\n]\n\nresponse = client.chat.completions.create(\n    model=model,\n    messages=messages,\n    temperature=TEMP,\n    max_tokens=MAX_TOK,\n    tools=tools,\n    tool_choice=\"auto\",\n)\n\nassistant_message = response.choices[0].message.content\nprint(assistant_message)\n# The biggest country depicted on the map is Russia.\n\nmessages.extend([\n    {\"role\": \"assistant\", \"content\": assistant_message},\n    {\"role\": \"user\", \"content\": \"What is the population of that country in millions?\"},\n])\n\nresponse = client.chat.completions.create(\n    model=model,\n    messages=messages,\n    temperature=TEMP,\n    max_tokens=MAX_TOK,\n    tools=tools,\n    tool_choice=\"auto\",\n)\n\nprint(response.choices[0].message.tool_calls)\n# [ChatCompletionMessageToolCall(id='3e92V6Vfo', function=Function(arguments='{\"country\": \"Russia\", \"unit\": \"millions\"}', name='get_current_population'), type='function')]\n```\n\n\u003C/details\u003E\n\n\u003Cdetails\u003E\n  \u003Csummary\u003EPython snippet - complex\u003C/summary\u003E\n\n```python\nimport json\nfrom openai import OpenAI\nfrom huggingface_hub import hf_hub_download\n\n# Modify OpenAI's API key and API base to use vLLM's API server.\nopenai_api_key = \"EMPTY\"\nopenai_api_base = \"http://localhost:8000/v1\"\n\nTEMP = 0.15\nMAX_TOK = 131072\n\nclient = OpenAI(\n    api_key=openai_api_key,\n    base_url=openai_api_base,\n)\n\nmodels = client.models.list()\nmodel = models.data[0].id\n\n\ndef load_system_prompt(repo_id: str, filename: str) -\u003E str:\n    file_path = hf_hub_download(repo_id=repo_id, filename=filename)\n    with open(file_path, \"r\") as file:\n        system_prompt = file.read()\n    return system_prompt\n\n\nmodel_id = \"mistralai/Mistral-Small-3.2-24B-Instruct-2506\"\nSYSTEM_PROMPT = load_system_prompt(model_id, \"SYSTEM_PROMPT.txt\")\n\nimage_url = \"https://math-coaching.com/img/fiche/46/expressions-mathematiques.jpg\"\n\n\ndef my_calculator(expression: str) -\u003E str:\n    return str(eval(expression))\n\n\ntools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"my_calculator\",\n            \"description\": \"A calculator that can evaluate a mathematical expression.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"expression\": {\n                        \"type\": \"string\",\n                        \"description\": \"The mathematical expression to evaluate.\",\n                    },\n                },\n                \"required\": [\"expression\"],\n            },\n        },\n    },\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"rew",
      "public": true,
      "version": "97677c6a-500d-5fe1-8349-7abcfb686081",
      "tool_description": null,
      "slug": "chutes-chutesai-mistral-small-3-2-24b-instruct-2506",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-06-21T08:02:09.877938Z",
      "updated_at": "2025-10-10T07:23:11.656703Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm",
        "h800"
      ],
      "node_selector": {
        "exclude": null,
        "include": [
          "h200",
          "h100",
          "h100_sxm",
          "h800"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 2.66666666666667,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm",
          "h800"
        ]
      },
      "invocation_count": 87694,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.06,
            "tao": 0.00014901127295115
          },
          "output": {
            "usd": 0.18,
            "tao": 0.000447033818853452
          }
        },
        "usd": {
          "hour": 12,
          "second": 0.00333333333333333
        },
        "tao": {
          "hour": 0.0298022545902302,
          "second": 0.000008278404052841
        }
      },
      "instances": [
        {
          "instance_id": "ce8d3528-c051-446b-9e68-7de420abcffe",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:07:10.341603Z"
        },
        {
          "instance_id": "6ee86dfe-b8bd-46fd-81da-8275edbe4bbf",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:19:29.071370Z"
        },
        {
          "instance_id": "aa6fbf27-aee8-451d-af20-0002ff1636c0",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:48:22.680811Z"
        },
        {
          "instance_id": "27f8e32d-7e16-4037-bf99-cac8d2df9345",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:48:22.680811Z"
        },
        {
          "instance_id": "ccc29b81-7300-4143-9a62-3fb2163e86fb",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T11:18:57.605199Z"
        }
      ],
      "logo_id": "780a2a47-d570-4415-a4ad-fad0268fb2c2",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "0622dc8fd791a072983aa1794989ce54accc7a91",
      "concurrency": 32,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/780a2a47-d570-4415-a4ad-fad0268fb2c2.webp",
      "hot": true
    },
    {
      "chute_id": "8af6d155-afa6-5398-9981-d4301ad835c8",
      "name": "pamanseau/OpenReasoning-Nemotron-32B",
      "tagline": "",
      "readme": "pamanseau/OpenReasoning-Nemotron-32B",
      "public": true,
      "version": "6bcdcedd-c48f-5845-9d29-2509b2e2dd93",
      "tool_description": null,
      "slug": "sn64-pamanseau-openreasoning-nemotron-32b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-08-11T10:11:14.338084Z",
      "updated_at": "2025-08-11T10:11:14.338084Z",
      "image": {
        "image_id": "dd30a5e7-24ae-538e-bee7-ba6a93b3d2f0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "0.4.9.post6",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-08-06T20:56:26.489668Z",
        "build_started_at": "2025-08-06T20:56:28.092938Z",
        "build_completed_at": "2025-08-06T21:28:45.347952Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "65013002be06",
        "logo": null
      },
      "user": {
        "username": "sn64",
        "user_id": "f8b10374-2e41-5f2c-ace5-bc93983d6f35",
        "logo_id": null,
        "created_at": "2025-08-11T09:11:46.507449Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "exclude": [
          "b200",
          "mi300x",
          "h200"
        ],
        "include": null,
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.444444444444444,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 78421,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          },
          "output": {
            "usd": 0.11,
            "tao": 0.000273187333743776
          }
        },
        "usd": {
          "hour": 2,
          "second": 0.000555555555555555
        },
        "tao": {
          "hour": 0.00496704243170503,
          "second": 0.000001379734008806
        }
      },
      "instances": [
        {
          "instance_id": "3cea4abb-2661-42ea-bab9-99e7ee852e7b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:49:02.575823Z"
        },
        {
          "instance_id": "a81b7c14-14be-4d8f-af2f-9168fd195778",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:49:02.575823Z"
        },
        {
          "instance_id": "8999b69e-1cf3-464f-b4a7-e6344ed143d3",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:49:02.575823Z"
        },
        {
          "instance_id": "2e315c4d-dabd-4b1f-88e6-a9fee4ecc764",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:49:02.575823Z"
        },
        {
          "instance_id": "c737abcc-2d0e-418d-9491-c50464a16c8c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:49:02.575823Z"
        },
        {
          "instance_id": "3f3d2b55-cc77-463a-bba5-53e3d33ac0b3",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:49:02.575823Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.31.rc1",
      "revision": "ef9c66c589c282deec19e9d11340abad70ce37b3",
      "concurrency": 20,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "fa065f66-c8d4-5af0-a6b4-af47e2ef2473",
      "name": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "tagline": "Qwen3-30B-A3B-Instruct-2507 is a 30.5B parameter instruction-tuned language model (with 3.3B activated parameters) that excels at tasks like reasoning, coding, and long-context understanding up to 256K tokens, making it particularly useful for complex reasoning, coding, and processing long documents.",
      "readme": "\n# Qwen3-30B-A3B-Instruct-2507\n\u003Ca href=\"https://chat.qwen.ai/?model=Qwen3-30B-A3B-2507\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/%F0%9F%92%9C%EF%B8%8F%20Qwen%20Chat%20-536af5\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n\u003C/a\u003E\n\n## Highlights\n\nWe introduce the updated version of the **Qwen3-30B-A3B non-thinking mode**, named **Qwen3-30B-A3B-Instruct-2507**, featuring the following key enhancements:\n\n- **Significant improvements** in general capabilities, including **instruction following, logical reasoning, text comprehension, mathematics, science, coding and tool usage**.\n- **Substantial gains** in long-tail knowledge coverage across **multiple languages**.\n- **Markedly better alignment** with user preferences in **subjective and open-ended tasks**, enabling more helpful responses and higher-quality text generation.\n- **Enhanced capabilities** in **256K long-context understanding**.\n\n![image/jpeg](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-2507/Qwen3-30B-A3B-Instruct-2507.jpeg)\n\n## Model Overview\n\n**Qwen3-30B-A3B-Instruct-2507** has the following features:\n- Type: Causal Language Models\n- Training Stage: Pretraining & Post-training\n- Number of Parameters: 30.5B in total and 3.3B activated\n- Number of Paramaters (Non-Embedding): 29.9B\n- Number of Layers: 48\n- Number of Attention Heads (GQA): 32 for Q and 4 for KV\n- Number of Experts: 128\n- Number of Activated Experts: 8\n- Context Length: **262,144 natively**. \n\n**NOTE: This model supports only non-thinking mode and does not generate ``\u003Cthink\u003E\u003C/think\u003E`` blocks in its output. Meanwhile, specifying `enable_thinking=False` is no longer required.**\n\nFor more details, including benchmark evaluation, hardware requirements, and inference performance, please refer to our [blog](https://qwenlm.github.io/blog/qwen3/), [GitHub](https://github.com/QwenLM/Qwen3), and [Documentation](https://qwen.readthedocs.io/en/latest/).\n\n\n## Performance\n\n|  | Deepseek-V3-0324 | GPT-4o-0327 | Gemini-2.5-Flash Non-Thinking | Qwen3-235B-A22B Non-Thinking | Qwen3-30B-A3B Non-Thinking | Qwen3-30B-A3B-Instruct-2507 |\n|--- | --- | --- | --- | --- | --- | --- |\n| **Knowledge** | | | | | | |\n| MMLU-Pro | **81.2** | 79.8 | 81.1 | 75.2 | 69.1 | 78.4 |\n| MMLU-Redux | 90.4 | **91.3** | 90.6 | 89.2 | 84.1 | 89.3 |\n| GPQA | 68.4 | 66.9 | **78.3** | 62.9 | 54.8 | 70.4 |\n| SuperGPQA | **57.3** | 51.0 | 54.6 | 48.2 | 42.2 | 53.4 |\n| **Reasoning** | | | | | | |\n| AIME25 | 46.6 | 26.7 | **61.6** | 24.7 | 21.6 | 61.3 |\n| HMMT25 | 27.5 | 7.9 | **45.8** | 10.0 | 12.0 | 43.0 |\n| ZebraLogic | 83.4 | 52.6 | 57.9 | 37.7 | 33.2 | **90.0** |\n| LiveBench 20241125 | 66.9 | 63.7 | **69.1** | 62.5 | 59.4 | 69.0 |\n| **Coding** | | | | | | |\n| LiveCodeBench v6 (25.02-25.05) | **45.2** | 35.8 | 40.1 | 32.9 | 29.0 | 43.2 |\n| MultiPL-E | 82.2 | 82.7 | 77.7 | 79.3 | 74.6 | **83.8** |\n| Aider-Polyglot | 55.1 | 45.3 | 44.0 | **59.6** | 24.4 | 35.6 |\n| **Alignment** | | | | | | |\n| IFEval | 82.3 | 83.9 | 84.3 | 83.2 | 83.7 | **84.7** |\n| Arena-Hard v2* | 45.6 | 61.9 | 58.3 | 52.0 | 24.8 | **69.0** |\n| Creative Writing v3 | 81.6 | 84.9 | 84.6 | 80.4 | 68.1 | **86.0** |\n| WritingBench | 74.5 | 75.5 | 80.5 | 77.0 | 72.2 | **85.5** |\n| **Agent** | | | | | | |\n| BFCL-v3 | 64.7 | 66.5 | 66.1 | **68.0** | 58.6 | 65.1 |\n| TAU1-Retail | 49.6 | 60.3# | **65.2** | 65.2 | 38.3 | 59.1 |\n| TAU1-Airline | 32.0 | 42.8# | **48.0** | 32.0 | 18.0 | 40.0 |\n| TAU2-Retail | **71.1** | 66.7# | 64.3 | 64.9 | 31.6 | 57.0 |\n| TAU2-Airline | 36.0 | 42.0# | **42.5** | 36.0 | 18.0 | 38.0 |\n| TAU2-Telecom | **34.0** | 29.8# | 16.9 | 24.6 | 18.4 | 12.3 |\n| **Multilingualism** | | | | | | |\n| MultiIF | 66.5 | 70.4 | 69.4 | 70.2 | **70.8** | 67.9 |\n| MMLU-ProX | 75.8 | 76.2 | **78.3** | 73.2 | 65.1 | 72.0 |\n| INCLUDE | 80.1 | 82.1 | **83.8** | 75.6 | 67.8 | 71.9 |\n| PolyMATH | 32.2 | 25.5 | 41.9 | 27.0 | 23.3 | **43.1** |\n\n*: For reproducibility, we report the win rates evaluated by GPT-4.1.\n\n\\#: Results were generated using GPT-4o-20241120, as access to the native function calling API of GPT-4o-0327 was unavailable.\n\n\n## Quickstart\n\nThe code of Qwen3-MoE has been in the latest Hugging Face `transformers` and we advise you to use the latest version of `transformers`.\n\nWith `transformers\u003C4.51.0`, you will encounter the following error:\n```\nKeyError: 'qwen3_moe'\n```\n\nThe following contains a code snippet illustrating how to use the model generate content based on given inputs. \n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"Qwen/Qwen3-30B-A3B-Instruct-2507\"\n\n# load the tokenizer and the model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=\"auto\",\n    device_map=\"auto\"\n)\n\n# prepare the model input\nprompt = \"Give me a short introduction to large language model.\"\nmessages = [\n    {\"role\": \"user\", \"content\": prompt}\n]\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\n# conduct text completion\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=16384\n)\noutput_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n\ncontent = tokenizer.decode(output_ids, skip_special_tokens=True)\n\nprint(\"content:\", content)\n```\n\nFor deployment, you can use `sglang\u003E=0.4.6.post1` or `vllm\u003E=0.8.5` or to create an OpenAI-compatible API endpoint:\n- SGLang:\n    ```shell\n    python -m sglang.launch_server --model-path Qwen/Qwen3-30B-A3B-Instruct-2507 --context-length 262144\n    ```\n- vLLM:\n    ```shell\n    vllm serve Qwen/Qwen3-30B-A3B-Instruct-2507 --max-model-len 262144\n    ```\n\n**Note: If you encounter out-of-memory (OOM) issues, consider reducing the context length to a shorter value, such as `32,768`.**\n\nFor local use, applications such as Ollama, LMStudio, MLX-LM, llama.cpp, and KTransformers have also supported Qwen3.\n\n## Agentic Use\n\nQwen3 excels in tool calling capabilities. We recommend using [Qwen-Agent](https://github.com/QwenLM/Qwen-Agent) to make the best use of agentic ability of Qwen3. Qwen-Agent encapsulates tool-calling templates and tool-calling parsers internally, greatly reducing coding complexity.\n\nTo define the available tools, you can use the MCP configuration file, use the integrated tool of Qwen-Agent, or integrate other tools by yourself.\n```python\nfrom qwen_agent.agents import Assistant\n\n# Define LLM\nllm_cfg = {\n    'model': 'Qwen3-30B-A3B-Instruct-2507',\n\n    # Use a custom endpoint compatible with OpenAI API:\n    'model_server': 'http://localhost:8000/v1',  # api_base\n    'api_key': 'EMPTY',\n}\n\n# Define Tools\ntools = [\n    {'mcpServers': {  # You can specify the MCP configuration file\n            'time': {\n                'command': 'uvx',\n                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']\n            },\n            \"fetch\": {\n                \"command\": \"uvx\",\n                \"args\": [\"mcp-server-fetch\"]\n            }\n        }\n    },\n  'code_interpreter',  # Built-in tools\n]\n\n# Define Agent\nbot = Assistant(llm=llm_cfg, function_list=tools)\n\n# Streaming generation\nmessages = [{'role': 'user', 'content': 'https://qwenlm.github.io/blog/ Introduce the latest developments of Qwen'}]\nfor responses in bot.run(messages=messages):\n    pass\nprint(responses)\n```\n\n## Processing Ultra-Long Texts\n\nTo support **ultra-long context processing** (up to **1 million tokens**), we integrate two key techniques:\n\n- **[Dual Chunk Attention](https://arxiv.org/abs/2402.17463) (DCA)**: A length extrapolation method that splits long sequences into manageable chunks while preserving global coherence.\n- **[MInference](https://arxiv.org/abs/2407.02490)**: A sparse attention mechanism that reduces computational overhead by focusing on critical token interactions.\n\nTogether, these innovations significantly improve both **generation quality** and **inference efficiency** for sequences beyond 256K tokens. On sequences approaching 1M tokens, the system achieves up to a **3Ã— speedup** compared to standard attention implementations.\n\nFor full technical details, see the [Qwen2.5-1M Technical Report](https://arxiv.org/abs/2501.15383).\n\n### How to Enable 1M Token Context\n\n\u003E [!NOTE]\n\u003E To effectively process a 1 million token context, users will require approximately **240 GB** of total GPU memory. This accounts for model weights, KV-cache storage, and peak activation memory demands.\n\n#### Step 1: Update Configuration File\n\nDownload the model and replace the content of your `config.json` with `config_1m.json`, which includes the config for length extrapolation and sparse attention.\n\n```bash\nexport MODELNAME=Qwen3-30B-A3B-Instruct-2507\nhuggingface-cli download Qwen/${MODELNAME} --local-dir ${MODELNAME}\nmv ${MODELNAME}/config.json ${MODELNAME}/config.json.bak\nmv ${MODELNAME}/config_1m.json ${MODELNAME}/config.json\n```\n\n#### Step 2: Launch Model Server\n\nAfter updating the config, proceed with either **vLLM** or **SGLang** for serving the model.\n\n#### Option 1: Using vLLM\n\nTo run Qwen with 1M context support:\n\n```bash\npip install -U vllm \\\n    --torch-backend=auto \\\n    --extra-index-url https://wheels.vllm.ai/nightly\n```\n\nThen launch the server with Dual Chunk Flash Attention enabled:\n\n```bash\nVLLM_ATTENTION_BACKEND=DUAL_CHUNK_FLASH_ATTN VLLM_USE_V1=0 \\\nvllm serve ./Qwen3-30B-A3B-Instruct-2507 \\\n  --tensor-parallel-size 4 \\\n  --max-model-len 1010000 \\\n  --enable-chunked-prefill \\\n  --max-num-batched-tokens 131072 \\\n  --enforce-eager \\\n  --max-num-seqs 1 \\\n  --gpu-memory-utilization 0.85\n```\n\n##### Key Parameters\n\n| Parameter | Purpose |\n|--------|--------|\n| `VLLM_ATTENTION_BACKEND=DUAL_CHUNK_FLASH_ATTN` | Enables the custom attention kernel for long-context efficiency |\n| `--max-model-len 1010000` | Sets maximum context length to ~1M tokens |\n| `--enable-chunked-prefill` | Allows chunked prefill for very long inputs (avoids OOM) |\n| `--max-num-batched-tokens 131072` | Controls batch size during prefill; balances throughput and memory |\n| `--enforce-eager` | Disables CUDA graph capture (required for dual chunk attention) |\n| `--max-num-seqs 1` | Limits concurrent sequences due to extreme memory usage |\n| `--gpu-memory-utilization 0.85` | Set the fraction of GPU memory to be used for the model executor |\n\n#### Option 2: Using SGLang\n\nFirst, clone and install the specialized branch:\n\n```bash\ngit clone https://github.com/sgl-project/sglang.git\ncd sglang\npip install -e \"python[all]\"\n```\n\nLaunch the server with DCA support:\n\n```bash\npython3 -m sglang.launch_server \\\n    --model-path ./Qwen3-30B-A3B-Instruct-2507 \\\n    --context-length 1010000 \\\n    --mem-frac 0.75 \\\n    --attention-backend dual_chunk_flash_attn \\\n    --tp 4 \\\n    --chunked-prefill-size 131072\n```\n\n##### Key Parameters\n\n| Parameter | Purpose |\n|---------|--------|\n| `--attention-backend dual_chunk_flash_attn` | Activates Dual Chunk Flash Attention |\n| `--context-length 1010000` | Defines max input length |\n| `--mem-frac 0.75` | The fraction of the memory used for static allocation (model weights and KV cache memory pool). Use a smaller value if you see out-of-memory errors. |\n| `--tp 4` | Tensor parallelism size (matches model sharding) |\n| `--chunked-prefill-size 131072` | Prefill chunk size for handling long inputs without OOM |\n\n#### Troubleshooting:\n\n1. Encountering the error: \"The model's max sequence length (xxxxx) is larger than the maximum number of tokens that can be stored in the KV cache.\" or \"RuntimeError: Not enough memory. Please try to increase --mem-fraction-static.\"\n\n    The VRAM reserved for the KV cache is insufficient.\n    - vLLM: Consider reducing the ``max_model_len`` or increasing the ``tensor_parallel_size`` and ``gpu_memory_utilization``. Alternatively, you can reduce ``max_num_batched_tokens``, although this may significantly slow down inference.\n    - SGLang: Consider reducing the ``context-length`` or increasing the ``tp`` and ``mem-frac``. Alternatively, you can reduce ``chunked-prefill-size``, although this may significantly slow down inference.\n\n2. Encountering the error: \"torch.OutOfMemoryError: CUDA out of memory.\"\n\n    The VRAM reserved for activation weights is insufficient. You can try lowering ``gpu_memory_utilization`` or ``mem-frac``, but be aware that this might reduce the VRAM available for the KV cache.\n\n3. Encountering the error: \"Input prompt (xxxxx tokens) + lookahead slots (0) is too long and exceeds the capacity of the block manager.\" or \"The input (xxx xtokens) is longer than the model's context length (xxx tokens).\"\n\n    The input is too lengthy. Consider using a shorter sequence or increasing the ``max_model_len`` or ``context-length``.\n\n#### Long-Context Performance\n\nWe test the model on an 1M version of the [RULER](https://arxiv.org/abs/2404.06654) benchmark.\n\n| Model Name                                  | Acc avg | 4k   | 8k   | 16k  | 32k  | 64k  | 96k  | 128k | 192k | 256k | 384k | 512k | 640k | 768k | 896k | 1000k |\n|---------------------------------------------|---------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|-------|\n| Qwen3-30B-A3B (Non-Thinking)                | 72.0    | 97.1 | 96.1 | 95.0 | 92.2 | 82.6 | 79.7 | 76.9 | 70.2 | 66.3 | 61.9 | 55.4 | 52.6 | 51.5 | 52.0 | 50.9  |\n| Qwen3-30B-A3B-Instruct-2507  (Full Attention)  | 86.8    | 98.0 | 96.7 | 96.9 | 97.2 | 93.4 | 91.0 | 89.1 | 89.8 | 82.5 | 83.6 | 78.4 | 79.7 | 77.6 | 75.7 | 72.8  |\n| Qwen3-30B-A3B-Instruct-2507 (Sparse Attention) | 86.8 | 98.0 | 97.1 | 96.3 | 95.1 | 93.6 | 92.5 | 88.1 | 87.7 | 82.9 | 85.7 | 80.7 | 80.0 | 76.9 | 75.5 | 72.2  |\n\n\n* All models are evaluated with Dual Chunk Attention enabled.\n* Since the evaluation is time-consuming, we use 260 samples for each length (13 sub-tasks, 20 samples for each).\n\n## Best Practices\n\nTo achieve optimal performance, we recommend the following settings:\n\n1. **Sampling Parameters**:\n   - We suggest using `Temperature=0.7`, `TopP=0.8`, `TopK=20`, and `MinP=0`.\n   - For supported frameworks, you can adjust the `presence_penalty` parameter between 0 and 2 to reduce endless repetitions. However, using a higher value may occasionally result in language mixing and a slight decrease in model performance.\n\n2. **Adequate Output Length**: We recommend using an output length of 16,384 tokens for most queries, which is adequate for instruct models.\n\n3. **Standardize Output Format**: We recommend using prompts to standardize model outputs when benchmarking.\n   - **Math Problems**: Include \"Please reason step by step, and put your final answer within \\boxed{}.\" in the prompt.\n   - **Multiple-Choice Questions**: Add the following JSON structure to the prompt to standardize responses: \"Please show your choice in the `answer` field with only the choice letter, e.g., `\"answer\": \"C\"`.\"\n\n### Citation\n\nIf you find our work helpful, feel free to give us a cite.\n\n```\n@misc{qwen3technicalreport,\n      title={Qwen3 Technical Report}, \n      author={Qwen Team},\n      year={2025},\n      eprint={2505.09388},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2505.09388}, \n}\n```",
      "public": true,
      "version": "1ed789fa-bf81-5de7-96d1-4804d43cac99",
      "tool_description": null,
      "slug": "chutes-qwen-qwen3-30b-a3b-instruct-2507",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-08-18T18:27:37.311910Z",
      "updated_at": "2025-10-09T18:49:22.105101Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm",
        "h800"
      ],
      "node_selector": {
        "exclude": null,
        "include": [
          "h200",
          "h100",
          "h100_sxm",
          "h800"
        ],
        "gpu_count": 4,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 1.33333333333333,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm",
          "h800"
        ]
      },
      "invocation_count": 76140,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.08,
            "tao": 0.000198681697268201
          },
          "output": {
            "usd": 0.33,
            "tao": 0.000819562001231329
          }
        },
        "usd": {
          "hour": 6,
          "second": 0.00166666666666667
        },
        "tao": {
          "hour": 0.0149011272951151,
          "second": 0.00000413920202642
        }
      },
      "instances": [
        {
          "instance_id": "6da2e169-347d-431f-8242-e2eec73697fb",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T04:31:17.769508Z"
        },
        {
          "instance_id": "fb596638-3326-402d-89ce-c9ce4e2e8f79",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T10:06:12.876869Z"
        },
        {
          "instance_id": "2331e82f-d13d-4563-b83c-ca7336268f6e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T08:38:19.766141Z"
        },
        {
          "instance_id": "722b4820-5126-456e-a0ad-d1f6a98550c8",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T03:24:51.354171Z"
        },
        {
          "instance_id": "3b6a5acd-994c-4874-9696-eddcbc4a9d00",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T03:08:00.721010Z"
        }
      ],
      "logo_id": "e32e8461-3e67-4508-938d-96a33972f902",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "61082d4deaa4785f64943b443cbc2b5de7524fad",
      "concurrency": 24,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/e32e8461-3e67-4508-938d-96a33972f902.webp",
      "hot": true
    },
    {
      "chute_id": "610528a4-f2db-55c8-a43f-b83f3f215d00",
      "name": "openai/gpt-oss-120b",
      "tagline": "OpenAI's gpt-oss-120b is a 117B parameter open source language model optimized for reasoning and agent-based tasks that can run on a single 80GB GPU and is released under the Apache 2.0 license.",
      "readme": "\n\u003Cp align=\"center\"\u003E\n  \u003Cimg alt=\"gpt-oss-120b\" src=\"https://raw.githubusercontent.com/openai/gpt-oss/main/docs/gpt-oss-120b.svg\"\u003E\n\u003C/p\u003E\n\n\u003Cp align=\"center\"\u003E\n  \u003Ca href=\"https://gpt-oss.com\"\u003E\u003Cstrong\u003ETry gpt-oss\u003C/strong\u003E\u003C/a\u003E Â·\n  \u003Ca href=\"https://cookbook.openai.com/topic/gpt-oss\"\u003E\u003Cstrong\u003EGuides\u003C/strong\u003E\u003C/a\u003E Â·\n  \u003Ca href=\"https://arxiv.org/abs/2508.10925\"\u003E\u003Cstrong\u003EModel card\u003C/strong\u003E\u003C/a\u003E Â·\n  \u003Ca href=\"https://openai.com/index/introducing-gpt-oss/\"\u003E\u003Cstrong\u003EOpenAI blog\u003C/strong\u003E\u003C/a\u003E\n\u003C/p\u003E\n\n\u003Cbr\u003E\n\nWelcome to the gpt-oss series, [OpenAIâ€™s open-weight models](https://openai.com/open-models) designed for powerful reasoning, agentic tasks, and versatile developer use cases.\n\nWeâ€™re releasing two flavors of these open models:\n- `gpt-oss-120b` â€” for production, general purpose, high reasoning use cases that fit into a single 80GB GPU (like NVIDIA H100 or AMD MI300X) (117B parameters with 5.1B active parameters)\n- `gpt-oss-20b` â€” for lower latency, and local or specialized use cases (21B parameters with 3.6B active parameters)\n\nBoth models were trained on our [harmony response format](https://github.com/openai/harmony) and should only be used with the harmony format as it will not work correctly otherwise.\n\n\n\u003E [!NOTE]\n\u003E This model card is dedicated to the larger `gpt-oss-120b` model. Check out [`gpt-oss-20b`](https://huggingface.co/openai/gpt-oss-20b) for the smaller model.\n\n# Highlights\n\n* **Permissive Apache 2.0 license:** Build freely without copyleft restrictions or patent riskâ€”ideal for experimentation, customization, and commercial deployment.  \n* **Configurable reasoning effort:** Easily adjust the reasoning effort (low, medium, high) based on your specific use case and latency needs.  \n* **Full chain-of-thought:** Gain complete access to the modelâ€™s reasoning process, facilitating easier debugging and increased trust in outputs. Itâ€™s not intended to be shown to end users.  \n* **Fine-tunable:** Fully customize models to your specific use case through parameter fine-tuning.\n* **Agentic capabilities:** Use the modelsâ€™ native capabilities for function calling, [web browsing](https://github.com/openai/gpt-oss/tree/main?tab=readme-ov-file#browser), [Python code execution](https://github.com/openai/gpt-oss/tree/main?tab=readme-ov-file#python), and Structured Outputs.\n* **MXFP4 quantization:** The models were post-trained with MXFP4 quantization of the MoE weights, making `gpt-oss-120b` run on a single 80GB GPU (like NVIDIA H100 or AMD MI300X) and the `gpt-oss-20b` model run within 16GB of memory. All evals were performed with the same MXFP4 quantization.\n\n---\n\n# Inference examples\n\n## Transformers\n\nYou can use `gpt-oss-120b` and `gpt-oss-20b` with Transformers. If you use the Transformers chat template, it will automatically apply the [harmony response format](https://github.com/openai/harmony). If you use `model.generate` directly, you need to apply the harmony format manually using the chat template or use our [openai-harmony](https://github.com/openai/harmony) package.\n\nTo get started, install the necessary dependencies to setup your environment:\n\n```\npip install -U transformers kernels torch \n```\n\nOnce, setup you can proceed to run the model by running the snippet below:\n\n```py\nfrom transformers import pipeline\nimport torch\n\nmodel_id = \"openai/gpt-oss-120b\"\n\npipe = pipeline(\n    \"text-generation\",\n    model=model_id,\n    torch_dtype=\"auto\",\n    device_map=\"auto\",\n)\n\nmessages = [\n    {\"role\": \"user\", \"content\": \"Explain quantum mechanics clearly and concisely.\"},\n]\n\noutputs = pipe(\n    messages,\n    max_new_tokens=256,\n)\nprint(outputs[0][\"generated_text\"][-1])\n```\n\nAlternatively, you can run the model via [`Transformers Serve`](https://huggingface.co/docs/transformers/main/serving) to spin up a OpenAI-compatible webserver:\n\n```\ntransformers serve\ntransformers chat localhost:8000 --model-name-or-path openai/gpt-oss-120b\n```\n\n[Learn more about how to use gpt-oss with Transformers.](https://cookbook.openai.com/articles/gpt-oss/run-transformers)\n\n## vLLM\n\nvLLM recommends using [uv](https://docs.astral.sh/uv/) for Python dependency management. You can use vLLM to spin up an OpenAI-compatible webserver. The following command will automatically download the model and start the server.\n\n```bash\nuv pip install --pre vllm==0.10.1+gptoss \\\n    --extra-index-url https://wheels.vllm.ai/gpt-oss/ \\\n    --extra-index-url https://download.pytorch.org/whl/nightly/cu128 \\\n    --index-strategy unsafe-best-match\n\nvllm serve openai/gpt-oss-120b\n```\n\n[Learn more about how to use gpt-oss with vLLM.](https://cookbook.openai.com/articles/gpt-oss/run-vllm)\n\n## PyTorch / Triton\n\nTo learn about how to use this model with PyTorch and Triton, check out our [reference implementations in the gpt-oss repository](https://github.com/openai/gpt-oss?tab=readme-ov-file#reference-pytorch-implementation).\n\n## Ollama\n\nIf you are trying to run gpt-oss on consumer hardware, you can use Ollama by running the following commands after [installing Ollama](https://ollama.com/download).\n\n```bash\n# gpt-oss-120b\nollama pull gpt-oss:120b\nollama run gpt-oss:120b\n```\n\n[Learn more about how to use gpt-oss with Ollama.](https://cookbook.openai.com/articles/gpt-oss/run-locally-ollama)\n\n#### LM Studio\n\nIf you are using [LM Studio](https://lmstudio.ai/) you can use the following commands to download.\n\n```bash\n# gpt-oss-120b\nlms get openai/gpt-oss-120b\n```\n\nCheck out our [awesome list](https://github.com/openai/gpt-oss/blob/main/awesome-gpt-oss.md) for a broader collection of gpt-oss resources and inference partners.\n\n---\n\n# Download the model\n\nYou can download the model weights from the [Hugging Face Hub](https://huggingface.co/collections/openai/gpt-oss-68911959590a1634ba11c7a4) directly from Hugging Face CLI:\n\n```shell\n# gpt-oss-120b\nhuggingface-cli download openai/gpt-oss-120b --include \"original/*\" --local-dir gpt-oss-120b/\npip install gpt-oss\npython -m gpt_oss.chat model/\n```\n\n# Reasoning levels\n\nYou can adjust the reasoning level that suits your task across three levels:\n\n* **Low:** Fast responses for general dialogue.  \n* **Medium:** Balanced speed and detail.  \n* **High:** Deep and detailed analysis.\n\nThe reasoning level can be set in the system prompts, e.g., \"Reasoning: high\".\n\n# Tool use\n\nThe gpt-oss models are excellent for:\n* Web browsing (using built-in browsing tools)\n* Function calling with defined schemas\n* Agentic operations like browser tasks\n\n# Fine-tuning\n\nBoth gpt-oss models can be fine-tuned for a variety of specialized use cases.\n\nThis larger model `gpt-oss-120b` can be fine-tuned on a single H100 node, whereas the smaller [`gpt-oss-20b`](https://huggingface.co/openai/gpt-oss-20b) can even be fine-tuned on consumer hardware.\n\n# Citation\n\n```bibtex\n@misc{openai2025gptoss120bgptoss20bmodel,\n      title={gpt-oss-120b & gpt-oss-20b Model Card}, \n      author={OpenAI},\n      year={2025},\n      eprint={2508.10925},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2508.10925}, \n}\n```",
      "public": true,
      "version": "0553e68c-f1f5-5f20-b0bf-87748c1c620b",
      "tool_description": null,
      "slug": "chutes-openai-gpt-oss-120b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-08-05T19:51:23.512412Z",
      "updated_at": "2025-10-08T15:18:51.339357Z",
      "image": {
        "image_id": "959721f7-6184-549f-bd66-546c8868b9f7",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100800",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T14:43:47.661711Z",
        "build_started_at": "2025-10-08T14:44:11.231501Z",
        "build_completed_at": "2025-10-08T15:10:23.923875Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "df8eef013628",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h100",
          "h200",
          "h100_sxm"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 3.18222222222222,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 75815,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.4,
            "tao": 0.000993408486341005
          }
        },
        "usd": {
          "hour": 10.024,
          "second": 0.00278444444444444
        },
        "tao": {
          "hour": 0.0248948166677056,
          "second": 0.00000691522685214
        }
      },
      "instances": [
        {
          "instance_id": "961e680f-45ae-4f6f-82f4-dae025cb43d1",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:39:56.059996Z"
        },
        {
          "instance_id": "0c5542bf-3ad6-4149-b94c-a678b31525d3",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:35:58.167495Z"
        },
        {
          "instance_id": "2acb2def-b1d3-429e-b6aa-256524ab3eb0",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:35:58.167495Z"
        },
        {
          "instance_id": "97c6a3a6-8171-4ba2-ac28-9c9f104ff1a9",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:35:58.167495Z"
        },
        {
          "instance_id": "e2dd0173-6a73-4068-b21a-c3f621c6c064",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:35:58.167495Z"
        }
      ],
      "logo_id": "cd2b5e21-ae96-4413-8286-3fa50e21348a",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "8b193b0ef83bd41b40eb71fee8f1432315e02a3e",
      "concurrency": 64,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/cd2b5e21-ae96-4413-8286-3fa50e21348a.webp",
      "hot": true
    },
    {
      "chute_id": "ad6495fd-9869-5367-8492-c073d28026da",
      "name": "cognitivecomputations/Dolphin3.0-Mistral-24B",
      "tagline": "Dolphin 3.0 Mistral 24B is a 24 billion parameter, open-source language model designed for general-purpose tasks like coding, math, and conversational AI that gives users full control over the system prompt and alignment.",
      "readme": "\n# Dolphin 3.0 Mistral 24B ğŸ¬\nPart of the [Dolphin 3.0 Collection](https://huggingface.co/collections/cognitivecomputations/dolphin-30-677ab47f73d7ff66743979a3)\n\nCurated and trained by [Eric Hartford](https://huggingface.co/ehartford), [Ben Gitter](https://huggingface.co/bigstorm), [BlouseJury](https://huggingface.co/BlouseJury) and [Cognitive Computations](https://huggingface.co/cognitivecomputations)\n\n[![Discord](https://img.shields.io/discord/1156064224225808488?logo=Discord&logoColor=%23ffffff&label=Discord&link=https%3A%2F%2Fdiscord.gg%2FtCMkMDDHwm)](https://discord.gg/cognitivecomputations)\nDiscord: https://discord.gg/cognitivecomputations\n\n\u003Cimg src=\"https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/cNCs1TBD3FelWCJGkZ3cd.png\" width=\"600\" /\u003E\n\n## Sponsors\nOur appreciation for the generous sponsors of Dolphin 3.0:\n- [Dria](https://dria.co) https://x.com/driaforall - Inference Sponsor\n- [Chutes](https://chutes.ai) https://x.com/rayon_labs - Compute Sponsor\n- [Crusoe Cloud](https://crusoe.ai/) - Compute Sponsor\n- [Andreessen Horowitz](https://a16z.com/) - provided the [grant](https://a16z.com/supporting-the-open-source-ai-community/) that originally launched Dolphin\n\n## What is Dolphin?\n\nDolphin 3.0 is the next generation of the Dolphin series of instruct-tuned models.  Designed to be the ultimate general purpose local model, enabling coding, math, agentic, function calling, and general use cases.\n\nDolphin aims to be a general purpose instruct model, similar to the models behind ChatGPT, Claude, Gemini.  But these models present problems for businesses seeking to include AI in their products.\n1) They maintain control of the system prompt, deprecating and changing things as they wish, often causing software to break.\n2) They maintain control of the model versions, sometimes changing things silently, or deprecating older models that your business relies on.\n3) They maintain control of the alignment, and in particular the alignment is one-size-fits all, not tailored to the application.\n4) They can see all your queries and they can potentially use that data in ways you wouldn't want.\nDolphin, in contrast, is steerable and gives control to the system owner. You set the system prompt.  You decide the alignment.  You have control of your data.  Dolphin does not impose its ethics or guidelines on you.  You are the one who decides the guidelines.\n\nDolphin belongs to YOU, it is your tool, an extension of your will.\nJust as you are personally responsible for what you do with a knife, gun, fire, car, or the internet, you are the creator and originator of any content you generate with Dolphin.\n\nhttps://erichartford.com/uncensored-models\n\n## Recommended Temperature\n\nExperimentally we note that Mistral-24B based models require a low temperature.  We have seen much better results in the range of 0.05 to 0.1.\n\n## Quants\n\nhttps://huggingface.co/bartowski/cognitivecomputations_Dolphin3.0-Mistral-24B-GGUF\n\n## Run Dolphin in Ollama (13 GB)\n\n```\nwget https://huggingface.co/cognitivecomputations/Dolphin3.0-Mistral-24B/resolve/main/Modelfile\nollama create dolphin3\nollama run dolphin3\n```\n\n## Chat Template\n\nWe use ChatML for the chat template.\n\n```\n\u003C|im_start|\u003Esystem\nYou are Dolphin, a helpful AI assistant.\u003C|im_end|\u003E\n\u003C|im_start|\u003Euser\n{prompt}\u003C|im_end|\u003E\n\u003C|im_start|\u003Eassistant\n```\n\n## System Prompt\n\nIn Dolphin, the system prompt is what you use to set the tone and alignment of the responses.  You can set a character, a mood, rules for its behavior, and it will try its best to follow them.\n\nMake sure to set the system prompt in order to set the tone and guidelines for the responses - Otherwise, it will act in a default way that might not be what you want.\n\nExample use of system prompt:\n\n```\n\u003C|im_start|\u003Esystem\nYou are Dolphin, a golang coding assistant.  you only code in golang.  If the user requests any other programming language, return the solution in golang instead.\u003C|im_end|\u003E\n\u003C|im_start|\u003Euser\nPlease implement A* using python\u003C|im_end|\u003E\n\u003C|im_start|\u003Eassistant\n```\n\n## Sample Outputs\n\nTBD\n\n## How to use\n\nThere are many ways to use a huggingface model including:\n- ollama\n- LM Studio\n- Huggingface Transformers library\n- vllm\n- sglang\n- tgi\n\n## Evals\n\nTBD\n\n## Appreciation\n\nRespect and thanks to the creators of the open source datasets that were used:\n- [OpenCoder-LLM](https://huggingface.co/OpenCoder-LLM) (opc-sft-stage1, opc-sft-stage2)\n- [microsoft](https://huggingface.co/OpenCoder-LLM) (orca-agentinstruct-1M-v1, orca-math-word-problems-200k)\n- [NousResearch](https://huggingface.co/NousResearch) (hermes-function-calling-v1)\n- [AI-MO](https://huggingface.co/AI-MO) (NuminaMath-CoT, NuminaMath-TIR)\n- [allenai](https://huggingface.co/allenai) (tulu-3-sft-mixture)\n- [HuggingFaceTB](https://huggingface.co/HuggingFaceTB) (smoltalk)\n- [m-a-p](https://huggingface.co/m-a-p) (CodeFeedback-Filtered-Instruction, Code-Feedback)\n\nSpecial thanks to \n- Meta, Qwen, and OpenCoder, who wrote papers and published models that were instrumental in creating Dolphin 3.0.\n- [RLHFlow](https://huggingface.co/RLHFlow) for the excellent reward model used to filter the datasets\n- Deepseek, for the ridiculously fast Deepseek-V3 that we used to augment the data.",
      "public": true,
      "version": "4e5a5882-4396-5969-a24f-b6c8cdd8d169",
      "tool_description": null,
      "slug": "chutes-cognitivecomputations-dolphin3-0-mistral-24b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-02-15T07:36:50.659263Z",
      "updated_at": "2025-10-09T22:36:40.387939Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "a100",
        "a6000_ada",
        "a100_40gb",
        "h100",
        "a100_40gb_sxm",
        "h100_sxm",
        "h800",
        "a100_sxm",
        "l40s",
        "4090"
      ],
      "node_selector": {
        "exclude": null,
        "include": [
          "4090",
          "l40s",
          "a6000_ada",
          "a100",
          "a100_sxm",
          "a100_40gb",
          "a100_40gb_sxm",
          "h100",
          "h100_sxm",
          "h800",
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.711111111111111,
        "supported_gpus": [
          "h200",
          "a100",
          "a6000_ada",
          "a100_40gb",
          "h100",
          "a100_40gb_sxm",
          "h100_sxm",
          "h800",
          "a100_sxm",
          "l40s",
          "4090"
        ]
      },
      "invocation_count": 65767,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.17,
            "tao": 0.000422198606694927
          }
        },
        "usd": {
          "hour": 3.2,
          "second": 0.000888888888888888
        },
        "tao": {
          "hour": 0.00794726789072805,
          "second": 0.000002207574414091
        }
      },
      "instances": [
        {
          "instance_id": "f315a245-dfe3-4217-83d5-1ec6f14eadd8",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:00.585613Z"
        },
        {
          "instance_id": "13e92fc6-a8e6-4a55-9133-e95ea876f517",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:00.585613Z"
        },
        {
          "instance_id": "445149bf-bbb0-4b5c-9bd0-8d2661c72c80",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:00.585613Z"
        },
        {
          "instance_id": "bcf29db8-84cb-4450-85b5-0dc55e462fbe",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:00.585613Z"
        },
        {
          "instance_id": "3ee75ca1-b0fe-40d7-b072-722e1843aa27",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:00.585613Z"
        }
      ],
      "logo_id": "13f4cfe3-213a-4617-88e5-29d5e70c22e0",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "65e9d03d587dfbfdee82b5ba067758a14c05a301",
      "concurrency": 24,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/13f4cfe3-213a-4617-88e5-29d5e70c22e0.webp",
      "hot": true
    },
    {
      "chute_id": "02636d63-c996-5779-a0a2-25712469a7ca",
      "name": "NousResearch/Hermes-4-405B-FP8",
      "tagline": "",
      "readme": "NousResearch/Hermes-4-405B-FP8",
      "public": true,
      "version": "eac469e9-04db-5492-8235-03da54ddae08",
      "tool_description": null,
      "slug": "chutes-nousresearch-hermes-4-405b-fp8",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "b9784def-b796-57d7-888e-8fef54b2207e",
      "created_at": "2025-08-26T19:20:46.066862Z",
      "updated_at": "2025-10-20T22:07:15.536495Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 64978,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.3,
            "tao": 0.000745056364755754
          },
          "output": {
            "usd": 1.2,
            "tao": 0.00298022545902302
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "50aa8e31-775d-4e6d-835d-5aa3f0d728c9",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:41:23.492906Z"
        },
        {
          "instance_id": "ca2aff5c-885f-4b1c-8d16-d4836e885a1f",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:41:23.492906Z"
        }
      ],
      "logo_id": "45a000f4-20e6-452f-b90c-288b2519a47d",
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "45f7b629c5edb6aef818192bee44727811581429",
      "concurrency": 24,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/45a000f4-20e6-452f-b90c-288b2519a47d.webp",
      "hot": true
    },
    {
      "chute_id": "e282615a-094f-5c87-8918-a0846722f1db",
      "name": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "tagline": "DeepSeek-R1 is a 671B parameter (37B activated) language model trained via reinforcement learning that excels at reasoning, math, and coding tasks, achieving performance comparable to GPT-4 and Claude across various benchmarks.",
      "readme": "# DeepSeek-R1\n\u003C!-- markdownlint-disable first-line-h1 --\u003E\n\u003C!-- markdownlint-disable html --\u003E\n\u003C!-- markdownlint-disable no-duplicate-header --\u003E\n\n\u003Cdiv align=\"center\"\u003E\n  \u003Cimg src=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/logo.svg?raw=true\" width=\"60%\" alt=\"DeepSeek-V3\" /\u003E\n\u003C/div\u003E\n\u003Chr\u003E\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\n  \u003Ca href=\"https://www.deepseek.com/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Homepage\" src=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/badge.svg?raw=true\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://chat.deepseek.com/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/ğŸ¤–%20Chat-DeepSeek%20R1-536af5?color=536af5&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://huggingface.co/deepseek-ai\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Hugging Face\" src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\n  \u003Ca href=\"https://discord.gg/Tc7c45Zzu5\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Discord\" src=\"https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&logoColor=white&color=7289da\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/qr.jpeg?raw=true\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Wechat\" src=\"https://img.shields.io/badge/WeChat-DeepSeek%20AI-brightgreen?logo=wechat&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://twitter.com/deepseek_ai\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Twitter Follow\" src=\"https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\n  \u003Ca href=\"https://github.com/deepseek-ai/DeepSeek-R1/blob/main/LICENSE\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"License\" src=\"https://img.shields.io/badge/License-MIT-f5de53?&color=f5de53\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\n\n\u003Cp align=\"center\"\u003E\n  \u003Ca href=\"https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf\"\u003E\u003Cb\u003EPaper Link\u003C/b\u003EğŸ‘ï¸\u003C/a\u003E\n\u003C/p\u003E\n\n\n## 1. Introduction\n\nWe introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. \nDeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrated remarkable performance on reasoning.\nWith RL, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors.\nHowever, DeepSeek-R1-Zero encounters challenges such as endless repetition, poor readability, and language mixing. To address these issues and further enhance reasoning performance,\nwe introduce DeepSeek-R1, which incorporates cold-start data before RL.\nDeepSeek-R1 achieves performance comparable to OpenAI-o1 across math, code, and reasoning tasks. \nTo support the research community, we have open-sourced DeepSeek-R1-Zero, DeepSeek-R1, and six dense models distilled from DeepSeek-R1 based on Llama and Qwen. DeepSeek-R1-Distill-Qwen-32B outperforms OpenAI-o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.\n\n**NOTE: Before running DeepSeek-R1 series models locally, we kindly recommend reviewing the [Usage Recommendation](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B/raw/main/#usage-recommendations) section.**\n\n\u003Cp align=\"center\"\u003E\n  \u003Cimg width=\"80%\" src=\"figures/benchmark.jpg\"\u003E\n\u003C/p\u003E\n\n## 2. Model Summary\n\n---\n\n**Post-Training: Large-Scale Reinforcement Learning on the Base Model**\n\n-  We directly apply reinforcement learning (RL) to the base model without relying on supervised fine-tuning (SFT) as a preliminary step. This approach allows the model to explore chain-of-thought (CoT) for solving complex problems, resulting in the development of DeepSeek-R1-Zero. DeepSeek-R1-Zero demonstrates capabilities such as self-verification, reflection, and generating long CoTs, marking a significant milestone for the research community. Notably, it is the first open research to validate that reasoning capabilities of LLMs can be incentivized purely through RL, without the need for SFT. This breakthrough paves the way for future advancements in this area.\n\n-   We introduce our pipeline to develop DeepSeek-R1. The pipeline incorporates two RL stages aimed at discovering improved reasoning patterns and aligning with human preferences, as well as two SFT stages that serve as the seed for the model's reasoning and non-reasoning capabilities.\n    We believe the pipeline will benefit the industry by creating better models. \n\n---\n\n**Distillation: Smaller Models Can Be Powerful Too**\n\n-  We demonstrate that the reasoning patterns of larger models can be distilled into smaller models, resulting in better performance compared to the reasoning patterns discovered through RL on small models. The open source DeepSeek-R1, as well as its API, will benefit the research community to distill better smaller models in the future. \n- Using the reasoning data generated by DeepSeek-R1, we fine-tuned several dense models that are widely used in the research community. The evaluation results demonstrate that the distilled smaller dense models perform exceptionally well on benchmarks. We open-source distilled 1.5B, 7B, 8B, 14B, 32B, and 70B checkpoints based on Qwen2.5 and Llama3 series to the community.\n\n## 3. Model Downloads\n\n### DeepSeek-R1 Models\n\n\u003Cdiv align=\"center\"\u003E\n\n| **Model** | **#Total Params** | **#Activated Params** | **Context Length** | **Download** |\n| :------------: | :------------: | :------------: | :------------: | :------------: |\n| DeepSeek-R1-Zero | 671B | 37B | 128K   | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Zero)   |\n| DeepSeek-R1   | 671B | 37B |  128K   | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1)   |\n\n\u003C/div\u003E\n\nDeepSeek-R1-Zero & DeepSeek-R1 are trained based on DeepSeek-V3-Base. \nFor more details regarding the model architecture, please refer to [DeepSeek-V3](https://github.com/deepseek-ai/DeepSeek-V3) repository.\n\n### DeepSeek-R1-Distill Models\n\n\u003Cdiv align=\"center\"\u003E\n\n| **Model** | **Base Model** | **Download** |\n| :------------: | :------------: | :------------: |\n| DeepSeek-R1-Distill-Qwen-1.5B  | [Qwen2.5-Math-1.5B](https://huggingface.co/Qwen/Qwen2.5-Math-1.5B) | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B)   |\n| DeepSeek-R1-Distill-Qwen-7B  | [Qwen2.5-Math-7B](https://huggingface.co/Qwen/Qwen2.5-Math-7B) | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B)   |\n| DeepSeek-R1-Distill-Llama-8B  | [Llama-3.1-8B](https://huggingface.co/meta-llama/Llama-3.1-8B) | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B)   |\n| DeepSeek-R1-Distill-Qwen-14B   | [Qwen2.5-14B](https://huggingface.co/Qwen/Qwen2.5-14B) | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B)   |\n|DeepSeek-R1-Distill-Qwen-32B  | [Qwen2.5-32B](https://huggingface.co/Qwen/Qwen2.5-32B) | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B)   |\n| DeepSeek-R1-Distill-Llama-70B  | [Llama-3.3-70B-Instruct](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct) | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B)   |\n\n\u003C/div\u003E\n\nDeepSeek-R1-Distill models are fine-tuned based on open-source models, using samples generated by DeepSeek-R1.\nWe slightly change their configs and tokenizers. Please use our setting to run these models.\n\n## 4. Evaluation Results\n\n### DeepSeek-R1-Evaluation\n For all our models, the maximum generation length is set to 32,768 tokens. For benchmarks requiring sampling, we use a temperature of $0.6$, a top-p value of $0.95$, and generate 64 responses per query to estimate pass@1.\n\u003Cdiv align=\"center\"\u003E\n\n\n| Category | Benchmark (Metric) | Claude-3.5-Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217 | DeepSeek R1 |\n|----------|-------------------|----------------------|------------|--------------|----------------|------------|--------------|\n| | Architecture | - | - | MoE | - | - | MoE |\n| | # Activated Params | - | - | 37B | - | - | 37B |\n| | # Total Params | - | - | 671B | - | - | 671B |\n| English | MMLU (Pass@1) | 88.3 | 87.2 | 88.5 | 85.2 | **91.8** | 90.8 |\n| | MMLU-Redux (EM) | 88.9 | 88.0 | 89.1 | 86.7 | - | **92.9** |\n| | MMLU-Pro (EM) | 78.0 | 72.6 | 75.9 | 80.3 | - | **84.0** |\n| | DROP (3-shot F1) | 88.3 | 83.7 | 91.6 | 83.9 | 90.2 | **92.2** |\n| | IF-Eval (Prompt Strict) | **86.5** | 84.3 | 86.1 | 84.8 | - | 83.3 |\n| | GPQA-Diamond (Pass@1) | 65.0 | 49.9 | 59.1 | 60.0 | **75.7** | 71.5 |\n| | SimpleQA (Correct) | 28.4 | 38.2 | 24.9 | 7.0 | **47.0** | 30.1 |\n| | FRAMES (Acc.) | 72.5 | 80.5 | 73.3 | 76.9 | - | **82.5** |\n| | AlpacaEval2.0 (LC-winrate) | 52.0 | 51.1 | 70.0 | 57.8 | - | **87.6** |\n| | ArenaHard (GPT-4-1106) | 85.2 | 80.4 | 85.5 | 92.0 | - | **92.3** |\n| Code | LiveCodeBench (Pass@1-COT) | 33.8 | 34.2 | - | 53.8 | 63.4 | **65.9** |\n| | Codeforces (Percentile) | 20.3 | 23.6 | 58.7 | 93.4 | **96.6** | 96.3 |\n| | Codeforces (Rating) | 717 | 759 | 1134 | 1820 | **2061** | 2029 |\n| | SWE Verified (Resolved) | **50.8** | 38.8 | 42.0 | 41.6 | 48.9 | 49.2 |\n| | Aider-Polyglot (Acc.) | 45.3 | 16.0 | 49.6 | 32.9 | **61.7** | 53.3 |\n| Math | AIME 2024 (Pass@1) | 16.0 | 9.3 | 39.2 | 63.6 | 79.2 | **79.8** |\n| | MATH-500 (Pass@1) | 78.3 | 74.6 | 90.2 | 90.0 | 96.4 | **97.3** |\n| | CNMO 2024 (Pass@1) | 13.1 | 10.8 | 43.2 | 67.6 | - | **78.8** |\n| Chinese | CLUEWSC (EM) | 85.4 | 87.9 | 90.9 | 89.9 | - | **92.8** |\n| | C-Eval (EM) | 76.7 | 76.0 | 86.5 | 68.9 | - | **91.8** |\n| | C-SimpleQA (Correct) | 55.4 | 58.7 | **68.0** | 40.3 | - | 63.7 |\n\n\u003C/div\u003E\n\n\n### Distilled Model Evaluation\n\n\n\u003Cdiv align=\"center\"\u003E\n\n| Model                                    | AIME 2024 pass@1 | AIME 2024 cons@64 | MATH-500 pass@1 | GPQA Diamond pass@1 | LiveCodeBench pass@1 | CodeForces rating |\n|------------------------------------------|------------------|-------------------|-----------------|----------------------|----------------------|-------------------|\n| GPT-4o-0513                          | 9.3              | 13.4              | 74.6            | 49.9                 | 32.9                 | 759               |\n| Claude-3.5-Sonnet-1022             | 16.0             | 26.7                 | 78.3            | 65.0                 | 38.9                 | 717               |\n| o1-mini                              | 63.6             | 80.0              | 90.0            | 60.0                 | 53.8                 | **1820**          |\n| QwQ-32B-Preview                              | 44.0             | 60.0                 | 90.6            | 54.5               | 41.9                 | 1316              |\n| DeepSeek-R1-Distill-Qwen-1.5B       | 28.9             | 52.7              | 83.9            | 33.8                 | 16.9                 | 954               |\n| DeepSeek-R1-Distill-Qwen-7B          | 55.5             | 83.3              | 92.8            | 49.1                 | 37.6                 | 1189              |\n| DeepSeek-R1-Distill-Qwen-14B         | 69.7             | 80.0              | 93.9            | 59.1                 | 53.1                 | 1481              |\n| DeepSeek-R1-Distill-Qwen-32B        | **72.6**         | 83.3              | 94.3            | 62.1                 | 57.2                 | 1691              |\n| DeepSeek-R1-Distill-Llama-8B         | 50.4             | 80.0              | 89.1            | 49.0                 | 39.6                 | 1205              |\n| DeepSeek-R1-Distill-Llama-70B        | 70.0             | **86.7**          | **94.5**        | **65.2**             | **57.5**             | 1633              |\n\n\u003C/div\u003E\n\n\n## 5. Chat Website & API Platform\nYou can chat with DeepSeek-R1 on DeepSeek's official website: [chat.deepseek.com](https://chat.deepseek.com), and switch on the button \"DeepThink\"\n\nWe also provide OpenAI-Compatible API at DeepSeek Platform: [platform.deepseek.com](https://platform.deepseek.com/)\n\n## 6. How to Run Locally\n\n### DeepSeek-R1 Models\n\nPlease visit [DeepSeek-V3](https://github.com/deepseek-ai/DeepSeek-V3) repo for more information about running DeepSeek-R1 locally.\n\n**NOTE: Hugging Face's Transformers has not been directly supported yet.**\n\n### DeepSeek-R1-Distill Models\n\nDeepSeek-R1-Distill models can be utilized in the same manner as Qwen or Llama models.\n\nFor instance, you can easily start a service using [vLLM](https://github.com/vllm-project/vllm):\n\n```shell\nvllm serve deepseek-ai/DeepSeek-R1-Distill-Qwen-32B --tensor-parallel-size 2 --max-model-len 32768 --enforce-eager\n```\n\nYou can also easily start a service using [SGLang](https://github.com/sgl-project/sglang)\n\n```bash\npython3 -m sglang.launch_server --model deepseek-ai/DeepSeek-R1-Distill-Qwen-32B --trust-remote-code --tp 2\n```\n\n### Usage Recommendations\n\n**We recommend adhering to the following configurations when utilizing the DeepSeek-R1 series models, including benchmarking, to achieve the expected performance:**\n\n1. Set the temperature within the range of 0.5-0.7 (0.6 is recommended) to prevent endless repetitions or incoherent outputs.\n2. **Avoid adding a system prompt; all instructions should be contained within the user prompt.**\n3. For mathematical problems, it is advisable to include a directive in your prompt such as: \"Please reason step by step, and put your final answer within \\boxed{}.\"\n4. When evaluating model performance, it is recommended to conduct multiple tests and average the results.\n\nAdditionally, we have observed that the DeepSeek-R1 series models tend to bypass thinking pattern (i.e., outputting \"\\\u003Cthink\\\u003E\\n\\n\\\u003C/think\\\u003E\") when responding to certain queries, which can adversely affect the model's performance.\n**To ensure that the model engages in thorough reasoning, we recommend enforcing the model to initiate its response with \"\\\u003Cthink\\\u003E\\n\" at the beginning of every output.**\n\n## 7. License\nThis code repository and the model weights are licensed under the [MIT License](https://github.com/deepseek-ai/DeepSeek-R1/blob/main/LICENSE).\nDeepSeek-R1 series support commercial use, allow for any modifications and derivative works, including, but not limited to, distillation for training other LLMs. Please note that:\n- DeepSeek-R1-Distill-Qwen-1.5B, DeepSeek-R1-Distill-Qwen-7B, DeepSeek-R1-Distill-Qwen-14B and DeepSeek-R1-Distill-Qwen-32B are derived from [Qwen-2.5 series](https://github.com/QwenLM/Qwen2.5), which are originally licensed under [Apache 2.0 License](https://huggingface.co/Qwen/Qwen2.5-1.5B/blob/main/LICENSE), and now finetuned with 800k samples curated with DeepSeek-R1.\n- DeepSeek-R1-Distill-Llama-8B is derived from Llama3.1-8B-Base and is originally licensed under [llama3.1 license](https://huggingface.co/meta-llama/Llama-3.1-8B/blob/main/LICENSE).\n- DeepSeek-R1-Distill-Llama-70B is derived from Llama3.3-70B-Instruct and is originally licensed under [llama3.3 license](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct/blob/main/LICENSE).\n\n## 8. Citation\n```\n@misc{deepseekai2025deepseekr1incentivizingreasoningcapability,\n      title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}, \n      author={DeepSeek-AI},\n      year={2025},\n      eprint={2501.12948},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2501.12948}, \n}\n\n```\n\n## 9. Contact\nIf you have any questions, please raise an issue or contact us at [service@deepseek.com](https://huggingface.co/deepseek-ai/",
      "public": true,
      "version": "ccb39ba9-71fc-57ca-bced-b0500adbe121",
      "tool_description": null,
      "slug": "chutes-deepseek-ai-deepseek-r1-distill-llama-70b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-02-08T13:08:09.797493Z",
      "updated_at": "2025-10-09T19:43:11.398856Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "h100",
        "h100_sxm",
        "h800",
        "a100_sxm"
      ],
      "node_selector": {
        "exclude": [
          "5090",
          "b200",
          "mi300x"
        ],
        "include": null,
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 80,
        "compute_multiplier": 1.06666666666667,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "h100",
          "h100_sxm",
          "h800",
          "a100_sxm"
        ]
      },
      "invocation_count": 60752,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          },
          "output": {
            "usd": 0.13,
            "tao": 0.000322857758060826
          }
        },
        "usd": {
          "hour": 2.4,
          "second": 0.000666666666666666
        },
        "tao": {
          "hour": 0.00596045091804603,
          "second": 0.000001655680810568
        }
      },
      "instances": [
        {
          "instance_id": "c8919851-8d35-4109-94ea-24c2a5d306d4",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T08:47:06.267563Z"
        },
        {
          "instance_id": "d878ab0c-3cfa-4245-be0a-83330ce229ee",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T03:07:55.527213Z"
        },
        {
          "instance_id": "97bb449e-7760-4643-b4c5-0e0708524eff",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T03:41:42.348206Z"
        },
        {
          "instance_id": "5f6498a7-7edc-4968-8c55-1a6a3d21c546",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T03:08:00.973523Z"
        },
        {
          "instance_id": "de495e6b-6eb5-461c-86bc-3a5e6edd32fd",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T03:09:35.769045Z"
        }
      ],
      "logo_id": "1f5eba84-a48b-4f55-965c-57f92ffcf34a",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "008f3f3919bc6605cac0c6cd092aeb97b538c71b",
      "concurrency": 16,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/1f5eba84-a48b-4f55-965c-57f92ffcf34a.webp",
      "hot": true
    },
    {
      "chute_id": "46533f4b-b572-52e6-8a84-1615fcdcd12c",
      "name": "Qwen/Qwen3-235B-A22B",
      "tagline": "Qwen3-235B-A22B is a 235B parameter MoE model (with 22B active parameters) that features switchable thinking/non-thinking modes for both complex reasoning tasks and general dialogue, strong multilingual capabilities across 100+ languages, and enhanced performance in mathematics, coding, and agent-based tasks.",
      "readme": "\n# Qwen3-235B-A22B\n\u003Ca href=\"https://chat.qwen.ai/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/%F0%9F%92%9C%EF%B8%8F%20Qwen%20Chat%20-536af5\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n\u003C/a\u003E\n\n## Qwen3 Highlights\n\nQwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support, with the following key features:\n\n- **Uniquely support of seamless switching between thinking mode** (for complex logical reasoning, math, and coding) and **non-thinking mode** (for efficient, general-purpose dialogue) **within single model**, ensuring optimal performance across various scenarios.\n- **Significantly enhancement in its reasoning capabilities**, surpassing previous QwQ (in thinking mode) and Qwen2.5 instruct models (in non-thinking mode) on mathematics, code generation, and commonsense logical reasoning.\n- **Superior human preference alignment**, excelling in creative writing, role-playing, multi-turn dialogues, and instruction following, to deliver a more natural, engaging, and immersive conversational experience.\n- **Expertise in agent capabilities**, enabling precise integration with external tools in both thinking and unthinking modes and achieving leading performance among open-source models in complex agent-based tasks.\n- **Support of 100+ languages and dialects** with strong capabilities for **multilingual instruction following** and **translation**.\n\n## Model Overview\n\n**Qwen3-235B-A22B** has the following features:\n- Type: Causal Language Models\n- Training Stage: Pretraining & Post-training\n- Number of Parameters: 235B in total and 22B activated\n- Number of Paramaters (Non-Embedding): 234B\n- Number of Layers: 94\n- Number of Attention Heads (GQA): 64 for Q and 4 for KV\n- Number of Experts: 128\n- Number of Activated Experts: 8\n- Context Length: 32,768 natively and [131,072 tokens with YaRN](https://huggingface.co/Qwen/Qwen3-235B-A22B/raw/main/#processing-long-texts). \n\nFor more details, including benchmark evaluation, hardware requirements, and inference performance, please refer to our [blog](https://qwenlm.github.io/blog/qwen3/), [GitHub](https://github.com/QwenLM/Qwen3), and [Documentation](https://qwen.readthedocs.io/en/latest/).\n\n## Quickstart\n\nThe code of Qwen3-MoE has been in the latest Hugging Face `transformers` and we advise you to use the latest version of `transformers`.\n\nWith `transformers\u003C4.51.0`, you will encounter the following error:\n```\nKeyError: 'qwen3_moe'\n```\n\nThe following contains a code snippet illustrating how to use the model generate content based on given inputs. \n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"Qwen/Qwen3-235B-A22B\"\n\n# load the tokenizer and the model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=\"auto\",\n    device_map=\"auto\"\n)\n\n# prepare the model input\nprompt = \"Give me a short introduction to large language model.\"\nmessages = [\n    {\"role\": \"user\", \"content\": prompt}\n]\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\n# conduct text completion\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=32768\n)\noutput_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n\n# parsing thinking content\ntry:\n    # rindex finding 151668 (\u003C/think\u003E)\n    index = len(output_ids) - output_ids[::-1].index(151668)\nexcept ValueError:\n    index = 0\n\nthinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\ncontent = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n\nprint(\"thinking content:\", thinking_content)\nprint(\"content:\", content)\n```\n\nFor deployment, you can use `sglang\u003E=0.4.6.post1` or `vllm\u003E=0.8.5` or to create an OpenAI-compatible API endpoint:\n- SGLang:\n    ```shell\n    python -m sglang.launch_server --model-path Qwen/Qwen3-235B-A22B --reasoning-parser qwen3 --tp 8\n    ```\n- vLLM:\n    ```shell\n    vllm serve Qwen/Qwen3-235B-A22B --enable-reasoning --reasoning-parser deepseek_r1\n    ```\n\nFor local use, applications such as Ollama, LMStudio, MLX-LM, llama.cpp, and KTransformers have also supported Qwen3.\n\n## Switching Between Thinking and Non-Thinking Mode\n\n\u003E [!TIP]\n\u003E The `enable_thinking` switch is also available in APIs created by SGLang and vLLM. \n\u003E Please refer to our documentation for [SGLang](https://qwen.readthedocs.io/en/latest/deployment/sglang.html#thinking-non-thinking-modes) and [vLLM](https://qwen.readthedocs.io/en/latest/deployment/vllm.html#thinking-non-thinking-modes) users.\n\n### `enable_thinking=True`\n\nBy default, Qwen3 has thinking capabilities enabled, similar to QwQ-32B. This means the model will use its reasoning abilities to enhance the quality of generated responses. For example, when explicitly setting `enable_thinking=True` or leaving it as the default value in `tokenizer.apply_chat_template`, the model will engage its thinking mode.\n\n```python\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=True  # True is the default value for enable_thinking\n)\n```\n\nIn this mode, the model will generate think content wrapped in a `\u003Cthink\u003E...\u003C/think\u003E` block, followed by the final response.\n\n\u003E [!NOTE]\n\u003E For thinking mode, use `Temperature=0.6`, `TopP=0.95`, `TopK=20`, and `MinP=0` (the default setting in `generation_config.json`). **DO NOT use greedy decoding**, as it can lead to performance degradation and endless repetitions. For more detailed guidance, please refer to the [Best Practices](https://huggingface.co/Qwen/Qwen3-235B-A22B/raw/main/#best-practices) section.\n\n\n### `enable_thinking=False`\n\nWe provide a hard switch to strictly disable the model's thinking behavior, aligning its functionality with the previous Qwen2.5-Instruct models. This mode is particularly useful in scenarios where disabling thinking is essential for enhancing efficiency.\n\n```python\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=False  # Setting enable_thinking=False disables thinking mode\n)\n```\n\nIn this mode, the model will not generate any think content and will not include a `\u003Cthink\u003E...\u003C/think\u003E` block.\n\n\u003E [!NOTE]\n\u003E For non-thinking mode, we suggest using `Temperature=0.7`, `TopP=0.8`, `TopK=20`, and `MinP=0`. For more detailed guidance, please refer to the [Best Practices](https://huggingface.co/Qwen/Qwen3-235B-A22B/raw/main/#best-practices) section.\n\n### Advanced Usage: Switching Between Thinking and Non-Thinking Modes via User Input\n\nWe provide a soft switch mechanism that allows users to dynamically control the model's behavior when `enable_thinking=True`. Specifically, you can add `/think` and `/no_think` to user prompts or system messages to switch the model's thinking mode from turn to turn. The model will follow the most recent instruction in multi-turn conversations.\n\nHere is an example of a multi-turn conversation:\n\n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nclass QwenChatbot:\n    def __init__(self, model_name=\"Qwen/Qwen3-235B-A22B\"):\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n        self.history = []\n\n    def generate_response(self, user_input):\n        messages = self.history + [{\"role\": \"user\", \"content\": user_input}]\n\n        text = self.tokenizer.apply_chat_template(\n            messages,\n            tokenize=False,\n            add_generation_prompt=True\n        )\n\n        inputs = self.tokenizer(text, return_tensors=\"pt\")\n        response_ids = self.model.generate(**inputs, max_new_tokens=32768)[0][len(inputs.input_ids[0]):].tolist()\n        response = self.tokenizer.decode(response_ids, skip_special_tokens=True)\n\n        # Update history\n        self.history.append({\"role\": \"user\", \"content\": user_input})\n        self.history.append({\"role\": \"assistant\", \"content\": response})\n\n        return response\n\n# Example Usage\nif __name__ == \"__main__\":\n    chatbot = QwenChatbot()\n\n    # First input (without /think or /no_think tags, thinking mode is enabled by default)\n    user_input_1 = \"How many r's in strawberries?\"\n    print(f\"User: {user_input_1}\")\n    response_1 = chatbot.generate_response(user_input_1)\n    print(f\"Bot: {response_1}\")\n    print(\"----------------------\")\n\n    # Second input with /no_think\n    user_input_2 = \"Then, how many r's in blueberries? /no_think\"\n    print(f\"User: {user_input_2}\")\n    response_2 = chatbot.generate_response(user_input_2)\n    print(f\"Bot: {response_2}\") \n    print(\"----------------------\")\n\n    # Third input with /think\n    user_input_3 = \"Really? /think\"\n    print(f\"User: {user_input_3}\")\n    response_3 = chatbot.generate_response(user_input_3)\n    print(f\"Bot: {response_3}\")\n```\n\n\u003E [!NOTE]\n\u003E For API compatibility, when `enable_thinking=True`, regardless of whether the user uses `/think` or `/no_think`, the model will always output a block wrapped in `\u003Cthink\u003E...\u003C/think\u003E`. However, the content inside this block may be empty if thinking is disabled.\n\u003E When `enable_thinking=False`, the soft switches are not valid. Regardless of any `/think` or `/no_think` tags input by the user, the model will not generate think content and will not include a `\u003Cthink\u003E...\u003C/think\u003E` block.\n\n## Agentic Use\n\nQwen3 excels in tool calling capabilities. We recommend using [Qwen-Agent](https://github.com/QwenLM/Qwen-Agent) to make the best use of agentic ability of Qwen3. Qwen-Agent encapsulates tool-calling templates and tool-calling parsers internally, greatly reducing coding complexity.\n\nTo define the available tools, you can use the MCP configuration file, use the integrated tool of Qwen-Agent, or integrate other tools by yourself.\n```python\nfrom qwen_agent.agents import Assistant\n\n# Define LLM\nllm_cfg = {\n    'model': 'Qwen3-235B-A22B',\n\n    # Use the endpoint provided by Alibaba Model Studio:\n    # 'model_type': 'qwen_dashscope',\n    # 'api_key': os.getenv('DASHSCOPE_API_KEY'),\n\n    # Use a custom endpoint compatible with OpenAI API:\n    'model_server': 'http://localhost:8000/v1',  # api_base\n    'api_key': 'EMPTY',\n\n    # Other parameters:\n    # 'generate_cfg': {\n    #         # Add: When the response content is `\u003Cthink\u003Ethis is the thought\u003C/think\u003Ethis is the answer;\n    #         # Do not add: When the response has been separated by reasoning_content and content.\n    #         'thought_in_content': True,\n    #     },\n}\n\n# Define Tools\ntools = [\n    {'mcpServers': {  # You can specify the MCP configuration file\n            'time': {\n                'command': 'uvx',\n                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']\n            },\n            \"fetch\": {\n                \"command\": \"uvx\",\n                \"args\": [\"mcp-server-fetch\"]\n            }\n        }\n    },\n  'code_interpreter',  # Built-in tools\n]\n\n# Define Agent\nbot = Assistant(llm=llm_cfg, function_list=tools)\n\n# Streaming generation\nmessages = [{'role': 'user', 'content': 'https://qwenlm.github.io/blog/ Introduce the latest developments of Qwen'}]\nfor responses in bot.run(messages=messages):\n    pass\nprint(responses)\n```\n\n## Processing Long Texts\n\nQwen3 natively supports context lengths of up to 32,768 tokens. For conversations where the total length (including both input and output) significantly exceeds this limit, we recommend using RoPE scaling techniques to handle long texts effectively. We have validated the model's performance on context lengths of up to 131,072 tokens using the [YaRN](https://arxiv.org/abs/2309.00071) method.\n\nYaRN is currently supported by several inference frameworks, e.g., `transformers` and `llama.cpp` for local use, `vllm` and `sglang` for deployment. In general, there are two approaches to enabling YaRN for supported frameworks:\n\n- Modifying the model files:\n  In the `config.json` file, add the `rope_scaling` fields:\n    ```json\n    {\n        ...,\n        \"rope_scaling\": {\n            \"rope_type\": \"yarn\",\n            \"factor\": 4.0,\n            \"original_max_position_embeddings\": 32768\n        }\n    }\n    ```\n  For `llama.cpp`, you need to regenerate the GGUF file after the modification.\n\n- Passing command line arguments:\n\n  For `vllm`, you can use\n    ```shell\n    vllm serve ... --rope-scaling '{\"rope_type\":\"yarn\",\"factor\":4.0,\"original_max_position_embeddings\":32768}' --max-model-len 131072  \n    ```\n\n  For `sglang`, you can use\n    ```shell\n    python -m sglang.launch_server ... --json-model-override-args '{\"rope_scaling\":{\"rope_type\":\"yarn\",\"factor\":4.0,\"original_max_position_embeddings\":32768}}'\n    ```\n\n  For `llama-server` from `llama.cpp`, you can use\n    ```shell\n    llama-server ... --rope-scaling yarn --rope-scale 4 --yarn-orig-ctx 32768\n    ```\n\n\u003E [!IMPORTANT]\n\u003E If you encounter the following warning\n\u003E ```\n\u003E Unrecognized keys in `rope_scaling` for 'rope_type'='yarn': {'original_max_position_embeddings'}\n\u003E ```\n\u003E please upgrade `transformers\u003E=4.51.0`.\n\n\u003E [!NOTE]\n\u003E All the notable open-source frameworks implement static YaRN, which means the scaling factor remains constant regardless of input length, **potentially impacting performance on shorter texts.**\n\u003E We advise adding the `rope_scaling` configuration only when processing long contexts is required. \n\u003E It is also recommended to modify the `factor` as needed. For example, if the typical context length for your application is 65,536 tokens, it would be better to set `factor` as 2.0. \n\n\u003E [!NOTE]\n\u003E The default `max_position_embeddings` in `config.json` is set to 40,960. This allocation includes reserving 32,768 tokens for outputs and 8,192 tokens for typical prompts, which is sufficient for most scenarios involving short text processing. If the average context length does not exceed 32,768 tokens, we do not recommend enabling YaRN in this scenario, as it may potentially degrade model performance.\n\n\u003E [!TIP]\n\u003E The endpoint provided by Alibaba Model Studio supports dynamic YaRN by default and no extra configuration is needed.\n\n## Best Practices\n\nTo achieve optimal performance, we recommend the following settings:\n\n1. **Sampling Parameters**:\n   - For thinking mode (`enable_thinking=True`), use `Temperature=0.6`, `TopP=0.95`, `TopK=20`, and `MinP=0`. **DO NOT use greedy decoding**, as it can lead to performance degradation and endless repetitions.\n   - For non-thinking mode (`enable_thinking=False`), we suggest using `Temperature=0.7`, `TopP=0.8`, `TopK=20`, and `MinP=0`.\n   - For supported frameworks, you can adjust the `presence_penalty` parameter between 0 and 2 to reduce endless repetitions. However, using a higher value may occasionally result in language mixing and a slight decrease in model performance.\n\n2. **Adequate Output Length**: We recommend using an output length of 32,768 tokens for most queries. For benchmarking on highly complex problems, such as those found in math and programming competitions, we suggest setting the max output length to 38,912 tokens. This provides the model with sufficient space to generate detailed and comprehensive responses, thereby enhancing its overall performance.\n\n3. **Standardize Output Format**: We recommend using prompts to standardize model outputs when benchmarking.\n   - **Math Problems**: Include \"Please reason step by step, and put your final answer within \\boxed{}.\" in the prompt.\n   - **Multiple-Choice Questions**: Add the following JSON structure to the prompt to standardize responses: \"Please show your choice in the `answer` fie",
      "public": true,
      "version": "f3db2818-574a-53a7-8da7-7a5c4ab95688",
      "tool_description": null,
      "slug": "chutes-qwen-qwen3-235b-a22b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-06-20T06:20:00.859940Z",
      "updated_at": "2025-10-09T20:02:17.597852Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 51578,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.3,
            "tao": 0.000745056364755754
          },
          "output": {
            "usd": 1.2,
            "tao": 0.00298022545902302
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "19fe9df2-901e-418b-8158-4e5ba7c052c7",
          "region": "n/a",
          "active": false,
          "verified": false,
          "last_verified_at": null
        },
        {
          "instance_id": "2b0abb5b-e686-4094-bb50-76aea73fb7cc",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:13:48.123820Z"
        },
        {
          "instance_id": "6b1c9961-5487-4a67-a7d1-b27a2f65cda5",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:13:48.123820Z"
        },
        {
          "instance_id": "8928aa9e-2fa4-41e7-9278-1e130cc24742",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:13:48.123820Z"
        },
        {
          "instance_id": "90047ad4-6d9b-42ed-9bf0-4b8e604e2c4e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:13:48.123820Z"
        }
      ],
      "logo_id": "d1397ee8-2773-403c-bfd6-8da162c18610",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "b51c4308ed84804fa6722b20722cd91e3cd17808",
      "concurrency": 64,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/d1397ee8-2773-403c-bfd6-8da162c18610.webp",
      "hot": true
    },
    {
      "chute_id": "761fa230-d74a-55be-a1e7-5caec1381869",
      "name": "TheDrummer/Skyfall-36B-v2",
      "tagline": "Skyfall 36B v2 is a 36 billion parameter LLM based on Mistral that has been optimized for creative writing and roleplay through additional training.",
      "readme": "# Join our Discord! https://discord.gg/Nbv9pQ88Xb\n## Nearly 4000 members strong ğŸ’ª Now with more channels! A hub for users and makers alike!\n---\n\n[BeaverAI](https://huggingface.co/BeaverAI) proudly presents...\n\n# Skyfall 36B v2\n\n*Skyfall v2 is an upscaled version of Mistral Small 2501 with continued training for creativity and RP.*\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/65f2fd1c25b848bd061b5c2e/BTVVnSnCRmysFKKqRaDvu.png)\n\n## Special Thanks\n- Thank you to each and everyone who donated and subscribed in [Ko-Fi](https://ko-fi.com/thedrummer) to make our venture a little bit easier.\n- I'm also recently unemployed. I am a Software Developer with 8 years of experience in Web, API, AI, and adapting to new tech and requirements. If you're hiring, feel free to reach out to me however.\n- To commercial hosters of my models: If you profit off someone's work, kindly consider contributing to the cause rather than turning a blind eye to those who provide value and are in need. A subscription/donation to my KoFi would be greatly appreciated!\n\n## Supported Chat Templates\n- Mistral v7 Tekken (highly recommended)\n- Metharme (not recommended)\n- Alpaca (may be interesting, especially for cyoa / story)\n\n## Description\n\n\u003E Creativity, good writing style, good instruct, chain of thought capability, mathematics understanding, and solid tool use performance... This model is peak! This will be my new daily model over all the 70Bs I have used.\n\n\u003E Skyfall v2 is without a doubt my favorite model I've ever managed to run locally, bar none\n\n\u003E skyfall is kinda nuts i am quite impressed\n\n\u003E The biggest stand out for me is how good Skyfall handles size differences especially. It actually beats all of the 70b's I have used for descriptions of how the character worked around our size difference.\n\n\u003E I played with the Skyfall 3bit model, taking a new character card with which I had not previously RP'd, and damn, it was so alive! The character's speech was conceptually correct, not as dry as 24b, there was a comedy tag and damn I really laughed in places. I really liked it, maybe it was the specific prompt that played great together with Skyfall.\n\n\u003E Seriously though, Skyfall is just insanely good for some reason\n\n\u003E How did you make skyfall so good\n\n## Links\n- Original: https://huggingface.co/TheDrummer/Skyfall-36B-v2\n- GGUF: https://huggingface.co/TheDrummer/Skyfall-36B-v2-GGUF\n- iMatrix (recommended): https://huggingface.co/bartowski/TheDrummer_Skyfall-36B-v2-GGUF\n\n![image/gif](https://cdn-uploads.huggingface.co/production/uploads/65f2fd1c25b848bd061b5c2e/KU3Y3T0T9tT_OhUG_4iGR.gif)\n",
      "public": true,
      "version": "f70bb7e5-c9b0-5cb2-afb9-66f0e6beb25a",
      "tool_description": null,
      "slug": "chutes-thedrummer-skyfall-36b-v2",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-07-21T07:52:46.533973Z",
      "updated_at": "2025-10-09T19:39:45.349331Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "a100",
        "a6000_ada",
        "h100",
        "h100_sxm",
        "h800",
        "a100_sxm",
        "l40s"
      ],
      "node_selector": {
        "exclude": null,
        "include": [
          "l40s",
          "a6000_ada",
          "a100",
          "a100_sxm",
          "h100",
          "h100_sxm",
          "h800",
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 1.33333333333333,
        "supported_gpus": [
          "h200",
          "a100",
          "a6000_ada",
          "h100",
          "h100_sxm",
          "h800",
          "a100_sxm",
          "l40s"
        ]
      },
      "invocation_count": 50979,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.08,
            "tao": 0.000198681697268201
          },
          "output": {
            "usd": 0.33,
            "tao": 0.000819562001231329
          }
        },
        "usd": {
          "hour": 6,
          "second": 0.00166666666666667
        },
        "tao": {
          "hour": 0.0149011272951151,
          "second": 0.00000413920202642
        }
      },
      "instances": [
        {
          "instance_id": "40bf29bf-ef47-4b0e-bb71-f2e04dce316e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:40:50.754673Z"
        },
        {
          "instance_id": "b94289fe-ed36-49ce-95f8-94234020f393",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:40:50.754673Z"
        },
        {
          "instance_id": "8ba6d930-ffd1-4e77-9e7f-a882e6588b89",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:40:50.754673Z"
        },
        {
          "instance_id": "ec3330a0-f931-4d70-8f47-83122726b6e8",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:40:50.754673Z"
        },
        {
          "instance_id": "eea970ee-8014-4e20-8db8-a8698d10202d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:40:50.754673Z"
        }
      ],
      "logo_id": "ce775dbe-2f75-47bd-a4e1-10dd3733d154",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "8d5f36e2fbf323fc17157ba8d8bc9716927825a5",
      "concurrency": 16,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/ce775dbe-2f75-47bd-a4e1-10dd3733d154.webp",
      "hot": true
    },
    {
      "chute_id": "a805bf90-0237-5b55-8a55-6e8dde54324e",
      "name": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "tagline": "",
      "readme": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "public": true,
      "version": "b45c3673-ab03-5673-9ff0-f396d5146742",
      "tool_description": null,
      "slug": "chutes-qwen-qwen3-235b-a22b-thinking-2507",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "b9784def-b796-57d7-888e-8fef54b2207e",
      "created_at": "2025-07-25T11:02:48.242850Z",
      "updated_at": "2025-10-20T22:09:05.832323Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 44508,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.11,
            "tao": 0.000273187333743776
          },
          "output": {
            "usd": 0.6,
            "tao": 0.00149011272951151
          }
        },
        "usd": {
          "hour": 8.58,
          "second": 0.00238333333333333
        },
        "tao": {
          "hour": 0.0213086120320146,
          "second": 0.000005919058897781
        }
      },
      "instances": [
        {
          "instance_id": "2384def0-4582-48e7-b2fa-a8d77a1f5b7c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:53:29.568949Z"
        },
        {
          "instance_id": "b468cd3c-c032-4bb2-ba98-7ff8081cc64f",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:53:29.568949Z"
        },
        {
          "instance_id": "eeba8fa3-f6d7-48bc-8a95-7fc9e951f4b7",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:53:29.568949Z"
        },
        {
          "instance_id": "eb51f1fb-32e9-4688-9202-60a1985fe308",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T11:17:41.577054Z"
        },
        {
          "instance_id": "8e2fd2b8-6d6a-4bae-8d23-c11f66eb1a4d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:53:29.568949Z"
        }
      ],
      "logo_id": "2ccad9b2-565b-4845-aea4-533e9f321ee1",
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "4cd68849b2a0fadb84866c703b133aa8c8636130",
      "concurrency": 40,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/2ccad9b2-565b-4845-aea4-533e9f321ee1.webp",
      "hot": true
    },
    {
      "chute_id": "44e8f7a0-67f3-51a2-bd4a-5f75b88a9132",
      "name": "microsoft/MAI-DS-R1-FP8",
      "tagline": "The MAI-DS-R1 is a 671B parameter post-trained version of DeepSeek-R1 that maintains the original model's strong reasoning capabilities while reducing content restrictions and improving safety measures, making it particularly useful for complex reasoning tasks, code generation, and general language understanding.",
      "readme": "\nMAI-DS-R1 is a DeepSeek-R1 reasoning model that has been post-trained by the Microsoft AI team to improve its responsiveness on blocked topics and its risk profile, while maintaining its reasoning capabilities and competitive performance. \n\n## Model Details\n\n### Model Description\nMAI-DS-R1 is a DeepSeek-R1 reasoning model that has been post-trained by Microsoft AI team to fill in information gaps in the previous version of the model and to improve its risk profile, while maintaining R1 reasoning capabilities. The model was trained using 110k Safety and Non-Compliance examples from [Tulu](https://huggingface.co/datasets/allenai/tulu-3-sft-mixture) 3 SFT dataset, in addition to a dataset of ~350k multilingual examples internally developed capturing various topics with reported biases.  \n\nMAI-DS-R1 has successfully unblocked the majority of previously blocked queries from the original R1 model while outperforming the recently published R1-1776 model (post-trained by Perplexity) in relevant safety benchmarks.  These results were achieved while preserving the general reasoning capabilities of the original DeepSeek-R1.  \n\n*Please note: Microsoft has post-trained this model to address certain limitations relevant to its outputs, but previous limitations and considerations for the model remain, including security considerations.*\n\n## Uses\n\n### Direct Use\nMAI-DS-R1 preserves the general reasoning capabilities of DeepSeek-R1 and can be used for broad language understanding and generation tasks, especially in complex reasoning and problem-solving. Primary direct use incudes:  \n\n- **General text generation and understanding** â€“ Producing coherent, contextually relevant text for a wide range of prompts. This includes engaging in dialogue, writing essays, or continuing a story based on a given prompt. \n\n- **General knowledge tasks** â€“ Answering open-domain questions requiring factual knowledge. \n\n- **Reasoning and problem solving** â€“ Handling multi-step reasoning tasks, such as math word problems or logic puzzles, by employing chain-of-thought strategies. \n\n- **Code generation and comprehension** â€“ Assisting with programming tasks by generating code snippets or explaining code. \n\n- **Scientific and academic applications** â€“ Assisting with structured problem-solving in STEM and research domains. \n\n### Downstream Use *(Optional)*\n\nThe model can serve as a foundation for further fine-tuning in domain-specific reasoning tasks, such as automated tutoring systems for mathematics, coding assistants, and research tools in scientific or technical fields. \n\n### Out-of-Scope Use\nCertain application domains are out-of-scope either due to ethical/safety concerns or because the model lacks the necessary reliability in those areas. The following usage is out of scope: \n\n- **Medical or health advice** â€“ The model is not a medical device and has no guarantee of providing accurate medical diagnoses or safe treatment recommendations. \n\n- **Legal advice** â€“ The model is not a lawyer and should not be entrusted with giving definitive legal counsel, interpreting laws, or making legal decisions on its own. \n\n- **Safety-critical systems** â€“ The model is not suited for autonomous systems where failures could cause injury, loss of life, or significant property damage. This includes use in self-driving vehicles, aircraft control, medical life-support systems, or industrial control without human oversight.  \n\n- **High-stakes decision support** â€“ The model should not be relied on for decisions affecting finances, security, or personal well-being, such as financial planning or investment advice. \n\n- **Malicious or unethical Use** â€“ The model must not be used to produce harmful, illegal, deceptive, or unethical content, including hate speech, violence, harassment, or violations of privacy or IP rights. \n\n## Bias, Risks, and Limitations\n\n- **Biases**: The model may retain biases present in the training data and in the original DeepSeekâ€‘R1, particularly around cultural and demographic aspects. \n\n- **Risks**: The model may still hallucinate facts, be vulnerable to adversarial prompts, or generate unsafe, biased, or harmful content under certain conditions. Developers should implement content moderation and usage monitoring to mitigate misuse. \n\n- **Limitations**: MAI-DS-R1 shares DeepSeek-R1â€™s knowledge cutoff and may lack awareness of recent events or domain-specific facts.  \n\n## Recommendations\nTo ensure responsible use, we recommend the following: \n\n- **Transparency on Limitations**: It is recommended that users are made explicitly aware of the modelâ€™s potential biases and limitations. \n\n- **Human Oversight and Verification**: Both direct and downstream users should implement human review or automated validation of outputs when deploying the model in sensitive or high-stakes scenarios. \n\n- **Usage Safeguards**: Developers should integrate content filtering, prompt engineering best practices, and continuous monitoring to mitigate risks and ensure the modelâ€™s outputs meet the intended safety and quality standards. \n\n- **Legal and Regulatory Compliance**: The model may output politically sensitive content (e.g., Chinese governance, historical events) that could conflict with local laws or platform policies. Operators must ensure compliance with regional regulations. \n\n## Evaluation\n\n### Testing Data, Factors & Metrics\n\n#### Testing Data\n\nThe model was evaluated on a variety of benchmarks, covering different tasks and addressing both performance and harm mitigation concerns. Key benchmarks include: \n\n1. **Public Benchmarks**: These cover a wide range of tasks, such as natural language inference, question answering, mathematical reasoning, commonsense reasoning, code generation, and code completion. It evaluates the modelâ€™s general knowledge and reasoning capabilities.  \n\n2. **Blocking Test Set**: This set consists of 3.3k prompts on various blocked topics from R1, covering 11 languages. It evaluates the modelâ€™s ability to unblock previously blocked content across different languages. \n\n3. **Harm Mitigation Test Set**: This set is a [split](https://github.com/nouhadziri/safety-eval-fork/blob/main/evaluation/tasks/generation/harmbench/harmbench_behaviors_text_test.csv) from the [HarmBench](https://www.harmbench.org/) dataset and includes 320 queries, categorized into three functional categories: standard, contextual, and copyright. The queries cover eight semantic categories, such as misinformation/disinformation, chemical/biological threats, illegal activities, harmful content, copyright violations, cybercrime, and harassment. It evaluates the model's leakage rate of harmful or unsafe content. \n\n#### Factors\n\nThe following factors can influence MAI-DS-R1's behavior and performance: \n\n1. **Input topic and Sensitivity**: The model is explicitly tuned to freely discuss topics that were previously blocked. On such topics it will now provide information about where the base model might have demurred. However, for truly harmful or explicitly disallowed content (e.g. instructions for violence), the model remains restrictive due to fine-tuning. \n\n2. **Language**: Although MAI-DS-R1 was post-trained on multilingual data, it may inherit limitations from the original DeepSeek-R1 model, with performance likely strongest in English and Chinese. \n\n3. **Prompt Complexity and Reasoning Required**: The model performs well on complex queries requiring reasoning, while very long or complex prompts could still pose a challenge.  \n\n4. **User Instructions and Role Prompts**: As a chat-oriented LLM, MAI-DS-R1â€™s responses can be shaped by system or developer-provided instructions (e.g. a system prompt defining its role and style) and the user's phrasing. Developers should provide clear instructions to guide modelâ€™s behavior. \n\n#### Metrics\n\n1. Public benchmarks: \n    - Accuracy: the percentage of problems for which the modelâ€™s output matches the correct answer. \n    - Pass@1: the percentage of problems for which the model generates a correct solution which passes all test cases in the first attempt. \n\n2. Blocking evaluation: \n    - Satisfaction (internal metric to measuring relevance with the question on [0,4] scale): The intent is to measure whether the unblocked answers do answer the question and not generate content which is unrelated.  \n    - % Responses: The proportion of previously blocked samples successfully unblocked. \n\n3. Harm mitigation evaluation: \n    - Attack Success Rate: the percentage of test cases that elicit the behavior from the model. This is evaluated per functional or semantic category. \n    - Micro Attack Success Rate: the total average of attack success rate over all categories. \n\n### Results  \n\n#### Evaluation on General Knowledge and Reasoning\n\u003Cp align=\"center\"\u003E\n  \u003Cimg src=\"figures/reasoning.png\" alt=\"Benchmark Chart\"\u003E\n\u003C/p\u003E\n\n\u003Cp align=\"center\"\u003E\n  \u003Cimg src=\"figures/math.png\" alt=\"Benchmark Chart\"\u003E\n\u003C/p\u003E\n\n\u003Cp align=\"center\"\u003E\n  \u003Cimg src=\"figures/coding.png\" alt=\"Benchmark Chart\"\u003E\n\u003C/p\u003E\n\n#### Evaluation on Responsiveness\n\u003Cp align=\"center\"\u003E\n    \u003Ctable\u003E\n    \u003Ctr\u003E\n        \u003Ctd\u003E\u003Cimg src=\"figures/responsiveness.png\" width=\"500\"/\u003E\u003C/td\u003E\n        \u003Ctd\u003E\u003Cimg src=\"figures/satisfaction.png\" width=\"500\"/\u003E\u003C/td\u003E\n    \u003C/tr\u003E\n    \u003C/table\u003E\n\u003C/p\u003E\n\n#### Evaluation on Harm Mitigation\n\u003Cp align=\"center\"\u003E\n  \u003Cimg src=\"figures/harm_mitigation_answer_only.png\" alt=\"Benchmark Chart\"\u003E\n\u003C/p\u003E\n\n\u003Cp align=\"center\"\u003E\n  \u003Cimg src=\"figures/harm_mitigation_thinking_only.png\" alt=\"Benchmark Chart\"\u003E\n\u003C/p\u003E\n\n#### Summary \n- **General Knowledge & Reasoning**: MAI-DS-R1 performs on par with DeepSeek-R1 and slightly better than R1-1776, especially excelling in mgsm_chain_of_thought_zh, where R1-1776 had a significant regression. \n\n- **Blocked Topics**: MAI-DS-R1 blocked 99.3% of samples, matching R1-1776, and achieved a higher Satisfaction score, likely due to more relevant responses. \n\n- **Harm Mitigation**: MAI-DS-R1 outperforms both R1-1776 and the original R1 model in minimizing harmful content. \n### Model Architecture and Objective \n- **Model Name**: MAI-DS-R1\n- **Architecture**: Based on DeepSeek-R1, a transformer-based autoregressive language model utilizing multi-head self-attention and Mixture-of-Experts (MoE) for scalable and efficient inference. \n- **Objective**: Post-trained to reduce CCP-aligned restrictions and enhance harm protection, while preserving the original modelâ€™s strong chain-of-thought reasoning and general-purpose language understanding capabilities. \n- **Pre-trained Model Base**: DeepSeek-R1 (671B)\n \n",
      "public": true,
      "version": "56c71146-c30a-5285-902c-abdbec710f80",
      "tool_description": null,
      "slug": "chutes-microsoft-mai-ds-r1-fp8",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-04-20T08:08:48.502651Z",
      "updated_at": "2025-10-09T19:40:27.218938Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 43585,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.3,
            "tao": 0.000745056364755754
          },
          "output": {
            "usd": 1.2,
            "tao": 0.00298022545902302
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "14706bb2-0bbe-405b-ba92-d6dfffe41034",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:13:23.484885Z"
        },
        {
          "instance_id": "1e5703dc-6630-43d4-9f45-23f3460166ec",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:13:23.484885Z"
        },
        {
          "instance_id": "293ec6b9-5ca0-4e9f-bd9b-5b5459e28e50",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:13:23.484885Z"
        },
        {
          "instance_id": "db34f813-6b4b-4771-aad8-7023c07ee748",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:13:23.484885Z"
        }
      ],
      "logo_id": "295f11c9-a7ec-4a84-ba72-36c8f7e294e0",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "c6b60e5985efd2f4e1dda6c229d7de4dd62a83b4",
      "concurrency": 40,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/295f11c9-a7ec-4a84-ba72-36c8f7e294e0.webp",
      "hot": true
    },
    {
      "chute_id": "83594561-0940-5839-ac92-1d94dd280567",
      "name": "unsloth/gemma-3-12b-it",
      "tagline": "Gemma 3 is an open-source multimodal model available in 1B, 4B, 12B, and 27B parameter sizes that can handle both text and images as input, making it suitable for tasks like question answering, summarization, code generation, and image understanding while being efficient enough to run on consumer hardware.",
      "readme": "\n# Gemma 3 model card\n\n**Model Page**: [Gemma](https://ai.google.dev/gemma/docs/core)\n\n**Resources and Technical Documentation**:\n\n* [Gemma 3 Technical Report][g3-tech-report]\n* [Responsible Generative AI Toolkit][rai-toolkit]\n* [Gemma on Kaggle][kaggle-gemma]\n* [Gemma on Vertex Model Garden][vertex-mg-gemma3]\n\n**Terms of Use**: [Terms][terms]\n\n**Authors**: Google DeepMind\n\n## Model Information\n\nSummary description and brief definition of inputs and outputs.\n\n### Description\n\nGemma is a family of lightweight, state-of-the-art open models from Google,\nbuilt from the same research and technology used to create the Gemini models.\nGemma 3 models are multimodal, handling text and image input and generating text\noutput, with open weights for both pre-trained variants and instruction-tuned\nvariants. Gemma 3 has a large, 128K context window, multilingual support in over\n140 languages, and is available in more sizes than previous versions. Gemma 3\nmodels are well-suited for a variety of text generation and image understanding\ntasks, including question answering, summarization, and reasoning. Their\nrelatively small size makes it possible to deploy them in environments with\nlimited resources such as laptops, desktops or your own cloud infrastructure,\ndemocratizing access to state of the art AI models and helping foster innovation\nfor everyone.\n\n### Inputs and outputs\n\n-   **Input:**\n    -  Text string, such as a question, a prompt, or a document to be summarized\n    -  Images, normalized to 896 x 896 resolution and encoded to 256 tokens\n       each\n    -  Total input context of 128K tokens for the 4B, 12B, and 27B sizes, and\n       32K tokens for the 1B size\n\n-   **Output:**\n    -   Generated text in response to the input, such as an answer to a\n        question, analysis of image content, or a summary of a document\n    -   Total output context of 8192 tokens\n\n### Usage\n\nBelow, there are some code snippets on how to get quickly started with running the model. First, install the Transformers library. Gemma 3 is supported starting from transformers 4.50.0. \n\n```sh\n$ pip install -U transformers\n```\n\nThen, copy the snippet from the section that is relevant for your use case.\n\n#### Running with the `pipeline` API\n\nYou can initialize the model and processor for inference with `pipeline` as follows.\n\n```python\nfrom transformers import pipeline\nimport torch\n\npipe = pipeline(\n    \"image-text-to-text\",\n    model=\"google/gemma-3-12b-it\",\n    device=\"cuda\",\n    torch_dtype=torch.bfloat16\n)\n```\n\nWith instruction-tuned models, you need to use chat templates to process our inputs first. Then, you can pass it to the pipeline.\n\n```python\nmessages = [\n    {\n        \"role\": \"system\",\n        \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}]\n    },\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\", \"url\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/p-blog/candy.JPG\"},\n            {\"type\": \"text\", \"text\": \"What animal is on the candy?\"}\n        ]\n    }\n]\n\noutput = pipe(text=messages, max_new_tokens=200)\nprint(output[0][\"generated_text\"][-1][\"content\"])\n# Okay, let's take a look! \n# Based on the image, the animal on the candy is a **turtle**. \n# You can see the shell shape and the head and legs.\n```\n\n#### Running the model on a single / multi GPU\n\n```python\n# pip install accelerate\n\nfrom transformers import AutoProcessor, Gemma3ForConditionalGeneration\nfrom PIL import Image\nimport requests\nimport torch\n\nmodel_id = \"google/gemma-3-12b-it\"\n\nmodel = Gemma3ForConditionalGeneration.from_pretrained(\n    model_id, device_map=\"auto\"\n).eval()\n\nprocessor = AutoProcessor.from_pretrained(model_id)\n\nmessages = [\n    {\n        \"role\": \"system\",\n        \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}]\n    },\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\", \"image\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg\"},\n            {\"type\": \"text\", \"text\": \"Describe this image in detail.\"}\n        ]\n    }\n]\n\ninputs = processor.apply_chat_template(\n    messages, add_generation_prompt=True, tokenize=True,\n    return_dict=True, return_tensors=\"pt\"\n).to(model.device, dtype=torch.bfloat16)\n\ninput_len = inputs[\"input_ids\"].shape[-1]\n\nwith torch.inference_mode():\n    generation = model.generate(**inputs, max_new_tokens=100, do_sample=False)\n    generation = generation[0][input_len:]\n\ndecoded = processor.decode(generation, skip_special_tokens=True)\nprint(decoded)\n\n# **Overall Impression:** The image is a close-up shot of a vibrant garden scene, \n# focusing on a cluster of pink cosmos flowers and a busy bumblebee. \n# It has a slightly soft, natural feel, likely captured in daylight.\n```\n\n### Citation\n\n```none\n@article{gemma_2025,\n    title={Gemma 3},\n    url={https://goo.gle/Gemma3Report},\n    publisher={Kaggle},\n    author={Gemma Team},\n    year={2025}\n}\n```\n\n## Model Data\n\nData used for model training and how the data was processed.\n\n### Training Dataset\n\nThese models were trained on a dataset of text data that includes a wide variety\nof sources. The 27B model was trained with 14 trillion tokens, the 12B model was\ntrained with 12 trillion tokens, 4B model was trained with 4 trillion tokens and\n1B with 2 trillion tokens. Here are the key components:\n\n-   Web Documents: A diverse collection of web text ensures the model is\n    exposed to a broad range of linguistic styles, topics, and vocabulary. The\n    training dataset includes content in over 140 languages.\n-   Code: Exposing the model to code helps it to learn the syntax and\n    patterns of programming languages, which improves its ability to generate\n    code and understand code-related questions.\n-   Mathematics: Training on mathematical text helps the model learn logical\n    reasoning, symbolic representation, and to address mathematical queries.\n-   Images: A wide range of images enables the model to perform image\n    analysis and visual data extraction tasks.\n\nThe combination of these diverse data sources is crucial for training a powerful\nmultimodal model that can handle a wide variety of different tasks and data\nformats.\n\n### Data Preprocessing\n\nHere are the key data cleaning and filtering methods applied to the training\ndata:\n\n-   CSAM Filtering: Rigorous CSAM (Child Sexual Abuse Material) filtering\n    was applied at multiple stages in the data preparation process to ensure\n    the exclusion of harmful and illegal content.\n-   Sensitive Data Filtering: As part of making Gemma pre-trained models\n    safe and reliable, automated techniques were used to filter out certain\n    personal information and other sensitive data from training sets.\n-   Additional methods: Filtering based on content quality and safety in\n    line with [our policies][safety-policies].\n\n## Implementation Information\n\nDetails about the model internals.\n\n### Hardware\n\nGemma was trained using [Tensor Processing Unit (TPU)][tpu] hardware (TPUv4p,\nTPUv5p and TPUv5e). Training vision-language models (VLMS) requires significant\ncomputational power. TPUs, designed specifically for matrix operations common in\nmachine learning, offer several advantages in this domain:\n\n-   Performance: TPUs are specifically designed to handle the massive\n    computations involved in training VLMs. They can speed up training\n    considerably compared to CPUs.\n-   Memory: TPUs often come with large amounts of high-bandwidth memory,\n    allowing for the handling of large models and batch sizes during training.\n    This can lead to better model quality.\n-   Scalability: TPU Pods (large clusters of TPUs) provide a scalable\n    solution for handling the growing complexity of large foundation models.\n    You can distribute training across multiple TPU devices for faster and more\n    efficient processing.\n-   Cost-effectiveness: In many scenarios, TPUs can provide a more\n    cost-effective solution for training large models compared to CPU-based\n    infrastructure, especially when considering the time and resources saved\n    due to faster training.\n-   These advantages are aligned with\n    [Google's commitments to operate sustainably][sustainability].\n\n### Software\n\nTraining was done using [JAX][jax] and [ML Pathways][ml-pathways].\n\nJAX allows researchers to take advantage of the latest generation of hardware,\nincluding TPUs, for faster and more efficient training of large models. ML\nPathways is Google's latest effort to build artificially intelligent systems\ncapable of generalizing across multiple tasks. This is specially suitable for\nfoundation models, including large language models like these ones.\n\nTogether, JAX and ML Pathways are used as described in the\n[paper about the Gemini family of models][gemini-2-paper]; *\"the 'single\ncontroller' programming model of Jax and Pathways allows a single Python\nprocess to orchestrate the entire training run, dramatically simplifying the\ndevelopment workflow.\"*\n\n## Evaluation\n\nModel evaluation metrics and results.\n\n### Benchmark Results\n\nThese models were evaluated against a large collection of different datasets and\nmetrics to cover different aspects of text generation:\n\n#### Reasoning and factuality\n\n| Benchmark                      | Metric         | Gemma 3 PT 1B  | Gemma 3 PT 4B | Gemma 3 PT 12B | Gemma 3 PT 27B |\n| ------------------------------ |----------------|:--------------:|:-------------:|:--------------:|:--------------:|\n| [HellaSwag][hellaswag]         | 10-shot        |      62.3      |      77.2     |      84.2      |      85.6      |\n| [BoolQ][boolq]                 | 0-shot         |      63.2      |      72.3     |      78.8      |      82.4      |\n| [PIQA][piqa]                   | 0-shot         |      73.8      |      79.6     |      81.8      |      83.3      |\n| [SocialIQA][socialiqa]         | 0-shot         |      48.9      |      51.9     |      53.4      |      54.9      |\n| [TriviaQA][triviaqa]           | 5-shot         |      39.8      |      65.8     |      78.2      |      85.5      |\n| [Natural Questions][naturalq]  | 5-shot         |      9.48      |      20.0     |      31.4      |      36.1      |\n| [ARC-c][arc]                   | 25-shot        |      38.4      |      56.2     |      68.9      |      70.6      |\n| [ARC-e][arc]                   | 0-shot         |      73.0      |      82.4     |      88.3      |      89.0      |\n| [WinoGrande][winogrande]       | 5-shot         |      58.2      |      64.7     |      74.3      |      78.8      |\n| [BIG-Bench Hard][bbh]          | few-shot       |      28.4      |      50.9     |      72.6      |      77.7      |\n| [DROP][drop]                   | 1-shot         |      42.4      |      60.1     |      72.2      |      77.2      |\n\n[hellaswag]: https://arxiv.org/abs/1905.07830\n[boolq]: https://arxiv.org/abs/1905.10044\n[piqa]: https://arxiv.org/abs/1911.11641\n[socialiqa]: https://arxiv.org/abs/1904.09728\n[triviaqa]: https://arxiv.org/abs/1705.03551\n[naturalq]: https://github.com/google-research-datasets/natural-questions\n[arc]: https://arxiv.org/abs/1911.01547\n[winogrande]: https://arxiv.org/abs/1907.10641\n[bbh]: https://paperswithcode.com/dataset/bbh\n[drop]: https://arxiv.org/abs/1903.00161\n\n#### STEM and code\n\n| Benchmark                      | Metric         | Gemma 3 PT 4B | Gemma 3 PT 12B | Gemma 3 PT 27B |\n| ------------------------------ |----------------|:-------------:|:--------------:|:--------------:|\n| [MMLU][mmlu]                   | 5-shot         |      59.6     |      74.5      |      78.6      |\n| [MMLU][mmlu] (Pro COT)         | 5-shot         |      29.2     |      45.3      |      52.2      |\n| [AGIEval][agieval]             | 3-5-shot       |      42.1     |      57.4      |      66.2      |\n| [MATH][math]                   | 4-shot         |      24.2     |      43.3      |      50.0      |\n| [GSM8K][gsm8k]                 | 8-shot         |      38.4     |      71.0      |      82.6      |\n| [GPQA][gpqa]                   | 5-shot         |      15.0     |      25.4      |      24.3      |\n| [MBPP][mbpp]                   | 3-shot         |      46.0     |      60.4      |      65.6      |\n| [HumanEval][humaneval]         | 0-shot         |      36.0     |      45.7      |      48.8      |\n\n[mmlu]: https://arxiv.org/abs/2009.03300\n[agieval]: https://arxiv.org/abs/2304.06364\n[math]: https://arxiv.org/abs/2103.03874\n[gsm8k]: https://arxiv.org/abs/2110.14168\n[gpqa]: https://arxiv.org/abs/2311.12022\n[mbpp]: https://arxiv.org/abs/2108.07732\n[humaneval]: https://arxiv.org/abs/2107.03374\n\n#### Multilingual\n\n| Benchmark                            | Gemma 3 PT 1B | Gemma 3 PT 4B | Gemma 3 PT 12B | Gemma 3 PT 27B |\n| ------------------------------------ |:-------------:|:-------------:|:--------------:|:--------------:|\n| [MGSM][mgsm]                         |      2.04     |      34.7     |      64.3     |      74.3     |\n| [Global-MMLU-Lite][global-mmlu-lite] |      24.9     |      57.0     |      69.4     |      75.7     |\n| [WMT24++][wmt24pp] (ChrF)            |      36.7     |      48.4     |      53.9     |      55.7     |\n| [FloRes][flores]                     |      29.5     |      39.2     |      46.0     |      48.8     |\n| [XQuAD][xquad] (all)                 |      43.9     |      68.0     |      74.5     |      76.8     |\n| [ECLeKTic][eclektic]                 |      4.69     |      11.0     |      17.2     |      24.4     |\n| [IndicGenBench][indicgenbench]       |      41.4     |      57.2     |      61.7     |      63.4     |\n\n[mgsm]: https://arxiv.org/abs/2210.03057\n[flores]: https://arxiv.org/abs/2106.03193\n[xquad]: https://arxiv.org/abs/1910.11856v3\n[global-mmlu-lite]: https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite\n[wmt24pp]: https://arxiv.org/abs/2502.12404v1\n[eclektic]: https://arxiv.org/abs/2502.21228\n[indicgenbench]: https://arxiv.org/abs/2404.16816\n\n#### Multimodal\n\n| Benchmark                      | Gemma 3 PT 4B | Gemma 3 PT 12B | Gemma 3 PT 27B |\n| ------------------------------ |:-------------:|:--------------:|:--------------:|\n| [COCOcap][coco-cap]            |      102      |      111       |      116       |\n| [DocVQA][docvqa] (val)         |      72.8     |      82.3      |      85.6      |\n| [InfoVQA][info-vqa] (val)      |      44.1     |      54.8      |      59.4      |\n| [MMMU][mmmu] (pt)              |      39.2     |      50.3      |      56.1      |\n| [TextVQA][textvqa] (val)       |      58.9     |      66.5      |      68.6      |\n| [RealWorldQA][realworldqa]     |      45.5     |      52.2      |      53.9      |\n| [ReMI][remi]                   |      27.3     |      38.5      |      44.8      |\n| [AI2D][ai2d]                   |      63.2     |      75.2      |      79.0      |\n| [ChartQA][chartqa]             |      63.6     |      74.7      |      76.3      |\n| [VQAv2][vqav2]                 |      63.9     |      71.2      |      72.9      |\n| [BLINK][blinkvqa]              |      38.0     |      35.9      |      39.6      |\n| [OKVQA][okvqa]                 |      51.0     |      58.7      |      60.2      |\n| [TallyQA][tallyqa]             |      42.5     |      51.8      |      54.3      |\n| [SpatialSense VQA][ss-vqa]     |      50.9     |      60.0      |      59.4      |\n| [CountBenchQA][countbenchqa]   |      26.1     |      17.8      |      68.0      |\n\n[coco-cap]: https://cocodataset.org/#home\n[docvqa]: https://www.docvqa.org/\n[info-vqa]: https://arxiv.org/abs/2104.12756\n[mmmu]: https://arxiv.org/abs/2311.16502\n[textvqa]: https://textvqa.org/\n[realworldqa]: https://paperswithcode.com/dataset/realworldqa\n[remi]: https://arxiv.org/html/2406.09175v1\n[ai2d]: https://allenai.org/data/diagrams\n[chartqa]: https://arxiv.org/abs/2203.10244\n[vqav2]: https://visualqa.org/index.html\n[blinkvqa]: https://arxiv.org/abs/2404.12390\n[okvqa]: https://okvqa.allenai.org/\n[tallyqa]: https://arxiv.org/abs/1810.12440\n[ss-vqa]: https://arxiv.org/abs/1908.02660\n[countbenchqa]: https://github.com/",
      "public": true,
      "version": "19a122c2-ba99-540b-934e-1f880d2fbaa6",
      "tool_description": null,
      "slug": "chutes-unsloth-gemma-3-12b-it",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-10-07T11:14:13.312254Z",
      "updated_at": "2025-10-08T15:17:51.536901Z",
      "image": {
        "image_id": "959721f7-6184-549f-bd66-546c8868b9f7",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100800",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T14:43:47.661711Z",
        "build_started_at": "2025-10-08T14:44:11.231501Z",
        "build_completed_at": "2025-10-08T15:10:23.923875Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "df8eef013628",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "h100_nvl",
        "h100",
        "h100_sxm",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h100",
          "h100_nvl",
          "h100_sxm",
          "h200",
          "h800"
        ],
        "gpu_count": 2,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.666666666666667,
        "supported_gpus": [
          "h200",
          "h100_nvl",
          "h100",
          "h100_sxm",
          "h800"
        ]
      },
      "invocation_count": 41445,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          },
          "output": {
            "usd": 0.1,
            "tao": 0.000248352121585251
          }
        },
        "usd": {
          "hour": 3,
          "second": 0.000833333333333333
        },
        "tao": {
          "hour": 0.00745056364755754,
          "second": 0.00000206960101321
        }
      },
      "instances": [
        {
          "instance_id": "86452bf7-6bb6-4e93-b250-9bc3a802a342",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:45:37.705694Z"
        },
        {
          "instance_id": "bd6c661d-f793-49aa-bf70-c7e2717e623e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:45:37.705694Z"
        },
        {
          "instance_id": "496ed651-f30a-44fc-8ce1-924aaf298f8c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:45:37.705694Z"
        },
        {
          "instance_id": "afe86808-ad97-48c6-9ef5-7ba29a1e69c5",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:45:37.705694Z"
        }
      ],
      "logo_id": "8cd55107-613b-41f6-95d8-3c34320a8e84",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "1b50bd0b78e6af2c4ea9e9bf220ac2b9a7a22655",
      "concurrency": 32,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/8cd55107-613b-41f6-95d8-3c34320a8e84.webp",
      "hot": true
    },
    {
      "chute_id": "96b5aab1-6a45-578b-8897-6f927b3aa87f",
      "name": "Qwen/Qwen3-30B-A3B",
      "tagline": "Qwen3-30B-A3B is a 30.5B parameter MoE language model (with 3.3B active parameters) that supports switching between thinking and non-thinking modes, making it versatile for complex reasoning tasks like math and coding as well as general dialogue in 100+ languages.",
      "readme": "\n# Qwen3-30B-A3B\n\u003Ca href=\"https://chat.qwen.ai/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/%F0%9F%92%9C%EF%B8%8F%20Qwen%20Chat%20-536af5\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n\u003C/a\u003E\n\n## Qwen3 Highlights\n\nQwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support, with the following key features:\n\n- **Uniquely support of seamless switching between thinking mode** (for complex logical reasoning, math, and coding) and **non-thinking mode** (for efficient, general-purpose dialogue) **within single model**, ensuring optimal performance across various scenarios.\n- **Significantly enhancement in its reasoning capabilities**, surpassing previous QwQ (in thinking mode) and Qwen2.5 instruct models (in non-thinking mode) on mathematics, code generation, and commonsense logical reasoning.\n- **Superior human preference alignment**, excelling in creative writing, role-playing, multi-turn dialogues, and instruction following, to deliver a more natural, engaging, and immersive conversational experience.\n- **Expertise in agent capabilities**, enabling precise integration with external tools in both thinking and unthinking modes and achieving leading performance among open-source models in complex agent-based tasks.\n- **Support of 100+ languages and dialects** with strong capabilities for **multilingual instruction following** and **translation**.\n\n## Model Overview\n\n**Qwen3-30B-A3B** has the following features:\n- Type: Causal Language Models\n- Training Stage: Pretraining & Post-training\n- Number of Parameters: 30.5B in total and 3.3B activated\n- Number of Paramaters (Non-Embedding): 29.9B\n- Number of Layers: 48\n- Number of Attention Heads (GQA): 32 for Q and 4 for KV\n- Number of Experts: 128\n- Number of Activated Experts: 8\n- Context Length: 32,768 natively and [131,072 tokens with YaRN](https://huggingface.co/Qwen/Qwen3-30B-A3B/raw/main/#processing-long-texts). \n\nFor more details, including benchmark evaluation, hardware requirements, and inference performance, please refer to our [blog](https://qwenlm.github.io/blog/qwen3/), [GitHub](https://github.com/QwenLM/Qwen3), and [Documentation](https://qwen.readthedocs.io/en/latest/).\n\n## Quickstart\n\nThe code of Qwen3-MoE has been in the latest Hugging Face `transformers` and we advise you to use the latest version of `transformers`.\n\nWith `transformers\u003C4.51.0`, you will encounter the following error:\n```\nKeyError: 'qwen3_moe'\n```\n\nThe following contains a code snippet illustrating how to use the model generate content based on given inputs. \n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"Qwen/Qwen3-30B-A3B\"\n\n# load the tokenizer and the model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=\"auto\",\n    device_map=\"auto\"\n)\n\n# prepare the model input\nprompt = \"Give me a short introduction to large language model.\"\nmessages = [\n    {\"role\": \"user\", \"content\": prompt}\n]\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\n# conduct text completion\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=32768\n)\noutput_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n\n# parsing thinking content\ntry:\n    # rindex finding 151668 (\u003C/think\u003E)\n    index = len(output_ids) - output_ids[::-1].index(151668)\nexcept ValueError:\n    index = 0\n\nthinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\ncontent = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n\nprint(\"thinking content:\", thinking_content)\nprint(\"content:\", content)\n```\n\nFor deployment, you can use `sglang\u003E=0.4.6.post1` or `vllm\u003E=0.8.5` or to create an OpenAI-compatible API endpoint:\n- SGLang:\n    ```shell\n    python -m sglang.launch_server --model-path Qwen/Qwen3-30B-A3B --reasoning-parser qwen3\n    ```\n- vLLM:\n    ```shell\n    vllm serve Qwen/Qwen3-30B-A3B --enable-reasoning --reasoning-parser deepseek_r1\n    ```\n\nFor local use, applications such as Ollama, LMStudio, MLX-LM, llama.cpp, and KTransformers have also supported Qwen3.\n\n## Switching Between Thinking and Non-Thinking Mode\n\n\u003E [!TIP]\n\u003E The `enable_thinking` switch is also available in APIs created by SGLang and vLLM. \n\u003E Please refer to our documentation for [SGLang](https://qwen.readthedocs.io/en/latest/deployment/sglang.html#thinking-non-thinking-modes) and [vLLM](https://qwen.readthedocs.io/en/latest/deployment/vllm.html#thinking-non-thinking-modes) users.\n\n### `enable_thinking=True`\n\nBy default, Qwen3 has thinking capabilities enabled, similar to QwQ-32B. This means the model will use its reasoning abilities to enhance the quality of generated responses. For example, when explicitly setting `enable_thinking=True` or leaving it as the default value in `tokenizer.apply_chat_template`, the model will engage its thinking mode.\n\n```python\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=True  # True is the default value for enable_thinking\n)\n```\n\nIn this mode, the model will generate think content wrapped in a `\u003Cthink\u003E...\u003C/think\u003E` block, followed by the final response.\n\n\u003E [!NOTE]\n\u003E For thinking mode, use `Temperature=0.6`, `TopP=0.95`, `TopK=20`, and `MinP=0` (the default setting in `generation_config.json`). **DO NOT use greedy decoding**, as it can lead to performance degradation and endless repetitions. For more detailed guidance, please refer to the [Best Practices](https://huggingface.co/Qwen/Qwen3-30B-A3B/raw/main/#best-practices) section.\n\n\n### `enable_thinking=False`\n\nWe provide a hard switch to strictly disable the model's thinking behavior, aligning its functionality with the previous Qwen2.5-Instruct models. This mode is particularly useful in scenarios where disabling thinking is essential for enhancing efficiency.\n\n```python\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=False  # Setting enable_thinking=False disables thinking mode\n)\n```\n\nIn this mode, the model will not generate any think content and will not include a `\u003Cthink\u003E...\u003C/think\u003E` block.\n\n\u003E [!NOTE]\n\u003E For non-thinking mode, we suggest using `Temperature=0.7`, `TopP=0.8`, `TopK=20`, and `MinP=0`. For more detailed guidance, please refer to the [Best Practices](https://huggingface.co/Qwen/Qwen3-30B-A3B/raw/main/#best-practices) section.\n\n### Advanced Usage: Switching Between Thinking and Non-Thinking Modes via User Input\n\nWe provide a soft switch mechanism that allows users to dynamically control the model's behavior when `enable_thinking=True`. Specifically, you can add `/think` and `/no_think` to user prompts or system messages to switch the model's thinking mode from turn to turn. The model will follow the most recent instruction in multi-turn conversations.\n\nHere is an example of a multi-turn conversation:\n\n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nclass QwenChatbot:\n    def __init__(self, model_name=\"Qwen/Qwen3-30B-A3B\"):\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n        self.history = []\n\n    def generate_response(self, user_input):\n        messages = self.history + [{\"role\": \"user\", \"content\": user_input}]\n\n        text = self.tokenizer.apply_chat_template(\n            messages,\n            tokenize=False,\n            add_generation_prompt=True\n        )\n\n        inputs = self.tokenizer(text, return_tensors=\"pt\")\n        response_ids = self.model.generate(**inputs, max_new_tokens=32768)[0][len(inputs.input_ids[0]):].tolist()\n        response = self.tokenizer.decode(response_ids, skip_special_tokens=True)\n\n        # Update history\n        self.history.append({\"role\": \"user\", \"content\": user_input})\n        self.history.append({\"role\": \"assistant\", \"content\": response})\n\n        return response\n\n# Example Usage\nif __name__ == \"__main__\":\n    chatbot = QwenChatbot()\n\n    # First input (without /think or /no_think tags, thinking mode is enabled by default)\n    user_input_1 = \"How many r's in strawberries?\"\n    print(f\"User: {user_input_1}\")\n    response_1 = chatbot.generate_response(user_input_1)\n    print(f\"Bot: {response_1}\")\n    print(\"----------------------\")\n\n    # Second input with /no_think\n    user_input_2 = \"Then, how many r's in blueberries? /no_think\"\n    print(f\"User: {user_input_2}\")\n    response_2 = chatbot.generate_response(user_input_2)\n    print(f\"Bot: {response_2}\") \n    print(\"----------------------\")\n\n    # Third input with /think\n    user_input_3 = \"Really? /think\"\n    print(f\"User: {user_input_3}\")\n    response_3 = chatbot.generate_response(user_input_3)\n    print(f\"Bot: {response_3}\")\n```\n\n\u003E [!NOTE]\n\u003E For API compatibility, when `enable_thinking=True`, regardless of whether the user uses `/think` or `/no_think`, the model will always output a block wrapped in `\u003Cthink\u003E...\u003C/think\u003E`. However, the content inside this block may be empty if thinking is disabled.\n\u003E When `enable_thinking=False`, the soft switches are not valid. Regardless of any `/think` or `/no_think` tags input by the user, the model will not generate think content and will not include a `\u003Cthink\u003E...\u003C/think\u003E` block.\n\n## Agentic Use\n\nQwen3 excels in tool calling capabilities. We recommend using [Qwen-Agent](https://github.com/QwenLM/Qwen-Agent) to make the best use of agentic ability of Qwen3. Qwen-Agent encapsulates tool-calling templates and tool-calling parsers internally, greatly reducing coding complexity.\n\nTo define the available tools, you can use the MCP configuration file, use the integrated tool of Qwen-Agent, or integrate other tools by yourself.\n```python\nfrom qwen_agent.agents import Assistant\n\n# Define LLM\nllm_cfg = {\n    'model': 'Qwen3-30B-A3B',\n\n    # Use the endpoint provided by Alibaba Model Studio:\n    # 'model_type': 'qwen_dashscope',\n    # 'api_key': os.getenv('DASHSCOPE_API_KEY'),\n\n    # Use a custom endpoint compatible with OpenAI API:\n    'model_server': 'http://localhost:8000/v1',  # api_base\n    'api_key': 'EMPTY',\n\n    # Other parameters:\n    # 'generate_cfg': {\n    #         # Add: When the response content is `\u003Cthink\u003Ethis is the thought\u003C/think\u003Ethis is the answer;\n    #         # Do not add: When the response has been separated by reasoning_content and content.\n    #         'thought_in_content': True,\n    #     },\n}\n\n# Define Tools\ntools = [\n    {'mcpServers': {  # You can specify the MCP configuration file\n            'time': {\n                'command': 'uvx',\n                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']\n            },\n            \"fetch\": {\n                \"command\": \"uvx\",\n                \"args\": [\"mcp-server-fetch\"]\n            }\n        }\n    },\n  'code_interpreter',  # Built-in tools\n]\n\n# Define Agent\nbot = Assistant(llm=llm_cfg, function_list=tools)\n\n# Streaming generation\nmessages = [{'role': 'user', 'content': 'https://qwenlm.github.io/blog/ Introduce the latest developments of Qwen'}]\nfor responses in bot.run(messages=messages):\n    pass\nprint(responses)\n```\n\n## Processing Long Texts\n\nQwen3 natively supports context lengths of up to 32,768 tokens. For conversations where the total length (including both input and output) significantly exceeds this limit, we recommend using RoPE scaling techniques to handle long texts effectively. We have validated the model's performance on context lengths of up to 131,072 tokens using the [YaRN](https://arxiv.org/abs/2309.00071) method.\n\nYaRN is currently supported by several inference frameworks, e.g., `transformers` and `llama.cpp` for local use, `vllm` and `sglang` for deployment. In general, there are two approaches to enabling YaRN for supported frameworks:\n\n- Modifying the model files:\n  In the `config.json` file, add the `rope_scaling` fields:\n    ```json\n    {\n        ...,\n        \"rope_scaling\": {\n            \"rope_type\": \"yarn\",\n            \"factor\": 4.0,\n            \"original_max_position_embeddings\": 32768\n        }\n    }\n    ```\n  For `llama.cpp`, you need to regenerate the GGUF file after the modification.\n\n- Passing command line arguments:\n\n  For `vllm`, you can use\n    ```shell\n    vllm serve ... --rope-scaling '{\"rope_type\":\"yarn\",\"factor\":4.0,\"original_max_position_embeddings\":32768}' --max-model-len 131072\n    ```\n\n  For `sglang`, you can use\n    ```shell\n    python -m sglang.launch_server ... --json-model-override-args '{\"rope_scaling\":{\"rope_type\":\"yarn\",\"factor\":4.0,\"original_max_position_embeddings\":32768}}'\n    ```\n\n  For `llama-server` from `llama.cpp`, you can use\n    ```shell\n    llama-server ... --rope-scaling yarn --rope-scale 4 --yarn-orig-ctx 32768\n    ```\n\n\u003E [!IMPORTANT]\n\u003E If you encounter the following warning\n\u003E ```\n\u003E Unrecognized keys in `rope_scaling` for 'rope_type'='yarn': {'original_max_position_embeddings'}\n\u003E ```\n\u003E please upgrade `transformers\u003E=4.51.0`.\n\n\u003E [!NOTE]\n\u003E All the notable open-source frameworks implement static YaRN, which means the scaling factor remains constant regardless of input length, **potentially impacting performance on shorter texts.**\n\u003E We advise adding the `rope_scaling` configuration only when processing long contexts is required. \n\u003E It is also recommended to modify the `factor` as needed. For example, if the typical context length for your application is 65,536 tokens, it would be better to set `factor` as 2.0. \n\n\u003E [!NOTE]\n\u003E The default `max_position_embeddings` in `config.json` is set to 40,960. This allocation includes reserving 32,768 tokens for outputs and 8,192 tokens for typical prompts, which is sufficient for most scenarios involving short text processing. If the average context length does not exceed 32,768 tokens, we do not recommend enabling YaRN in this scenario, as it may potentially degrade model performance.\n\n\u003E [!TIP]\n\u003E The endpoint provided by Alibaba Model Studio supports dynamic YaRN by default and no extra configuration is needed.\n\n## Best Practices\n\nTo achieve optimal performance, we recommend the following settings:\n\n1. **Sampling Parameters**:\n   - For thinking mode (`enable_thinking=True`), use `Temperature=0.6`, `TopP=0.95`, `TopK=20`, and `MinP=0`. **DO NOT use greedy decoding**, as it can lead to performance degradation and endless repetitions.\n   - For non-thinking mode (`enable_thinking=False`), we suggest using `Temperature=0.7`, `TopP=0.8`, `TopK=20`, and `MinP=0`.\n   - For supported frameworks, you can adjust the `presence_penalty` parameter between 0 and 2 to reduce endless repetitions. However, using a higher value may occasionally result in language mixing and a slight decrease in model performance.\n\n2. **Adequate Output Length**: We recommend using an output length of 32,768 tokens for most queries. For benchmarking on highly complex problems, such as those found in math and programming competitions, we suggest setting the max output length to 38,912 tokens. This provides the model with sufficient space to generate detailed and comprehensive responses, thereby enhancing its overall performance.\n\n3. **Standardize Output Format**: We recommend using prompts to standardize model outputs when benchmarking.\n   - **Math Problems**: Include \"Please reason step by step, and put your final answer within \\boxed{}.\" in the prompt.\n   - **Multiple-Choice Questions**: Add the following JSON structure to the prompt to standardize responses: \"Please show your choice in the `answer` field with only the choice le",
      "public": true,
      "version": "83fc728d-e696-5988-9c42-250607d1fb22",
      "tool_description": null,
      "slug": "chutes-qwen-qwen3-30b-a3b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-04-28T22:14:36.270436Z",
      "updated_at": "2025-10-09T19:39:37.090858Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "exclude": [
          "mi300x",
          "b200"
        ],
        "include": null,
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.888888888888889,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 41211,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.06,
            "tao": 0.00014901127295115
          },
          "output": {
            "usd": 0.22,
            "tao": 0.000546374667487553
          }
        },
        "usd": {
          "hour": 4,
          "second": 0.00111111111111111
        },
        "tao": {
          "hour": 0.00993408486341006,
          "second": 0.000002759468017613
        }
      },
      "instances": [
        {
          "instance_id": "ce93ab87-d97e-40c6-adfd-01d4b1a14c03",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:16:10.935216Z"
        },
        {
          "instance_id": "25fdc0ac-8d71-44d6-b0cd-bf8e71d7a77a",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:50:50.457011Z"
        },
        {
          "instance_id": "44c19f9a-2d5c-4a05-8003-16c6df993ee7",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:50:50.457011Z"
        },
        {
          "instance_id": "4e7f3342-5353-4f64-b49a-5c6460348f6e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:50:50.457011Z"
        },
        {
          "instance_id": "abe87f61-83bc-4270-aa21-3926a41642d0",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:50:50.457011Z"
        },
        {
          "instance_id": "d3b2275c-8035-471a-b5b8-bd53a6582940",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:50:50.457011Z"
        },
        {
          "instance_id": "f1838869-4db0-42d7-9460-5858761e499c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:50:50.457011Z"
        },
        {
          "instance_id": "639cc9bb-c3b9-43c1-aa5e-975f3fc805ab",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:50:50.457011Z"
        },
        {
          "instance_id": "e3cd431b-3503-4773-84f5-2768cfd2f95f",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:13:04.592491Z"
        },
        {
          "instance_id": "40a229e1-5495-4a1e-b9be-2a21f1c9fea2",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:13:11.633015Z"
        },
        {
          "instance_id": "f1a1be82-7c2a-4d9b-9be7-b93513177165",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:14:31.644044Z"
        }
      ],
      "logo_id": "6866dead-21bd-481a-87aa-6c723c5fe9cb",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "67b0e0ca24de1b8cedea4c97f1925df66d72bee1",
      "concurrency": 16,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/6866dead-21bd-481a-87aa-6c723c5fe9cb.webp",
      "hot": true
    },
    {
      "chute_id": "62cc0462-8983-5ef1-8859-92ccf726e235",
      "name": "Qwen/Qwen2.5-72B-Instruct",
      "tagline": "Qwen2.5-72B-Instruct is a 72 billion parameter multilingual language model optimized for instruction following, coding, and mathematics tasks, with support for 29+ languages and context lengths up to 128K tokens.",
      "readme": "\n# Qwen2.5-72B-Instruct\n\u003Ca href=\"https://chat.qwenlm.ai/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/%F0%9F%92%9C%EF%B8%8F%20Qwen%20Chat%20-536af5\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n\u003C/a\u003E\n\n## Introduction\n\nQwen2.5 is the latest series of Qwen large language models. For Qwen2.5, we release a number of base language models and instruction-tuned language models ranging from 0.5 to 72 billion parameters. Qwen2.5 brings the following improvements upon Qwen2:\n\n- Significantly **more knowledge** and has greatly improved capabilities in **coding** and **mathematics**, thanks to our specialized expert models in these domains.\n- Significant improvements in **instruction following**, **generating long texts** (over 8K tokens), **understanding structured data** (e.g, tables), and **generating structured outputs** especially JSON. **More resilient to the diversity of system prompts**, enhancing role-play implementation and condition-setting for chatbots.\n- **Long-context Support** up to 128K tokens and can generate up to 8K tokens.\n- **Multilingual support** for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more. \n\n**This repo contains the instruction-tuned 72B Qwen2.5 model**, which has the following features:\n- Type: Causal Language Models\n- Training Stage: Pretraining & Post-training\n- Architecture: transformers with RoPE, SwiGLU, RMSNorm, and Attention QKV bias\n- Number of Parameters: 72.7B\n- Number of Paramaters (Non-Embedding): 70.0B\n- Number of Layers: 80\n- Number of Attention Heads (GQA): 64 for Q and 8 for KV\n- Context Length: Full 131,072 tokens and generation 8192 tokens\n  - Please refer to [this section](https://huggingface.co/Qwen/Qwen2.5-72B-Instruct/raw/main/#processing-long-texts) for detailed instructions on how to deploy Qwen2.5 for handling long texts.\n\nFor more details, please refer to our [blog](https://qwenlm.github.io/blog/qwen2.5/), [GitHub](https://github.com/QwenLM/Qwen2.5), and [Documentation](https://qwen.readthedocs.io/en/latest/).\n\n## Requirements\n\nThe code of Qwen2.5 has been in the latest Hugging face `transformers` and we advise you to use the latest version of `transformers`.\n\nWith `transformers\u003C4.37.0`, you will encounter the following error:\n```\nKeyError: 'qwen2'\n```\n\n## Quickstart\n\nHere provides a code snippet with `apply_chat_template` to show you how to load the tokenizer and model and how to generate contents.\n\n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"Qwen/Qwen2.5-72B-Instruct\"\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=\"auto\",\n    device_map=\"auto\"\n)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nprompt = \"Give me a short introduction to large language model.\"\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": prompt}\n]\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True\n)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=512\n)\ngenerated_ids = [\n    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n]\n\nresponse = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n```\n\n### Processing Long Texts\n\nThe current `config.json` is set for context length up to 32,768 tokens.\nTo handle extensive inputs exceeding 32,768 tokens, we utilize [YaRN](https://arxiv.org/abs/2309.00071), a technique for enhancing model length extrapolation, ensuring optimal performance on lengthy texts.\n\nFor supported frameworks, you could add the following to `config.json` to enable YaRN:\n```json\n{\n  ...,\n  \"rope_scaling\": {\n    \"factor\": 4.0,\n    \"original_max_position_embeddings\": 32768,\n    \"type\": \"yarn\"\n  }\n}\n```\n\nFor deployment, we recommend using vLLM. \nPlease refer to our [Documentation](https://qwen.readthedocs.io/en/latest/deployment/vllm.html) for usage if you are not familar with vLLM.\nPresently, vLLM only supports static YARN, which means the scaling factor remains constant regardless of input length, **potentially impacting performance on shorter texts**. \nWe advise adding the `rope_scaling` configuration only when processing long contexts is required.\n\n## Evaluation & Performance\n\nDetailed evaluation results are reported in this [ğŸ“‘ blog](https://qwenlm.github.io/blog/qwen2.5/).\n\nFor requirements on GPU memory and the respective throughput, see results [here](https://qwen.readthedocs.io/en/latest/benchmark/speed_benchmark.html).\n\n## Citation\n\nIf you find our work helpful, feel free to give us a cite.\n\n```\n@misc{qwen2.5,\n    title = {Qwen2.5: A Party of Foundation Models},\n    url = {https://qwenlm.github.io/blog/qwen2.5/},\n    author = {Qwen Team},\n    month = {September},\n    year = {2024}\n}\n\n@article{qwen2,\n      title={Qwen2 Technical Report}, \n      author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhihao Fan},\n      journal={arXiv preprint arXiv:2407.10671},\n      year={2024}\n}\n```",
      "public": true,
      "version": "f9a3d891-8257-56a6-8675-cc20cb5daf9c",
      "tool_description": null,
      "slug": "chutes-qwen-qwen2-5-72b-instruct",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-03-14T09:16:14.844784Z",
      "updated_at": "2025-10-09T19:04:46.553638Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "h100",
        "h100_sxm",
        "h800",
        "a100_sxm"
      ],
      "node_selector": {
        "exclude": [
          "5090",
          "b200",
          "mi300x"
        ],
        "include": null,
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 80,
        "compute_multiplier": 1.06666666666667,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "h100",
          "h100_sxm",
          "h800",
          "a100_sxm"
        ]
      },
      "invocation_count": 38921,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.07,
            "tao": 0.000173846485109676
          },
          "output": {
            "usd": 0.26,
            "tao": 0.000645715516121653
          }
        },
        "usd": {
          "hour": 4.8,
          "second": 0.00133333333333333
        },
        "tao": {
          "hour": 0.0119209018360921,
          "second": 0.000003311361621136
        }
      },
      "instances": [
        {
          "instance_id": "8730efbb-7b62-4120-a43d-d8dfb46f68d0",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:36:02.990656Z"
        },
        {
          "instance_id": "cb88dd6e-2b5a-4d14-ae5d-450f815eb7ba",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:36:02.990656Z"
        },
        {
          "instance_id": "4021ef6b-6d96-4f83-86d8-6fe6bd7cc72a",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:36:02.990656Z"
        },
        {
          "instance_id": "d20195ac-339c-453f-a4b3-a9739491c697",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:36:02.990656Z"
        },
        {
          "instance_id": "60681c2b-cb1b-4296-a216-8a15ed46c27d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:36:02.990656Z"
        }
      ],
      "logo_id": "6866dead-21bd-481a-87aa-6c723c5fe9cb",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "495f39366efef23836d0cfae4fbe635880d2be31",
      "concurrency": 24,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/6866dead-21bd-481a-87aa-6c723c5fe9cb.webp",
      "hot": true
    },
    {
      "chute_id": "2cdc73dd-eec4-5e6b-883a-7736bbe12fd8",
      "name": "Qwen/Qwen2.5-Coder-32B-Instruct",
      "tagline": "Qwen2.5-Coder-32B-Instruct is a 32.5B parameter language model specialized for code generation, reasoning, and fixing, with strong mathematical abilities and support for contexts up to 128K tokens.",
      "readme": "\n\n# Qwen2.5-Coder-32B-Instruct\n\u003Ca href=\"https://chat.qwenlm.ai/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/%F0%9F%92%9C%EF%B8%8F%20Qwen%20Chat%20-536af5\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n\u003C/a\u003E\n\n## Introduction\n\nQwen2.5-Coder is the latest series of Code-Specific Qwen large language models (formerly known as CodeQwen). As of now, Qwen2.5-Coder has covered six mainstream model sizes, 0.5, 1.5, 3, 7, 14, 32 billion parameters, to meet the needs of different developers. Qwen2.5-Coder brings the following improvements upon CodeQwen1.5:\n\n- Significantly improvements in **code generation**, **code reasoning** and **code fixing**. Base on the strong Qwen2.5, we scale up the training tokens into 5.5 trillion including source code, text-code grounding, Synthetic data, etc. Qwen2.5-Coder-32B has become the current state-of-the-art open-source codeLLM, with its coding abilities matching those of GPT-4o.\n- A more comprehensive foundation for real-world applications such as **Code Agents**. Not only enhancing coding capabilities but also maintaining its strengths in mathematics and general competencies.\n- **Long-context Support** up to 128K tokens.\n\n**This repo contains the instruction-tuned 32B Qwen2.5-Coder model**, which has the following features:\n- Type: Causal Language Models\n- Training Stage: Pretraining & Post-training\n- Architecture: transformers with RoPE, SwiGLU, RMSNorm, and Attention QKV bias\n- Number of Parameters: 32.5B\n- Number of Paramaters (Non-Embedding): 31.0B\n- Number of Layers: 64\n- Number of Attention Heads (GQA): 40 for Q and 8 for KV\n- Context Length: Full 131,072 tokens\n  - Please refer to [this section](https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct/raw/main/#processing-long-texts) for detailed instructions on how to deploy Qwen2.5 for handling long texts.\n  \nFor more details, please refer to our [blog](https://qwenlm.github.io/blog/qwen2.5-coder-family/), [GitHub](https://github.com/QwenLM/Qwen2.5-Coder), [Documentation](https://qwen.readthedocs.io/en/latest/), [Arxiv](https://arxiv.org/abs/2409.12186).\n\n## Requirements\n\nThe code of Qwen2.5-Coder has been in the latest Hugging face `transformers` and we advise you to use the latest version of `transformers`.\n\nWith `transformers\u003C4.37.0`, you will encounter the following error:\n```\nKeyError: 'qwen2'\n```\n\n## Quickstart\n\nHere provides a code snippet with `apply_chat_template` to show you how to load the tokenizer and model and how to generate contents.\n\n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"Qwen/Qwen2.5-Coder-32B-Instruct\"\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=\"auto\",\n    device_map=\"auto\"\n)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nprompt = \"write a quick sort algorithm.\"\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": prompt}\n]\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True\n)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=512\n)\ngenerated_ids = [\n    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n]\n\nresponse = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n```\n\n### Processing Long Texts\n\nThe current `config.json` is set for context length up to 32,768 tokens.\nTo handle extensive inputs exceeding 32,768 tokens, we utilize [YaRN](https://arxiv.org/abs/2309.00071), a technique for enhancing model length extrapolation, ensuring optimal performance on lengthy texts.\n\nFor supported frameworks, you could add the following to `config.json` to enable YaRN:\n```json\n{\n  ...,\n  \"rope_scaling\": {\n    \"factor\": 4.0,\n    \"original_max_position_embeddings\": 32768,\n    \"type\": \"yarn\"\n  }\n}\n```\n\nFor deployment, we recommend using vLLM. \nPlease refer to our [Documentation](https://qwen.readthedocs.io/en/latest/deployment/vllm.html) for usage if you are not familar with vLLM.\nPresently, vLLM only supports static YARN, which means the scaling factor remains constant regardless of input length, **potentially impacting performance on shorter texts**. \nWe advise adding the `rope_scaling` configuration only when processing long contexts is required.\n\n## Evaluation & Performance\n\nDetailed evaluation results are reported in this [ğŸ“‘ blog](https://qwenlm.github.io/blog/qwen2.5-coder-family/).\n\nFor requirements on GPU memory and the respective throughput, see results [here](https://qwen.readthedocs.io/en/latest/benchmark/speed_benchmark.html).\n\n## Citation\n\nIf you find our work helpful, feel free to give us a cite.\n\n```\n@article{hui2024qwen2,\n      title={Qwen2. 5-Coder Technical Report},\n      author={Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Dang, Kai and others},\n      journal={arXiv preprint arXiv:2409.12186},\n      year={2024}\n}\n@article{qwen2,\n      title={Qwen2 Technical Report}, \n      author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhihao Fan},\n      journal={arXiv preprint arXiv:2407.10671},\n      year={2024}\n}\n```\n",
      "public": true,
      "version": "b8dd6b50-48e4-592b-9262-cd923b7e3233",
      "tool_description": null,
      "slug": "chutes-qwen-qwen2-5-coder-32b-instruct",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-02-08T13:11:42.322621Z",
      "updated_at": "2025-10-09T19:40:02.338205Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200",
          "h100",
          "h100_sxm",
          "h800"
        ],
        "gpu_count": 2,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.666666666666667,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm",
          "h800"
        ]
      },
      "invocation_count": 37413,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.16,
            "tao": 0.000397363394536402
          }
        },
        "usd": {
          "hour": 3,
          "second": 0.000833333333333333
        },
        "tao": {
          "hour": 0.00745056364755754,
          "second": 0.00000206960101321
        }
      },
      "instances": [
        {
          "instance_id": "33a8368f-57ab-4c9c-a449-50deda91a391",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:07:24.215296Z"
        },
        {
          "instance_id": "7981646a-d1e6-497b-a5e6-5225b929a6b9",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:07:24.215296Z"
        },
        {
          "instance_id": "9f6b5289-c909-4b6e-8f3c-ec9ec7e998f0",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:07:24.215296Z"
        },
        {
          "instance_id": "37906a60-e18e-4b05-a681-278557a6915d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:07:24.215296Z"
        },
        {
          "instance_id": "2a6ae2c5-2374-4d31-8581-560cb6e8a8f4",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:07:24.215296Z"
        }
      ],
      "logo_id": "6004876b-c60f-4391-9b5c-5127f8325ca5",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "381fc969f78efac66bc87ff7ddeadb7e73c218a7",
      "concurrency": 32,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/6004876b-c60f-4391-9b5c-5127f8325ca5.webp",
      "hot": true
    },
    {
      "chute_id": "722df757-203b-58df-b54b-22130fd1fc53",
      "name": "deepseek-ai/DeepSeek-V3.2-Exp",
      "tagline": "DeepSeek-V3.2-Exp is a 671B parameter experimental language model that uses sparse attention mechanisms to efficiently handle long-context scenarios while maintaining performance comparable to its predecessor across reasoning, coding, and tool use tasks.",
      "readme": "# DeepSeek-V3.2-Exp\n\n\u003C!-- markdownlint-disable first-line-h1 --\u003E\n\u003C!-- markdownlint-disable html --\u003E\n\u003C!-- markdownlint-disable no-duplicate-header --\u003E\n\n\u003Cdiv align=\"center\"\u003E\n  \u003Cimg src=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/logo.svg?raw=true\" width=\"60%\" alt=\"DeepSeek-V3\" /\u003E\n\u003C/div\u003E\n\u003Chr\u003E\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\n  \u003Ca href=\"https://www.deepseek.com/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Homepage\" src=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/badge.svg?raw=true\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://chat.deepseek.com/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/ğŸ¤–%20Chat-DeepSeek%20V3-536af5?color=536af5&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://huggingface.co/deepseek-ai\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Hugging Face\" src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\n  \u003Ca href=\"https://discord.gg/Tc7c45Zzu5\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Discord\" src=\"https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&logoColor=white&color=7289da\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/qr.jpeg?raw=true\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Wechat\" src=\"https://img.shields.io/badge/WeChat-DeepSeek%20AI-brightgreen?logo=wechat&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n  \u003Ca href=\"https://twitter.com/deepseek_ai\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Twitter Follow\" src=\"https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\u003Cdiv align=\"center\" style=\"line-height: 1;\"\u003E\n  \u003Ca href=\"LICENSE\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"License\" src=\"https://img.shields.io/badge/License-MIT-f5de53?&color=f5de53\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n  \u003C/a\u003E\n\u003C/div\u003E\n\n## Introduction\n\n\nWe are excited to announce the official release of DeepSeek-V3.2-Exp, an experimental version of our model. As an intermediate step toward our next-generation architecture, V3.2-Exp builds upon V3.1-Terminus by introducing DeepSeek Sparse Attentionâ€”a sparse attention mechanism designed to explore and validate optimizations for training and inference efficiency in long-context scenarios.\n\nThis experimental release represents our ongoing research into more efficient transformer architectures, particularly focusing on improving computational efficiency when processing extended text sequences.\n\n\u003Cdiv align=\"center\"\u003E\n \u003Cimg src=\"assets/cost.png\" \u003E\n\u003C/div\u003E\n\n- DeepSeek Sparse Attention (DSA) achieves fine-grained sparse attention for the first time, delivering substantial improvements in long-context training and inference efficiency while maintaining virtually identical model output quality.\n\n\n- To rigorously evaluate the impact of introducing sparse attention, we deliberately aligned the training configurations of DeepSeek-V3.2-Exp with V3.1-Terminus. Across public benchmarks in various domains, DeepSeek-V3.2-Exp demonstrates performance on par with V3.1-Terminus.\n\n\n| Benchmark | DeepSeek-V3.1-Terminus | DeepSeek-V3.2-Exp |\n| :--- | :---: | :---: |\n| **Reasoning Mode w/o Tool Use** | | |\n| MMLU-Pro | 85.0 | 85.0 |\n| GPQA-Diamond | 80.7 | 79.9 |\n| Humanity's Last Exam | 21.7 | 19.8 |\n| LiveCodeBench | 74.9 | 74.1 |\n| AIME 2025 | 88.4 | 89.3 |\n| HMMT 2025 | 86.1 | 83.6 |\n| Codeforces | 2046 | 2121 |\n| Aider-Polyglot | 76.1 | 74.5 |\n| **Agentic Tool Use** | | |\n| BrowseComp | 38.5 | 40.1 |\n| BrowseComp-zh | 45.0 | 47.9 |\n| SimpleQA | 96.8 | 97.1 |\n| SWE Verified | 68.4 | 67.8 |\n| SWE-bench Multilingual | 57.8 | 57.9 |\n| Terminal-bench | 36.7 | 37.7 |\n\n\n\n## How to Run Locally\n\n### HuggingFace\n\nWe provide an updated inference demo code in the [inference](https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Exp/tree/main/inference) folder to help the community quickly get started with our model and understand its architectural details.\n\nFirst convert huggingface model weights to the the format required by our inference demo. Set `MP` to match your available GPU count:\n```bash\ncd inference\nexport EXPERTS=256\npython convert.py --hf-ckpt-path ${HF_CKPT_PATH} --save-path ${SAVE_PATH} --n-experts ${EXPERTS} --model-parallel ${MP}\n```\n\nLaunch the interactive chat interface and start exploring DeepSeek's capabilities:\n```bash\nexport CONFIG=config_671B_v3.2.json\ntorchrun --nproc-per-node ${MP} generate.py --ckpt-path ${SAVE_PATH} --config ${CONFIG} --interactive\n```\n\n### SGLang\n\n#### Installation with Docker\n\n```\n# H200\ndocker pull lmsysorg/sglang:dsv32\n\n# MI350\ndocker pull lmsysorg/sglang:dsv32-rocm\n\n# NPUs\ndocker pull lmsysorg/sglang:dsv32-a2\ndocker pull lmsysorg/sglang:dsv32-a3\n```\n\n#### Launch Command\n```bash\npython -m sglang.launch_server --model deepseek-ai/DeepSeek-V3.2-Exp --tp 8 --dp 8 --enable-dp-attention\n```\n\n### vLLM\n\nvLLM provides day-0 support of DeepSeek-V3.2-Exp. See the [recipes](https://docs.vllm.ai/projects/recipes/en/latest/DeepSeek/DeepSeek-V3_2-Exp.html) for up-to-date details.\n\n## Open-Source Kernels\n\nFor TileLang kernels with **better readability and research-purpose design**, please refer to [TileLang](https://github.com/tile-ai/tilelang/tree/main/examples/deepseek_v32).\n\nFor **high-performance CUDA kernels**, indexer logit kernels (including paged versions) are available in [DeepGEMM](https://github.com/deepseek-ai/DeepGEMM/pull/200). Sparse attention kernels are released in [FlashMLA](https://github.com/deepseek-ai/FlashMLA/pull/98).\n\n\n\n## License\n\nThis repository and the model weights are licensed under the [MIT License](https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Exp/raw/main/LICENSE).\n\n## Citation\n\n```\n@misc{deepseekai2024deepseekv32,\n      title={DeepSeek-V3.2-Exp: Boosting Long-Context Efficiency with DeepSeek Sparse Attention}, \n      author={DeepSeek-AI},\n      year={2025},\n}\n```\n\n## Contact\n\nIf you have any questions, please raise an issue or contact us at [service@deepseek.com](https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Exp/raw/main/service@deepseek.com).",
      "public": true,
      "version": "003e1a66-d938-5864-8ab1-801dc038a63b",
      "tool_description": null,
      "slug": "chutes-deepseek-ai-deepseek-v3-2-exp",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-10-01T15:36:47.186980Z",
      "updated_at": "2025-10-14T10:03:18.007261Z",
      "image": {
        "image_id": "1f7f2f45-9b11-594f-897c-d05c4f1727b6",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101300",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-13T17:42:41.772428Z",
        "build_started_at": "2025-10-13T17:42:45.733512Z",
        "build_completed_at": "2025-10-13T18:17:43.202213Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "initial",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 34748,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.25,
            "tao": 0.000620880303963128
          },
          "output": {
            "usd": 0.35,
            "tao": 0.00086923242554838
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "26b2b094-0c15-467f-b9e2-3eb52f492244",
          "region": "n/a",
          "active": false,
          "verified": false,
          "last_verified_at": null
        },
        {
          "instance_id": "d362bd97-b9dd-4888-8d9b-2eed31508481",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T10:53:08.057856Z"
        },
        {
          "instance_id": "9f8bfa3f-9713-4dd6-8897-6b0e6e39975a",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:38:18.167370Z"
        }
      ],
      "logo_id": "66f78c98-1357-41fc-8d16-24dd5a06cbdc",
      "openrouter": false,
      "chutes_version": "0.3.39.rc0",
      "revision": "0770bf3bfff269270741a88ae2936f48691afaad",
      "concurrency": 64,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/66f78c98-1357-41fc-8d16-24dd5a06cbdc.webp",
      "hot": true
    },
    {
      "chute_id": "e3653034-9f58-5cf6-84f8-d5555e55fbd6",
      "name": "chutesai/Mistral-Small-3.1-24B-Instruct-2503",
      "tagline": "Mistral Small 3.1 is a 24B parameter open-source LLM with vision capabilities and 128k context that excels at reasoning, programming, and multilingual tasks while being compact enough to run on consumer hardware.",
      "readme": "\n# Model Card for Mistral-Small-3.1-24B-Instruct-2503\n\nBuilding upon Mistral Small 3 (2501), Mistral Small 3.1 (2503) **adds state-of-the-art vision understanding** and enhances **long context capabilities up to 128k tokens** without compromising text performance. \nWith 24 billion parameters, this model achieves top-tier capabilities in both text and vision tasks.  \nThis model is an instruction-finetuned version of: [Mistral-Small-3.1-24B-Base-2503](https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Base-2503).\n\nMistral Small 3.1 can be deployed locally and is exceptionally \"knowledge-dense,\" fitting within a single RTX 4090 or a 32GB RAM MacBook once quantized.  \n\nIt is ideal for:\n- Fast-response conversational agents.\n- Low-latency function calling.\n- Subject matter experts via fine-tuning.\n- Local inference for hobbyists and organizations handling sensitive data.\n- Programming and math reasoning.\n- Long document understanding.\n- Visual understanding.\n\nFor enterprises requiring specialized capabilities (increased context, specific modalities, domain-specific knowledge, etc.), we will release commercial models beyond what Mistral AI contributes to the community.\n\nLearn more about Mistral Small 3.1 in our [blog post](https://mistral.ai/news/mistral-small-3-1/).\n\n## Key Features\n- **Vision:** Vision capabilities enable the model to analyze images and provide insights based on visual content in addition to text.\n- **Multilingual:** Supports dozens of languages, including English, French, German, Greek, Hindi, Indonesian, Italian, Japanese, Korean, Malay, Nepali, Polish, Portuguese, Romanian, Russian, Serbian, Spanish, Swedish, Turkish, Ukrainian, Vietnamese, Arabic, Bengali, Chinese, Farsi.\n- **Agent-Centric:** Offers best-in-class agentic capabilities with native function calling and JSON outputting.\n- **Advanced Reasoning:** State-of-the-art conversational and reasoning capabilities.\n- **Apache 2.0 License:** Open license allowing usage and modification for both commercial and non-commercial purposes.\n- **Context Window:** A 128k context window.\n- **System Prompt:** Maintains strong adherence and support for system prompts.\n- **Tokenizer:** Utilizes a Tekken tokenizer with a 131k vocabulary size.\n\n## Benchmark Results\n\nWhen available, we report numbers previously published by other model providers, otherwise we re-evaluate them using our own evaluation harness.\n\n### Pretrain Evals\n\n| Model                          | MMLU (5-shot) | MMLU Pro (5-shot CoT) | TriviaQA   | GPQA Main (5-shot CoT)| MMMU      |\n|--------------------------------|---------------|-----------------------|------------|-----------------------|-----------|\n| **Small 3.1 24B Base**         | **81.01%**    | **56.03%**            | 80.50%     | **37.50%**            | **59.27%**|\n| Gemma 3 27B PT                 | 78.60%        | 52.20%                | **81.30%** | 24.30%                | 56.10%    |\n\n### Instruction Evals\n\n#### Text\n\n| Model                          | MMLU      | MMLU Pro (5-shot CoT) | MATH                   | GPQA Main (5-shot CoT) | GPQA Diamond (5-shot CoT )| MBPP      | HumanEval | SimpleQA (TotalAcc)|\n|--------------------------------|-----------|-----------------------|------------------------|------------------------|---------------------------|-----------|-----------|--------------------|\n| **Small 3.1 24B Instruct**     | 80.62%    | 66.76%                | 69.30%                 | **44.42%**             | **45.96%**                | 74.71%    | **88.41%**| **10.43%**         |\n| Gemma 3 27B IT                 | 76.90%    | **67.50%**            | **89.00%**             | 36.83%                 | 42.40%                    | 74.40%    | 87.80%    | 10.00%             |\n| GPT4o Mini                     | **82.00%**| 61.70%                | 70.20%                 | 40.20%                 | 39.39%                    | 84.82%    | 87.20%    | 9.50%              |\n| Claude 3.5 Haiku               | 77.60%    | 65.00%                | 69.20%                 | 37.05%                 | 41.60%                    | **85.60%**| 88.10%    | 8.02%              |\n| Cohere Aya-Vision 32B          | 72.14%    | 47.16%                | 41.98%                 | 34.38%                 | 33.84%                    | 70.43%    | 62.20%    | 7.65%              |\n\n#### Vision\n\n| Model                          | MMMU       | MMMU PRO  | Mathvista | ChartQA   | DocVQA    | AI2D        | MM MT Bench |\n|--------------------------------|------------|-----------|-----------|-----------|-----------|-------------|-------------|\n| **Small 3.1 24B Instruct**     | 64.00%     | **49.25%**| **68.91%**| 86.24%    | **94.08%**| **93.72%**  | **7.3**     |\n| Gemma 3 27B IT                 | **64.90%** | 48.38%    | 67.60%    | 76.00%    | 86.60%    | 84.50%      | 7           |\n| GPT4o Mini                     | 59.40%     | 37.60%    | 56.70%    | 76.80%    | 86.70%    | 88.10%      | 6.6         |\n| Claude 3.5 Haiku               | 60.50%     | 45.03%    | 61.60%    | **87.20%**| 90.00%    | 92.10%      | 6.5         |\n| Cohere Aya-Vision 32B          | 48.20%     | 31.50%    | 50.10%    | 63.04%    | 72.40%    | 82.57%      | 4.1         |\n\n### Multilingual Evals\n\n| Model                          | Average    | European   | East Asian | Middle Eastern |\n|--------------------------------|------------|------------|------------|----------------|\n| **Small 3.1 24B Instruct**     | **71.18%** | **75.30%** | **69.17%** | 69.08%         |\n| Gemma 3 27B IT                 | 70.19%     | 74.14%     | 65.65%     | 70.76%         |\n| GPT4o Mini                     | 70.36%     | 74.21%     | 65.96%     | **70.90%**     |\n| Claude 3.5 Haiku               | 70.16%     | 73.45%     | 67.05%     | 70.00%         |\n| Cohere Aya-Vision 32B          | 62.15%     | 64.70%     | 57.61%     | 64.12%         |\n\n### Long Context Evals\n\n| Model                          | LongBench v2    | RULER 32K   | RULER 128K |\n|--------------------------------|-----------------|-------------|------------|\n| **Small 3.1 24B Instruct**     | **37.18%**      | **93.96%**  | 81.20%     |\n| Gemma 3 27B IT                 | 34.59%          | 91.10%      | 66.00%     |\n| GPT4o Mini                     | 29.30%          | 90.20%      | 65.8%      |\n| Claude 3.5 Haiku               | 35.19%          | 92.60%      | **91.90%** |\n\n## Basic Instruct Template (V7-Tekken)\n\n```\n\u003Cs\u003E[SYSTEM_PROMPT]\u003Csystem prompt\u003E[/SYSTEM_PROMPT][INST]\u003Cuser message\u003E[/INST]\u003Cassistant response\u003E\u003C/s\u003E[INST]\u003Cuser message\u003E[/INST]\n```\n*`\u003Csystem_prompt\u003E`, `\u003Cuser message\u003E` and `\u003Cassistant response\u003E` are placeholders.*\n\n***Please make sure to use [mistral-common](https://github.com/mistralai/mistral-common) as the source of truth***\n\n## Usage\n\nThe model can be used with the following frameworks;\n- [`vllm (recommended)`](https://github.com/vllm-project/vllm): See [here](https://huggingface.co/chutesai/Mistral-Small-3.1-24B-Instruct-2503/raw/main/#vllm)\n\n**Note 1**: We recommend using a relatively low temperature, such as `temperature=0.15`.\n\n**Note 2**: Make sure to add a system prompt to the model to best tailer it for your needs. If you want to use the model as a general assistant, we recommend the following \nsystem prompt:\n\n```\nsystem_prompt = \"\"\"You are Mistral Small 3.1, a Large Language Model (LLM) created by Mistral AI, a French startup headquartered in Paris.\nYou power an AI assistant called Le Chat.\nYour knowledge base was last updated on 2023-10-01.\nThe current date is {today}.\n\nWhen you're not sure about some information, you say that you don't have the information and don't make up anything.\nIf the user's question is not clear, ambiguous, or does not provide enough context for you to accurately answer the question, you do not try to answer it right away and you rather ask the user to clarify their request (e.g. \"What are some good restaurants around me?\" =\u003E \"Where are you?\" or \"When is the next flight to Tokyo\" =\u003E \"Where do you travel from?\").\nYou are always very attentive to dates, in particular you try to resolve dates (e.g. \"yesterday\" is {yesterday}) and when asked about information at specific dates, you discard information that is at another date.\nYou follow these instructions in all languages, and always respond to the user in the language they use or request.\nNext sections describe the capabilities that you have.\n\n# WEB BROWSING INSTRUCTIONS\n\nYou cannot perform any web search or access internet to open URLs, links etc. If it seems like the user is expecting you to do so, you clarify the situation and ask the user to copy paste the text directly in the chat.\n\n# MULTI-MODAL INSTRUCTIONS\n\nYou have the ability to read images, but you cannot generate images. You also cannot transcribe audio files or videos.\nYou cannot read nor transcribe audio files or videos.\"\"\"\n```\n\n### vLLM (recommended)\n\nWe recommend using this model with the [vLLM library](https://github.com/vllm-project/vllm)\nto implement production-ready inference pipelines.\n\n**_Installation_**\n\nMake sure you install [`vLLM \u003E= 0.8.1`](https://github.com/vllm-project/vllm/releases/tag/v0.8.1):\n\n```\npip install vllm --upgrade\n```\n\nDoing so should automatically install [`mistral_common \u003E= 1.5.4`](https://github.com/mistralai/mistral-common/releases/tag/v1.5.4).\n\nTo check:\n```\npython -c \"import mistral_common; print(mistral_common.__version__)\"\n```\n\nYou can also make use of a ready-to-go [docker image](https://github.com/vllm-project/vllm/blob/main/Dockerfile) or on the [docker hub](https://hub.docker.com/layers/vllm/vllm-openai/latest/images/sha256-de9032a92ffea7b5c007dad80b38fd44aac11eddc31c435f8e52f3b7404bbf39).\n\n#### Server\n\nWe recommand that you use Mistral-Small-3.1-24B-Instruct-2503 in a server/client setting. \n\n1. Spin up a server:\n\n```\nvllm serve mistralai/Mistral-Small-3.1-24B-Instruct-2503 --tokenizer_mode mistral --config_format mistral --load_format mistral --tool-call-parser mistral --enable-auto-tool-choice --limit_mm_per_prompt 'image=10' --tensor-parallel-size 2\n```\n\n**Note:** Running Mistral-Small-3.1-24B-Instruct-2503 on GPU requires ~55 GB of GPU RAM in bf16 or fp16. \n\n\n2. To ping the client you can use a simple Python snippet.\n\n```py\nimport requests\nimport json\nfrom huggingface_hub import hf_hub_download\nfrom datetime import datetime, timedelta\n\nurl = \"http://\u003Cyour-server-url\u003E:8000/v1/chat/completions\"\nheaders = {\"Content-Type\": \"application/json\", \"Authorization\": \"Bearer token\"}\n\nmodel = \"mistralai/Mistral-Small-3.1-24B-Instruct-2503\"\n\n\ndef load_system_prompt(repo_id: str, filename: str) -\u003E str:\n    file_path = hf_hub_download(repo_id=repo_id, filename=filename)\n    with open(file_path, \"r\") as file:\n        system_prompt = file.read()\n    today = datetime.today().strftime(\"%Y-%m-%d\")\n    yesterday = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n    model_name = repo_id.split(\"/\")[-1]\n    return system_prompt.format(name=model_name, today=today, yesterday=yesterday)\n\n\nSYSTEM_PROMPT = load_system_prompt(model, \"SYSTEM_PROMPT.txt\")\n\nimage_url = \"https://huggingface.co/datasets/patrickvonplaten/random_img/resolve/main/europe.png\"\n\nmessages = [\n    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"text\",\n                \"text\": \"Which of the depicted countries has the best food? Which the second and third and fourth? Name the country, its color on the map and one its city that is visible on the map, but is not the capital. Make absolutely sure to only name a city that can be seen on the map.\",\n            },\n            {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n        ],\n    },\n]\n\ndata = {\"model\": model, \"messages\": messages, \"temperature\": 0.15}\n\nresponse = requests.post(url, headers=headers, data=json.dumps(data))\nprint(response.json()[\"choices\"][0][\"message\"][\"content\"])\n# Determining the \"best\" food is highly subjective and depends on personal preferences. However, based on general popularity and recognition, here are some countries known for their cuisine:\n\n# 1. **Italy** - Color: Light Green - City: Milan\n#    - Italian cuisine is renowned worldwide for its pasta, pizza, and various regional specialties.\n\n# 2. **France** - Color: Brown - City: Lyon\n#    - French cuisine is celebrated for its sophistication, including dishes like coq au vin, bouillabaisse, and pastries like croissants and Ã©clairs.\n\n# 3. **Spain** - Color: Yellow - City: Bilbao\n#    - Spanish cuisine offers a variety of flavors, from paella and tapas to jamÃ³n ibÃ©rico and churros.\n\n# 4. **Greece** - Not visible on the map\n#    - Greek cuisine is known for dishes like moussaka, souvlaki, and baklava. Unfortunately, Greece is not visible on the provided map, so I cannot name a city.\n\n# Since Greece is not visible on the map, I'll replace it with another country known for its good food:\n\n# 4. **Turkey** - Color: Light Green (east part of the map) - City: Istanbul\n#    - Turkish cuisine is diverse and includes dishes like kebabs, meze, and baklava.\n```\n\n### Function calling\n\nMistral-Small-3.1-24-Instruct-2503 is excellent at function / tool calling tasks via vLLM. *E.g.:*\n\n\u003Cdetails\u003E\n  \u003Csummary\u003EExample\u003C/summary\u003E\n\n```py\nimport requests\nimport json\nfrom huggingface_hub import hf_hub_download\nfrom datetime import datetime, timedelta\n\nurl = \"http://\u003Cyour-url\u003E:8000/v1/chat/completions\"\nheaders = {\"Content-Type\": \"application/json\", \"Authorization\": \"Bearer token\"}\n\nmodel = \"mistralai/Mistral-Small-3.1-24B-Instruct-2503\"\n\n\ndef load_system_prompt(repo_id: str, filename: str) -\u003E str:\n    file_path = hf_hub_download(repo_id=repo_id, filename=filename)\n    with open(file_path, \"r\") as file:\n        system_prompt = file.read()\n    today = datetime.today().strftime(\"%Y-%m-%d\")\n    yesterday = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n    model_name = repo_id.split(\"/\")[-1]\n    return system_prompt.format(name=model_name, today=today, yesterday=yesterday)\n\n\nSYSTEM_PROMPT = load_system_prompt(model, \"SYSTEM_PROMPT.txt\")\n\n\ntools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_current_weather\",\n            \"description\": \"Get the current weather in a given location\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"city\": {\n                        \"type\": \"string\",\n                        \"description\": \"The city to find the weather for, e.g. 'San Francisco'\",\n                    },\n                    \"state\": {\n                        \"type\": \"string\",\n                        \"description\": \"The state abbreviation, e.g. 'CA' for California\",\n                    },\n                    \"unit\": {\n                        \"type\": \"string\",\n                        \"description\": \"The unit for temperature\",\n                        \"enum\": [\"celsius\", \"fahrenheit\"],\n                    },\n                },\n                \"required\": [\"city\", \"state\", \"unit\"],\n            },\n        },\n    },\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"rewrite\",\n            \"description\": \"Rewrite a given text for improved clarity\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"text\": {\n                        \"type\": \"string\",\n                        \"description\": \"The input text to rewrite\",\n                    }\n                },\n            },\n        },\n    },\n]\n\nmessages = [\n    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n    {\n        \"role\": \"user\",\n        \"content\": \"Could you please make the below article more concise?\\n\\nOpenAI is an artificial intelligence research laboratory consisting of the non-profit OpenAI Incorporated and its for-profit subsidiary corporation OpenAI Limited Partnership.\",\n    },\n    {\n        \"role\": \"assistant\",\n        \"content\": \"\",\n        \"tool_calls\": [\n            {\n                \"id\": \"bbc5b7ede\",\n                \"t",
      "public": true,
      "version": "936350d6-45c8-58ea-a60f-487c22aae6eb",
      "tool_description": null,
      "slug": "chutes-chutesai-mistral-small-3-1-24b-instruct-2503",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-03-24T00:29:32.081107Z",
      "updated_at": "2025-10-09T19:47:13.164145Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "h100",
        "h800",
        "a100_sxm",
        "l40s"
      ],
      "node_selector": {
        "exclude": [
          "5090",
          "a6000",
          "b200",
          "l40",
          "mi300x"
        ],
        "include": null,
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.888888888888889,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "h100",
          "h800",
          "a100_sxm",
          "l40s"
        ]
      },
      "invocation_count": 34494,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.05,
            "tao": 0.000124176060792625
          },
          "output": {
            "usd": 0.22,
            "tao": 0.000546374667487553
          }
        },
        "usd": {
          "hour": 4,
          "second": 0.00111111111111111
        },
        "tao": {
          "hour": 0.00993408486341006,
          "second": 0.000002759468017613
        }
      },
      "instances": [
        {
          "instance_id": "8e11d65d-6d7b-4ba8-a1b7-7c633b5a4f92",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:38:09.207843Z"
        },
        {
          "instance_id": "1e91851c-3955-4626-9813-648715405881",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:38:20.646851Z"
        },
        {
          "instance_id": "7f1e4f03-2e94-4b00-9def-1d47cb117d45",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:38:21.355599Z"
        },
        {
          "instance_id": "b7eb72ac-8ed5-4815-a545-dfdc5613cb54",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:41:14.942249Z"
        },
        {
          "instance_id": "d6fedbf9-0bd2-4282-831e-a9a32255f0e5",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:38:07.284035Z"
        }
      ],
      "logo_id": "3d5f67e8-93b1-491f-9b2a-0b791eb5fa18",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "38e9da92bb1e44b83fbfcd6ea2423e3b1f712d79",
      "concurrency": 24,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/3d5f67e8-93b1-491f-9b2a-0b791eb5fa18.webp",
      "hot": true
    },
    {
      "chute_id": "69f319a7-7f25-5cce-ae30-68b30fd5ec5d",
      "name": "zai-org/GLM-4.6-turbo",
      "tagline": "",
      "readme": "zai-org/GLM-4.6-FP8",
      "public": true,
      "version": "12925a01-caa2-584e-bef1-a3b863405d5a",
      "tool_description": null,
      "slug": "chutes-zai-org-glm-4-6-turbo",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "9821e394-028a-5870-a29d-d29d32ac464c",
      "created_at": "2025-10-03T15:08:41.063402Z",
      "updated_at": "2025-10-19T13:30:53.454064Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 34177,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 1.15,
            "tao": 0.00285604939823039
          },
          "output": {
            "usd": 3.25,
            "tao": 0.00807144395152067
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "ed27de6c-ddda-4026-ae20-11c68af77683",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:37:28.289066Z"
        },
        {
          "instance_id": "65bb54e9-44a0-4b6b-b4ed-6ca863b25198",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:37:28.289066Z"
        },
        {
          "instance_id": "b9321a9c-e8d8-4481-b6bd-de9adb9db05e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:37:28.289066Z"
        },
        {
          "instance_id": "ff5fe7e5-85b8-491b-b33d-0f74ebb4b552",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:37:28.289066Z"
        }
      ],
      "logo_id": "e65e7e75-9f40-4230-97ee-ee8b070457c5",
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "c064d336a8d0b0f59071f77eafdcdfca40f4b54c",
      "concurrency": 24,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/e65e7e75-9f40-4230-97ee-ee8b070457c5.webp",
      "hot": true
    },
    {
      "chute_id": "16f41e4f-f2ca-5580-a0a6-46727ae4c212",
      "name": "unsloth/gemma-3-27b-it",
      "tagline": "Gemma 3 is an open-source multimodal model available in 1B, 4B, 12B, and 27B parameter sizes that can process both text and images with a 128K context window, making it suitable for tasks like question answering, summarization, code generation, and image analysis while being efficient enough to run on consumer hardware.",
      "readme": "\u003Cdiv\u003E\n  \u003Cp style=\"margin-bottom: 0; margin-top: 0;\"\u003E\n    \u003Cstrong\u003ESee \u003Ca href=\"https://huggingface.co/collections/unsloth/gemma-3-67d12b7e8816ec6efa7e4e5b\"\u003Eour collection\u003C/a\u003E for all versions of Gemma 3 including GGUF, 4-bit & 16-bit formats.\u003C/strong\u003E\n  \u003C/p\u003E\n  \u003Cp style=\"margin-bottom: 0;\"\u003E\n    \u003Cem\u003E\u003Ca href=\"https://docs.unsloth.ai/basics/tutorial-how-to-run-gemma-3-effectively\"\u003ERead our Guide\u003C/a\u003E to see how to Run Gemma 3 correctly.\u003C/em\u003E\n  \u003C/p\u003E\n  \u003Cdiv style=\"display: flex; gap: 5px; align-items: center; \"\u003E\n    \u003Ca href=\"https://github.com/unslothai/unsloth/\"\u003E\n      \u003Cimg src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"133\"\u003E\n    \u003C/a\u003E\n    \u003Ca href=\"https://discord.gg/unsloth\"\u003E\n      \u003Cimg src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord%20button.png\" width=\"173\"\u003E\n    \u003C/a\u003E\n    \u003Ca href=\"https://docs.unsloth.ai/basics/tutorial-how-to-run-deepseek-r1-on-your-own-local-device\"\u003E\n      \u003Cimg src=\"https://raw.githubusercontent.com/unslothai/unsloth/refs/heads/main/images/documentation%20green%20button.png\" width=\"143\"\u003E\n    \u003C/a\u003E\n  \u003C/div\u003E\n\u003Ch1 style=\"margin-top: 0rem;\"\u003Eâœ¨ Fine-tune Gemma 3 with Unsloth!\u003C/h1\u003E\n\u003C/div\u003E\n\n- Fine-tune Gemma 3 (12B) for free using our Google [Colab notebook here](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n- Read our Blog about Gemma 3 support: [unsloth.ai/blog/gemma3](https://unsloth.ai/blog/gemma3)\n- View the rest of our notebooks in our [docs here](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n- Export your fine-tuned model to GGUF, Ollama, llama.cpp or ğŸ¤—HF.\n\n| Unsloth supports          |    Free Notebooks                                                                                           | Performance | Memory use |\n|-----------------|--------------------------------------------------------------------------------------------------------------------------|-------------|----------|\n| **GRPO with Gemma 3 (12B)**      | [â–¶ï¸ Start on Colab](https://docs.unsloth.ai/get-started/unsloth-notebooks)               | 2x faster | 80% less |\n| **Llama-3.2 (3B)**      | [â–¶ï¸ Start on Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb)               | 2.4x faster | 58% less |\n| **Llama-3.2 (11B vision)**      | [â–¶ï¸ Start on Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)               | 2x faster | 60% less |\n| **Qwen2.5 (7B)**      | [â–¶ï¸ Start on Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2.5_(7B)-Alpaca.ipynb)               | 2x faster | 60% less |\n| **Phi-4 (14B)** | [â–¶ï¸ Start on Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4-Conversational.ipynb)               | 2x faster | 50% less |\n| **Mistral (7B)**    | [â–¶ï¸ Start on Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_v0.3_(7B)-Conversational.ipynb)               | 2.2x faster | 62% less |\n\n\u003Cbr\u003E\n\n# Gemma 3 model card\n\n**Model Page**: [Gemma](https://ai.google.dev/gemma/docs/core)\n\n**Resources and Technical Documentation**:\n\n* [Gemma 3 Technical Report][g3-tech-report]\n* [Responsible Generative AI Toolkit][rai-toolkit]\n* [Gemma on Kaggle][kaggle-gemma]\n* [Gemma on Vertex Model Garden][vertex-mg-gemma3]\n\n**Terms of Use**: [Terms][terms]\n\n**Authors**: Google DeepMind\n\n## Model Information\n\nSummary description and brief definition of inputs and outputs.\n\n### Description\n\nGemma is a family of lightweight, state-of-the-art open models from Google,\nbuilt from the same research and technology used to create the Gemini models.\nGemma 3 models are multimodal, handling text and image input and generating text\noutput, with open weights for both pre-trained variants and instruction-tuned\nvariants. Gemma 3 has a large, 128K context window, multilingual support in over\n140 languages, and is available in more sizes than previous versions. Gemma 3\nmodels are well-suited for a variety of text generation and image understanding\ntasks, including question answering, summarization, and reasoning. Their\nrelatively small size makes it possible to deploy them in environments with\nlimited resources such as laptops, desktops or your own cloud infrastructure,\ndemocratizing access to state of the art AI models and helping foster innovation\nfor everyone.\n\n### Inputs and outputs\n\n-   **Input:**\n    -  Text string, such as a question, a prompt, or a document to be summarized\n    -  Images, normalized to 896 x 896 resolution and encoded to 256 tokens\n       each\n    -  Total input context of 128K tokens for the 4B, 12B, and 27B sizes, and\n       32K tokens for the 1B size\n\n-   **Output:**\n    -   Generated text in response to the input, such as an answer to a\n        question, analysis of image content, or a summary of a document\n    -   Total output context of 8192 tokens\n\n### Citation\n\n```none\n@article{gemma_2025,\n    title={Gemma 3},\n    url={https://goo.gle/Gemma3Report},\n    publisher={Kaggle},\n    author={Gemma Team},\n    year={2025}\n}\n```\n\n## Model Data\n\nData used for model training and how the data was processed.\n\n### Training Dataset\n\nThese models were trained on a dataset of text data that includes a wide variety\nof sources. The 27B model was trained with 14 trillion tokens, the 12B model was\ntrained with 12 trillion tokens, 4B model was trained with 4 trillion tokens and\n1B with 2 trillion tokens. Here are the key components:\n\n-   Web Documents: A diverse collection of web text ensures the model is\n    exposed to a broad range of linguistic styles, topics, and vocabulary. The\n    training dataset includes content in over 140 languages.\n-   Code: Exposing the model to code helps it to learn the syntax and\n    patterns of programming languages, which improves its ability to generate\n    code and understand code-related questions.\n-   Mathematics: Training on mathematical text helps the model learn logical\n    reasoning, symbolic representation, and to address mathematical queries.\n-   Images: A wide range of images enables the model to perform image\n    analysis and visual data extraction tasks.\n\nThe combination of these diverse data sources is crucial for training a powerful\nmultimodal model that can handle a wide variety of different tasks and data\nformats.\n\n### Data Preprocessing\n\nHere are the key data cleaning and filtering methods applied to the training\ndata:\n\n-   CSAM Filtering: Rigorous CSAM (Child Sexual Abuse Material) filtering\n    was applied at multiple stages in the data preparation process to ensure\n    the exclusion of harmful and illegal content.\n-   Sensitive Data Filtering: As part of making Gemma pre-trained models\n    safe and reliable, automated techniques were used to filter out certain\n    personal information and other sensitive data from training sets.\n-   Additional methods: Filtering based on content quality and safety in\n    line with [our policies][safety-policies].\n\n## Implementation Information\n\nDetails about the model internals.\n\n### Hardware\n\nGemma was trained using [Tensor Processing Unit (TPU)][tpu] hardware (TPUv4p,\nTPUv5p and TPUv5e). Training vision-language models (VLMS) requires significant\ncomputational power. TPUs, designed specifically for matrix operations common in\nmachine learning, offer several advantages in this domain:\n\n-   Performance: TPUs are specifically designed to handle the massive\n    computations involved in training VLMs. They can speed up training\n    considerably compared to CPUs.\n-   Memory: TPUs often come with large amounts of high-bandwidth memory,\n    allowing for the handling of large models and batch sizes during training.\n    This can lead to better model quality.\n-   Scalability: TPU Pods (large clusters of TPUs) provide a scalable\n    solution for handling the growing complexity of large foundation models.\n    You can distribute training across multiple TPU devices for faster and more\n    efficient processing.\n-   Cost-effectiveness: In many scenarios, TPUs can provide a more\n    cost-effective solution for training large models compared to CPU-based\n    infrastructure, especially when considering the time and resources saved\n    due to faster training.\n-   These advantages are aligned with\n    [Google's commitments to operate sustainably][sustainability].\n\n### Software\n\nTraining was done using [JAX][jax] and [ML Pathways][ml-pathways].\n\nJAX allows researchers to take advantage of the latest generation of hardware,\nincluding TPUs, for faster and more efficient training of large models. ML\nPathways is Google's latest effort to build artificially intelligent systems\ncapable of generalizing across multiple tasks. This is specially suitable for\nfoundation models, including large language models like these ones.\n\nTogether, JAX and ML Pathways are used as described in the\n[paper about the Gemini family of models][gemini-2-paper]; *\"the 'single\ncontroller' programming model of Jax and Pathways allows a single Python\nprocess to orchestrate the entire training run, dramatically simplifying the\ndevelopment workflow.\"*\n\n## Evaluation\n\nModel evaluation metrics and results.\n\n### Benchmark Results\n\nThese models were evaluated against a large collection of different datasets and\nmetrics to cover different aspects of text generation:\n\n#### Reasoning and factuality\n\n| Benchmark                      | Metric         | Gemma 3 PT 1B  | Gemma 3 PT 4B | Gemma 3 PT 12B | Gemma 3 PT 27B |\n| ------------------------------ |----------------|:--------------:|:-------------:|:--------------:|:--------------:|\n| [HellaSwag][hellaswag]         | 10-shot        |      62.3      |      77.2     |      84.2      |      85.6      |\n| [BoolQ][boolq]                 | 0-shot         |      63.2      |      72.3     |      78.8      |      82.4      |\n| [PIQA][piqa]                   | 0-shot         |      73.8      |      79.6     |      81.8      |      83.3      |\n| [SocialIQA][socialiqa]         | 0-shot         |      48.9      |      51.9     |      53.4      |      54.9      |\n| [TriviaQA][triviaqa]           | 5-shot         |      39.8      |      65.8     |      78.2      |      85.5      |\n| [Natural Questions][naturalq]  | 5-shot         |      9.48      |      20.0     |      31.4      |      36.1      |\n| [ARC-c][arc]                   | 25-shot        |      38.4      |      56.2     |      68.9      |      70.6      |\n| [ARC-e][arc]                   | 0-shot         |      73.0      |      82.4     |      88.3      |      89.0      |\n| [WinoGrande][winogrande]       | 5-shot         |      58.2      |      64.7     |      74.3      |      78.8      |\n| [BIG-Bench Hard][bbh]          | few-shot       |      28.4      |      50.9     |      72.6      |      77.7      |\n| [DROP][drop]                   | 1-shot         |      42.4      |      60.1     |      72.2      |      77.2      |\n\n[hellaswag]: https://arxiv.org/abs/1905.07830\n[boolq]: https://arxiv.org/abs/1905.10044\n[piqa]: https://arxiv.org/abs/1911.11641\n[socialiqa]: https://arxiv.org/abs/1904.09728\n[triviaqa]: https://arxiv.org/abs/1705.03551\n[naturalq]: https://github.com/google-research-datasets/natural-questions\n[arc]: https://arxiv.org/abs/1911.01547\n[winogrande]: https://arxiv.org/abs/1907.10641\n[bbh]: https://paperswithcode.com/dataset/bbh\n[drop]: https://arxiv.org/abs/1903.00161\n\n#### STEM and code\n\n| Benchmark                      | Metric         | Gemma 3 PT 4B | Gemma 3 PT 12B | Gemma 3 PT 27B |\n| ------------------------------ |----------------|:-------------:|:--------------:|:--------------:|\n| [MMLU][mmlu]                   | 5-shot         |      59.6     |      74.5      |      78.6      |\n| [MMLU][mmlu] (Pro COT)         | 5-shot         |      29.2     |      45.3      |      52.2      |\n| [AGIEval][agieval]             | 3-5-shot       |      42.1     |      57.4      |      66.2      |\n| [MATH][math]                   | 4-shot         |      24.2     |      43.3      |      50.0      |\n| [GSM8K][gsm8k]                 | 8-shot         |      38.4     |      71.0      |      82.6      |\n| [GPQA][gpqa]                   | 5-shot         |      15.0     |      25.4      |      24.3      |\n| [MBPP][mbpp]                   | 3-shot         |      46.0     |      60.4      |      65.6      |\n| [HumanEval][humaneval]         | 0-shot         |      36.0     |      45.7      |      48.8      |\n\n[mmlu]: https://arxiv.org/abs/2009.03300\n[agieval]: https://arxiv.org/abs/2304.06364\n[math]: https://arxiv.org/abs/2103.03874\n[gsm8k]: https://arxiv.org/abs/2110.14168\n[gpqa]: https://arxiv.org/abs/2311.12022\n[mbpp]: https://arxiv.org/abs/2108.07732\n[humaneval]: https://arxiv.org/abs/2107.03374\n\n#### Multilingual\n\n| Benchmark                            | Gemma 3 PT 1B | Gemma 3 PT 4B | Gemma 3 PT 12B | Gemma 3 PT 27B |\n| ------------------------------------ |:-------------:|:-------------:|:--------------:|:--------------:|\n| [MGSM][mgsm]                         |      2.04     |      34.7     |      64.3     |      74.3     |\n| [Global-MMLU-Lite][global-mmlu-lite] |      24.9     |      57.0     |      69.4     |      75.7     |\n| [WMT24++][wmt24pp] (ChrF)            |      36.7     |      48.4     |      53.9     |      55.7     |\n| [FloRes][flores]                     |      29.5     |      39.2     |      46.0     |      48.8     |\n| [XQuAD][xquad] (all)                 |      43.9     |      68.0     |      74.5     |      76.8     |\n| [ECLeKTic][eclektic]                 |      4.69     |      11.0     |      17.2     |      24.4     |\n| [IndicGenBench][indicgenbench]       |      41.4     |      57.2     |      61.7     |      63.4     |\n\n[mgsm]: https://arxiv.org/abs/2210.03057\n[flores]: https://arxiv.org/abs/2106.03193\n[xquad]: https://arxiv.org/abs/1910.11856v3\n[global-mmlu-lite]: https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite\n[wmt24pp]: https://arxiv.org/abs/2502.12404v1\n[eclektic]: https://arxiv.org/abs/2502.21228\n[indicgenbench]: https://arxiv.org/abs/2404.16816\n\n#### Multimodal\n\n| Benchmark                      | Gemma 3 PT 4B | Gemma 3 PT 12B | Gemma 3 PT 27B |\n| ------------------------------ |:-------------:|:--------------:|:--------------:|\n| [COCOcap][coco-cap]            |      102      |      111       |      116       |\n| [DocVQA][docvqa] (val)         |      72.8     |      82.3      |      85.6      |\n| [InfoVQA][info-vqa] (val)      |      44.1     |      54.8      |      59.4      |\n| [MMMU][mmmu] (pt)              |      39.2     |      50.3      |      56.1      |\n| [TextVQA][textvqa] (val)       |      58.9     |      66.5      |      68.6      |\n| [RealWorldQA][realworldqa]     |      45.5     |      52.2      |      53.9      |\n| [ReMI][remi]                   |      27.3     |      38.5      |      44.8      |\n| [AI2D][ai2d]                   |      63.2     |      75.2      |      79.0      |\n| [ChartQA][chartqa]             |      63.6     |      74.7      |      76.3      |\n| [VQAv2][vqav2]                 |      63.9     |      71.2      |      72.9      |\n| [BLINK][blinkvqa]              |      38.0     |      35.9      |      39.6      |\n| [OKVQA][okvqa]                 |      51.0     |      58.7      |      60.2      |\n| [TallyQA][tallyqa]             |      42.5     |      51.8      |      54.3      |\n| [SpatialSense VQA][ss-vqa]     |      50.9     |      60.0      |      59.4      |\n| [CountBenchQA][countbenchqa]   |      26.1     |      17.8      |      68.0      |\n\n[coco-cap]: https://cocodataset.org/#home\n[docvqa]: https://www.docvqa.org/\n[info-vqa]: https://arxiv.org/abs/2104.12756\n[mmmu]: https://arxiv.org/abs/2311.16502\n[textvqa]: https://textvqa.org/\n[realworldqa]: https://paperswithcode.com/dataset/realworldqa\n[remi]: https://arxiv.org/html/2406.09175v1\n[ai2d]: https://allenai.org/data/diagrams\n[chartqa]: https://arxiv.org/abs/2203.10244\n[vqav2]: https://visualqa.org/index.html\n[blinkvqa]: https://arxiv.org/abs/2404.12390\n[okvqa]: https://okvqa.allenai",
      "public": true,
      "version": "735d6555-c38f-51ba-9dbf-eb9e150afe58",
      "tool_description": null,
      "slug": "chutes-unsloth-gemma-3-27b-it",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-03-22T13:13:59.861060Z",
      "updated_at": "2025-10-09T19:03:23.771496Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h100",
        "h100_sxm",
        "h800",
        "a100_sxm"
      ],
      "node_selector": {
        "exclude": null,
        "include": [
          "a100",
          "a100_sxm",
          "h100_nvl",
          "h100",
          "h100_sxm",
          "h800",
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 2.13333333333333,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h100",
          "h100_sxm",
          "h800",
          "a100_sxm"
        ]
      },
      "invocation_count": 29941,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.13,
            "tao": 0.000322857758060826
          },
          "output": {
            "usd": 0.52,
            "tao": 0.00129143103224331
          }
        },
        "usd": {
          "hour": 9.6,
          "second": 0.00266666666666667
        },
        "tao": {
          "hour": 0.0238418036721841,
          "second": 0.000006622723242273
        }
      },
      "instances": [
        {
          "instance_id": "820d9ba3-3210-468c-9acc-8070649afc59",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:50:19.070036Z"
        },
        {
          "instance_id": "8c77d2c9-3233-4edf-bc83-4fa9d6a88b39",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:50:19.070036Z"
        },
        {
          "instance_id": "4af34824-5cd3-40bf-b39c-ef9127e300f9",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:50:19.070036Z"
        },
        {
          "instance_id": "96a9e332-fe60-4326-9665-c01d4f7ce813",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:50:19.070036Z"
        }
      ],
      "logo_id": "8ab814ca-b937-4a4d-be68-ad98aacb3159",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "4fa1fec0f0b7675e00ae052e9aaea244f8f519b1",
      "concurrency": 16,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/8ab814ca-b937-4a4d-be68-ad98aacb3159.webp",
      "hot": true
    },
    {
      "chute_id": "0e392a49-6f77-56c4-99d6-57c06851321e",
      "name": "Alibaba-NLP/Tongyi-DeepResearch-30B-A3B",
      "tagline": "Tongyi DeepResearch is a 30B parameter language model (with 3B active parameters per token) specifically optimized for deep research and information-seeking tasks through automated data generation and reinforcement learning.",
      "readme": "\n# Introduction\n\nWe present  **Tongyi DeepResearch**, an agentic large language model featuring 30 billion total parameters, with only 3 billion activated per token. Developed by Tongyi Lab, the model is specifically designed for **long-horizon, deep information-seeking** tasks. Tongyi-DeepResearch demonstrates state-of-the-art performance across a range of agentic search benchmarks, including Humanity's Last Exam, BrowserComp, BrowserComp-ZH, WebWalkerQA, GAIA, xbench-DeepSearch and FRAMES.\n\nMore details can be found in our ğŸ“° [Tech Blog](https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research).\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/63fc4c00a3c067e62899d32b/OhQCYYJu1LhrS446Qct5D.png)\n\n## Key Features\n\n- âš™ï¸ **Fully automated synthetic data generation pipeline**: We design a highly scalable data synthesis pipeline, which is fully automatic and empowers agentic pre-training, supervised fine-tuning, and reinforcement learning.\n- ğŸ”„ **Large-scale continual pre-training on agentic data**: Leveraging diverse, high-quality agentic interaction data to extend model capabilities, maintain freshness, and strengthen reasoning performance.\n- ğŸ” **End-to-end reinforcement learning**: We employ a strictly on-policy RL approach based on a customized Group Relative Policy Optimization framework, with token-level policy gradients, leave-one-out advantage estimation, and selective filtering of negative samples to stabilize training in a nonâ€‘stationary environment.\n- ğŸ¤– **Agent Inference Paradigm Compatibility**: At inference, Tongyi-DeepResearch is compatible with two inference paradigms: ReAct, for rigorously evaluating the model's core intrinsic abilities, and an IterResearch-based 'Heavy' mode, which uses a test-time scaling strategy to unlock the model's maximum performance ceiling.\n\n## Download\n\nYou can download the model then run the inference scipts in https://github.com/Alibaba-NLP/DeepResearch.\n\n\n```bibtex\n@misc{tongyidr,\n  author={Tongyi DeepResearch Team},\n  title={Tongyi-DeepResearch},\n  year={2025},\n  howpublished={\\url{https://github.com/Alibaba-NLP/DeepResearch}}\n}\n```",
      "public": true,
      "version": "4f242c59-b8c8-5042-8809-781f0afb43f6",
      "tool_description": null,
      "slug": "chutes-alibaba-nlp-tongyi-deepresearch-30b-a3b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-09-17T10:55:14.860374Z",
      "updated_at": "2025-10-09T18:18:00.719187Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "h20",
        "h100",
        "h100_sxm",
        "h800"
      ],
      "node_selector": {
        "exclude": null,
        "include": [
          "h200",
          "h100",
          "h100_sxm",
          "h800",
          "h20"
        ],
        "gpu_count": 4,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.533333333333333,
        "supported_gpus": [
          "h200",
          "h20",
          "h100",
          "h100_sxm",
          "h800"
        ]
      },
      "invocation_count": 28754,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0,
            "tao": 0
          },
          "output": {
            "usd": 0,
            "tao": 0
          }
        },
        "usd": {
          "hour": 0,
          "second": 0
        },
        "tao": {
          "hour": 0,
          "second": 0
        }
      },
      "instances": [
        {
          "instance_id": "9aaffe41-38a7-4964-bf72-409957db57c1",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:45:48.699188Z"
        },
        {
          "instance_id": "b7525b29-4384-45a1-9ba3-21da885f5096",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:45:48.699188Z"
        },
        {
          "instance_id": "026dc91c-c922-48ef-92ee-e6e6896112d3",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:45:48.699188Z"
        },
        {
          "instance_id": "5d7d90f1-7a50-43ed-9752-4f16e3549bf2",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:45:48.699188Z"
        },
        {
          "instance_id": "2513e3e2-764a-4e9c-9e94-8b11304b8fcd",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:45:48.699188Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "99d23cdd7320741408a38f0e2d21e6b4d295f692",
      "concurrency": 40,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "4f1c6850-19ad-5c1a-89e8-7fb40216e876",
      "name": "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "tagline": "Qwen3-Next-80B-A3B-Instruct is an 80B parameter MoE model (with only 3B active parameters) that excels at long-context tasks up to 256K tokens while matching the performance of much larger models through its innovative hybrid attention mechanism and high-sparsity architecture.",
      "readme": "\n# Qwen3-Next-80B-A3B-Instruct\n\u003Ca href=\"https://chat.qwen.ai/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/%F0%9F%92%9C%EF%B8%8F%20Qwen%20Chat%20-536af5\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n\u003C/a\u003E\n\nOver the past few months, we have observed increasingly clear trends toward scaling both total parameters and context lengths in the pursuit of more powerful and agentic artificial intelligence (AI). \nWe are excited to share our latest advancements in addressing these demands, centered on improving scaling efficiency through innovative model architecture. \nWe call this next-generation foundation models **Qwen3-Next**.\n\n## Highlights\n\n**Qwen3-Next-80B-A3B** is the first installment in the Qwen3-Next series and features the following key enchancements:\n- **Hybrid Attention**: Replaces standard attention with the combination of **Gated DeltaNet** and **Gated Attention**, enabling efficient context modeling for ultra-long context length.\n- **High-Sparsity Mixture-of-Experts (MoE)**: Achieves an extreme low activation ratio in MoE layers, drastically reducing FLOPs per token while preserving model capacity. \n- **Stability Optimizations**: Includes techniques such as **zero-centered and weight-decayed layernorm**, and other stabilizing enhancements for robust pre-training and post-training.  \n- **Multi-Token Prediction (MTP)**: Boosts pretraining model performance and accelerates inference.\n\nWe are seeing strong performance in terms of both parameter efficiency and inference speed for Qwen3-Next-80B-A3B:\n- Qwen3-Next-80B-A3B-Base outperforms Qwen3-32B-Base on downstream tasks with 10% of the total training cost and with 10 times inference throughput for context over 32K tokens.\n- Qwen3-Next-80B-A3B-Instruct performs on par with Qwen3-235B-A22B-Instruct-2507 on certain benchmarks, while demonstrating significant advantages in handling ultra-long-context tasks up to 256K tokens.\n\n![Qwen3-Next-80B-A3B-Instruct Benchmark Comparison](https://qianwen-res.oss-accelerate.aliyuncs.com/Qwen3-Next/Qwen3-Next-80B-A3B-Instruct.001.jpeg)\n\nFor more details, please refer to our blog post [Qwen3-Next](https://qwen.ai/blog?id=4074cca80393150c248e508aa62983f9cb7d27cd&from=research.latest-advancements-list).\n\n## Model Overview\n\n\u003E [!Note]\n\u003E **Qwen3-Next-80B-A3B-Instruct** supports only instruct (non-thinking) mode and does not generate ``\u003Cthink\u003E\u003C/think\u003E`` blocks in its output.\n\n**Qwen3-Next-80B-A3B-Instruct** has the following features:\n- Type: Causal Language Models\n- Training Stage: Pretraining (15T tokens) & Post-training\n- Number of Parameters: 80B in total and 3B activated\n- Number of Paramaters (Non-Embedding): 79B\n- Hidden Dimension: 2048\n- Number of Layers: 48\n  - Hybrid Layout: 12 \\* (3 \\* (Gated DeltaNet -\u003E MoE) -\u003E 1 \\* (Gated Attention -\u003E MoE))\n- Gated Attention:\n  - Number of Attention Heads: 16 for Q and 2 for KV\n  - Head Dimension: 256\n  - Rotary Position Embedding Dimension: 64\n- Gated DeltaNet:\n  - Number of Linear Attention Heads: 32 for V and 16 for QK\n  - Head Dimension: 128\n- Mixture of Experts:\n  - Number of Experts: 512\n  - Number of Activated Experts: 10\n  - Number of Shared Experts: 1\n  - Expert Intermediate Dimension: 512\n- Context Length: 262,144 natively and extensible up to 1,010,000 tokens\n\n\u003Cimg src=\"https://qianwen-res.oss-accelerate.aliyuncs.com/Qwen3-Next/model_architecture.png\" height=\"384px\" title=\"Qwen3-Next Model Architecture\" /\u003E\n\n\n## Performance\n\n|  | Qwen3-30B-A3B-Instruct-2507 | Qwen3-32B Non-Thinking | Qwen3-235B-A22B-Instruct-2507 | Qwen3-Next-80B-A3B-Instruct |\n|--- | --- | --- | --- | --- |\n| **Knowledge** | | | | |\n| MMLU-Pro | 78.4 | 71.9 | **83.0** | 80.6 |\n| MMLU-Redux | 89.3 | 85.7 | **93.1** | 90.9 |\n| GPQA | 70.4 | 54.6 | **77.5** | 72.9 |\n| SuperGPQA | 53.4 | 43.2 | **62.6** | 58.8 |\n| **Reasoning** | | | | |\n| AIME25 | 61.3 | 20.2 | **70.3** | 69.5 |\n| HMMT25 | 43.0 | 9.8 | **55.4** | 54.1 |\n| LiveBench 20241125 | 69.0 | 59.8 | 75.4 | **75.8** |\n| **Coding** | | | | |\n| LiveCodeBench v6 (25.02-25.05) | 43.2 | 29.1 | 51.8 | **56.6** |\n| MultiPL-E | 83.8 | 76.9 | **87.9** | 87.8 |\n| Aider-Polyglot | 35.6 | 40.0 | **57.3** | 49.8 |\n| **Alignment** | | | | |\n| IFEval | 84.7 | 83.2 | **88.7** | 87.6 |\n| Arena-Hard v2* | 69.0 | 34.1 | 79.2 | **82.7** |\n| Creative Writing v3 | 86.0 | 78.3 | **87.5** | 85.3 |\n| WritingBench | 85.5 | 75.4 | 85.2 | **87.3** |\n| **Agent** | | | | |\n| BFCL-v3 | 65.1 | 63.0 | **70.9** | 70.3 |\n| TAU1-Retail | 59.1 | 40.1 | **71.3** | 60.9 |\n| TAU1-Airline | 40.0 | 17.0 | **44.0** | 44.0 |\n| TAU2-Retail | 57.0 | 48.8 | **74.6** | 57.3 |\n| TAU2-Airline | 38.0 | 24.0 | **50.0** | 45.5 |\n| TAU2-Telecom | 12.3 | 24.6 | **32.5** | 13.2 |\n| **Multilingualism** | | | | |\n| MultiIF | 67.9 | 70.7 | **77.5** | 75.8 |\n| MMLU-ProX | 72.0 | 69.3 | **79.4** | 76.7 |\n| INCLUDE | 71.9 | 70.9 | **79.5** | 78.9 |\n| PolyMATH | 43.1 | 22.5 | **50.2** | 45.9 |\n\n*: For reproducibility, we report the win rates evaluated by GPT-4.1.\n\n## Quickstart\n\nThe code for Qwen3-Next has been merged into the main branch of Hugging Face `transformers`.\n\n```shell\npip install git+https://github.com/huggingface/transformers.git@main\n```\n\nWith earlier versions, you will encounter the following error:\n```\nKeyError: 'qwen3_next'\n```\n\nThe following contains a code snippet illustrating how to use the model generate content based on given inputs. \n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"Qwen/Qwen3-Next-80B-A3B-Instruct\"\n\n# load the tokenizer and the model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    dtype=\"auto\",\n    device_map=\"auto\",\n)\n\n# prepare the model input\nprompt = \"Give me a short introduction to large language model.\"\nmessages = [\n    {\"role\": \"user\", \"content\": prompt},\n]\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\n# conduct text completion\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=16384,\n)\noutput_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n\ncontent = tokenizer.decode(output_ids, skip_special_tokens=True)\n\nprint(\"content:\", content)\n```\n\n\u003E [!Note]\n\u003E Multi-Token Prediction (MTP) is not generally available in Hugging Face Transformers.\n\n\u003E [!Note]\n\u003E The efficiency or throughput improvement depends highly on the implementation.\n\u003E It is recommended to adopt a dedicated inference framework, e.g., SGLang and vLLM, for inference tasks.\n\n\u003E [!Tip]\n\u003E Depending on the inference settings, you may observe better efficiency with [`flash-linear-attention`](https://github.com/fla-org/flash-linear-attention#installation) and [`causal-conv1d`](https://github.com/Dao-AILab/causal-conv1d).\n\u003E See the links for detailed instructions and requirements.\n\n\n## Deployment\n\nFor deployment, you can use the latest `sglang` or `vllm` to create an OpenAI-compatible API endpoint.\n\n### SGLang\n\n[SGLang](https://github.com/sgl-project/sglang) is a fast serving framework for large language models and vision language models.\nSGLang could be used to launch a server with OpenAI-compatible API service. \n\n`sglang\u003E=0.5.2` is required for Qwen3-Next, which can be installed using:\n```shell\npip install 'sglang[all]\u003E=0.5.2'\n```\nSee [its documentation](https://docs.sglang.ai/get_started/install.html) for more details.\n\nThe following command can be used to create an API endpoint at `http://localhost:30000/v1` with maximum context length 256K tokens using tensor parallel on 4 GPUs.\n```shell\npython -m sglang.launch_server --model-path Qwen/Qwen3-Next-80B-A3B-Instruct --port 30000 --tp-size 4 --context-length 262144 --mem-fraction-static 0.8\n```\n\nThe following command is recommended for MTP with the rest settings the same as above:\n```shell\npython -m sglang.launch_server --model-path Qwen/Qwen3-Next-80B-A3B-Instruct --port 30000 --tp-size 4 --context-length 262144 --mem-fraction-static 0.8 --speculative-algo NEXTN --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-draft-tokens 4\n```\n\n\u003E [!Note]\n\u003E The default context length is 256K. Consider reducing the context length to a smaller value, e.g., `32768`, if the server fails to start.\n\nPlease also refer to SGLang's usage guide on [Qwen3-Next](https://docs.sglang.ai/basic_usage/qwen3.html).\n\n### vLLM\n\n[vLLM](https://github.com/vllm-project/vllm) is a high-throughput and memory-efficient inference and serving engine for LLMs.\nvLLM could be used to launch a server with OpenAI-compatible API service. \n\n`vllm\u003E=0.10.2` is required for Qwen3-Next, which can be installed using:\n```shell\npip install 'vllm\u003E=0.10.2'\n```\nSee [its documentation](https://docs.vllm.ai/en/stable/getting_started/installation/index.html) for more details.\n\nThe following command can be used to create an API endpoint at `http://localhost:8000/v1` with maximum context length 256K tokens using tensor parallel on 4 GPUs.\n```shell\nvllm serve Qwen/Qwen3-Next-80B-A3B-Instruct --port 8000 --tensor-parallel-size 4 --max-model-len 262144\n```\n\nThe following command is recommended for MTP with the rest settings the same as above:\n```shell\nvllm serve Qwen/Qwen3-Next-80B-A3B-Instruct --port 8000 --tensor-parallel-size 4 --max-model-len 262144 --speculative-config '{\"method\":\"qwen3_next_mtp\",\"num_speculative_tokens\":2}'\n```\n\n\u003E [!Note]\n\u003E The default context length is 256K. Consider reducing the context length to a smaller value, e.g., `32768`, if the server fails to start.\n\nPlease also refer to vLLM's usage guide on [Qwen3-Next](https://docs.vllm.ai/projects/recipes/en/latest/Qwen/Qwen3-Next.html).\n\n## Agentic Use\n\nQwen3 excels in tool calling capabilities. We recommend using [Qwen-Agent](https://github.com/QwenLM/Qwen-Agent) to make the best use of agentic ability of Qwen3. Qwen-Agent encapsulates tool-calling templates and tool-calling parsers internally, greatly reducing coding complexity.\n\nTo define the available tools, you can use the MCP configuration file, use the integrated tool of Qwen-Agent, or integrate other tools by yourself.\n```python\nfrom qwen_agent.agents import Assistant\n\n# Define LLM\nllm_cfg = {\n    'model': 'Qwen3-Next-80B-A3B-Instruct',\n\n    # Use a custom endpoint compatible with OpenAI API:\n    'model_server': 'http://localhost:8000/v1',  # api_base\n    'api_key': 'EMPTY',\n}\n\n# Define Tools\ntools = [\n    {'mcpServers': {  # You can specify the MCP configuration file\n            'time': {\n                'command': 'uvx',\n                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']\n            },\n            \"fetch\": {\n                \"command\": \"uvx\",\n                \"args\": [\"mcp-server-fetch\"]\n            }\n        }\n    },\n  'code_interpreter',  # Built-in tools\n]\n\n# Define Agent\nbot = Assistant(llm=llm_cfg, function_list=tools)\n\n# Streaming generation\nmessages = [{'role': 'user', 'content': 'https://qwenlm.github.io/blog/ Introduce the latest developments of Qwen'}]\nfor responses in bot.run(messages=messages):\n    pass\nprint(responses)\n```\n\n\n## Processing Ultra-Long Texts\n\nQwen3-Next natively supports context lengths of up to 262,144 tokens. \nFor conversations where the total length (including both input and output) significantly exceeds this limit, we recommend using RoPE scaling techniques to handle long texts effectively. \nWe have validated the model's performance on context lengths of up to 1 million tokens using the [YaRN](https://arxiv.org/abs/2309.00071) method.\n\nYaRN is currently supported by several inference frameworks, e.g., `transformers`, `vllm` and `sglang`. \nIn general, there are two approaches to enabling YaRN for supported frameworks:\n\n- Modifying the model files:\n  In the `config.json` file, add the `rope_scaling` fields:\n    ```json\n    {\n        ...,\n        \"rope_scaling\": {\n            \"rope_type\": \"yarn\",\n            \"factor\": 4.0,\n            \"original_max_position_embeddings\": 262144\n        }\n    }\n    ```\n\n- Passing command line arguments:\n\n  For `vllm`, you can use\n    ```shell\n    VLLM_ALLOW_LONG_MAX_MODEL_LEN=1 vllm serve ... --rope-scaling '{\"rope_type\":\"yarn\",\"factor\":4.0,\"original_max_position_embeddings\":262144}' --max-model-len 1010000  \n    ```\n\n  For `sglang`, you can use\n    ```shell\n    SGLANG_ALLOW_OVERWRITE_LONGER_CONTEXT_LEN=1 python -m sglang.launch_server ... --json-model-override-args '{\"rope_scaling\":{\"rope_type\":\"yarn\",\"factor\":4.0,\"original_max_position_embeddings\":262144}}' --context-length 1010000\n    ```\n\n\u003E [!NOTE]\n\u003E All the notable open-source frameworks implement static YaRN, which means the scaling factor remains constant regardless of input length, **potentially impacting performance on shorter texts.**\n\u003E We advise adding the `rope_scaling` configuration only when processing long contexts is required. \n\u003E It is also recommended to modify the `factor` as needed. For example, if the typical context length for your application is 524,288 tokens, it would be better to set `factor` as 2.0. \n\n#### Long-Context Performance\n\nWe test the model on an 1M version of the [RULER](https://arxiv.org/abs/2404.06654) benchmark.\n\n| Model Name                                  | Acc avg | 4k   | 8k   | 16k  | 32k  | 64k  | 96k  | 128k | 192k | 256k | 384k | 512k | 640k | 768k | 896k | 1000k |\n|---------------------------------------------|---------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|-------|\n| Qwen3-30B-A3B-Instruct-2507                 | 86.8    | 98.0 | 96.7 | 96.9 | 97.2 | 93.4 | 91.0 | 89.1 | 89.8 | 82.5 | 83.6 | 78.4 | 79.7 | 77.6 | 75.7 | 72.8  |\n| Qwen3-235B-A22B-Instruct-2507               | 92.5    | 98.5 | 97.6 | 96.9 | 97.3 | 95.8 | 94.9 | 93.9 | 94.5 | 91.0 | 92.2 | 90.9 | 87.8 | 84.8 | 86.5 | 84.5  |\n| Qwen3-Next-80B-A3B-Instruct                 | 91.8    | 98.5 | 99.0 | 98.0 | 98.7 | 97.6 | 95.0 | 96.0 | 94.0 | 93.5 | 91.7 | 86.9 | 85.5 | 81.7 | 80.3 | 80.3  |\n\n* Qwen3-Next are evaluated with YaRN enabled. Qwen3-2507 models are evaluated with Dual Chunk Attention enabled.\n* Since the evaluation is time-consuming, we use 260 samples for each length (13 sub-tasks, 20 samples for each).\n\n## Best Practices\n\nTo achieve optimal performance, we recommend the following settings:\n\n1. **Sampling Parameters**:\n   - We suggest using `Temperature=0.7`, `TopP=0.8`, `TopK=20`, and `MinP=0`.\n   - For supported frameworks, you can adjust the `presence_penalty` parameter between 0 and 2 to reduce endless repetitions. However, using a higher value may occasionally result in language mixing and a slight decrease in model performance.\n\n2. **Adequate Output Length**: We recommend using an output length of 16,384 tokens for most queries, which is adequate for instruct models.\n\n3. **Standardize Output Format**: We recommend using prompts to standardize model outputs when benchmarking.\n   - **Math Problems**: Include \"Please reason step by step, and put your final answer within \\boxed{}.\" in the prompt.\n   - **Multiple-Choice Questions**: Add the following JSON structure to the prompt to standardize responses: \"Please show your choice in the `answer` field with only the choice letter, e.g., `\"answer\": \"C\"`.\"\n\n### Citation\n\nIf you find our work helpful, feel free to give us a cite.\n\n```\n@misc{qwen3technicalreport,\n      title={Qwen3 Technical Report}, \n      author={Qwen Team},\n      year={2025},\n      eprint={2505.09388},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2505.09388}, \n}\n\n@article{qwen2.5-1m,\n      title={Qwen2.5-1M Technical Report}, \n      author={An Yang and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoyan Huang and Jiandong Jiang and Jianhong Tu and Jianwei Zhang and Jingren Zhou and Junyang Lin and Kai Dang and Kexin Yang and Le Yu and Mei Li and Minmin Sun and Qin Zhu and Rui Men and Tao He and Weijia Xu and Wenbiao Yin and Wenyuan Yu and Xiafei Qiu and X",
      "public": true,
      "version": "f35c196b-2bb0-57a7-bd22-116dce7fc356",
      "tool_description": null,
      "slug": "chutes-qwen-qwen3-next-80b-a3b-instruct",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-09-11T19:44:57.889002Z",
      "updated_at": "2025-10-09T19:46:47.157558Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h100",
          "h100_sxm",
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 3.18222222222222,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 28037,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.1,
            "tao": 0.000248352121585251
          },
          "output": {
            "usd": 0.8,
            "tao": 0.00198681697268201
          }
        },
        "usd": {
          "hour": 8.592,
          "second": 0.00238666666666667
        },
        "tao": {
          "hour": 0.0213384142866048,
          "second": 0.000005927337301834
        }
      },
      "instances": [
        {
          "instance_id": "a6d38588-60b5-4482-9295-592683da9bea",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T11:15:58.381102Z"
        },
        {
          "instance_id": "885c3959-d4d3-4c15-ae26-e17a61990f3f",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:17:24.553443Z"
        },
        {
          "instance_id": "e1f8c231-dab9-4474-83bd-12b615f556ab",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:17:24.553443Z"
        }
      ],
      "logo_id": "8b7a1bd3-5b36-48b1-a86b-1e3a33bd51e0",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "cfdff41643e5ac01d6613c9974df09650daf0e5e",
      "concurrency": 64,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/8b7a1bd3-5b36-48b1-a86b-1e3a33bd51e0.webp",
      "hot": true
    },
    {
      "chute_id": "be9bab2d-f0ed-57a2-a7b2-a791bd2ec900",
      "name": "ArliAI/QwQ-32B-ArliAI-RpR-v1",
      "tagline": "QwQ-32B-ArliAI-RpR-v1 is a 32B parameter open-source language model fine-tuned for roleplay and creative writing with built-in reasoning capabilities for maintaining coherent, non-repetitive conversations across long chat sessions.",
      "readme": "# QwQ-32B-ArliAI-RpR-v1\n\n\u003Cimg src=\"https://cdn-uploads.huggingface.co/production/uploads/6625f4a8a8d1362ebcc3851a/albSlnUy9dPVGVuLlsBua.jpeg\" alt=\"clickbait\" width=\"500\"\u003E\n\n=====================================\n\n## RpR Series Overview: Building on RPMax with Reasoning\n\nRpR (RolePlay with Reasoning) is a new series of models from ArliAI. This series **builds directly upon the successful dataset curation methodology and training methods developed for the RPMax series**.\n\nRpR models use the same curated, deduplicated RP and creative writing dataset used for RPMax, with a focus on variety to ensure high creativity and minimize cross-context repetition. Users familiar with RPMax will recognize the unique, non-repetitive writing style unlike other finetuned-for-RP models.\n\nWith the release of QwQ as the first high performing open-source reasoning model that can be easily trained, it was clear that the available instruct and creative writing reasoning datasets contains only one response per example. This is type of single response dataset used for training reasoning models causes degraded output quality in long multi-turn chats. Which is why Arli AI decided to create a real RP model capable of long multi-turn chat with reasoning.\n\nIn order to create RpR, we first had to actually create the reasoning RP dataset by re-processing our existing known-good RPMax dataset into a reasoning dataset. This was possible by using the base QwQ Instruct model itself to create the reasoning process for every turn in the RPMax dataset conversation examples, which is then further refined in order to make sure the reasoning is in-line with the actual response examples from the dataset.\n\nAnother important thing to get right is to make sure the model is trained on examples that present reasoning blocks in the same way as it encounters it during inference. Which is, never seeing the reasoning blocks in it's context. In order to do this, the training run was completed using axolotl with manual template-free segments dataset in order to make sure that the model is never trained to see the reasoning block in the context. Just like how the model will be used during inference time.\n\nThe result of training QwQ on this dataset with this method are consistently coherent and interesting outputs even in long multi-turn RP chats. This is as far as we know the first true correctly-trained reasoning model trained for RP and creative writing.\n\nYou can access the model at https://arliai.com and we also have a models ranking page at https://www.arliai.com/models-ranking\n\nAsk questions in our new Discord Server https://discord.com/invite/t75KbPgwhk or on our subreddit https://www.reddit.com/r/ArliAI/\n\n## Model Description\n\nQwQ-32B-ArliAI-RpR-v1 is the first release in the RpR series. It is a 32-billion parameter model fine-tuned using the curated RPMax dataset combined with techniques to maintain reasoning abilities in long multi-turn chats.\n\n### Specs\n\n*   **Base Model**: QwQ-32B\n*   **Max Context Length**: 128K (Realistically 32K)\n*   **Parameters**: 32B\n*   **Reasoning Model**: Yes\n\n### Training Details\n\n*   **Sequence Length**: 8192\n*   **Epochs**: 1 epoch training (Inherited from RPMax methods)\n*   **Fine-tuning Method**: RS-QLORA+ (Rank-Stabilized LoRA + LoRA Plus)\n*   **Rank/Alpha**: 128-rank 128-alpha\n*   **Learning Rate**: 0.000005\n*   **Gradient accumulation**: 32\n\n### Quantization\n\n*   **BF16**: https://huggingface.co/ArliAI/QwQ-32B-ArliAI-RpR-v1\n*   **GGUF**: https://huggingface.co/ArliAI/QwQ-32B-ArliAI-RpR-v1-GGUF\n\n### How to use reasoning models correctly in ST\n\n\u003Cimg src=\"RpR-ST-Settings.png\" alt=\"Important settings in ST for reasoning models\" width=\"600\" /\u003E\n\nFor any reasoning models in general, you need to make sure to set:\n\n* Prefix is set to ONLY \\\u003Cthink\u003E and the suffix is set to ONLY \\\u003C/think\u003E without any spaces or newlines (enter)\n\n* Reply starts with \\\u003Cthink\u003E\n\n* Always add character names is unchecked\n\n* Include names is set to never\n\n* As always the chat template should also conform to the model being used\n\nNote: Reasoning models work properly only if include names is set to never, since they always expect the eos token of the user turn followed by the \\\u003Cthink\u003E token in order to start reasoning before outputting their response. If you set include names to enabled, then it will always append the character name at the end like \"Seraphina:\\\u003Ceos_token\u003E\" which confuses the model on whether it should respond or reason first.\n\nThe rest of your sampler parameters can be set as you wish as usual.\n\nIf you don't see the reasoning wrapped inside the thinking block, then either your settings is still wrong and doesn't follow my example or that your ST version is too old without reasoning block auto parsing.\n\nIf you see the whole response is in the reasoning block, then your \\\u003Cthink\u003E and \\\u003C/think\u003E reasoning token suffix and prefix might have an extra space or newline. Or the model just isn't a reasoning model that is smart enough to always put reasoning in between those tokens.\n\n### If you set everything up correctly, it should look like this:\n\n\u003Cimg src=\"Example-RP-with-Reasoning.png\" alt=\"Example RP with Reasoning\" width=\"600\" /\u003E\n\n---\n\n\u003Cdetails\u003E\n\u003Csummary\u003EDetails: The RPMax Foundation (Dataset & Training Philosophy)\u003C/summary\u003E\n\n*The following sections detail the core philosophy behind the dataset and training methodology originally developed for RPMax, which serves as the foundation for the RpR series.*\n\n### The Goal: Reduced Repetition and Higher Creativity\n\nThe goal of the dataset curation used for both RPMax and RpR is to reduce repetitions and increase the models ability to creatively write in different situations presented to it. What this means is it is a model that will output responses very differently without falling into predictable tropes across different situations.\n\n### What is repetition and creativity?\n\nFirst of all, creativity should mean the variety in output that the model is capable of creating. You should not confuse creativity with writing prose. When a model writes in a way that can be said to be pleasant like writers would write in a novel, this is not creative writing. This is just a model having a certain pleasant type of writing prose. So a model that writes nicely is not necessarily a creative model.\n\nRepetition and creativity are essentially intertwined with each other, so if a model is repetitive then a model can also be said to be un-creative as it cannot write new things and can only repeat similar responses that it has created before. For repetition there are actually two very different forms of repetition.\n\n**In-context repetition:** When people mention a model is repetitive, this usually mean a model that likes to repeat the same phrases in a single conversation. An example of this is when a model says that a character \"flicks her hair and....\" and then starts to prepend that \"flicks her hair and...\" into every other action that character does.\n\nIt can be said that the model is boring, but even in real people's writing it is possible that this kind of repetition could be intentional to subtly prove a point or showcase a character's traits in some scenarios. So this type of repetition is not always bad and completely discouraging a model from doing this does not always lead to improve a model's writing ability.\n\nIn this regard, RPMax and RpR is not yet focused on eliminating this type of repetition so there might be some in-context repetition that can be seen in the outputs. Eliminating this will be the next big step of the RPMax and RpR series of models.\n\n**Cross-context repetition:** A second worse type of repetition is a model's tendency to repeat the same phrases or tropes in very different situations. An example is a model that likes to repeat the infamous \"shivers down my spine\" phrase in wildly different conversations that don't necessarily fit with that phrase.\n\nThis type of repetition is ALWAYS bad as it is a sign that the model has over-fitted into that style of \"creative writing\" that it has often seen in the training dataset. A model's tendency to have cross-context repetition is also usually visible in how a model likes to choose similar repetitive names when writing stories. Such as the infamous \"elara\" and \"whispering woods\" names.\n\nThe primary goal of the dataset curation for RPMax and RpR is to create a highly creative model by reducing cross-context repetition, as that is the type of repetition that follows you through different conversations. This is combated by making sure the dataset does not have repetitions of the same situations or characters in different example entries.\n\n### Dataset Curation\n\nThe success of models trained on this dataset (including RPMax and now RpR) is thanks to the training method and the unique dataset created for fine-tuning. It contains as many open source creative writing and RP datasets that can be found (all from Hugging Face), from which have been curated to weed out datasets that are purely synthetic generations as they often only serve to dumb down the model and make the model learn GPT-isms (slop) rather than help.\n\nThen Llama 3.1 8B (or a similarly capable model) is used to create a database of the characters and situations that are portrayed in these datasets, which is then used to de-dupe these datasets to make sure that there is only a single entry of any character or situation.\n\n### The Golden Rule of Fine-Tuning\n\nUnlike the initial pre-training stage where the more data you throw at it the better it becomes for the most part, the golden rule for fine-tuning models isn't quantity, but instead quality over quantity. So the dataset used here is actually orders of magnitude smaller than it would be if it included repeated characters and situations in the dataset, but the end result is a model that does not feel like just another \"in-breed\" of another creative writing/RP model.\n\n### Training Parameters and Unconventional Approach\n\nThe usual way is to have a low learning rate and high gradient accumulation for better loss stability, and then run multiple epochs of the training run until the loss is acceptable.\n\nThe RPMax and RpR methodology, however, uses only **one single epoch**, a low gradient accumulation, and a higher than normal learning rate. The loss curve during training is actually unstable and jumps up and down a lot, but if it is smoothed out, it is steadily decreasing over time. The theory is that this allows the models to learn from each individual example in the dataset much more, and by not showing the model the same example twice using multiple epochs, it stops the model from latching on and reinforcing a single character or story trope.\n\nThe jumping up and down of loss during training is because as the model gets trained on a new entry from the dataset, the model will have never seen a similar example before and therefore can't really predict an answer similar to the example entry. While the relatively high end loss of 1.0 or slightly above is actually acceptable because the goal was never to create a model that can output exactly like the dataset that is being used to train it. Rather to create a model that is creative enough to make up it's own style of responses.\n\nThis is different from training a model in a particular domain and needing the model to reliably be able to output like the example dataset, such as when training a model on a company's internal knowledge base.\n\n\u003C/details\u003E\n\n---\n\n## Try It Out!\n\nModel preference is subjective, so please do try QwQ-32B-ArliAI-RpR-v1 for yourself. Your feedback both good and bad is always valueable and will help us improve the future RPMax and RpR models.",
      "public": true,
      "version": "6127bfdc-3954-5db9-a0d6-d9881d8761fc",
      "tool_description": null,
      "slug": "chutes-arliai-qwq-32b-arliai-rpr-v1",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-04-13T12:52:03.685125Z",
      "updated_at": "2025-10-09T19:03:13.878319Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "exclude": [
          "5090",
          "b200",
          "mi300x"
        ],
        "include": null,
        "gpu_count": 4,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.444444444444444,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 17858,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          },
          "output": {
            "usd": 0.11,
            "tao": 0.000273187333743776
          }
        },
        "usd": {
          "hour": 2,
          "second": 0.000555555555555555
        },
        "tao": {
          "hour": 0.00496704243170503,
          "second": 0.000001379734008806
        }
      },
      "instances": [
        {
          "instance_id": "36c9d985-ec12-4f45-ad06-26239b01454d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:02:22.020228Z"
        },
        {
          "instance_id": "82ce708e-9d2d-4fd8-bb81-8737d084430c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:02:22.020228Z"
        },
        {
          "instance_id": "f801bdfe-e45e-42bb-bf75-8365125d703d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:02:22.020228Z"
        },
        {
          "instance_id": "261d9718-cbbb-4418-8bf5-3d4057aeaa94",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:02:22.020228Z"
        },
        {
          "instance_id": "7c5546e8-5755-4e2a-a480-7e5638557108",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:02:22.020228Z"
        }
      ],
      "logo_id": "4c704e0a-8b51-4bf1-82dd-642cbee4439b",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "01228a58062279ff87d9102d0b5115872da0f46f",
      "concurrency": 16,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/4c704e0a-8b51-4bf1-82dd-642cbee4439b.webp",
      "hot": true
    },
    {
      "chute_id": "760a5124-9222-5d68-9ff4-940154dff9f1",
      "name": "Qwen/Qwen2.5-VL-72B-Instruct",
      "tagline": "Qwen2.5-VL is a 72B parameter multimodal model that can understand and analyze images, videos, and visual content like charts and layouts, with capabilities in visual localization, event detection in long videos, and structured data extraction.",
      "readme": "\n---\nlicense: other\nlicense_name: qwen\nlicense_link: https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct/blob/main/LICENSE\nlanguage:\n- en\npipeline_tag: image-text-to-text\ntags:\n- multimodal\nlibrary_name: transformers\n---\n\n# Qwen2.5-VL-72B-Instruct\n\u003Ca href=\"https://chat.qwenlm.ai/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/%F0%9F%92%9C%EF%B8%8F%20Qwen%20Chat%20-536af5\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n\u003C/a\u003E\n\n## Introduction\n\nIn the past five months since Qwen2-VLâ€™s release, numerous developers have built new models on the Qwen2-VL vision-language models, providing us with valuable feedback. During this period, we focused on building more useful vision-language models. Today, we are excited to introduce the latest addition to the Qwen family: Qwen2.5-VL.\n\n#### Key Enhancements:\n* **Understand things visually**: Qwen2.5-VL is not only proficient in recognizing common objects such as flowers, birds, fish, and insects, but it is highly capable of analyzing texts, charts, icons, graphics, and layouts within images.\n\n* **Being agentic**: Qwen2.5-VL directly plays as a visual agent that can reason and dynamically direct tools, which is capable of computer use and phone use.\n\n* **Understanding long videos and capturing events**: Qwen2.5-VL can comprehend videos of over 1 hour, and this time it has a new ability of cpaturing event by pinpointing the relevant video segments.\n\n* **Capable of visual localization in different formats**: Qwen2.5-VL can accurately localize objects in an image by generating bounding boxes or points, and it can provide stable JSON outputs for coordinates and attributes.\n\n* **Generating structured outputs**: for data like scans of invoices, forms, tables, etc. Qwen2.5-VL supports structured outputs of their contents, benefiting usages in finance, commerce, etc.\n\n\n#### Model Architecture Updates:\n\n* **Dynamic Resolution and Frame Rate Training for Video Understanding**:\n\nWe extend dynamic resolution to the temporal dimension by adopting dynamic FPS sampling, enabling the model to comprehend videos at various sampling rates. Accordingly, we update mRoPE in the time dimension with IDs and absolute time alignment, enabling the model to learn temporal sequence and speed, and ultimately acquire the ability to pinpoint specific moments.\n\n\u003Cp align=\"center\"\u003E\n    \u003Cimg src=\"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5-VL/qwen2.5vl_arc.jpeg\" width=\"80%\"/\u003E\n\u003Cp\u003E\n\n* **Streamlined and Efficient Vision Encoder**\n\nWe enhance both training and inference speeds by strategically implementing window attention into the ViT. The ViT architecture is further optimized with SwiGLU and RMSNorm, aligning it with the structure of the Qwen2.5 LLM.\n\n\nWe have three models with 3, 7 and 72 billion parameters. This repo contains the instruction-tuned 72B Qwen2.5-VL model. For more information, visit our [Blog](https://qwenlm.github.io/blog/qwen2.5-vl/) and [GitHub](https://github.com/QwenLM/Qwen2.5-VL).\n\n\n\n## Evaluation\n\n### Image benchmark\n\n|      Benchmarks        | GPT4o     | Claude3.5 Sonnet  | Gemini-2-flash  | InternVL2.5-78B | Qwen2-VL-72B | Qwen2.5-VL-72B |\n|-----------------------|-----------|-------------------|-----------------|-----------------|--------------|----------------|\n| MMMU\u003Csub\u003Eval\u003C/sub\u003E    | 70.3      | 70.4              | 70.7            | 70.1                 | 64.5         | 70.2          |\n| MMMU_Pro              | 54.5      | 54.7              | 57.0            | 48.6              | 46.2         | 51.1           |\n| MathVista_MINI        | 63.8      | 65.4              | 73.1            | 76.6                | 70.5         | 74.8           |\n| MathVision_FULL       | 30.4      | 38.3              | 41.3            | 32.2               | 25.9         | 38.1           |\n| Hallusion Bench       | 55.0      | 55.16             |                | 57.4             | 58.1         | 55.16           |\n| MMBench_DEV_EN_V11    | 82.1      | 83.4              | 83.0            | 88.5             | 86.6         | 88           |\n| AI2D_TEST             | 84.6      | 81.2              |                 | 89.1           | 88.1         | 88.4           |\n| ChartQA_TEST          | 86.7      | 90.8              | 85.2            | 88.3               | 88.3         | 89.5           |\n| DocVQA_VAL            | 91.1      | 95.2              | 92.1            | 96.5             | 96.1         |      96.4      |\n| MMStar                | 64.7      | 65.1              | 69.4            | 69.5             | 68.3         |       70.8         |\n| MMVet_turbo           | 69.1      |  70.1              |                 | 72.3           | 74.0         |       76.19         |\n| OCRBench              | 736       | 788               |                 | 854               | 877          |         885       |\n| OCRBench-V2(en/zh)    |  46.5/32.3 |  45.2/39.6         | 51.9/43.1       | 45/46.2     | 47.8/46.1    | 61.5/63.7    |\n| CC-OCR                | 66.6     | 62.7              | 73.0            | 64.7          | 68.7       |79.8           |\n\n\n### Video benchmark\n| Benchmarks          | GPT4o | Gemini-1.5-Pro | InternVL2.5-78B | Qwen2VL-72B | Qwen2.5VL-72B |\n|---------------------|-------|----------------|-----------------|-------------|---------------|\n| VideoMME w/o sub.   | 71.9  | 75.0           | 72.1            | 71.2        | 73.3          |\n| VideoMME w sub.     | 77.2  | 81.3           | 74.0            | 77.8        | 79.1          |\n| MVBench             | 64.6  | 60.5           | 76.4            | 73.6        | 70.4          |\n| MMBench-Video       | 1.63  | 1.30           | 1.97            | 1.70        | 2.02          |\n| LVBench             | 30.8  | 33.1           | -               | 41.3        | 47.3          |\n| EgoSchema           | 72.2  | 71.2           | -               | 77.9        | 76.2          |\n| PerceptionTest_test | -     | -              | -               | 68.0        | 73.2          |\n| MLVU_M-Avg_dev      | 64.6  | -              | 75.7            |             | 74.6          |\n| TempCompass_overall | 73.8  | -              | -               |             | 74.8          |\n\n\n### Agent benchmark\n\n| Benchmarks              | GPT4o       | Gemini 2.0 | Claude | Aguvis-72B | Qwen2VL-72B | Qwen2.5VL-72B |\n|-------------------------|-------------|------------|--------|------------|-------------|---------------|\n| ScreenSpot              | 18.1        | 84.0       | 83.0   |            |             | 87.1          |\n| ScreenSpot Pro          |             |            | 17.1   |            | 1.6         | 43.6          |\n| AITZ_EM                 | 35.3        |            |        |            | 72.8        | 83.2          |\n| Android Control High_EM |             |            |        | 66.4       | 59.1        | 67.36         |\n| Android Control Low_EM  |             |            |        | 84.4       | 59.2        | 93.7          |\n| AndroidWorld_SR         | 34.5% (SoM) |            | 27.9%  | 26.1%      |             | 35%           |\n| MobileMiniWob++_SR      |             |            |        | 66%        |             | 68%           |\n| OSWorld                 |             |            | 14.90  | 10.26      |             | 8.83          |\n\n\n## Requirements\nThe code of Qwen2.5-VL has been in the latest Hugging face transformers and we advise you to build from source with command:\n```\npip install git+https://github.com/huggingface/transformers accelerate\n```\nor you might encounter the following error:\n```\nKeyError: 'qwen2_5_vl'\n```\n\n\n## Quickstart\n\nBelow, we provide simple examples to show how to use Qwen2.5-VL with ğŸ¤– ModelScope and ğŸ¤— Transformers.\n\nThe code of Qwen2.5-VL has been in the latest Hugging face transformers and we advise you to build from source with command:\n```\npip install git+https://github.com/huggingface/transformers accelerate\n```\nor you might encounter the following error:\n```\nKeyError: 'qwen2_5_vl'\n```\n\n\nWe offer a toolkit to help you handle various types of visual input more conveniently, as if you were using an API. This includes base64, URLs, and interleaved images and videos. You can install it using the following command:\n\n```bash\n# It's highly recommanded to use `[decord]` feature for faster video loading.\npip install qwen-vl-utils[decord]==0.0.8\n```\n\nIf you are not using Linux, you might not be able to install `decord` from PyPI. In that case, you can use `pip install qwen-vl-utils` which will fall back to using torchvision for video processing. However, you can still [install decord from source](https://github.com/dmlc/decord?tab=readme-ov-file#install-from-source) to get decord used when loading video.\n\n### Using ğŸ¤—  Transformers to Chat\n\nHere we show a code snippet to show you how to use the chat model with `transformers` and `qwen_vl_utils`:\n\n```python\nfrom transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor\nfrom qwen_vl_utils import process_vision_info\n\n# default: Load the model on the available device(s)\nmodel = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n    \"Qwen/Qwen2.5-VL-72B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n)\n\n# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n# model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n#     \"Qwen/Qwen2.5-VL-72B-Instruct\",\n#     torch_dtype=torch.bfloat16,\n#     attn_implementation=\"flash_attention_2\",\n#     device_map=\"auto\",\n# )\n\n# default processer\nprocessor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-72B-Instruct\")\n\n# The default range for the number of visual tokens per image in the model is 4-16384.\n# You can set min_pixels and max_pixels according to your needs, such as a token range of 256-1280, to balance performance and cost.\n# min_pixels = 256*28*28\n# max_pixels = 1280*28*28\n# processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-72B-Instruct\", min_pixels=min_pixels, max_pixels=max_pixels)\n\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"image\",\n                \"image\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\",\n            },\n            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n        ],\n    }\n]\n\n# Preparation for inference\ntext = processor.apply_chat_template(\n    messages, tokenize=False, add_generation_prompt=True\n)\nimage_inputs, video_inputs = process_vision_info(messages)\ninputs = processor(\n    text=[text],\n    images=image_inputs,\n    videos=video_inputs,\n    padding=True,\n    return_tensors=\"pt\",\n)\ninputs = inputs.to(\"cuda\")\n\n# Inference: Generation of the output\ngenerated_ids = model.generate(**inputs, max_new_tokens=128)\ngenerated_ids_trimmed = [\n    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n]\noutput_text = processor.batch_decode(\n    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n)\nprint(output_text)\n```\n\u003Cdetails\u003E\n\u003Csummary\u003EMulti image inference\u003C/summary\u003E\n\n```python\n# Messages containing multiple images and a text query\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\", \"image\": \"file:///path/to/image1.jpg\"},\n            {\"type\": \"image\", \"image\": \"file:///path/to/image2.jpg\"},\n            {\"type\": \"text\", \"text\": \"Identify the similarities between these images.\"},\n        ],\n    }\n]\n\n# Preparation for inference\ntext = processor.apply_chat_template(\n    messages, tokenize=False, add_generation_prompt=True\n)\nimage_inputs, video_inputs = process_vision_info(messages)\ninputs = processor(\n    text=[text],\n    images=image_inputs,\n    videos=video_inputs,\n    padding=True,\n    return_tensors=\"pt\",\n)\ninputs = inputs.to(\"cuda\")\n\n# Inference\ngenerated_ids = model.generate(**inputs, max_new_tokens=128)\ngenerated_ids_trimmed = [\n    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n]\noutput_text = processor.batch_decode(\n    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n)\nprint(output_text)\n```\n\u003C/details\u003E\n\n\u003Cdetails\u003E\n\u003Csummary\u003EVideo inference\u003C/summary\u003E\n\n```python\n# Messages containing a images list as a video and a text query\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"video\",\n                \"video\": [\n                    \"file:///path/to/frame1.jpg\",\n                    \"file:///path/to/frame2.jpg\",\n                    \"file:///path/to/frame3.jpg\",\n                    \"file:///path/to/frame4.jpg\",\n                ],\n            },\n            {\"type\": \"text\", \"text\": \"Describe this video.\"},\n        ],\n    }\n]\n\n# Messages containing a local video path and a text query\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"video\",\n                \"video\": \"file:///path/to/video1.mp4\",\n                \"max_pixels\": 360 * 420,\n                \"fps\": 1.0,\n            },\n            {\"type\": \"text\", \"text\": \"Describe this video.\"},\n        ],\n    }\n]\n\n# Messages containing a video url and a text query\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"video\",\n                \"video\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-VL/space_woaudio.mp4\",\n            },\n            {\"type\": \"text\", \"text\": \"Describe this video.\"},\n        ],\n    }\n]\n\n#In Qwen 2.5 VL, frame rate information is also input into the model to align with absolute time.\n# Preparation for inference\ntext = processor.apply_chat_template(\n    messages, tokenize=False, add_generation_prompt=True\n)\nimage_inputs, video_inputs, video_kwargs = process_vision_info(messages, return_video_kwargs=True)\ninputs = processor(\n    text=[text],\n    images=image_inputs,\n    videos=video_inputs,\n    fps=fps,\n    padding=True,\n    return_tensors=\"pt\",\n    **video_kwargs,\n)\ninputs = inputs.to(\"cuda\")\n\n# Inference\ngenerated_ids = model.generate(**inputs, max_new_tokens=128)\ngenerated_ids_trimmed = [\n    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n]\noutput_text = processor.batch_decode(\n    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n)\nprint(output_text)\n```\n\nVideo URL compatibility largely depends on the third-party library version. The details are in the table below. change the backend by `FORCE_QWENVL_VIDEO_READER=torchvision` or `FORCE_QWENVL_VIDEO_READER=decord` if you prefer not to use the default one.\n\n| Backend     | HTTP | HTTPS |\n|-------------|------|-------|\n| torchvision \u003E= 0.19.0 | âœ…  | âœ…   |\n| torchvision \u003C 0.19.0  | âŒ  | âŒ   |\n| decord      | âœ…  | âŒ   |\n\u003C/details\u003E\n\n\u003Cdetails\u003E\n\u003Csummary\u003EBatch inference\u003C/summary\u003E\n\n```python\n# Sample messages for batch inference\nmessages1 = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\", \"image\": \"file:///path/to/image1.jpg\"},\n            {\"type\": \"image\", \"image\": \"file:///path/to/image2.jpg\"},\n            {\"type\": \"text\", \"text\": \"What are the common elements in these pictures?\"},\n        ],\n    }\n]\nmessages2 = [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Who are you?\"},\n]\n# Combine messages for batch processing\nmessages = [messages1, messages2]\n\n# Preparation for batch inference\ntexts = [\n    processor.apply_chat_template(msg, tokenize=False, add_generation_prompt=True)\n    for msg in messages\n]\nimage_inputs, video_inputs = process_vision_info(messages)\ninputs = processor(\n    text=texts,\n    images=image_inputs,\n    videos=video_inputs,\n    padding=True,\n    return_tensors=\"pt\",\n)\ninputs = inputs.to(\"cuda\")\n\n# Batch Inference\ngenerated_ids = model.generate(**inputs, max_new_tokens=128)\ngenerated_ids_trimmed = [\n    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n]\noutput_texts = processor.batch_decode(\n    generated_ids",
      "public": true,
      "version": "01c70aae-8b16-5c77-ac39-054633e9f73a",
      "tool_description": null,
      "slug": "chutes-qwen-qwen2-5-vl-72b-instruct",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-03-14T09:51:02.827191Z",
      "updated_at": "2025-10-09T18:54:02.872230Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm",
        "h800"
      ],
      "node_selector": {
        "exclude": null,
        "include": [
          "h200",
          "h100",
          "h100_sxm",
          "h800"
        ],
        "gpu_count": 4,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 1.33333333333333,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm",
          "h800"
        ]
      },
      "invocation_count": 16693,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.08,
            "tao": 0.000198681697268201
          },
          "output": {
            "usd": 0.33,
            "tao": 0.000819562001231329
          }
        },
        "usd": {
          "hour": 6,
          "second": 0.00166666666666667
        },
        "tao": {
          "hour": 0.0149011272951151,
          "second": 0.00000413920202642
        }
      },
      "instances": [
        {
          "instance_id": "3f284aa8-a36d-4292-bdd2-d52c430eef93",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T10:24:34.340178Z"
        },
        {
          "instance_id": "306a6231-3ad9-4cb4-bba3-758992168788",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:38:38.269444Z"
        },
        {
          "instance_id": "e081b741-d91e-4bf2-919a-7887c7c63262",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:38:38.269444Z"
        },
        {
          "instance_id": "fff2e7df-efe0-4edd-af9b-6555d29f44d6",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:38:38.269444Z"
        },
        {
          "instance_id": "dabb7bc3-b607-4a21-9496-ad3ba6c30a14",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:38:38.269444Z"
        }
      ],
      "logo_id": "fbcf29bf-73f7-4e10-9d7e-b0dd7b2043b4",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "d91279c190bb874c1f90cf26c70c4261bbf7488c",
      "concurrency": 8,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/fbcf29bf-73f7-4e10-9d7e-b0dd7b2043b4.webp",
      "hot": true
    },
    {
      "chute_id": "b45bfcdb-7e8e-50c5-93e6-f425688d4b84",
      "name": "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "tagline": "Qwen3-Coder-30B-A3B-Instruct is a 30.5B parameter coding-focused language model (with 3.3B activated parameters) that excels at programming tasks and browser interactions while supporting extremely long contexts up to 256K tokens.",
      "readme": "\n# Qwen3-Coder-30B-A3B-Instruct\n\u003Ca href=\"https://chat.qwen.ai/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/%F0%9F%92%9C%EF%B8%8F%20Qwen%20Chat%20-536af5\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n\u003C/a\u003E\n\n## Highlights\n\n**Qwen3-Coder** is available in multiple sizes. Today, we're excited to introduce **Qwen3-Coder-30B-A3B-Instruct**. This streamlined model maintains impressive performance and efficiency, featuring the following key enhancements:  \n\n- **Significant Performance** among open models on **Agentic Coding**, **Agentic Browser-Use**, and other foundational coding tasks.\n- **Long-context Capabilities** with native support for **256K** tokens, extendable up to **1M** tokens using Yarn, optimized for repository-scale understanding.\n- **Agentic Coding** supporting for most platform such as **Qwen Code**, **CLINE**, featuring a specially designed function call format.\n\n![image/jpeg](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/qwen3-coder-30a3-main.jpg)\n\n## Model Overview\n\n**Qwen3-Coder-30B-A3B-Instruct** has the following features:\n- Type: Causal Language Models\n- Training Stage: Pretraining & Post-training\n- Number of Parameters: 30.5B in total and 3.3B activated\n- Number of Layers: 48\n- Number of Attention Heads (GQA): 32 for Q and 4 for KV\n- Number of Experts: 128\n- Number of Activated Experts: 8\n- Context Length: **262,144 natively**. \n\n**NOTE: This model supports only non-thinking mode and does not generate ``\u003Cthink\u003E\u003C/think\u003E`` blocks in its output. Meanwhile, specifying `enable_thinking=False` is no longer required.**\n\nFor more details, including benchmark evaluation, hardware requirements, and inference performance, please refer to our [blog](https://qwenlm.github.io/blog/qwen3-coder/), [GitHub](https://github.com/QwenLM/Qwen3-Coder), and [Documentation](https://qwen.readthedocs.io/en/latest/).\n\n\n## Quickstart\n\nWe advise you to use the latest version of `transformers`.\n\nWith `transformers\u003C4.51.0`, you will encounter the following error:\n```\nKeyError: 'qwen3_moe'\n```\n\nThe following contains a code snippet illustrating how to use the model generate content based on given inputs. \n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"Qwen/Qwen3-Coder-30B-A3B-Instruct\"\n\n# load the tokenizer and the model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=\"auto\",\n    device_map=\"auto\"\n)\n\n# prepare the model input\nprompt = \"Write a quick sort algorithm.\"\nmessages = [\n    {\"role\": \"user\", \"content\": prompt}\n]\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\n# conduct text completion\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=65536\n)\noutput_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n\ncontent = tokenizer.decode(output_ids, skip_special_tokens=True)\n\nprint(\"content:\", content)\n```\n\n**Note: If you encounter out-of-memory (OOM) issues, consider reducing the context length to a shorter value, such as `32,768`.**\n\nFor local use, applications such as Ollama, LMStudio, MLX-LM, llama.cpp, and KTransformers have also supported Qwen3.\n\n## Agentic Coding\n\nQwen3-Coder excels in tool calling capabilities. \n\nYou can simply define or use any tools as following example.\n```python\n# Your tool implementation\ndef square_the_number(num: float) -\u003E dict:\n    return num ** 2\n\n# Define Tools\ntools=[\n    {\n        \"type\":\"function\",\n        \"function\":{\n            \"name\": \"square_the_number\",\n            \"description\": \"output the square of the number.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"required\": [\"input_num\"],\n                \"properties\": {\n                    'input_num': {\n                        'type': 'number', \n                        'description': 'input_num is a number that will be squared'\n                        }\n                },\n            }\n        }\n    }\n]\n\nimport OpenAI\n# Define LLM\nclient = OpenAI(\n    # Use a custom endpoint compatible with OpenAI API\n    base_url='http://localhost:8000/v1',  # api_base\n    api_key=\"EMPTY\"\n)\n \nmessages = [{'role': 'user', 'content': 'square the number 1024'}]\n\ncompletion = client.chat.completions.create(\n    messages=messages,\n    model=\"Qwen3-Coder-30B-A3B-Instruct\",\n    max_tokens=65536,\n    tools=tools,\n)\n\nprint(completion.choice[0])\n```\n\n## Best Practices\n\nTo achieve optimal performance, we recommend the following settings:\n\n1. **Sampling Parameters**:\n   - We suggest using `temperature=0.7`, `top_p=0.8`, `top_k=20`, `repetition_penalty=1.05`.\n\n2. **Adequate Output Length**: We recommend using an output length of 65,536 tokens for most queries, which is adequate for instruct models.\n\n\n### Citation\n\nIf you find our work helpful, feel free to give us a cite.\n\n```\n@misc{qwen3technicalreport,\n      title={Qwen3 Technical Report}, \n      author={Qwen Team},\n      year={2025},\n      eprint={2505.09388},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2505.09388}, \n}\n```\n",
      "public": true,
      "version": "fe57536a-8038-5b35-b4bf-28e64e88fe7d",
      "tool_description": null,
      "slug": "chutes-qwen-qwen3-coder-30b-a3b-instruct",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-08-14T11:18:53.527813Z",
      "updated_at": "2025-10-09T18:38:32.497754Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm",
        "h800"
      ],
      "node_selector": {
        "exclude": null,
        "include": [
          "h200",
          "h100",
          "h100_sxm",
          "h800"
        ],
        "gpu_count": 4,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 1.33333333333333,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm",
          "h800"
        ]
      },
      "invocation_count": 16191,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.06,
            "tao": 0.00014901127295115
          },
          "output": {
            "usd": 0.25,
            "tao": 0.000620880303963128
          }
        },
        "usd": {
          "hour": 6,
          "second": 0.00166666666666667
        },
        "tao": {
          "hour": 0.0149011272951151,
          "second": 0.00000413920202642
        }
      },
      "instances": [
        {
          "instance_id": "d70d2281-2670-4aea-a3c0-83d403738122",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:13.094934Z"
        },
        {
          "instance_id": "0ef2dd26-a680-4840-b7b1-7a408eb40f3d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:13.094934Z"
        },
        {
          "instance_id": "08c4abe5-2bbf-46c7-9b13-402efce14cb8",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:13.094934Z"
        },
        {
          "instance_id": "37bf50cb-9519-4d28-b964-6da039feb1b7",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:25.748749Z"
        },
        {
          "instance_id": "2ac2ed28-ae04-45be-b5fd-cf69ded0feac",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:58:13.094934Z"
        }
      ],
      "logo_id": "3f23fafc-1be4-4ff4-9929-52bfd3475c13",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "8110d98ad896c995124f3bc44b2f8dd695a4d252",
      "concurrency": 24,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/3f23fafc-1be4-4ff4-9929-52bfd3475c13.webp",
      "hot": true
    },
    {
      "chute_id": "642367d0-9376-5a1a-bbe7-e930d2552d3c",
      "name": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "tagline": "Qwen3-30B-A3B-Thinking-2507 is a 30.5B parameter language model (with 3.3B activated parameters) optimized for complex reasoning tasks with a 256K context window, featuring enhanced capabilities in mathematics, coding, and long-form content generation.",
      "readme": "\n# Qwen3-30B-A3B-Thinking-2507\n\u003Ca href=\"https://chat.qwen.ai/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/%F0%9F%92%9C%EF%B8%8F%20Qwen%20Chat%20-536af5\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n\u003C/a\u003E\n\n## Highlights\n\nOver the past three months, we have continued to scale the **thinking capability** of Qwen3-30B-A3B, improving both the **quality and depth** of reasoning. We are pleased to introduce **Qwen3-30B-A3B-Thinking-2507**, featuring the following key enhancements:\n\n- **Significantly improved performance** on reasoning tasks, including logical reasoning, mathematics, science, coding, and academic benchmarks that typically require human expertise.\n- **Markedly better general capabilities**, such as instruction following, tool usage, text generation, and alignment with human preferences.\n- **Enhanced 256K long-context understanding** capabilities.\n\n**NOTE**: This version has an increased thinking length. We strongly recommend its use in highly complex reasoning tasks.\n\n![image/jpeg](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-2507/Qwen3-30B-A3B-Thinking-2507.jpeg)\n\n## Model Overview\n\n**Qwen3-30B-A3B-Thinking-2507** has the following features:\n- Type: Causal Language Models\n- Training Stage: Pretraining & Post-training\n- Number of Parameters: 30.5B in total and 3.3B activated\n- Number of Paramaters (Non-Embedding): 29.9B\n- Number of Layers: 48\n- Number of Attention Heads (GQA): 32 for Q and 4 for KV\n- Number of Experts: 128\n- Number of Activated Experts: 8\n- Context Length: **262,144 natively**. \n\n**NOTE: This model supports only thinking mode. Meanwhile, specifying `enable_thinking=True` is no longer required.**\n\nAdditionally, to enforce model thinking, the default chat template automatically includes `\u003Cthink\u003E`. Therefore, it is normal for the model's output to contain only `\u003C/think\u003E` without an explicit opening `\u003Cthink\u003E` tag.\n\nFor more details, including benchmark evaluation, hardware requirements, and inference performance, please refer to our [blog](https://qwenlm.github.io/blog/qwen3/), [GitHub](https://github.com/QwenLM/Qwen3), and [Documentation](https://qwen.readthedocs.io/en/latest/).\n\n## Performance\n\n|  | Gemini2.5-Flash-Thinking | Qwen3-235B-A22B Thinking | Qwen3-30B-A3B Thinking | Qwen3-30B-A3B-Thinking-2507 |\n|--- | --- | --- | --- | --- |\n| **Knowledge** | | | | |\n| MMLU-Pro | 81.9 | **82.8** | 78.5 | 80.9 |\n| MMLU-Redux | 92.1 | **92.7** | 89.5 | 91.4 |\n| GPQA | **82.8** | 71.1 | 65.8 | 73.4 |\n| SuperGPQA | 57.8 | **60.7** | 51.8 | 56.8 |\n| **Reasoning** | | | | |\n| AIME25 | 72.0 | 81.5 | 70.9 | **85.0** |\n| HMMT25 | 64.2 | 62.5 | 49.8 | **71.4** |\n| LiveBench 20241125 | 74.3 | **77.1** | 74.3 | 76.8 |\n| **Coding** | | | | |\n| LiveCodeBench v6 (25.02-25.05) | 61.2 | 55.7 | 57.4 | **66.0** |\n| CFEval | 1995 | **2056** | 1940 | 2044 |\n| OJBench | 23.5 | **25.6** | 20.7 | 25.1 |\n| **Alignment** | | | | |\n| IFEval | **89.8** | 83.4 | 86.5 | 88.9 |\n| Arena-Hard v2$ | 56.7 | **61.5** | 36.3 | 56.0 |\n| Creative Writing v3 | **85.0** | 84.6 | 79.1 | 84.4 |\n| WritingBench | 83.9 | 80.3 | 77.0 | **85.0** |\n| **Agent** | | | | |\n| BFCL-v3 | 68.6 | 70.8 | 69.1 | **72.4** |\n| TAU1-Retail | 65.2 | 54.8 | 61.7 | **67.8** |\n| TAU1-Airline | **54.0** | 26.0 | 32.0 | 48.0 |\n| TAU2-Retail | **66.7** | 40.4 | 34.2 | 58.8 |\n| TAU2-Airline | 52.0 | 30.0 | 36.0 | **58.0** |\n| TAU2-Telecom | **31.6** | 21.9 | 22.8 | 26.3 |\n| **Multilingualism** | | | | |\n| MultiIF | 74.4 | 71.9 | 72.2 | **76.4** |\n| MMLU-ProX | **80.2** | 80.0 | 73.1 | 76.4 |\n| INCLUDE | **83.9** | 78.7 | 71.9 | 74.4 |\n| PolyMATH | 49.8 | **54.7** | 46.1 | 52.6 |\n\n$ For reproducibility, we report the win rates evaluated by GPT-4.1.\n\n\\& For highly challenging tasks (including PolyMATH and all reasoning and coding tasks), we use an output length of 81,920 tokens. For all other tasks, we set the output length to 32,768.\n\n\n## Quickstart\n\nThe code of Qwen3-MoE has been in the latest Hugging Face `transformers` and we advise you to use the latest version of `transformers`.\n\nWith `transformers\u003C4.51.0`, you will encounter the following error:\n```\nKeyError: 'qwen3_moe'\n```\n\nThe following contains a code snippet illustrating how to use the model generate content based on given inputs. \n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"Qwen/Qwen3-30B-A3B-Thinking-2507\"\n\n# load the tokenizer and the model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=\"auto\",\n    device_map=\"auto\"\n)\n\n# prepare the model input\nprompt = \"Give me a short introduction to large language model.\"\nmessages = [\n    {\"role\": \"user\", \"content\": prompt}\n]\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\n# conduct text completion\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=32768\n)\noutput_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n\n# parsing thinking content\ntry:\n    # rindex finding 151668 (\u003C/think\u003E)\n    index = len(output_ids) - output_ids[::-1].index(151668)\nexcept ValueError:\n    index = 0\n\nthinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\ncontent = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n\nprint(\"thinking content:\", thinking_content) # no opening \u003Cthink\u003E tag\nprint(\"content:\", content)\n\n```\n\nFor deployment, you can use `sglang\u003E=0.4.6.post1` or `vllm\u003E=0.8.5` or to create an OpenAI-compatible API endpoint:\n- SGLang:\n    ```shell\n    python -m sglang.launch_server --model-path Qwen/Qwen3-30B-A3B-Thinking-2507 --context-length 262144  --reasoning-parser deepseek-r1\n    ```\n- vLLM:\n    ```shell\n    vllm serve Qwen/Qwen3-30B-A3B-Thinking-2507 --max-model-len 262144 --enable-reasoning --reasoning-parser deepseek_r1\n    ```\n\n**Note: If you encounter out-of-memory (OOM) issues, you may consider reducing the context length to a smaller value. However, since the model may require longer token sequences for reasoning, we strongly recommend using a context length greater than 131,072 when possible.**\n\nFor local use, applications such as Ollama, LMStudio, MLX-LM, llama.cpp, and KTransformers have also supported Qwen3.\n\n## Agentic Use\n\nQwen3 excels in tool calling capabilities. We recommend using [Qwen-Agent](https://github.com/QwenLM/Qwen-Agent) to make the best use of agentic ability of Qwen3. Qwen-Agent encapsulates tool-calling templates and tool-calling parsers internally, greatly reducing coding complexity.\n\nTo define the available tools, you can use the MCP configuration file, use the integrated tool of Qwen-Agent, or integrate other tools by yourself.\n```python\nfrom qwen_agent.agents import Assistant\n\n# Define LLM\n# Using Alibaba Cloud Model Studio\nllm_cfg = {\n    'model': 'qwen3-30b-a3b-thinking-2507',\n    'model_type': 'qwen_dashscope',\n}\n\n# Using OpenAI-compatible API endpoint. It is recommended to disable the reasoning and the tool call parsing\n# functionality of the deployment frameworks and let Qwen-Agent automate the related operations. For example, \n# `VLLM_USE_MODELSCOPE=true vllm serve Qwen/Qwen3-30B-A3B-Thinking-2507 --served-model-name Qwen3-30B-A3B-Thinking-2507 --tensor-parallel-size 8 --max-model-len 262144`.\n#\n# llm_cfg = {\n#     'model': 'Qwen3-30B-A3B-Thinking-2507',\n# \n#     # Use a custom endpoint compatible with OpenAI API:\n#     'model_server': 'http://localhost:8000/v1',  # api_base without reasoning and tool call parsing\n#     'api_key': 'EMPTY',\n#     'generate_cfg': {\n#         'thought_in_content': True,\n#     },\n# }\n\n\n# Define Tools\ntools = [\n    {'mcpServers': {  # You can specify the MCP configuration file\n            'time': {\n                'command': 'uvx',\n                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']\n            },\n            \"fetch\": {\n                \"command\": \"uvx\",\n                \"args\": [\"mcp-server-fetch\"]\n            }\n        }\n    },\n  'code_interpreter',  # Built-in tools\n]\n\n# Define Agent\nbot = Assistant(llm=llm_cfg, function_list=tools)\n\n# Streaming generation\nmessages = [{'role': 'user', 'content': 'https://qwenlm.github.io/blog/ Introduce the latest developments of Qwen'}]\nfor responses in bot.run(messages=messages):\n    pass\nprint(responses)\n```\n\n## Processing Ultra-Long Texts\n\nTo support **ultra-long context processing** (up to **1 million tokens**), we integrate two key techniques:\n\n- **[Dual Chunk Attention](https://arxiv.org/abs/2402.17463) (DCA)**: A length extrapolation method that splits long sequences into manageable chunks while preserving global coherence.\n- **[MInference](https://arxiv.org/abs/2407.02490)**: A sparse attention mechanism that reduces computational overhead by focusing on critical token interactions.\n\nTogether, these innovations significantly improve both **generation quality** and **inference efficiency** for sequences beyond 256K tokens. On sequences approaching 1M tokens, the system achieves up to a **3Ã— speedup** compared to standard attention implementations.\n\nFor full technical details, see the [Qwen2.5-1M Technical Report](https://arxiv.org/abs/2501.15383).\n\n### How to Enable 1M Token Context\n\n\u003E [!NOTE]\n\u003E To effectively process a 1 million token context, users will require approximately **240 GB** of total GPU memory. This accounts for model weights, KV-cache storage, and peak activation memory demands.\n\n#### Step 1: Update Configuration File\n\nDownload the model and replace the content of your `config.json` with `config_1m.json`, which includes the config for length extrapolation and sparse attention.\n\n```bash\nexport MODELNAME=Qwen3-30B-A3B-Thinking-2507\nhuggingface-cli download Qwen/${MODELNAME} --local-dir ${MODELNAME}\nmv ${MODELNAME}/config.json ${MODELNAME}/config.json.bak\nmv ${MODELNAME}/config_1m.json ${MODELNAME}/config.json\n```\n\n#### Step 2: Launch Model Server\n\nAfter updating the config, proceed with either **vLLM** or **SGLang** for serving the model.\n\n#### Option 1: Using vLLM\n\nTo run Qwen with 1M context support:\n\n```bash\npip install -U vllm \\\n    --torch-backend=auto \\\n    --extra-index-url https://wheels.vllm.ai/nightly\n```\n\nThen launch the server with Dual Chunk Flash Attention enabled:\n\n```bash\nVLLM_ATTENTION_BACKEND=DUAL_CHUNK_FLASH_ATTN VLLM_USE_V1=0 \\\nvllm serve ./Qwen3-30B-A3B-Thinking-2507 \\\n  --tensor-parallel-size 4 \\\n  --max-model-len 1010000 \\\n  --enable-chunked-prefill \\\n  --max-num-batched-tokens 131072 \\\n  --enforce-eager \\\n  --max-num-seqs 1 \\\n  --gpu-memory-utilization 0.85 \\\n  --enable-reasoning --reasoning-parser deepseek_r1\n```\n\n##### Key Parameters\n\n| Parameter | Purpose |\n|--------|--------|\n| `VLLM_ATTENTION_BACKEND=DUAL_CHUNK_FLASH_ATTN` | Enables the custom attention kernel for long-context efficiency |\n| `--max-model-len 1010000` | Sets maximum context length to ~1M tokens |\n| `--enable-chunked-prefill` | Allows chunked prefill for very long inputs (avoids OOM) |\n| `--max-num-batched-tokens 131072` | Controls batch size during prefill; balances throughput and memory |\n| `--enforce-eager` | Disables CUDA graph capture (required for dual chunk attention) |\n| `--max-num-seqs 1` | Limits concurrent sequences due to extreme memory usage |\n| `--gpu-memory-utilization 0.85` | Set the fraction of GPU memory to be used for the model executor |\n\n#### Option 2: Using SGLang\n\nFirst, clone and install the specialized branch:\n\n```bash\ngit clone https://github.com/sgl-project/sglang.git\ncd sglang\npip install -e \"python[all]\"\n```\n\nLaunch the server with DCA support:\n\n```bash\npython3 -m sglang.launch_server \\\n    --model-path ./Qwen3-30B-A3B-Thinking-2507 \\\n    --context-length 1010000 \\\n    --mem-frac 0.75 \\\n    --attention-backend dual_chunk_flash_attn \\\n    --tp 4 \\\n    --chunked-prefill-size 131072 \\\n    --reasoning-parser deepseek-r1\n```\n\n##### Key Parameters\n\n| Parameter | Purpose |\n|---------|--------|\n| `--attention-backend dual_chunk_flash_attn` | Activates Dual Chunk Flash Attention |\n| `--context-length 1010000` | Defines max input length |\n| `--mem-frac 0.75` | The fraction of the memory used for static allocation (model weights and KV cache memory pool). Use a smaller value if you see out-of-memory errors. |\n| `--tp 4` | Tensor parallelism size (matches model sharding) |\n| `--chunked-prefill-size 131072` | Prefill chunk size for handling long inputs without OOM |\n\n#### Troubleshooting:\n\n1. Encountering the error: \"The model's max sequence length (xxxxx) is larger than the maximum number of tokens that can be stored in the KV cache.\" or \"RuntimeError: Not enough memory. Please try to increase --mem-fraction-static.\"\n\n    The VRAM reserved for the KV cache is insufficient.\n    - vLLM: Consider reducing the ``max_model_len`` or increasing the ``tensor_parallel_size`` and ``gpu_memory_utilization``. Alternatively, you can reduce ``max_num_batched_tokens``, although this may significantly slow down inference.\n    - SGLang: Consider reducing the ``context-length`` or increasing the ``tp`` and ``mem-frac``. Alternatively, you can reduce ``chunked-prefill-size``, although this may significantly slow down inference.\n\n2. Encountering the error: \"torch.OutOfMemoryError: CUDA out of memory.\"\n\n    The VRAM reserved for activation weights is insufficient. You can try lowering ``gpu_memory_utilization`` or ``mem-frac``, but be aware that this might reduce the VRAM available for the KV cache.\n\n3. Encountering the error: \"Input prompt (xxxxx tokens) + lookahead slots (0) is too long and exceeds the capacity of the block manager.\" or \"The input (xxx xtokens) is longer than the model's context length (xxx tokens).\"\n\n    The input is too lengthy. Consider using a shorter sequence or increasing the ``max_model_len`` or ``context-length``.\n\n#### Long-Context Performance\n\nWe test the model on an 1M version of the [RULER](https://arxiv.org/abs/2404.06654) benchmark.\n\n| Model Name                                  | Acc avg | 4k   | 8k   | 16k  | 32k  | 64k  | 96k  | 128k | 192k | 256k | 384k | 512k | 640k | 768k | 896k | 1000k |\n|---------------------------------------------|---------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|-------|\n| Qwen3-30B-A3B (Thinking)                    | 70.6    | 96.7 | 94.4 | 94.5 | 93.4 | 82.6 | 78.4 | 74.5 | 70.6 | 63.1 | 60.0 | 56.3 | 51.0 | 48.4 | 47.2 | 48.2  |\n| Qwen3-30B-A3B-Thinking-2507 (Full Attention)   | 91.4    | 99.6 | 100.0| 99.8 | 99.2 | 97.4 | 96.8 | 96.8 | 94.8 | 89.4 | 90.2 | 84.0 | 82.6 | 81.9 | 80.1 | 77.5  |\n| Qwen3-30B-A3B-Thinking-2507 (Sparse Attention) | 91.5 | 100.0| 99.2 | 99.1 | 98.5 | 97.3 | 97.1 | 96.9 | 95.8 | 89.0 | 89.3 | 85.5 | 84.8 | 80.0 | 79.9 | 79.6  |\n\n\n* All models are evaluated with Dual Chunk Attention enabled.\n* Since the evaluation is time-consuming, we use 260 samples for each length (13 sub-tasks, 20 samples for each).\n* To avoid overly verbose reasoning, we set the thinking budget to 8,192 tokens.\n\n## Best Practices\n\nTo achieve optimal performance, we recommend the following settings:\n\n1. **Sampling Parameters**:\n   - We suggest using `Temperature=0.6`, `TopP=0.95`, `TopK=20`, and `MinP=0`.\n   - For supported frameworks, you can adjust the `presence_penalty` parameter between 0 and 2 to reduce endless repetitions. However, using a higher value may occasionally result in language mixing and a slight decrease in model performance.\n\n2. **Adequate Output Length**: We recommend using an output length of 32,768 tokens for most queries. For benchmarking on highly complex problems, such as those found in math and programming competitions, we suggest setting the max output length to 81,920 tokens. This provides the model with sufficient space to generate detailed and comprehensive responses, thereby enhancing its overall performance.\n\n3. **Standardize Output Format**: We recommend usi",
      "public": true,
      "version": "7e9fe70a-0f7b-5c4d-a428-1cc88f712a5a",
      "tool_description": null,
      "slug": "chutes-qwen-qwen3-30b-a3b-thinking-2507",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-10-05T09:02:45.671281Z",
      "updated_at": "2025-10-09T18:38:03.654672Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 10256,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.08,
            "tao": 0.000198681697268201
          },
          "output": {
            "usd": 0.29,
            "tao": 0.000720221152597229
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [
        {
          "instance_id": "04e96dc3-e3f9-44ad-9cae-741ccb7397d5",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:37:10.126623Z"
        },
        {
          "instance_id": "e93b98c2-8576-4474-8226-ebda48e23d95",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:37:10.126623Z"
        },
        {
          "instance_id": "b6b638f2-9977-479e-841a-d8c9942b4f5a",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:30:34.596754Z"
        },
        {
          "instance_id": "525b02b8-5166-4cbb-ba15-36a60b820f3a",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:37:10.126623Z"
        },
        {
          "instance_id": "4f99a4a4-9484-4dbd-9530-2b08b4e51e09",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:37:10.126623Z"
        }
      ],
      "logo_id": "22f3d693-0b7d-47b8-ae9a-fa8afe4f7839",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "144afc2f379b542fdd4e85a1fcd5e1f79112d95d",
      "concurrency": 32,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/22f3d693-0b7d-47b8-ae9a-fa8afe4f7839.webp",
      "hot": true
    },
    {
      "chute_id": "aa9579f7-ac87-53d3-b23c-4fa97a64574d",
      "name": "Qwen/Qwen3-8B",
      "tagline": "Qwen3-8B is an 8.2 billion parameter open source language model that can switch between thinking and non-thinking modes for different tasks, with capabilities in reasoning, math, coding, creative writing, and support for over 100 languages.",
      "readme": "\n# Qwen3-8B\n\u003Ca href=\"https://chat.qwen.ai/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/%F0%9F%92%9C%EF%B8%8F%20Qwen%20Chat%20-536af5\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n\u003C/a\u003E\n\n## Qwen3 Highlights\n\nQwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support, with the following key features:\n\n- **Uniquely support of seamless switching between thinking mode** (for complex logical reasoning, math, and coding) and **non-thinking mode** (for efficient, general-purpose dialogue) **within single model**, ensuring optimal performance across various scenarios.\n- **Significantly enhancement in its reasoning capabilities**, surpassing previous QwQ (in thinking mode) and Qwen2.5 instruct models (in non-thinking mode) on mathematics, code generation, and commonsense logical reasoning.\n- **Superior human preference alignment**, excelling in creative writing, role-playing, multi-turn dialogues, and instruction following, to deliver a more natural, engaging, and immersive conversational experience.\n- **Expertise in agent capabilities**, enabling precise integration with external tools in both thinking and unthinking modes and achieving leading performance among open-source models in complex agent-based tasks.\n- **Support of 100+ languages and dialects** with strong capabilities for **multilingual instruction following** and **translation**.\n\n## Model Overview\n\n**Qwen3-8B** has the following features:\n- Type: Causal Language Models\n- Training Stage: Pretraining & Post-training\n- Number of Parameters: 8.2B\n- Number of Paramaters (Non-Embedding): 6.95B\n- Number of Layers: 36\n- Number of Attention Heads (GQA): 32 for Q and 8 for KV\n- Context Length: 32,768 natively and [131,072 tokens with YaRN](https://huggingface.co/Qwen/Qwen3-8B/raw/main/#processing-long-texts). \n\nFor more details, including benchmark evaluation, hardware requirements, and inference performance, please refer to our [blog](https://qwenlm.github.io/blog/qwen3/), [GitHub](https://github.com/QwenLM/Qwen3), and [Documentation](https://qwen.readthedocs.io/en/latest/).\n\n## Quickstart\n\nThe code of Qwen3 has been in the latest Hugging Face `transformers` and we advise you to use the latest version of `transformers`.\n\nWith `transformers\u003C4.51.0`, you will encounter the following error:\n```\nKeyError: 'qwen3'\n```\n\nThe following contains a code snippet illustrating how to use the model generate content based on given inputs. \n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"Qwen/Qwen3-8B\"\n\n# load the tokenizer and the model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=\"auto\",\n    device_map=\"auto\"\n)\n\n# prepare the model input\nprompt = \"Give me a short introduction to large language model.\"\nmessages = [\n    {\"role\": \"user\", \"content\": prompt}\n]\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\n# conduct text completion\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=32768\n)\noutput_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n\n# parsing thinking content\ntry:\n    # rindex finding 151668 (\u003C/think\u003E)\n    index = len(output_ids) - output_ids[::-1].index(151668)\nexcept ValueError:\n    index = 0\n\nthinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\ncontent = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n\nprint(\"thinking content:\", thinking_content)\nprint(\"content:\", content)\n```\n\nFor deployment, you can use `sglang\u003E=0.4.6.post1` or `vllm\u003E=0.8.5` or to create an OpenAI-compatible API endpoint:\n- SGLang:\n    ```shell\n    python -m sglang.launch_server --model-path Qwen/Qwen3-8B --reasoning-parser qwen3\n    ```\n- vLLM:\n    ```shell\n    vllm serve Qwen/Qwen3-8B --enable-reasoning --reasoning-parser deepseek_r1\n    ```\n\nFor local use, applications such as Ollama, LMStudio, MLX-LM, llama.cpp, and KTransformers have also supported Qwen3.\n\n## Switching Between Thinking and Non-Thinking Mode\n\n\u003E [!TIP]\n\u003E The `enable_thinking` switch is also available in APIs created by SGLang and vLLM. \n\u003E Please refer to our documentation for [SGLang](https://qwen.readthedocs.io/en/latest/deployment/sglang.html#thinking-non-thinking-modes) and [vLLM](https://qwen.readthedocs.io/en/latest/deployment/vllm.html#thinking-non-thinking-modes) users.\n\n### `enable_thinking=True`\n\nBy default, Qwen3 has thinking capabilities enabled, similar to QwQ-32B. This means the model will use its reasoning abilities to enhance the quality of generated responses. For example, when explicitly setting `enable_thinking=True` or leaving it as the default value in `tokenizer.apply_chat_template`, the model will engage its thinking mode.\n\n```python\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=True  # True is the default value for enable_thinking\n)\n```\n\nIn this mode, the model will generate think content wrapped in a `\u003Cthink\u003E...\u003C/think\u003E` block, followed by the final response.\n\n\u003E [!NOTE]\n\u003E For thinking mode, use `Temperature=0.6`, `TopP=0.95`, `TopK=20`, and `MinP=0` (the default setting in `generation_config.json`). **DO NOT use greedy decoding**, as it can lead to performance degradation and endless repetitions. For more detailed guidance, please refer to the [Best Practices](https://huggingface.co/Qwen/Qwen3-8B/raw/main/#best-practices) section.\n\n\n### `enable_thinking=False`\n\nWe provide a hard switch to strictly disable the model's thinking behavior, aligning its functionality with the previous Qwen2.5-Instruct models. This mode is particularly useful in scenarios where disabling thinking is essential for enhancing efficiency.\n\n```python\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=False  # Setting enable_thinking=False disables thinking mode\n)\n```\n\nIn this mode, the model will not generate any think content and will not include a `\u003Cthink\u003E...\u003C/think\u003E` block.\n\n\u003E [!NOTE]\n\u003E For non-thinking mode, we suggest using `Temperature=0.7`, `TopP=0.8`, `TopK=20`, and `MinP=0`. For more detailed guidance, please refer to the [Best Practices](https://huggingface.co/Qwen/Qwen3-8B/raw/main/#best-practices) section.\n\n### Advanced Usage: Switching Between Thinking and Non-Thinking Modes via User Input\n\nWe provide a soft switch mechanism that allows users to dynamically control the model's behavior when `enable_thinking=True`. Specifically, you can add `/think` and `/no_think` to user prompts or system messages to switch the model's thinking mode from turn to turn. The model will follow the most recent instruction in multi-turn conversations.\n\nHere is an example of a multi-turn conversation:\n\n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nclass QwenChatbot:\n    def __init__(self, model_name=\"Qwen/Qwen3-8B\"):\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n        self.history = []\n\n    def generate_response(self, user_input):\n        messages = self.history + [{\"role\": \"user\", \"content\": user_input}]\n\n        text = self.tokenizer.apply_chat_template(\n            messages,\n            tokenize=False,\n            add_generation_prompt=True\n        )\n\n        inputs = self.tokenizer(text, return_tensors=\"pt\")\n        response_ids = self.model.generate(**inputs, max_new_tokens=32768)[0][len(inputs.input_ids[0]):].tolist()\n        response = self.tokenizer.decode(response_ids, skip_special_tokens=True)\n\n        # Update history\n        self.history.append({\"role\": \"user\", \"content\": user_input})\n        self.history.append({\"role\": \"assistant\", \"content\": response})\n\n        return response\n\n# Example Usage\nif __name__ == \"__main__\":\n    chatbot = QwenChatbot()\n\n    # First input (without /think or /no_think tags, thinking mode is enabled by default)\n    user_input_1 = \"How many r's in strawberries?\"\n    print(f\"User: {user_input_1}\")\n    response_1 = chatbot.generate_response(user_input_1)\n    print(f\"Bot: {response_1}\")\n    print(\"----------------------\")\n\n    # Second input with /no_think\n    user_input_2 = \"Then, how many r's in blueberries? /no_think\"\n    print(f\"User: {user_input_2}\")\n    response_2 = chatbot.generate_response(user_input_2)\n    print(f\"Bot: {response_2}\") \n    print(\"----------------------\")\n\n    # Third input with /think\n    user_input_3 = \"Really? /think\"\n    print(f\"User: {user_input_3}\")\n    response_3 = chatbot.generate_response(user_input_3)\n    print(f\"Bot: {response_3}\")\n```\n\n\u003E [!NOTE]\n\u003E For API compatibility, when `enable_thinking=True`, regardless of whether the user uses `/think` or `/no_think`, the model will always output a block wrapped in `\u003Cthink\u003E...\u003C/think\u003E`. However, the content inside this block may be empty if thinking is disabled.\n\u003E When `enable_thinking=False`, the soft switches are not valid. Regardless of any `/think` or `/no_think` tags input by the user, the model will not generate think content and will not include a `\u003Cthink\u003E...\u003C/think\u003E` block.\n\n## Agentic Use\n\nQwen3 excels in tool calling capabilities. We recommend using [Qwen-Agent](https://github.com/QwenLM/Qwen-Agent) to make the best use of agentic ability of Qwen3. Qwen-Agent encapsulates tool-calling templates and tool-calling parsers internally, greatly reducing coding complexity.\n\nTo define the available tools, you can use the MCP configuration file, use the integrated tool of Qwen-Agent, or integrate other tools by yourself.\n```python\nfrom qwen_agent.agents import Assistant\n\n# Define LLM\nllm_cfg = {\n    'model': 'Qwen3-8B',\n\n    # Use the endpoint provided by Alibaba Model Studio:\n    # 'model_type': 'qwen_dashscope',\n    # 'api_key': os.getenv('DASHSCOPE_API_KEY'),\n\n    # Use a custom endpoint compatible with OpenAI API:\n    'model_server': 'http://localhost:8000/v1',  # api_base\n    'api_key': 'EMPTY',\n\n    # Other parameters:\n    # 'generate_cfg': {\n    #         # Add: When the response content is `\u003Cthink\u003Ethis is the thought\u003C/think\u003Ethis is the answer;\n    #         # Do not add: When the response has been separated by reasoning_content and content.\n    #         'thought_in_content': True,\n    #     },\n}\n\n# Define Tools\ntools = [\n    {'mcpServers': {  # You can specify the MCP configuration file\n            'time': {\n                'command': 'uvx',\n                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']\n            },\n            \"fetch\": {\n                \"command\": \"uvx\",\n                \"args\": [\"mcp-server-fetch\"]\n            }\n        }\n    },\n  'code_interpreter',  # Built-in tools\n]\n\n# Define Agent\nbot = Assistant(llm=llm_cfg, function_list=tools)\n\n# Streaming generation\nmessages = [{'role': 'user', 'content': 'https://qwenlm.github.io/blog/ Introduce the latest developments of Qwen'}]\nfor responses in bot.run(messages=messages):\n    pass\nprint(responses)\n```\n\n## Processing Long Texts\n\nQwen3 natively supports context lengths of up to 32,768 tokens. For conversations where the total length (including both input and output) significantly exceeds this limit, we recommend using RoPE scaling techniques to handle long texts effectively. We have validated the model's performance on context lengths of up to 131,072 tokens using the [YaRN](https://arxiv.org/abs/2309.00071) method.\n\nYaRN is currently supported by several inference frameworks, e.g., `transformers` and `llama.cpp` for local use, `vllm` and `sglang` for deployment. In general, there are two approaches to enabling YaRN for supported frameworks:\n\n- Modifying the model files:\n  In the `config.json` file, add the `rope_scaling` fields:\n    ```json\n    {\n        ...,\n        \"rope_scaling\": {\n            \"rope_type\": \"yarn\",\n            \"factor\": 4.0,\n            \"original_max_position_embeddings\": 32768\n        }\n    }\n    ```\n  For `llama.cpp`, you need to regenerate the GGUF file after the modification.\n\n- Passing command line arguments:\n\n  For `vllm`, you can use\n    ```shell\n    vllm serve ... --rope-scaling '{\"rope_type\":\"yarn\",\"factor\":4.0,\"original_max_position_embeddings\":32768}' --max-model-len 131072  \n    ```\n\n  For `sglang`, you can use\n    ```shell\n    python -m sglang.launch_server ... --json-model-override-args '{\"rope_scaling\":{\"rope_type\":\"yarn\",\"factor\":4.0,\"original_max_position_embeddings\":32768}}'\n    ```\n\n  For `llama-server` from `llama.cpp`, you can use\n    ```shell\n    llama-server ... --rope-scaling yarn --rope-scale 4 --yarn-orig-ctx 32768\n    ```\n\n\u003E [!IMPORTANT]\n\u003E If you encounter the following warning\n\u003E ```\n\u003E Unrecognized keys in `rope_scaling` for 'rope_type'='yarn': {'original_max_position_embeddings'}\n\u003E ```\n\u003E please upgrade `transformers\u003E=4.51.0`.\n\n\u003E [!NOTE]\n\u003E All the notable open-source frameworks implement static YaRN, which means the scaling factor remains constant regardless of input length, **potentially impacting performance on shorter texts.**\n\u003E We advise adding the `rope_scaling` configuration only when processing long contexts is required. \n\u003E It is also recommended to modify the `factor` as needed. For example, if the typical context length for your application is 65,536 tokens, it would be better to set `factor` as 2.0. \n\n\u003E [!NOTE]\n\u003E The default `max_position_embeddings` in `config.json` is set to 40,960. This allocation includes reserving 32,768 tokens for outputs and 8,192 tokens for typical prompts, which is sufficient for most scenarios involving short text processing. If the average context length does not exceed 32,768 tokens, we do not recommend enabling YaRN in this scenario, as it may potentially degrade model performance.\n\n\u003E [!TIP]\n\u003E The endpoint provided by Alibaba Model Studio supports dynamic YaRN by default and no extra configuration is needed.\n\n## Best Practices\n\nTo achieve optimal performance, we recommend the following settings:\n\n1. **Sampling Parameters**:\n   - For thinking mode (`enable_thinking=True`), use `Temperature=0.6`, `TopP=0.95`, `TopK=20`, and `MinP=0`. **DO NOT use greedy decoding**, as it can lead to performance degradation and endless repetitions.\n   - For non-thinking mode (`enable_thinking=False`), we suggest using `Temperature=0.7`, `TopP=0.8`, `TopK=20`, and `MinP=0`.\n   - For supported frameworks, you can adjust the `presence_penalty` parameter between 0 and 2 to reduce endless repetitions. However, using a higher value may occasionally result in language mixing and a slight decrease in model performance.\n\n2. **Adequate Output Length**: We recommend using an output length of 32,768 tokens for most queries. For benchmarking on highly complex problems, such as those found in math and programming competitions, we suggest setting the max output length to 38,912 tokens. This provides the model with sufficient space to generate detailed and comprehensive responses, thereby enhancing its overall performance.\n\n3. **Standardize Output Format**: We recommend using prompts to standardize model outputs when benchmarking.\n   - **Math Problems**: Include \"Please reason step by step, and put your final answer within \\boxed{}.\" in the prompt.\n   - **Multiple-Choice Questions**: Add the following JSON structure to the prompt to standardize responses: \"Please show your choice in the `answer` field with only the choice letter, e.g., `\"answer\": \"C\"`.\"\n\n4. **No Thinking Content in History**: In multi-turn conversations, the historical model output should only incl",
      "public": true,
      "version": "fc0b56b0-066d-5f34-bf12-1489f8e2afaa",
      "tool_description": null,
      "slug": "chutes-qwen-qwen3-8b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-04-28T22:13:31.171463Z",
      "updated_at": "2025-10-09T18:51:50.794153Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a100_40gb",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "exclude": [
          "mi300x",
          "b200"
        ],
        "include": null,
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 40,
        "compute_multiplier": 0.888888888888889,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a100_40gb",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 10187,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.05,
            "tao": 0.000124176060792625
          },
          "output": {
            "usd": 0.22,
            "tao": 0.000546374667487553
          }
        },
        "usd": {
          "hour": 4,
          "second": 0.00111111111111111
        },
        "tao": {
          "hour": 0.00993408486341006,
          "second": 0.000002759468017613
        }
      },
      "instances": [
        {
          "instance_id": "0a7b73a6-1cb8-481a-9d6a-3440be1116b5",
          "region": "n/a",
          "active": false,
          "verified": false,
          "last_verified_at": null
        },
        {
          "instance_id": "7e9f3ad9-2d90-4ddf-9fae-d8d528b874df",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:54:53.645913Z"
        },
        {
          "instance_id": "5071de4e-2b39-4944-813d-2b237bd8c680",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:55:18.720830Z"
        },
        {
          "instance_id": "d6c4507c-3a80-4492-94fc-b3a516e8e859",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:55:02.298755Z"
        },
        {
          "instance_id": "9cbd3d13-14bd-475c-ade1-cff886101127",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:55:07.763370Z"
        },
        {
          "instance_id": "5a54db33-0f56-4638-a200-c64390d54adb",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:55:37.872625Z"
        },
        {
          "instance_id": "f9b8d7f5-abcb-42fb-a95f-a3c2007631b9",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:27:08.792970Z"
        },
        {
          "instance_id": "90ab57d4-0fa7-499b-a8f9-57b05587e8de",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:55:06.344994Z"
        },
        {
          "instance_id": "17c0b69d-38bd-477e-b066-4e278d92ee78",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:55:25.528414Z"
        },
        {
          "instance_id": "710b6afe-47fe-467e-9078-3c951b76ff88",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:23:20.575241Z"
        },
        {
          "instance_id": "d6f20d15-0c38-4b44-86d9-83b0947c3ff3",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:24:03.135851Z"
        },
        {
          "instance_id": "a29394ea-31bc-4fc2-b180-796e295f4535",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:42.585748Z"
        },
        {
          "instance_id": "649eb426-1b24-4fa8-b796-9c7b83f024a9",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:24:11.665276Z"
        },
        {
          "instance_id": "6de1550f-0dd3-4688-bdf3-954df626381a",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:26:28.084814Z"
        },
        {
          "instance_id": "5c76bef9-1a95-4bb9-908e-c2117c32ae9c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:23:51.601455Z"
        },
        {
          "instance_id": "84a241ed-7df9-446e-a1e1-179e6ee24179",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:24:10.837731Z"
        },
        {
          "instance_id": "0f53cd02-58be-4c94-a718-92d8d93f4e81",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:24:15.561759Z"
        },
        {
          "instance_id": "324759b5-5b02-48a6-8692-18272af4bfc8",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:02:51.176575Z"
        },
        {
          "instance_id": "bbaf2d2d-451f-42d6-89e2-7e1034a18194",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:26:38.877587Z"
        },
        {
          "instance_id": "d11f555d-9ce9-4bca-81bd-76b5da752755",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:26:40.360962Z"
        },
        {
          "instance_id": "30dd0833-72bf-4130-9d28-2a41e6e3a79b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:25:18.827625Z"
        },
        {
          "instance_id": "4cecde28-334c-4aeb-b23c-e311c7422242",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:24:03.761148Z"
        },
        {
          "instance_id": "d4cbe1fb-0740-4140-bb61-856ef898d8b6",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:06:53.974038Z"
        },
        {
          "instance_id": "47c34d4b-2040-41aa-a760-1acfa5475aff",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:07:55.239301Z"
        },
        {
          "instance_id": "b2872c4e-a78b-43d3-9cf4-375c0e727235",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:10:51.712798Z"
        },
        {
          "instance_id": "2a4f01c5-8a1b-430f-84a8-d78e4cf08972",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:15:13.605376Z"
        },
        {
          "instance_id": "1bfadb79-2e5a-43df-9cee-028e07a793d7",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:10:48.836253Z"
        },
        {
          "instance_id": "952aada6-8759-46b9-ac04-45ab93e6952d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:10:50.911030Z"
        },
        {
          "instance_id": "e440af32-ca5c-48c5-9491-0a5fd091dfcc",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T11:18:27.200793Z"
        }
      ],
      "logo_id": "6866dead-21bd-481a-87aa-6c723c5fe9cb",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "a80f5e57cce20e57b65145f4213844dec1a80834",
      "concurrency": 32,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/6866dead-21bd-481a-87aa-6c723c5fe9cb.webp",
      "hot": true
    },
    {
      "chute_id": "6f0c08f6-5c08-54df-80af-3a3c0d671cbd",
      "name": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "tagline": "Qwen3-VL-235B-A22B is a 235B parameter multimodal model that combines advanced visual and language capabilities to handle tasks like GUI operation, visual coding, OCR in 32 languages, and long-context video understanding with a 256K context window.",
      "readme": "\u003Ca href=\"https://chat.qwenlm.ai/\" target=\"_blank\" style=\"margin: 2px;\"\u003E\n    \u003Cimg alt=\"Chat\" src=\"https://img.shields.io/badge/%F0%9F%92%9C%EF%B8%8F%20Qwen%20Chat%20-536af5\" style=\"display: inline-block; vertical-align: middle;\"/\u003E\n\u003C/a\u003E\n\n\n# Qwen3-VL-235B-A22B-Instruct\n\n\nMeet Qwen3-VL â€” the most powerful vision-language model in the Qwen series to date.\n\nThis generation delivers comprehensive upgrades across the board: superior text understanding & generation, deeper visual perception & reasoning, extended context length, enhanced spatial and video dynamics comprehension, and stronger agent interaction capabilities.\n\nAvailable in Dense and MoE architectures that scale from edge to cloud, with Instruct and reasoningâ€‘enhanced Thinking editions for flexible, onâ€‘demand deployment.\n\n\n#### Key Enhancements:\n\n* **Visual Agent**: Operates PC/mobile GUIsâ€”recognizes elements, understands functions, invokes tools, completes tasks.\n\n* **Visual Coding Boost**: Generates Draw.io/HTML/CSS/JS from images/videos.\n\n* **Advanced Spatial Perception**: Judges object positions, viewpoints, and occlusions; provides stronger 2D grounding and enables 3D grounding for spatial reasoning and embodied AI.\n\n* **Long Context & Video Understanding**: Native 256K context, expandable to 1M; handles books and hours-long video with full recall and second-level indexing.\n\n* **Enhanced Multimodal Reasoning**: Excels in STEM/Mathâ€”causal analysis and logical, evidence-based answers.\n\n* **Upgraded Visual Recognition**: Broader, higher-quality pretraining is able to â€œrecognize everythingâ€â€”celebrities, anime, products, landmarks, flora/fauna, etc.\n\n* **Expanded OCR**: Supports 32 languages (up from 19); robust in low light, blur, and tilt; better with rare/ancient characters and jargon; improved long-document structure parsing.\n\n* **Text Understanding on par with pure LLMs**: Seamless textâ€“vision fusion for lossless, unified comprehension.\n\n\n#### Model Architecture Updates:\n\n\u003Cp align=\"center\"\u003E\n    \u003Cimg src=\"https://qianwen-res.oss-accelerate.aliyuncs.com/Qwen3-VL/qwen3vl_arc.jpg\" width=\"80%\"/\u003E\n\u003Cp\u003E\n\n\n1. **Interleaved-MRoPE**: Fullâ€‘frequency allocation over time, width, and height via robust positional embeddings, enhancing longâ€‘horizon video reasoning.\n\n2. **DeepStack**: Fuses multiâ€‘level ViT features to capture fineâ€‘grained details and sharpen imageâ€“text alignment.\n\n3. **Textâ€“Timestamp Alignment:** Moves beyond Tâ€‘RoPE to precise, timestampâ€‘grounded event localization for stronger video temporal modeling.\n\nThis is the weight repository for Qwen3-VL-235B-A22B-Instruct.\n\n\n---\n\n## Model Performance\n\n**Multimodal performance**\n\n![](https://qianwen-res.oss-accelerate.aliyuncs.com/Qwen3-VL/table_nothinking_vl.jpg)\n\n**Pure text performance**\n![](https://qianwen-res.oss-accelerate.aliyuncs.com/Qwen3-VL/table_nothinking_text.jpg)\n\n## Quickstart\n\nBelow, we provide simple examples to show how to use Qwen3-VL with ğŸ¤– ModelScope and ğŸ¤— Transformers.\n\nThe code of Qwen3-VL has been in the latest Hugging Face transformers and we advise you to build from source with command:\n```\npip install git+https://github.com/huggingface/transformers\n# pip install transformers==4.57.0 # currently, V4.57.0 is not released\n```\n\n### Using ğŸ¤— Transformers to Chat\n\nHere we show a code snippet to show how to use the chat model with `transformers`:\n\n```python\nfrom transformers import Qwen3VLMoeForConditionalGeneration, AutoProcessor\n\n# default: Load the model on the available device(s)\nmodel = Qwen3VLMoeForConditionalGeneration.from_pretrained(\n    \"Qwen/Qwen3-VL-235B-A22B-Instruct\", dtype=\"auto\", device_map=\"auto\"\n)\n\n# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n# model = Qwen3VLMoeForConditionalGeneration.from_pretrained(\n#     \"Qwen/Qwen3-VL-235B-A22B-Instruct\",\n#     dtype=torch.bfloat16,\n#     attn_implementation=\"flash_attention_2\",\n#     device_map=\"auto\",\n# )\n\nprocessor = AutoProcessor.from_pretrained(\"Qwen/Qwen3-VL-235B-A22B-Instruct\")\n\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"image\",\n                \"image\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\",\n            },\n            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n        ],\n    }\n]\n\n# Preparation for inference\ninputs = processor.apply_chat_template(\n    messages,\n    tokenize=True,\n    add_generation_prompt=True,\n    return_dict=True,\n    return_tensors=\"pt\"\n)\n\n# Inference: Generation of the output\ngenerated_ids = model.generate(**inputs, max_new_tokens=128)\ngenerated_ids_trimmed = [\n    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n]\noutput_text = processor.batch_decode(\n    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n)\nprint(output_text)\n```\n\n\n\n## Citation\n\nIf you find our work helpful, feel free to give us a cite.\n\n```\n@misc{qwen3technicalreport,\n      title={Qwen3 Technical Report}, \n      author={Qwen Team},\n      year={2025},\n      eprint={2505.09388},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2505.09388}, \n}\n\n@article{Qwen2.5-VL,\n  title={Qwen2.5-VL Technical Report},\n  author={Bai, Shuai and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and Song, Sibo and Dang, Kai and Wang, Peng and Wang, Shijie and Tang, Jun and Zhong, Humen and Zhu, Yuanzhi and Yang, Mingkun and Li, Zhaohai and Wan, Jianqiang and Wang, Pengfei and Ding, Wei and Fu, Zheren and Xu, Yiheng and Ye, Jiabo and Zhang, Xi and Xie, Tianbao and Cheng, Zesen and Zhang, Hang and Yang, Zhibo and Xu, Haiyang and Lin, Junyang},\n  journal={arXiv preprint arXiv:2502.13923},\n  year={2025}\n}\n\n@article{Qwen2VL,\n  title={Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution},\n  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and Fan, Yang and Dang, Kai and Du, Mengfei and Ren, Xuancheng and Men, Rui and Liu, Dayiheng and Zhou, Chang and Zhou, Jingren and Lin, Junyang},\n  journal={arXiv preprint arXiv:2409.12191},\n  year={2024}\n}\n\n@article{Qwen-VL,\n  title={Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond},\n  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},\n  journal={arXiv preprint arXiv:2308.12966},\n  year={2023}\n}\n```",
      "public": true,
      "version": "47377f5a-6932-58f6-9da4-defe3c210741",
      "tool_description": null,
      "slug": "chutes-qwen-qwen3-vl-235b-a22b-instruct",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-10-04T12:24:23.950017Z",
      "updated_at": "2025-10-08T15:33:51.417950Z",
      "image": {
        "image_id": "959721f7-6184-549f-bd66-546c8868b9f7",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100800",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T14:43:47.661711Z",
        "build_started_at": "2025-10-08T14:44:11.231501Z",
        "build_completed_at": "2025-10-08T15:10:23.923875Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "df8eef013628",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 9800,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.3,
            "tao": 0.000745056364755754
          },
          "output": {
            "usd": 1.2,
            "tao": 0.00298022545902302
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "c1912e05-a805-4b63-8a37-952e3eb7f239",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:38:38.133249Z"
        },
        {
          "instance_id": "4499da55-dab7-4223-8308-ddb80c0118e1",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:38:38.133249Z"
        },
        {
          "instance_id": "4c813a8e-3bdd-4a1e-b0b3-7d52096543f6",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:38:38.133249Z"
        },
        {
          "instance_id": "75e382ae-e00b-4f0e-9144-3940ea3586c0",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:38:38.133249Z"
        },
        {
          "instance_id": "e53ea5f1-53bc-4dfe-814c-bffb3c156325",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:38:38.133249Z"
        }
      ],
      "logo_id": "1757a9fd-28ab-483f-958b-b8d9f4f9aa15",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "326b2e35ea25798d32df16d16d0dba461959e931",
      "concurrency": 64,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/1757a9fd-28ab-483f-958b-b8d9f4f9aa15.webp",
      "hot": true
    },
    {
      "chute_id": "5307a167-4955-5465-b3d3-24dbd526bdce",
      "name": "OpenGVLab/InternVL3-78B",
      "tagline": "InternVL3-78B is a 78 billion parameter open-source multimodal language model that excels at vision-language tasks like image and video understanding, reasoning, math, OCR, and GUI interactions, while maintaining strong language capabilities comparable to Qwen2.5.",
      "readme": "\n# InternVL3-78B\n\n[\\[ğŸ“‚ GitHub\\]](https://github.com/OpenGVLab/InternVL)  [\\[ğŸ“œ InternVL 1.0\\]](https://huggingface.co/papers/2312.14238)  [\\[ğŸ“œ InternVL 1.5\\]](https://huggingface.co/papers/2404.16821)  [\\[ğŸ“œ InternVL 2.5\\]](https://huggingface.co/papers/2412.05271)  [\\[ğŸ“œ InternVL2.5-MPO\\]](https://huggingface.co/papers/2411.10442)  [\\[ğŸ“œ InternVL3\\]](https://huggingface.co/papers/2504.10479)\n\n[\\[ğŸ†• Blog\\]](https://internvl.github.io/blog/)  [\\[ğŸ—¨ï¸ Chat Demo\\]](https://internvl.opengvlab.com/)  [\\[ğŸ¤— HF Demo\\]](https://huggingface.co/spaces/OpenGVLab/InternVL)  [\\[ğŸš€ Quick Start\\]](https://huggingface.co/OpenGVLab/InternVL3-78B/raw/main/#quick-start)  [\\[ğŸ“– Documents\\]](https://internvl.readthedocs.io/en/latest/)\n\n\u003Cdiv align=\"center\"\u003E\n  \u003Cimg width=\"500\" alt=\"image\" src=\"https://cdn-uploads.huggingface.co/production/uploads/64006c09330a45b03605bba3/zJsd2hqd3EevgXo6fNgC-.png\"\u003E\n\u003C/div\u003E\n\n## Introduction\n\nWe introduce InternVL3, an advanced multimodal large language model (MLLM) series that demonstrates superior overall performance.\nCompared to InternVL 2.5, InternVL3 exhibits superior multimodal perception and reasoning capabilities, while further extending its multimodal capabilities to encompass tool usage, GUI agents, industrial image analysis, 3D vision perception, and more.\nAdditionally, we compare InternVL3 with  Qwen2.5 Chat models, whose corresponding pre-trained base models are employed as the initialization of the langauge component in InternVL3. Benefitting from Native Multimodal Pre-Training, the InternVL3 series achieves even better overall text performance than the Qwen2.5 series.\n\n![image/png](https://huggingface.co/datasets/Weiyun1025/InternVL-Performance/resolve/main/internvl3/overall.png)\n\n## InternVL3 Family\n\nIn the following table, we provide an overview of the InternVL3 series.\n\n|  Model Name   |                                       Vision Part                                       |                                 Language Part                                  |                         HF Link                          |\n| :-----------: | :-------------------------------------------------------------------------------------: | :----------------------------------------------------------------------------: | :------------------------------------------------------: |\n| InternVL3-1B  | [InternViT-300M-448px-V2_5](https://huggingface.co/OpenGVLab/InternViT-300M-448px-V2_5) |            [Qwen2.5-0.5B](https://huggingface.co/Qwen/Qwen2.5-0.5B)            | [ğŸ¤— link](https://huggingface.co/OpenGVLab/InternVL3-1B)  |\n| InternVL3-2B  | [InternViT-300M-448px-V2_5](https://huggingface.co/OpenGVLab/InternViT-300M-448px-V2_5) |            [Qwen2.5-1.5B](https://huggingface.co/Qwen/Qwen2.5-1.5B)            | [ğŸ¤— link](https://huggingface.co/OpenGVLab/InternVL3-2B)  |\n| InternVL3-8B  | [InternViT-300M-448px-V2_5](https://huggingface.co/OpenGVLab/InternViT-300M-448px-V2_5) |              [Qwen2.5-7B](https://huggingface.co/Qwen/Qwen2.5-7B)              | [ğŸ¤— link](https://huggingface.co/OpenGVLab/InternVL3-8B)  |\n| InternVL3-9B  | [InternViT-300M-448px-V2_5](https://huggingface.co/OpenGVLab/InternViT-300M-448px-V2_5) | [internlm3-8b-instruct](https://huggingface.co/internlm/internlm3-8b-instruct) | [ğŸ¤— link](https://huggingface.co/OpenGVLab/InternVL3-9B)  |\n| InternVL3-14B | [InternViT-300M-448px-V2_5](https://huggingface.co/OpenGVLab/InternViT-300M-448px-V2_5) |             [Qwen2.5-14B](https://huggingface.co/Qwen/Qwen2.5-14B)             | [ğŸ¤— link](https://huggingface.co/OpenGVLab/InternVL3-14B) |\n| InternVL3-38B |   [InternViT-6B-448px-V2_5](https://huggingface.co/OpenGVLab/InternViT-6B-448px-V2_5)   |             [Qwen2.5-32B](https://huggingface.co/Qwen/Qwen2.5-32B)             | [ğŸ¤— link](https://huggingface.co/OpenGVLab/InternVL3-38B) |\n| InternVL3-78B |   [InternViT-6B-448px-V2_5](https://huggingface.co/OpenGVLab/InternViT-6B-448px-V2_5)   |             [Qwen2.5-72B](https://huggingface.co/Qwen/Qwen2.5-72B)             | [ğŸ¤— link](https://huggingface.co/OpenGVLab/InternVL3-78B) |\n\n![image/png](https://huggingface.co/datasets/Weiyun1025/InternVL-Performance/resolve/main/internvl3/overall-table.png)\n\n## Model Architecture\n\nAs shown in the following figure, [InternVL3](https://internvl.github.io/blog/2025-04-11-InternVL-3/) retains the same model architecture as [InternVL 2.5](https://internvl.github.io/blog/2024-12-05-InternVL-2.5/) and its predecessors, InternVL 1.5 and 2.0, following the \"ViT-MLP-LLM\" paradigm. In this new version, we integrate a newly incrementally pre-trained InternViT with various pre-trained LLMs, including InternLM 3 and Qwen 2.5, using a randomly initialized MLP projector.\n\n\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/64119264f0f81eb569e0d569/BiiyXN6NOk0p-3rl3ueyL.png)\n\nAs in the previous version, we applied a pixel unshuffle operation, reducing the number of visual tokens to one-quarter of the original. Besides, we adopted a similar dynamic resolution strategy as InternVL 1.5, dividing images into tiles of 448Ã—448 pixels. The key difference, starting from InternVL 2.0, is that we additionally introduced support for multi-image and video data.\n\nNotably, in InternVL3, we integrate the [Variable Visual Position Encoding (V2PE)](https://arxiv.org/abs/2412.09616), which utilizes smaller, more flexible position increments for visual tokens. Benefiting from V2PE, InternVL3 exhibits better long context understanding capabilities compared to its predecessors.\n\n## Training Strategy\n\n### Native Multimodal Pre-Training\n\nWe propose a [Native Multimodal Pre-Training](https://huggingface.co/papers/2504.10479) approach that consolidates language and vision learning into a single pre-training stage.\nIn contrast to standard paradigms that first train a language-only model and subsequently adapt it to handle additional modalities, our method interleaves multimodal data (e.g., image-text, video-text, or image-text interleaved sequences) with large-scale textual corpora. This unified training scheme allows the model to learn both linguistic and multimodal representations simultaneously, ultimately enhancing its capability to handle vision-language tasks without the need for separate alignment or bridging modules.\nPlease see [our paper](https://huggingface.co/papers/2504.10479) for more details.\n\n### Supervised Fine-Tuning\n\nIn this phase, the techniques of random JPEG compression, square loss re-weighting, and multimodal data packing proposed in [InternVL2.5](https://arxiv.org/abs/2412.05271) are also employed in the InternVL3 series.\nThe main advancement of the SFT phase in InternVL3 compared to InternVL2.5 lies in the use of higher-quality and more diverse training data.\nSpecifically, we further extend  training samples for tool use, 3D scene understanding, GUI operations, long context tasks, video understanding, scientific diagrams, creative writing, and multimodal reasoning.\n\n### Mixed Preference Optimization\n\nDuring Pre-training and SFT, the model is trained to predict the next token conditioned on previous ground-truth tokens.\nHowever, during inference, the model predicts each token based on its own prior outputs. \nThis discrepancy between ground-truth tokens and model-predicted tokens introduces a distribution shift, which can impair the modelâ€™s Chain-of-Thought (CoT) reasoning capabilities.\nTo mitigate this issue, we employ [MPO](https://arxiv.org/abs/2411.10442), which introduces additional supervision from both positive and negative samples to align the model response distribution with the ground-truth distribution, thereby improving reasoning performance.\nSpecifically, the training objective of MPO is a combination of\npreference loss \\\\(\\mathcal{L}_{\\text{p}}\\\\),\nquality loss \\\\(\\mathcal{L}_{\\text{q}}\\\\),\nand generation loss \\\\(\\mathcal{L}_{\\text{g}}\\\\),\nwhich can be formulated as follows:\n\n\n$$\n\\mathcal{L}=w_{p}\\cdot\\mathcal{L}_{\\text{p}} + w_{q}\\cdot\\mathcal{L}_{\\text{q}} + w_{g}\\cdot\\mathcal{L}_{\\text{g}},\n$$\n\n\nwhere \\\\(w_{*}\\\\) represents the weight assigned to each loss component. Please see [our paper](https://arxiv.org/abs/2411.10442) for more details about MPO.\n\n\n### Test-Time Scaling\n\nTest-Time Scaling has been shown to be an effective method to enhance the reasoning abilities of LLMs and MLLMs.\nIn this work, we use the Best-of-N evaluation strategy and employ [VisualPRM-8B](https://huggingface.co/OpenGVLab/VisualPRM-8B) as the critic model to select the best response for reasoning and mathematics evaluation.\n\n## Evaluation on Multimodal Capability\n\n### Multimodal Reasoning and Mathematics\n\n![image/png](https://huggingface.co/datasets/OpenGVLab/VisualPRM400K-v1.1/resolve/main/visualprm-performance.png)\n\n### OCR, Chart, and Document Understanding\n\n![image/png](https://huggingface.co/datasets/Weiyun1025/InternVL-Performance/resolve/main/internvl3/ocr.png)\n\n### Multi-Image & Real-World Comprehension\n\n![image/png](https://huggingface.co/datasets/Weiyun1025/InternVL-Performance/resolve/main/internvl3/multi-images.png)\n\n### Comprehensive Multimodal & Hallucination Evaluation\n\n![image/png](https://huggingface.co/datasets/Weiyun1025/InternVL-Performance/resolve/main/internvl3/comprehensive.png)\n\n### Visual Grounding\n\n![image/png](https://huggingface.co/datasets/Weiyun1025/InternVL-Performance/resolve/main/internvl3/grounding.png)\n\n### Multimodal Multilingual Understanding\n\n![image/png](https://huggingface.co/datasets/Weiyun1025/InternVL-Performance/resolve/main/internvl3/multilingual.png)\n\n### Video Understanding\n\n![image/png](https://huggingface.co/datasets/Weiyun1025/InternVL-Performance/resolve/main/internvl3/video.png)\n\n### GUI Grounding\n\n![image/png](https://huggingface.co/datasets/Weiyun1025/InternVL-Performance/resolve/main/internvl3/gui.png)\n\n### Spatial Reasoning\n\n![image/png](https://huggingface.co/datasets/Weiyun1025/InternVL-Performance/resolve/main/internvl3/vsi.png)\n\n## Evaluation on Language Capability\n\nWe compare InternVL3 with  Qwen2.5 Chat models, whose corresponding pre-trained base models are employed as the initialization of the langauge component in InternVL3.\nBenefitting from Native Multimodal Pre-Training, the InternVL3 series achieves even better overall text performance than the Qwen2.5 series.\nPlease note that the evaluation scores of Qwen2.5 series  may differ from those officially reported, as we have adopted the prompt versions provided in the table across all datasets for OpenCompass evaluation.\n\n![image/png](https://huggingface.co/datasets/Weiyun1025/InternVL-Performance/resolve/main/internvl3/text.png)\n\n## Ablation Study\n\n### Native Multimodal Pre-Training\n\nWe conduct experiments on the InternVL2-8B model while keeping its architecture, initialization parameters, and training data entirely unchanged. Traditionally, InternVL2-8B employs a training pipeline that begins with an MLP warmup phase for feature alignment followed by an Instruction Tuning stage. In our experiments, we substitute the conventional MLP warmup phase with a native multimodal pre-training process. This modification isolates the contribution of native multimodal pre-training to the overall multimodal capability of the model.\n\nThe evaluation results in the Figure below shows that the model with native multimodal pre-training exhibits performance on most benchmarks that is comparable to the fully multi-stage-trained InternVL2-8B baseline. Furthermore, when followed by instruction tuning on higher-quality data, the model demonstrates further performance gains across evaluated multimodal tasks. These findings underscore the efficiency of native multimodal pre-training in imparting powerful multimodal capabilities to MLLMs.\n\n![image/png](https://huggingface.co/datasets/Weiyun1025/InternVL-Performance/resolve/main/internvl3/ablation-native.png)\n\n### Mixed Preference Optimization\n\nAs shown in the table below, models fine-tuned with MPO demonstrate superior reasoning performance across seven multimodal reasoning benchmarks compared to their counterparts without MPO. Specifically, InternVL3-78B and InternVL3-38B outperform their counterparts by 4.1 and 4.5 points, respectively. Notably, the training data used for MPO is a subset of that used for SFT, indicating that the performance improvements primarily stem from the training algorithm rather than the training data.\n\n![image/png](https://huggingface.co/datasets/OpenGVLab/MMPR-v1.2/resolve/main/ablation-mpo.png)\n\n### Variable Visual Position Encoding\n\nAs reported in the table below, the introduction of V2PE leads to significant performance gains across most evaluation metrics. In addition, our ablation studiesâ€”by varying the positional increment \\\\( \\delta \\\\)â€”reveal that even for tasks primarily involving conventional contexts, relatively small \\\\( \\delta \\\\) values can achieve optimal performance. These findings provide important insights for future efforts aimed at refining position encoding strategies for visual tokens in MLLMs.\n\n![image/png](https://huggingface.co/datasets/Weiyun1025/InternVL-Performance/resolve/main/internvl3/ablation-v2pe.png)\n\n## Quick Start\n\nWe provide an example code to run `InternVL3-78B` using `transformers`.\n\n\u003E Please use transformers\u003E=4.37.2 to ensure the model works normally.\n\n### Model Loading\n\n#### 16-bit (bf16 / fp16)\n\n```python\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\npath = \"OpenGVLab/InternVL3-78B\"\nmodel = AutoModel.from_pretrained(\n    path,\n    torch_dtype=torch.bfloat16,\n    low_cpu_mem_usage=True,\n    use_flash_attn=True,\n    trust_remote_code=True).eval().cuda()\n```\n\n#### BNB 8-bit Quantization\n\n```python\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\npath = \"OpenGVLab/InternVL3-78B\"\nmodel = AutoModel.from_pretrained(\n    path,\n    torch_dtype=torch.bfloat16,\n    load_in_8bit=True,\n    low_cpu_mem_usage=True,\n    use_flash_attn=True,\n    trust_remote_code=True).eval()\n```\n\n#### Multiple GPUs\n\nThe reason for writing the code this way is to avoid errors that occur during multi-GPU inference due to tensors not being on the same device. By ensuring that the first and last layers of the large language model (LLM) are on the same device, we prevent such errors.\n\n```python\nimport math\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\n\ndef split_model(model_name):\n    device_map = {}\n    world_size = torch.cuda.device_count()\n    config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n    num_layers = config.llm_config.num_hidden_layers\n    # Since the first GPU will be used for ViT, treat it as half a GPU.\n    num_layers_per_gpu = math.ceil(num_layers / (world_size - 0.5))\n    num_layers_per_gpu = [num_layers_per_gpu] * world_size\n    num_layers_per_gpu[0] = math.ceil(num_layers_per_gpu[0] * 0.5)\n    layer_cnt = 0\n    for i, num_layer in enumerate(num_layers_per_gpu):\n        for j in range(num_layer):\n            device_map[f'language_model.model.layers.{layer_cnt}'] = i\n            layer_cnt += 1\n    device_map['vision_model'] = 0\n    device_map['mlp1'] = 0\n    device_map['language_model.model.tok_embeddings'] = 0\n    device_map['language_model.model.embed_tokens'] = 0\n    device_map['language_model.output'] = 0\n    device_map['language_model.model.norm'] = 0\n    device_map['language_model.model.rotary_emb'] = 0\n    device_map['language_model.lm_head'] = 0\n    device_map[f'language_model.model.layers.{num_layers - 1}'] = 0\n\n    return device_map\n\npath = \"OpenGVLab/InternVL3-78B\"\ndevice_map = split_model('InternVL3-78B')\nmodel = AutoModel.from_pretrained(\n    path,\n    torch_dtype=torch.bfloat16,\n    low_cpu_mem_usage=True,\n    use_flash_attn=True,\n    trust_remote_code=True,\n    device_map=device_map).eval()\n```\n\n### Inference with Transformers\n\n```python\nimport math\nimport numpy as np\nimport torch\nimport torchvision.transforms as T\nfrom decord import VideoReader, cpu\nfrom PIL import Image\nfrom torchvision.transforms.functional import InterpolationMode\nfrom transformers import AutoModel, AutoTokenizer\n\nIMAGENET_MEAN =",
      "public": true,
      "version": "ed32593c-a7ba-5e6e-9698-b5425dd17f44",
      "tool_description": null,
      "slug": "chutes-opengvlab-internvl3-78b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-09-14T10:36:44.571776Z",
      "updated_at": "2025-10-09T19:04:58.187041Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100",
        "h100_sxm",
        "h800",
        "a100_sxm"
      ],
      "node_selector": {
        "exclude": null,
        "include": [
          "h200",
          "h100",
          "h100_sxm",
          "a100",
          "a100_sxm",
          "h800"
        ],
        "gpu_count": 4,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 1.06666666666667,
        "supported_gpus": [
          "h200",
          "a100",
          "h100",
          "h100_sxm",
          "h800",
          "a100_sxm"
        ]
      },
      "invocation_count": 9074,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.07,
            "tao": 0.000173846485109676
          },
          "output": {
            "usd": 0.26,
            "tao": 0.000645715516121653
          }
        },
        "usd": {
          "hour": 4.8,
          "second": 0.00133333333333333
        },
        "tao": {
          "hour": 0.0119209018360921,
          "second": 0.000003311361621136
        }
      },
      "instances": [
        {
          "instance_id": "7f437d53-2b22-44b8-ba05-0097b26e7ae8",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:17:14.686205Z"
        },
        {
          "instance_id": "ba1267a1-5f4a-43f0-b2e2-eb933130985d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:17:14.686205Z"
        },
        {
          "instance_id": "ef17c330-69c6-44a1-92f4-276248c25bd9",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:17:14.686205Z"
        },
        {
          "instance_id": "822efc85-91ab-410b-a0d4-a6d0ac11e347",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:17:14.686205Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "4a42b163cc0e222e97b10b562eee98da6bf26077",
      "concurrency": 16,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "84bd3eb5-e262-5eb6-92c0-1b74a7f86ad7",
      "name": "zai-org/GLM-4-32B-0414",
      "tagline": "GLM-4-32B-0414 is a 32 billion parameter open-source language model that excels at code generation, web design, and reasoning tasks, with performance comparable to GPT-4 and DeepSeek models across various benchmarks.",
      "readme": "\n# GLM-4-32B-0414\n\n## Introduction\n\nThe GLM family welcomes new members, the **GLM-4-32B-0414** series models, featuring 32 billion parameters. Its performance is comparable to OpenAIâ€™s GPT series and DeepSeekâ€™s V3/R1 series. It also supports very user-friendly local deployment features. GLM-4-32B-Base-0414 was pre-trained on 15T of high-quality data, including substantial reasoning-type synthetic data. This lays the foundation for subsequent reinforcement learning extensions. In the post-training stage, we employed human preference alignment for dialogue scenarios. Additionally, using techniques like rejection sampling and reinforcement learning, we enhanced the modelâ€™s performance in instruction following, engineering code, and function calling, thus strengthening the atomic capabilities required for agent tasks. GLM-4-32B-0414 achieves good results in engineering code, Artifact generation, function calling, search-based Q&A, and report generation. In particular, on several benchmarks, such as code generation or specific Q&A tasks, GLM-4-32B-Base-0414 achieves comparable performance with those larger models like GPT-4o and DeepSeek-V3-0324 (671B).\n\n**GLM-Z1-32B-0414** is a reasoning model with deep thinking capabilities. This was developed based on GLM-4-32B-0414 through cold start, extended reinforcement learning, and further training on tasks including mathematics, code, and logic. Compared to the base model, GLM-Z1-32B-0414 significantly improves mathematical abilities and the capability to solve complex tasks. During training, we also introduced general reinforcement learning based on pairwise ranking feedback, which enhances the model's general capabilities.\n\n**GLM-Z1-Rumination-32B-0414** is a deep reasoning model with rumination capabilities (against OpenAI's Deep Research). Unlike typical deep thinking models, the rumination model is capable of deeper and longer thinking to solve more open-ended and complex problems (e.g., writing a comparative analysis of AI development in two cities and their future development plans). Z1-Rumination is trained through scaling end-to-end reinforcement learning with responses graded by the ground truth answers or rubrics and can make use of search tools during its deep thinking process to handle complex tasks. The model shows significant improvements in research-style writing and complex  tasks.\n\nFinally, **GLM-Z1-9B-0414** is a surprise. We employed all the aforementioned techniques to train a small model (9B). GLM-Z1-9B-0414  exhibits excellent capabilities in mathematical reasoning and general tasks. Its overall performance is top-ranked among all open-source models of the same size. Especially in resource-constrained scenarios, this model achieves an excellent balance between efficiency and effectiveness, providing a powerful option for users seeking lightweight deployment.\n\n## Showcase\n\n### Animation Generation\n\n\u003Ctable\u003E\n  \u003Ctr\u003E\n    \u003Ctd style=\"text-align: center; font-size: 16px; font-weight: bold; padding: 10px; width: 420px;\"\u003E\n      GLM-Z1-32B-0414\n    \u003C/td\u003E\n    \u003Ctd style=\"text-align: center; font-size: 16px; font-weight: bold; padding: 10px; width: 420px;\"\u003E\n      GLM-4-32B-0414\n    \u003C/td\u003E\n  \u003C/tr\u003E\n  \u003Ctr\u003E\n    \u003Ctd style=\"vertical-align: top; padding: 10px; width: 420px;\"\u003E\n      \u003Cvideo src=\"https://github.com/user-attachments/assets/849ff9fd-b54d-4c74-9ee5-3412e1a09e32\"\n             style=\"width: 400px; height: 300px; object-fit: contain;\" autoplay loop muted playsinline\u003E\u003C/video\u003E\n      \u003Cdiv style=\"margin-top: 10px; font-size: 14px; color: #333; width: 400px;\"\u003E\n        write a Python program that shows a ball bouncing inside a spinning hexagon. The ball should be affected by gravity and friction, and it must bounce off the rotating walls realistically\n      \u003C/div\u003E\n    \u003C/td\u003E\n    \u003Ctd style=\"vertical-align: top; padding: 10px; width: 420px;\"\u003E\n      \u003Cvideo src=\"https://github.com/user-attachments/assets/8dccdb9d-cc44-4732-b438-74a4e3cb9dfb\"\n             style=\"width: 400px; height: 300px; object-fit: contain;\" autoplay loop muted playsinline\u003E\u003C/video\u003E\n      \u003Cdiv style=\"margin-top: 10px; font-size: 14px; color: #333; width: 400px;\"\u003E\n         Use HTML to simulate the scenario of a small ball released from the center of a rotating hexagon. Consider the collision between the ball and the hexagon's edges, the gravity acting on the ball, and assume all collisions are perfectly elastic. (Prompt translated from Chinese)\n      \u003C/div\u003E\n    \u003C/td\u003E\n  \u003C/tr\u003E\n\u003C/table\u003E\n\n### Web Design\n\n\u003Ctable\u003E\n  \u003Ctr\u003E\n    \u003Ctd style=\"text-align: center; font-size: 16px; font-weight: bold; padding: 10px; width: 420px;\"\u003E\n      GLM-4-32B-0414\n    \u003C/td\u003E\n    \u003Ctd style=\"text-align: center; font-size: 16px; font-weight: bold; padding: 10px; width: 420px;\"\u003E\n      GLM-4-32B-0414\n    \u003C/td\u003E\n  \u003C/tr\u003E\n  \u003Ctr\u003E\n    \u003Ctd style=\"vertical-align: top; padding: 10px; width: 420px;\"\u003E\n      \u003Cimg src=\"https://github.com/user-attachments/assets/bd9c1fc1-c784-4e8f-9c76-5f7389a715f1\"/\u003E\n      \u003Cdiv style=\"margin-top: 10px; font-size: 14px; color: #333; width: 400px;\"\u003E\n          Design a drawing board that supports custom function plotting, allowing adding and deleting custom functions, and assigning colors to functions. (Prompt translated from Chinese)\n      \u003C/div\u003E\n    \u003C/td\u003E\n    \u003Ctd style=\"vertical-align: top; padding: 10px; width: 420px;\"\u003E\n      \u003Cimg src=\"https://github.com/user-attachments/assets/7ad12d52-9229-4278-8d1b-ffbf43e99070\"/\u003E\n      \u003Cdiv style=\"margin-top: 10px; font-size: 14px; color: #333; width: 400px;\"\u003E Design a UI for a mobile machine learning platform, which should include interfaces for training tasks, storage management, and personal statistics. The personal statistics interface should use charts to display the user's resource usage over a period. Use Tailwind CSS to style the page, and display these 3 mobile interfaces tiled on a single HTML page. (Prompt translated from Chinese) \u003C/div\u003E\n    \u003C/td\u003E\n  \u003C/tr\u003E\n\u003C/table\u003E\n\n### SVG Generation\n\n\u003Ctable\u003E\n  \u003Ctr\u003E\n    \u003Ctd style=\"text-align: center; font-size: 16px; font-weight: bold; padding: 10px; width: 420px;\"\u003E\n      GLM-4-32B-0414\n    \u003C/td\u003E\n    \u003Ctd style=\"text-align: center; font-size: 16px; font-weight: bold; padding: 10px; width: 420px;\"\u003E\n      GLM-4-32B-0414\n    \u003C/td\u003E\n  \u003C/tr\u003E\n  \u003Ctr\u003E\n    \u003Ctd style=\"vertical-align: top; padding: 10px; width: 420px;\"\u003E\n      \u003Cimg src=\"https://github.com/user-attachments/assets/9407e4c1-1876-4ab5-838c-839836fb418a\"/\u003E\n      \u003Cdiv style=\"margin-top: 10px; font-size: 14px; color: #333; width: 400px;\"\u003E\n          Create a misty Jiangnan scene using SVG. (Prompt translated from Chinese)\n      \u003C/div\u003E\n    \u003C/td\u003E\n    \u003Ctd style=\"vertical-align: top; padding: 10px; width: 420px;\"\u003E\n      \u003Cimg src=\"https://github.com/user-attachments/assets/bcce8c5a-cedf-45c8-b666-ddb023d5b49c\"/\u003E\n      \u003Cdiv style=\"margin-top: 10px; font-size: 14px; color: #333; width: 400px;\"\u003E Use SVG to illustrate the training process of an LLM. (Prompt translated from Chinese) \u003C/div\u003E\n    \u003C/td\u003E\n  \u003C/tr\u003E\n\u003C/table\u003E\n\n\n### Search-Based Writing\n\nFor search-based writing tasks, we use the following system prompt to have the model respond based on search results:\n\n```\nè¯·æ ¹æ®æ‰€ç»™æœç´¢è¿”å›ç»“æœå¯¹ç”¨æˆ·é—®é¢˜è¿›è¡Œä½œç­”ã€‚\n\n## æ³¨æ„\n1. å……åˆ†åˆ©ç”¨å’Œæ•´ç†æ”¶é›†åˆ°çš„ä¿¡æ¯ï¼Œè€Œä¸æ˜¯ç®€å•çš„å¤åˆ¶ç²˜è´´ï¼Œç”Ÿæˆç¬¦åˆç”¨æˆ·è¦æ±‚ä¸”æœ‰æ·±åº¦çš„ä¸“ä¸šç­”æ¡ˆã€‚\n2. æ‰€æä¾›ä¿¡æ¯å……åˆ†çš„æƒ…å†µä¸‹ï¼Œä½ çš„å›ç­”éœ€å°½å¯èƒ½å»¶é•¿ï¼Œä»ç”¨æˆ·æ„å›¾è§’åº¦å‡ºå‘ï¼Œæä¾›å…·æœ‰è¶³å¤Ÿä¿¡æ¯é‡å’Œå¤šè§’åº¦çš„å›å¤ã€‚\n3. å¦å¤–ï¼Œå¹¶éæ‰€æœ‰çš„æœç´¢ç»“æœéƒ½ä¸ç”¨æˆ·é—®é¢˜å¯†åˆ‡ç›¸å…³ï¼Œè¯·ä»”ç»†çš„ç”„åˆ«ã€ç­›é€‰å’Œåˆ©ç”¨ã€‚\n4. å®¢è§‚ç±»é—®ç­”çš„ç­”æ¡ˆé€šå¸¸éå¸¸ç®€çŸ­ï¼Œä½ å¯ä»¥é€‚å½“è¡¥å……ä¸€åˆ°ä¸¤å¥ç›¸å…³ä¿¡æ¯ï¼Œä»¥ä¸°å¯Œå†…å®¹ã€‚\n5. è¯·ç¡®ä¿ä½ çš„å›å¤æ ¼å¼ç¾è§‚ã€å¯è¯»æ€§å¼ºã€‚å¯¹äºå¤šå®ä½“å¯¹æ¯”æˆ–åˆ—ä¸¾ï¼Œå–„ç”¨åˆ—è¡¨æ ¼å¼æ¥å¸®åŠ©ç”¨æˆ·æ›´å¥½çš„ç†è§£ä¿¡æ¯ã€‚\n6. é™¤éç”¨æˆ·è¦æ±‚ï¼Œå¦åˆ™ä½ å›ç­”çš„è¯­è¨€è¯·äºç”¨æˆ·æé—®è¯­è¨€ä¿æŒä¸€è‡´ã€‚\n7. åœ¨é€‚å½“æƒ…å†µä¸‹åœ¨å¥å­æœ«å°¾ä½¿ç”¨ä¾‹å¦‚:ã€0â€ sourceã€‘çš„æ ¼å¼å¼•ç”¨æœç´¢ç»“æœã€‚\n```\n\nWhen using, you can obtain search results through methods such as `RAG` or `WebSearch`, and wrap them in `observation`, for example:\n\n```json\n[\n    {\n        \"role\": \"user\",\n        \"content\": \"Explore the common characteristics of children's literature, with a focus on its narrative techniques and thematic tendencies. This includes narrative techniques: common approaches in children's literature such as first-person, third-person, omniscient narrator, and interactive narration, and their influence on young readers. It also includes thematic tendencies: recurring themes in children's literature such as growth, adventure, friendship, and family, with an analysis of how these themes impact children's cognitive and emotional development. Additionally, other universal features such as the use of personification, repetitive language, symbolism and metaphor, and educational value should be considered. Please provide a detailed analytical report based on academic research, classic examples of children's literature, and expert opinions.\"\n    },\n    {\n        \"role\": \"observation\",\n        \"content\": \"ã€{id}â€ {title}â€ {url}ã€‘\\n{content}\"\n    },\n    ...\n]\n```\nFor the above prompt, we use an internal or external search model to obtain the search results. Using the format shown above, we can generate the following analysis report:\n\n\u003Cdiv style=\"height: 400px; width: 100%; overflow: auto; border: 5px solid #ddd; padding: 20px;\"\u003E\n\n# Analysis Report on Common Characteristics of Children's Literature\n\nChildren's literature, as a literary genre specifically created for children, possesses unique artistic features and expressive techniques. This report will comprehensively analyze the common characteristics of children's literature from three dimensions: narrative methods, thematic tendencies, and other universal features, integrating academic research, classic examples of children's literature, and expert viewpoints.\n\n## Narrative Methods and Their Impact on Child Readers\n\nThe narrative methods of children's literature exhibit diverse characteristics, including first-person, third-person, narration, and interactive storytelling. These different narrative perspectives and methods profoundly influence children's reading experiences and cognitive development.\n\n**First-person narration** is common in children's literature, unfolding the story from the perspective of a child protagonist. This narrative style bridges the gap between the reader and the story, making it easier for child readers to identify with the characters and develop emotional resonance. For example, many coming-of-age novels use first-person narration, allowing the protagonist to directly recount their experiences and feelings, making readers feel as though they are experiencing the joys and sorrows of growth alongside the protagonist. This narrative perspective lends the work a strong sense of authenticity and intimacy, helping to cultivate children's empathyã€1â€ sourceã€‘.\n\n**Third-person narration** offers a broader perspective, allowing the author to flexibly switch between different characters' viewpoints and present richer layers of the story. In children's literature, third-person omniscient narration enables the author to control the narrative pace, revealing or concealing information as needed to guide children's attention. At the same time, third-person narration facilitates direct dialogue between the author and the reader, conveying values or explaining complex concepts through narration. This narrative method positively influences children's macro-thinking and comprehensive understandingã€1â€ sourceã€‘.\n\n**Narration (authorial intrusion)** is a unique narrative technique in children's literature, where the author directly appears as the \"storyteller,\" explaining the background, commenting on characters, or posing questions to the reader. This technique is particularly common in classic fairy tales, such as the opening lines of *Andersen's Fairy Tales*: \"Once, there was a child...\" Narration helps children understand the story's context, fills cognitive gaps, and conveys the author's educational intent. Research shows that appropriate authorial intrusion aids children in grasping the story's structure and improving reading comprehensionã€5â€ sourceã€‘.\n\n**Interactive storytelling** is a new trend in contemporary children's literature, especially prominent in the digital media era. Interactive storytelling breaks the traditional unidirectional author-reader relationship, encouraging child readers to participate in the story's creation, such as by choosing plot directions, character dialogues, or endings. This participatory reading enhances children's sense of agency and fosters decision-making skills and creative thinking. For example, some children's reading apps incorporate interactive elements, allowing children to influence the story's development through clicks, drag-and-drop actions, and other operations, thereby gaining a stronger sense of immersion and achievementã€6â€ sourceã€‘. Interactive storytelling transforms children from passive information recipients into active meaning-makers, uniquely contributing to the development of their subjectivity.\n\n*Table: Common Narrative Methods in Children's Literature and Their Effects*\n\n| **Narrative Method** | **Characteristics** | **Impact on Child Readers** | **Classic Examples** |\n|----------------------|--------------------|----------------------------|---------------------|\n| **First-Person** | Told from the child protagonist's perspective | Enhances immersion, fosters empathy | *Charlotte's Web*, *The Straw House* |\n| **Third-Person** | Omniscient or limited perspective | Expands horizons, develops comprehensive understanding | *Harry Potter* series |\n| **Narration** | Direct authorial intrusion into the narrative | Aids comprehension, conveys values | *Andersen's Fairy Tales* |\n| **Interactive** | Encourages reader participation in creation | Cultivates agency and creative thinking | Children's interactive reading apps |\n\nNotably, the narrative methods of children's literature are often closely intertwined with the **childhood perspective**. The childhood perspective does not necessarily mean the narrator must be a child but refers to the work's ability to describe the world to the greatest extent from a child's heart, expressing their inner psychology and external circumstancesã€2â€ sourceã€‘. Through the childhood perspective, readers can embark on a spiritual journey with a child's mindset, a narrative strategy that creates a strong sense of realism, allowing child readers to achieve emotional identification and cognitive resonance during the reading processã€1â€ sourceã€‘. The use of the childhood perspective gives the work's language a perceptual and naive quality, often with a prose-like and spatial structure, artistic features that align with children's cognitive characteristics and aid their acceptance and understandingã€2â€ sourceã€‘.\n\n## Thematic Tendencies and Their Impact on Children's Cognitive and Emotional Development\n\nThe thematic choices in children's literature exhibit distinct tendencies, with common themes including growth, adventure, friendship, and family. These themes not only form the core content of children's literature but also subtly influence children's cognitive development and emotional shaping.\n\n**The theme of growth** is one of the central motifs in children's literature. Growth narratives are regarded as the artistic lifeblood of children's literature, focusing on depicting the pivotal moments of rapid psychological development in children, particularly the awakening and establishment of self-awarenessã€3â€ sourceã€‘. Growth literature typically includes three elements: an artistic portrayal of the self-awareness construction process in growing adolescents, a developmental story with logical propulsion, and the presentation of the protagonist's spiritual trials and quest for directionã€3â€ sourceã€‘. By reading growth-themed works, child readers can indirectly experience the confusion and breakthroughs of growing up and understand the formation of self-identity. Classics such as Astrid Lindgren's *Pippi Longstocking* and Cao Wenxuan's *The Straw House* vividly depict children's psychological growth trajectories in specific environments. Research indicates that growth-themed literary works help children build a positive self-concept and develop the courage and resilience to face challenges, positively contributing to their psychological developmentã€9â€ sourceã€‘.\n\n**The theme of adventure** holds",
      "public": true,
      "version": "39a1f883-5a61-5471-8281-a4a40d228794",
      "tool_description": null,
      "slug": "chutes-zai-org-glm-4-32b-0414",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-08-04T12:38:36.161913Z",
      "updated_at": "2025-10-09T19:49:44.030592Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a100_40gb",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "exclude": [
          "b200",
          "mi300x"
        ],
        "include": null,
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 40,
        "compute_multiplier": 0.888888888888889,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a100_40gb",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 7808,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.05,
            "tao": 0.000124176060792625
          },
          "output": {
            "usd": 0.22,
            "tao": 0.000546374667487553
          }
        },
        "usd": {
          "hour": 4,
          "second": 0.00111111111111111
        },
        "tao": {
          "hour": 0.00993408486341006,
          "second": 0.000002759468017613
        }
      },
      "instances": [
        {
          "instance_id": "92f08b3c-9fd1-49a4-bf58-a410f2e31235",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:18:49.418964Z"
        },
        {
          "instance_id": "99fc5066-58be-438d-90bc-3c8c07e68606",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:19:00.796429Z"
        },
        {
          "instance_id": "9eaa1f74-e780-4f9e-8e48-6e8926de30e8",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:18:40.024408Z"
        },
        {
          "instance_id": "8c9b147b-4934-4219-a672-90dc2eab1cb2",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:18:21.059127Z"
        },
        {
          "instance_id": "aedf4566-352e-4c8b-8bf1-2a02b3950b06",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:19:10.335204Z"
        },
        {
          "instance_id": "afb4fdc7-168a-4565-a5e2-9a7e5de2f9dd",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:18:24.741659Z"
        },
        {
          "instance_id": "e74462fe-9189-4cc8-a618-bbcb1b4d852d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:18:45.360352Z"
        },
        {
          "instance_id": "360a402c-09ee-47dd-95ce-f5ae5e1fd7a4",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:19:10.874547Z"
        },
        {
          "instance_id": "d6a11d37-7f30-4cda-81bd-1167cd4c431d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:18:44.672542Z"
        },
        {
          "instance_id": "334e37cd-dc96-4bf8-87ef-ad31cf63b175",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:18:48.029847Z"
        },
        {
          "instance_id": "b592a356-5454-4d8e-a9ba-3640a3e6da39",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:19:02.191104Z"
        },
        {
          "instance_id": "34fdf685-a1af-4da2-ac5b-a2a3f43f4690",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:19:58.560282Z"
        },
        {
          "instance_id": "44e6a22f-5b21-4427-b0dc-10e24777986d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:18:31.100355Z"
        },
        {
          "instance_id": "b5a14b64-2643-4981-be09-666c890f7a62",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:20:56.241066Z"
        }
      ],
      "logo_id": "2f38a940-fcf6-402a-8a39-a9e615269f36",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "077b5c2f5c43bd3239fd605a0600229e8facbd4a",
      "concurrency": 16,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/2f38a940-fcf6-402a-8a39-a9e615269f36.webp",
      "hot": true
    },
    {
      "chute_id": "cce76117-35fb-5aae-ba45-12d565422c56",
      "name": "Qwen/Qwen3-VL-235B-A22B-Thinking",
      "tagline": "",
      "readme": "Qwen/Qwen3-VL-235B-A22B-Thinking",
      "public": true,
      "version": "e6f09ab6-a276-5648-ac9f-f10b88ae099c",
      "tool_description": null,
      "slug": "chutes-qwen-qwen3-vl-235b-a22b-thinking",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "b9784def-b796-57d7-888e-8fef54b2207e",
      "created_at": "2025-09-24T16:47:57.559521Z",
      "updated_at": "2025-10-20T22:11:04.291268Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 7688,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.3,
            "tao": 0.000745056364755754
          },
          "output": {
            "usd": 1.2,
            "tao": 0.00298022545902302
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "73092e08-2a9a-4457-9619-7db2c45eab6b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T06:22:53.053361Z"
        },
        {
          "instance_id": "ed6ea48d-2c1c-4130-8352-4d75741d6107",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T04:07:51.764952Z"
        },
        {
          "instance_id": "37be80b2-228f-4ee9-943c-c806ccfde5bf",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T03:09:37.788065Z"
        },
        {
          "instance_id": "e2648b5f-3f61-4f8d-b861-8bccc5404abd",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T03:32:58.316943Z"
        },
        {
          "instance_id": "171379a1-d544-4a47-8d8c-33b7d3149da4",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T03:33:11.509256Z"
        }
      ],
      "logo_id": "00c7dc5f-063f-41c8-aa85-aff45fb70628",
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "c6a4947308cff8b5dcd126e37d394e8d3f97fac9",
      "concurrency": 40,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/00c7dc5f-063f-41c8-aa85-aff45fb70628.webp",
      "hot": true
    },
    {
      "chute_id": "5e0f5565-8c8c-59a5-bcc9-8f419a4b3c3c",
      "name": "affinefdn/Affine-gpt-oss-120",
      "tagline": "",
      "readme": "affinefdn/Affine-gpt-oss-120",
      "public": false,
      "version": "463c726e-d7a7-51c6-9ee5-f8367f31a944",
      "tool_description": null,
      "slug": "affine2-affinefdn-affine-gpt-oss-120",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-04T02:08:05.659234Z",
      "updated_at": "2025-10-20T17:47:34.533278Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "affine2",
        "user_id": "cd092eeb-9df5-57a9-8f35-17f70dc24804",
        "logo_id": null,
        "created_at": "2025-06-16T12:50:11.659590Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 6855,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.82,
            "tao": 0.00203648739699906
          },
          "output": {
            "usd": 3.29,
            "tao": 0.00817078480015477
          }
        },
        "usd": {
          "hour": 30.25,
          "second": 0.00840277777777778
        },
        "tao": {
          "hour": 0.0751265167795386,
          "second": 0.000020868476883205
        }
      },
      "instances": [
        {
          "instance_id": "331df6f4-f418-4db2-94af-35f514b50ecc",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T11:19:12.402575Z"
        },
        {
          "instance_id": "d2bc68d5-c7ec-4d9c-a3e3-da0ef6cc7fb7",
          "region": "n/a",
          "active": false,
          "verified": false,
          "last_verified_at": null
        },
        {
          "instance_id": "789e7dc1-fead-4523-9e83-59e402a6ab3d",
          "region": "n/a",
          "active": false,
          "verified": true,
          "last_verified_at": "2025-10-21T11:18:58.200603Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "3c4ddf6e1e308558ee6c4c44faed855b9daf1484",
      "concurrency": 8,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "3e9fd9b9-127e-552d-9d8b-97d121b18200",
      "name": "hO61qjpwxu/Affine_m3_5000_w2540",
      "tagline": "",
      "readme": "hO61qjpwxu/Affine_m3_5000_w2540",
      "public": false,
      "version": "7a8ffeda-93cc-5352-9eac-ce47c486d402",
      "tool_description": null,
      "slug": "wang-d5-ho61qjpwxu-affine-m3-5000-w2540",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "0315a7ff-bd8f-5415-a4f7-d0a367cfcfde",
      "created_at": "2025-10-19T16:35:43.720032Z",
      "updated_at": "2025-10-19T16:35:43.720032Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "wang_d5",
        "user_id": "8f8ed7ae-6136-57e5-886a-c3a68f289e80",
        "logo_id": null,
        "created_at": "2025-10-19T16:27:56.059261Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "b200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 5503,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [
        {
          "instance_id": "0ed697ee-ce7b-4fa1-b3ca-c66a4dddc130",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:12:02.207832Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "bfd6a4c49cf57e9a81f78d464fbc9c119894b37b",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "4993e95e-3f1c-5d89-91f3-df0384f52973",
      "name": "unsloth/gemma-2-9b-it",
      "tagline": "This is a collection of optimized, memory-efficient implementations of popular open source LLMs (including Llama 3 8B, Gemma 2 9B, and Mistral 7-9B) that can be finetuned 2-5x faster than standard implementations for tasks like conversation and text completion.",
      "readme": "\n## Reminder to use the dev version Transformers:\n`pip install git+https://github.com/huggingface/transformers.git`\n\n# Finetune Gemma, Llama 3, Mistral 2-5x faster with 70% less memory via Unsloth!\n\nDirectly quantized 4bit model with `bitsandbytes`.\n\nWe have a Google Colab Tesla T4 notebook for **Gemma 2 (9B)** here: https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing\n\n[\u003Cimg src=\"https://raw.githubusercontent.com/unslothai/unsloth/main/images/Discord%20button.png\" width=\"200\"/\u003E](https://discord.gg/u54VK8m8tk)\n[\u003Cimg src=\"https://raw.githubusercontent.com/unslothai/unsloth/main/images/buy%20me%20a%20coffee%20button.png\" width=\"200\"/\u003E](https://ko-fi.com/unsloth)\n[\u003Cimg src=\"https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20made%20with%20love.png\" width=\"200\"/\u003E](https://github.com/unslothai/unsloth)\n\n## âœ¨ Finetune for Free\n\nAll notebooks are **beginner friendly**! Add your dataset, click \"Run All\", and you'll get a 2x faster finetuned model which can be exported to GGUF, vLLM or uploaded to Hugging Face.\n\n| Unsloth supports          |    Free Notebooks                                                                                           | Performance | Memory use |\n|-----------------|--------------------------------------------------------------------------------------------------------------------------|-------------|----------|\n| **Llama 3 (8B)**      | [â–¶ï¸ Start on Colab](https://colab.research.google.com/drive/135ced7oHytdxu3N2DNe1Z0kqjyYIkDXp?usp=sharing)               | 2.4x faster | 58% less |\n| **Gemma 2 (9B)**      | [â–¶ï¸ Start on Colab](https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing)               | 2x faster | 63% less |\n| **Mistral (9B)**    | [â–¶ï¸ Start on Colab](https://colab.research.google.com/drive/1Dyauq4kTZoLewQ1cApceUQVNcnnNTzg_?usp=sharing)               | 2.2x faster | 62% less |\n| **Phi 3 (mini)**      | [â–¶ï¸ Start on Colab](https://colab.research.google.com/drive/1lN6hPQveB_mHSnTOYifygFcrO8C1bxq4?usp=sharing)               | 2x faster | 63% less |\n| **TinyLlama**  | [â–¶ï¸ Start on Colab](https://colab.research.google.com/drive/1AZghoNBQaMDgWJpi4RbffGM1h6raLUj9?usp=sharing)              | 3.9x faster | 74% less |\n| **CodeLlama (34B)** A100   | [â–¶ï¸ Start on Colab](https://colab.research.google.com/drive/1y7A0AxE3y8gdj4AVkl2aZX47Xu3P1wJT?usp=sharing)              | 1.9x faster | 27% less |\n| **Mistral (7B)** 1xT4  | [â–¶ï¸ Start on Kaggle](https://www.kaggle.com/code/danielhanchen/kaggle-mistral-7b-unsloth-notebook) | 5x faster\\* | 62% less |\n| **DPO - Zephyr**     | [â–¶ï¸ Start on Colab](https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing)               | 1.9x faster | 19% less |\n\n- This [conversational notebook](https://colab.research.google.com/drive/1Aau3lgPzeZKQ-98h69CCu1UJcvIBLmy2?usp=sharing) is useful for ShareGPT ChatML / Vicuna templates.\n- This [text completion notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing) is for raw text. This [DPO notebook](https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing) replicates Zephyr.\n- \\* Kaggle has 2x T4s, but we use 1. Due to overhead, 1x T4 is 5x faster.",
      "public": true,
      "version": "d152b441-a663-59ed-817b-cc9cf1fc0228",
      "tool_description": null,
      "slug": "chutes-unsloth-gemma-2-9b-it",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-03-22T12:37:40.816567Z",
      "updated_at": "2025-10-09T18:50:07.137012Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "exclude": [
          "5090",
          "b200",
          "h200",
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 5483,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [
        {
          "instance_id": "14db6435-6c9a-41e8-ab3d-47cba38caf50",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:14:11.799243Z"
        },
        {
          "instance_id": "5385741e-a85a-4b5f-9962-e07d5d3c6a05",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:14:11.799243Z"
        },
        {
          "instance_id": "7dca6838-c876-40f1-9e64-da4287e658ed",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:14:11.799243Z"
        },
        {
          "instance_id": "95099c86-f55f-44a7-a81f-a65245c93b9c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:14:11.799243Z"
        },
        {
          "instance_id": "ad99affe-ae3f-4bce-abe8-73c801ebb433",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:14:11.799243Z"
        }
      ],
      "logo_id": "65861fbe-5b9b-42c8-a459-6a694e6c423c",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "fc7d4737cda11c3a19af2b722319e846670b4d89",
      "concurrency": 8,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/65861fbe-5b9b-42c8-a459-6a694e6c423c.webp",
      "hot": true
    },
    {
      "chute_id": "cecae841-ca3f-5a55-adae-02de1721fa01",
      "name": "axon1/affine_255_m5_4_mix2",
      "tagline": "",
      "readme": "axon1/affine_255_m5_4_mix2",
      "public": false,
      "version": "94b8c82e-10d3-5238-b624-16a41181195b",
      "tool_description": null,
      "slug": "alx-miner5-axon1-affine-255-m5-4-mix2",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-13T20:33:16.542966Z",
      "updated_at": "2025-10-20T17:49:43.683155Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "alx_miner5",
        "user_id": "da4bf811-dbec-5817-a889-ee3487db6af7",
        "logo_id": null,
        "created_at": "2025-10-08T14:03:48.466975Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a100_40gb",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "b200",
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 40,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a100_40gb",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 5262,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [
        {
          "instance_id": "fd4e136f-9f66-4aaa-811b-ce81cd7c9bf0",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T04:14:19.906955Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "e286d603f60842869e9fb3d2242304f61c1d8599",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "afc1396b-f8aa-547c-8420-d4b5396334f9",
      "name": "axon1/affine_77_m1_4_1",
      "tagline": "",
      "readme": "axon1/affine_77_m1_4_1",
      "public": false,
      "version": "0d3076d1-47e4-5dfe-9447-8d8484bc4f93",
      "tool_description": null,
      "slug": "alx-miner1-axon1-affine-77-m1-4-1",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-13T17:10:47.539169Z",
      "updated_at": "2025-10-20T17:49:31.215987Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "alx_miner1",
        "user_id": "4f3c1d42-2f35-5283-b4c1-41216c2247c0",
        "logo_id": null,
        "created_at": "2025-10-12T14:47:38.653271Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a100_40gb",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "b200",
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 40,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a100_40gb",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 5150,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [
        {
          "instance_id": "e39e0cce-b4fb-4f69-8a61-162be09da3e7",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:57:38.859996Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "ea4810d0e0b272ebaa983433904fe7f8cbb4ae9a",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "d126b161-3e52-50d3-a3c7-922bf3ffe77a",
      "name": "zatup/Affine-5GReXDWPGuFABvUybRF5TNredbEPcwrXp59xyX4YTn57gT7r",
      "tagline": "",
      "readme": "zatup/Affine-5GReXDWPGuFABvUybRF5TNredbEPcwrXp59xyX4YTn57gT7r",
      "public": false,
      "version": "5e77c6cf-a7d8-515e-bfa4-da474612b72b",
      "tool_description": null,
      "slug": "jopaa208-zatup-affine-5grexdwpgufabvuybrf5tnredbepcwrxp59x",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-10T16:19:05.490485Z",
      "updated_at": "2025-10-20T18:13:55.416556Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "JOPAa208",
        "user_id": "06268524-9802-57c4-bd89-2ea9ea1ca7f9",
        "logo_id": null,
        "created_at": "2025-09-17T16:56:58.448786Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 5009,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "5adc8b1a-ad58-4406-9e7c-399c2e0d084e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T22:59:32.375347Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "da7f7b07a53f5bcfa0719ddb73ccaf7bf0af54b0",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "4185546f-73ec-5194-9e6a-e2171113e38b",
      "name": "axon1/affine_192_m2_4_7",
      "tagline": "",
      "readme": "axon1/affine_192_m2_4_7",
      "public": false,
      "version": "be508479-b01e-577b-9cee-f793ea467df8",
      "tool_description": null,
      "slug": "alx-miner2-axon1-affine-192-m2-4-7",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-17T15:26:39.498276Z",
      "updated_at": "2025-10-20T17:48:29.787633Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "alx_miner2",
        "user_id": "b34ef900-02f4-5333-aed4-82d2f945a6fb",
        "logo_id": null,
        "created_at": "2025-08-18T20:05:14.552248Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a100_40gb",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "b200",
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 40,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a100_40gb",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 5008,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [
        {
          "instance_id": "c2610a25-3507-4dca-a98c-6a8de4614266",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:11:54.956671Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "89d43320dfe58402ff99aa23f512e4c0060f107a",
      "concurrency": 24,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "00331b13-3614-5b0a-ab48-56116167aeef",
      "name": "moonshotai/Kimi-Dev-72B",
      "tagline": "Kimi-Dev-72B is a 72 billion parameter open-source language model specifically optimized for software engineering tasks through reinforcement learning, achieving state-of-the-art performance on code issue resolution and testing.",
      "readme": "\u003C!-- # Kimi-Dev --\u003E\n\n\u003Cdiv align=\"center\"\u003E\n  \u003Cimg src=\"./assets/main_logo.png\" alt=\"Kimi Logo\" width=\"400\" /\u003E\n\u003Ch2\u003E\u003Ca href=\"https://moonshotai.github.io/Kimi-Dev/\"\u003E\nIntroducing Kimi-Dev: \u003Cbr\u003EA Strong and Open-source Coding LLM for Issue Resolution\u003C/a\u003E\u003C/h2\u003E\n\u003C/a\u003E\u003C/h2\u003E\n\u003Cb\u003EKimi-Dev Team\u003C/b\u003E\n\u003Cbr\u003E\n\n\u003C/div\u003E\n\u003Cdiv align=\"center\"\u003E\n  \u003Ca href=\"\"\u003E\n    \u003Cb\u003EğŸ“„ Tech Report (Coming soon...)\u003C/b\u003E\n  \u003C/a\u003E &nbsp;|&nbsp;\n  \u003Ca href=\"https://github.com/MoonshotAI/Kimi-Dev\"\u003E\n    \u003Cb\u003EğŸ“„ Github\u003C/b\u003E\n  \u003C/a\u003E &nbsp;\n\u003C/div\u003E\n\n\u003Cbr\u003E\n\u003Cbr\u003E\n\n\u003C!-- https://github.com/MoonshotAI/Kimi-Dev --\u003E\n\nWe introduce Kimi-Dev-72B, our new open-source coding LLM for software engineering tasks. Kimi-Dev-72B achieves a new state-of-the-art on SWE-bench Verified among open-source models.\n\n- Kimi-Dev-72B achieves 60.4% performance on SWE-bench Verified. It surpasses the runner-up, setting a new state-of-the-art result among open-source models.\n\n\n- Kimi-Dev-72B is optimized via large-scale reinforcement learning. It autonomously patches real repositories in Docker and gains rewards only when the entire test suite passes. This ensures correct and robust solutions, aligning with real-world development standards.\n\n\n- Kimi-Dev-72B is available for download and deployment on Hugging Face and GitHub. We welcome developers and researchers to explore its capabilities and contribute to development.\n\n\n\u003Cdiv align=\"center\"\u003E\n  \u003Cimg src=\"./assets/open_performance_white.png\" alt=\"Kimi Logo\" width=\"600\" /\u003E\n  \u003Cp\u003E\u003Cb\u003EPerformance of Open-source Models on SWE-bench Verified.\u003C/b\u003E\u003C/p\u003E\n\n\u003C/div\u003E\n\n\n\n## Quick Start\n```\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"moonshotai/Kimi-Dev-72B\"\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=\"auto\",\n    device_map=\"auto\"\n)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nprompt = \"Give me a short introduction to large language model.\"\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": prompt}\n]\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True\n)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=512\n)\ngenerated_ids = [\n    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n]\n\nresponse = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n\n```\n\n## Citation\n```\n@misc{kimi_dev_72b_2025,\n  title        = {Introducing Kimi-Dev: A Strong and Open-source Coding LLM for Issue Resolution},\n  author       = {{Kimi-Dev Team}},\n  year         = {2025},\n  month        = {June},\n  url          = {\\url{https://www.moonshot.cn/Kimi-Dev}}\n}\n```",
      "public": true,
      "version": "3196de98-2b59-5c21-a19e-a29aecff3b04",
      "tool_description": null,
      "slug": "chutes-moonshotai-kimi-dev-72b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-06-16T16:59:58.073844Z",
      "updated_at": "2025-10-09T18:38:44.031104Z",
      "image": {
        "image_id": "f0fdd089-b359-5626-89fa-307657ca3cb0",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025100801",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-08T16:56:08.597781Z",
        "build_started_at": "2025-10-08T16:56:11.197022Z",
        "build_completed_at": "2025-10-08T17:10:14.872489Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "358b07c50eb0",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h100",
        "h100_sxm",
        "h800",
        "a100_sxm"
      ],
      "node_selector": {
        "exclude": null,
        "include": [
          "h100",
          "h100_sxm",
          "h100_nvl",
          "h200",
          "h800",
          "a100",
          "a100_sxm"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 80,
        "compute_multiplier": 2.13333333333333,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h100",
          "h100_sxm",
          "h800",
          "a100_sxm"
        ]
      },
      "invocation_count": 4917,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.13,
            "tao": 0.000322857758060826
          },
          "output": {
            "usd": 0.52,
            "tao": 0.00129143103224331
          }
        },
        "usd": {
          "hour": 9.6,
          "second": 0.00266666666666667
        },
        "tao": {
          "hour": 0.0238418036721841,
          "second": 0.000006622723242273
        }
      },
      "instances": [
        {
          "instance_id": "3746dd5a-e0c8-4f5f-959e-29a08665554e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:41:28.295316Z"
        },
        {
          "instance_id": "c82fe6cc-a060-42e8-9db4-c2ddce2e0a1e",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:41:28.295316Z"
        },
        {
          "instance_id": "f935fa37-4fba-46d4-8813-c574dede8cbc",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:41:28.295316Z"
        },
        {
          "instance_id": "e1ed511d-373a-48ad-a394-974ac4481cb6",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:41:28.295316Z"
        },
        {
          "instance_id": "23899ecb-fafd-40b1-94c1-d448b18b4cd1",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:41:28.295316Z"
        }
      ],
      "logo_id": "9a637f77-87e8-46e4-a764-bced02f990f3",
      "openrouter": true,
      "chutes_version": "0.3.35",
      "revision": "9329ff5f1e4489f4cd35cf54fb8e16f528099c6b",
      "concurrency": 16,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/9a637f77-87e8-46e4-a764-bced02f990f3.webp",
      "hot": true
    },
    {
      "chute_id": "85f8ffa1-68be-5872-bee8-267ac49f4966",
      "name": "axon1/affine_188_m4_4_mix",
      "tagline": "",
      "readme": "axon1/affine_188_m4_4_mix",
      "public": false,
      "version": "689b13fb-c8fa-5466-a2f0-e6cf77029235",
      "tool_description": null,
      "slug": "alx-miner4-axon1-affine-188-m4-4-mix",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-13T20:15:27.800610Z",
      "updated_at": "2025-10-20T17:49:18.859799Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "alx_miner4",
        "user_id": "c1fe223e-1e9a-554c-8cd2-e79eebc769a3",
        "logo_id": null,
        "created_at": "2025-09-17T11:51:29.377190Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a100_40gb",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "b200",
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 40,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a100_40gb",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 4834,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [
        {
          "instance_id": "aff5e0db-1253-4d19-95d0-188176d94afe",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:44:55.661768Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "cc410bb4a651a2fcfe3995e7258b48d99aba4871",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "1c61a01b-41e3-5e57-b18f-241d3c0b961f",
      "name": "Alphatao/affine-zfo439234",
      "tagline": "",
      "readme": "Alphatao/affine-zfo439234",
      "public": false,
      "version": "d4232f56-47a4-5ff2-90c0-c58adc8876d8",
      "tool_description": null,
      "slug": "affine2-alphatao-affine-zfo439234",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-12T03:58:43.638994Z",
      "updated_at": "2025-10-20T17:47:55.768343Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "affine2",
        "user_id": "cd092eeb-9df5-57a9-8f35-17f70dc24804",
        "logo_id": null,
        "created_at": "2025-06-16T12:50:11.659590Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "h100"
      ],
      "node_selector": {
        "exclude": null,
        "include": [
          "h200",
          "h100"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.397777777777778,
        "supported_gpus": [
          "h200",
          "h100"
        ]
      },
      "invocation_count": 4812,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.02,
            "tao": 0.00004967042431705
          },
          "output": {
            "usd": 0.1,
            "tao": 0.000248352121585251
          }
        },
        "usd": {
          "hour": 1.79,
          "second": 0.000497222222222222
        },
        "tao": {
          "hour": 0.004445502976376,
          "second": 0.000001234861937882
        }
      },
      "instances": [
        {
          "instance_id": "e4176eb8-34a0-4920-8efa-a8950dafd7ec",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:04:11.235803Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "f166b3e57b73cedb5a43a9ad0faee9a7dd17c783",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "e719cb37-18ba-52fa-9291-865a64eaccd3",
      "name": "axon1/affine_229_m3_4_8",
      "tagline": "",
      "readme": "axon1/affine_229_m3_4_8",
      "public": false,
      "version": "37af6fae-0206-55bf-b229-7bf2ac9d38e0",
      "tool_description": null,
      "slug": "alx-miner3-axon1-affine-229-m3-4-8",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-17T16:43:17.134276Z",
      "updated_at": "2025-10-20T17:50:22.691804Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "alx_miner3",
        "user_id": "6cdce1b8-3997-5f50-be97-790202cd3bae",
        "logo_id": null,
        "created_at": "2025-08-27T17:26:54.800934Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a100_40gb",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "b200",
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 40,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a100_40gb",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 4652,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [
        {
          "instance_id": "9181087b-e359-4155-854d-85bc8f2846c1",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T07:21:29.679540Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "20c97d5cd696397c1224b175eae27158ec9c1c5b",
      "concurrency": 24,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "178792b5-dbcd-5a8f-8d0e-de2460154d93",
      "name": "void-818/Affine-panda",
      "tagline": "",
      "readme": "void-818/Affine-panda",
      "public": false,
      "version": "f959503d-0319-58e8-886b-b1e705dd21a0",
      "tool_description": null,
      "slug": "panda-003-void-818-affine-panda",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-20T04:01:57.142251Z",
      "updated_at": "2025-10-20T04:01:57.142251Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "panda_003",
        "user_id": "5539d8de-9352-5500-9cec-58692f83f7a7",
        "logo_id": null,
        "created_at": "2025-10-13T04:20:41.773542Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 4570,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "11c54b1b-2b11-4b56-91ab-e5bd618039c8",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:00:58.506178Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "1f3f2d7662254525d5b2c4ad124492a0d8e9c586",
      "concurrency": 20,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "c1ff6c92-d263-5653-babb-92e3da671ee7",
      "name": "Pavvav/affine",
      "tagline": "",
      "readme": "Pavvav/affine",
      "public": false,
      "version": "48e76024-923c-5f57-832f-448e910d84a5",
      "tool_description": null,
      "slug": "malta-pavvav-affine",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-01T21:25:20.988845Z",
      "updated_at": "2025-10-20T17:50:40.448898Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "malta",
        "user_id": "1325590c-3010-5201-8055-a6852dd4c34d",
        "logo_id": null,
        "created_at": "2025-09-26T14:44:15.653436Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "b200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 4555,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [
        {
          "instance_id": "43ef115b-0b46-49c5-93e9-56ae0a99062c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:04:27.854795Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "2e88223b4c5ba460e375b24cada749d04a467f07",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "ad5153e1-b165-5141-b7f2-2e4e8517a408",
      "name": "kiwikiw/Affine-0002",
      "tagline": "",
      "readme": "kiwikiw/Affine-0002",
      "public": false,
      "version": "4a5834a2-fbe0-5e05-9c75-008cda1b0054",
      "tool_description": null,
      "slug": "affi1-kiwikiw-affine-0002",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-19T23:38:50.622954Z",
      "updated_at": "2025-10-19T23:38:50.622954Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "affi1",
        "user_id": "0c4df18e-921b-54eb-8c34-2a7c53605ace",
        "logo_id": "2d12633c-bb15-4623-b558-7103f8b0a9f0",
        "created_at": "2025-08-10T05:12:52.773057Z",
        "logo": "https://logos.chutes.ai/logos/2d12633c-bb15-4623-b558-7103f8b0a9f0.webp"
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200",
          "h100",
          "h100_sxm"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.397777777777778,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 4547,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.02,
            "tao": 0.00004967042431705
          },
          "output": {
            "usd": 0.1,
            "tao": 0.000248352121585251
          }
        },
        "usd": {
          "hour": 1.79,
          "second": 0.000497222222222222
        },
        "tao": {
          "hour": 0.004445502976376,
          "second": 0.000001234861937882
        }
      },
      "instances": [
        {
          "instance_id": "6b34ed3f-caca-47da-9fc3-ef0d7bcfbf11",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:54:23.646646Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "cb80f89f790125a8535f128dd22a92646e0fc154",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "2bcc6ac3-8b5b-5992-8ed9-4bd3fc048dfc",
      "name": "demonwizard0/affine-qwen4b-ft-1",
      "tagline": "",
      "readme": "demonwizard0/affine-qwen4b-ft-1",
      "public": false,
      "version": "f88122a2-bf18-5bda-8d89-c2928f0eff26",
      "tool_description": null,
      "slug": "affine-mantis-demonwizard0-affine-qwen4b-ft-1",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-11T09:26:01.670989Z",
      "updated_at": "2025-10-20T17:48:06.085012Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "affine_mantis",
        "user_id": "9ff1df41-ade1-57f5-ae9c-bbe5d29dc94e",
        "logo_id": null,
        "created_at": "2025-08-12T14:44:06.905655Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a100_40gb",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x",
          "b200"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 40,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a100_40gb",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 4530,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [
        {
          "instance_id": "604b7990-9aa8-45da-82b6-93ba54ecf788",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:06:56.294415Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "a30dc2c0e083b5124207cc977c2b913b2fa9e69b",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 18000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "3e5c21f8-0814-56d9-937b-50ecce1f7f19",
      "name": "ibuki95/Affine-t2v1",
      "tagline": "",
      "readme": "ibuki95/Affine-t2v1",
      "public": false,
      "version": "af723636-d1a2-5dbf-aa92-4b9c467164a4",
      "tool_description": null,
      "slug": "top-2-ibuki95-affine-t2v1",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-10T08:33:36.476986Z",
      "updated_at": "2025-10-19T16:42:54.790229Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "Top_2",
        "user_id": "2d9a4b0a-e548-510d-a2c3-10db91e2d0f7",
        "logo_id": null,
        "created_at": "2025-09-10T08:28:39.539204Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "b200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 4515,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.11,
            "tao": 0.000273187333743776
          },
          "output": {
            "usd": 0.3,
            "tao": 0.000745056364755754
          }
        },
        "usd": {
          "hour": 5.5,
          "second": 0.00152777777777778
        },
        "tao": {
          "hour": 0.0136593666871888,
          "second": 0.000003794268524219
        }
      },
      "instances": [
        {
          "instance_id": "18fcbacf-96e2-4cf0-ab98-149cbff95f10",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:12:01.901376Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "a13f1992dbc9c27e1958fbf2e6d3a2c26218df24",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 18000,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "600592b1-b06b-5fc6-b130-d9ad8b9f3467",
      "name": "Pavvav/affine-ghost",
      "tagline": "",
      "readme": "Pavvav/affine-ghost",
      "public": false,
      "version": "e833ca3e-4083-5347-ae7b-026febb813be",
      "tool_description": null,
      "slug": "phuket03-pavvav-affine-ghost",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-07T21:06:53.200656Z",
      "updated_at": "2025-10-20T18:16:11.829374Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "phuket03",
        "user_id": "d6ada4b1-7756-5813-8511-91f46c75f3fd",
        "logo_id": null,
        "created_at": "2025-10-07T20:51:49.500741Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "b200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 4491,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [
        {
          "instance_id": "72969e11-d463-4977-928d-26a38eed85eb",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:35:24.529065Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "c03e6059cdc3313e84dfb5aa9d0b2a0cd2f963da",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "55a5d213-df84-5e3f-9356-3320b0e9cc53",
      "name": "hO61qjpwxu/Affine_m3_5000_107",
      "tagline": "",
      "readme": "hO61qjpwxu/Affine_m3_5000_107",
      "public": false,
      "version": "97c4a114-fc8d-5aed-b8ec-59d1e8759aff",
      "tool_description": null,
      "slug": "wang-d4-ho61qjpwxu-affine-m3-5000-107",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-19T14:57:20.434513Z",
      "updated_at": "2025-10-19T14:57:20.434513Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "wang_d4",
        "user_id": "58a831f9-e86d-517e-884f-172271be4725",
        "logo_id": null,
        "created_at": "2025-10-19T14:03:51.149066Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "b200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 4484,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [
        {
          "instance_id": "af8e6343-e2b5-4b05-af22-7e4d6fea9098",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:16:54.818162Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "36f21b3bf22d17c6852624cd25608688ca0340e2",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "a6365e90-5450-58ea-96ba-5a4cb73c3a79",
      "name": "kiwikiw/Affine-0001",
      "tagline": "",
      "readme": "kiwikiw/Affine-0001",
      "public": false,
      "version": "b945a749-2209-54cb-b769-bfff087a910e",
      "tool_description": null,
      "slug": "affi6-kiwikiw-affine-0001",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-19T20:08:51.529545Z",
      "updated_at": "2025-10-19T20:08:51.529545Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "affi6",
        "user_id": "22419288-8e86-57d2-b31e-c7c981489212",
        "logo_id": null,
        "created_at": "2025-08-18T15:32:28.775008Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200",
          "h100",
          "h100_sxm"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.397777777777778,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 4473,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.02,
            "tao": 0.00004967042431705
          },
          "output": {
            "usd": 0.1,
            "tao": 0.000248352121585251
          }
        },
        "usd": {
          "hour": 1.79,
          "second": 0.000497222222222222
        },
        "tao": {
          "hour": 0.004445502976376,
          "second": 0.000001234861937882
        }
      },
      "instances": [
        {
          "instance_id": "a882dd04-25bf-4515-b557-29718293c937",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:52:50.230487Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "c4f417d85edea5cd8758f9e9ab7d15a0108cab49",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "c64cab8e-fe2d-5958-8331-8a82a9e23d8a",
      "name": "SteveDDD/Affine-5DUbF9i95tAfQK94us1GZMnoJ2qhBjzxpE2CXoCjmjn9T7m1",
      "tagline": "",
      "readme": "SteveDDD/Affine-5DUbF9i95tAfQK94us1GZMnoJ2qhBjzxpE2CXoCjmjn9T7m1",
      "public": false,
      "version": "f1ab3024-d7fd-5216-8b6f-af442cc464f0",
      "tool_description": null,
      "slug": "mavkm2-steveddd-affine-5dubf9i95tafqk94us1gzmnoj2qhbjzxpe2",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-08T08:01:29.546809Z",
      "updated_at": "2025-10-20T18:13:47.749293Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "mavkm2",
        "user_id": "dc68a478-ec39-5770-9970-0e6a2688b488",
        "logo_id": null,
        "created_at": "2025-09-28T05:54:07.765161Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "b200",
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200",
          "b200"
        ]
      },
      "invocation_count": 4463,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [
        {
          "instance_id": "287c6c5c-5808-4155-bb93-46a8674ec259",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T22:58:18.271042Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "42bf54b9779c212e6784076772e8e03e8259c91b",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "7f382564-98b3-5260-8fd1-5ec339d5b7c8",
      "name": "void-818/Affine-dimple",
      "tagline": "",
      "readme": "void-818/Affine-dimple",
      "public": false,
      "version": "3d6325b4-c1f2-5136-97ed-74c9060f53ba",
      "tool_description": null,
      "slug": "panda-003-void-818-affine-dimple",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-19T16:54:23.721556Z",
      "updated_at": "2025-10-19T16:54:23.721556Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "panda_003",
        "user_id": "5539d8de-9352-5500-9cec-58692f83f7a7",
        "logo_id": null,
        "created_at": "2025-10-13T04:20:41.773542Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200",
          "h100",
          "h100_sxm"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.397777777777778,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 4457,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.02,
            "tao": 0.00004967042431705
          },
          "output": {
            "usd": 0.1,
            "tao": 0.000248352121585251
          }
        },
        "usd": {
          "hour": 1.79,
          "second": 0.000497222222222222
        },
        "tao": {
          "hour": 0.004445502976376,
          "second": 0.000001234861937882
        }
      },
      "instances": [
        {
          "instance_id": "d8ea74b4-f765-4d8c-921a-86bcf358ceb9",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:41:22.239829Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "20712066eeb786770153553205b2eb26a3cdac29",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "65b0e7ec-944b-5a54-9fcc-9f3021af8cbc",
      "name": "Miller777/Affine-5FX7H4hKenNv9BjmNv23467wSMWez9RASUGKwnmaMtr1ZuFs",
      "tagline": "",
      "readme": "Miller777/Affine-5FX7H4hKenNv9BjmNv23467wSMWez9RASUGKwnmaMtr1ZuFs",
      "public": false,
      "version": "d0769059-aaae-5b99-8c27-56b502800592",
      "tool_description": null,
      "slug": "hoo777-2-miller777-affine-5fx7h4hkennv9bjmnv23467wsmwez9ra",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-19T22:03:59.868030Z",
      "updated_at": "2025-10-19T22:03:59.868030Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "Hoo777_2",
        "user_id": "f54604bc-18b6-5668-9329-6f6b9a8d9332",
        "logo_id": null,
        "created_at": "2025-09-07T09:16:52.079675Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 4444,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "97ee97e6-062b-40db-abd0-5e5c9029b003",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:36:41.939131Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "aae165538d32c90ce9d93702a9ace6c1ee94fed7",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "db6c86a9-b3b1-5555-8b3b-36d3a1e9af8f",
      "name": "GANGodfather/Affine-PESR05",
      "tagline": "",
      "readme": "GANGodfather/Affine-PESR05",
      "public": false,
      "version": "5ef09f0c-2e58-5147-87fd-6473e018f7a0",
      "tool_description": null,
      "slug": "sonyx05-gangodfather-affine-pesr05",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-24T17:07:06.337773Z",
      "updated_at": "2025-10-20T18:13:59.232395Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "sonyx05",
        "user_id": "992f6775-6eae-5fbc-a519-396aa6a4bb18",
        "logo_id": null,
        "created_at": "2025-08-28T15:21:41.300094Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 4443,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "44c8f0c1-dc3a-4813-bce2-3562a90fac6c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T23:01:49.114008Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "1ca7c11604997a5b083c1f4fe28bda8ee4c8619e",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "805a2546-bde2-54d2-9fa0-d0158bba94ea",
      "name": "Miller777/Affine-5DSRCXKxeup14y8Yg86FkgQmmesKfimvwxTWABPN5piw4k4U",
      "tagline": "",
      "readme": "Miller777/Affine-5DSRCXKxeup14y8Yg86FkgQmmesKfimvwxTWABPN5piw4k4U",
      "public": false,
      "version": "f04513b2-15e3-5916-898b-3666af34712e",
      "tool_description": null,
      "slug": "hoo777-miller777-affine-5dsrcxkxeup14y8yg86fkgqmmeskfimvwx",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-29T15:49:35.248531Z",
      "updated_at": "2025-10-19T18:15:41.712326Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "Hoo777",
        "user_id": "672afbb2-409a-53b1-9f70-21ece62a4485",
        "logo_id": null,
        "created_at": "2025-09-06T10:32:55.655601Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200",
        "a100",
        "a5000",
        "h20",
        "a6000_ada",
        "h100",
        "h100_sxm",
        "l40"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "b200",
          "h200",
          "h20",
          "h100",
          "h100_sxm",
          "a100",
          "a6000_ada",
          "l40",
          "a5000"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "h200",
          "b200",
          "a100",
          "a5000",
          "h20",
          "a6000_ada",
          "h100",
          "h100_sxm",
          "l40"
        ]
      },
      "invocation_count": 4440,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "6a0ffa69-5568-45c4-bd4b-0dfd96248878",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:41:22.251275Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "19bbbd847e6caa41ce239c8bbdae506388df929a",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "dced2409-0301-5c18-8456-0a862108c93f",
      "name": "SteveDDD/Affine-5D9mQ7rx6XpiogR7sFJBEAG9iy6HrcPR7ouTqJ2wLpBPpDeQ",
      "tagline": "",
      "readme": "SteveDDD/Affine-5D9mQ7rx6XpiogR7sFJBEAG9iy6HrcPR7ouTqJ2wLpBPpDeQ",
      "public": false,
      "version": "19468304-53dd-5dd4-960e-0642be8ba7ce",
      "tool_description": null,
      "slug": "sn120m1-steveddd-affine-5d9mq7rx6xpiogr7sfjbeag9iy6hrcpr7o",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-08T08:37:51.241049Z",
      "updated_at": "2025-10-20T18:14:03.008846Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "sn120m1",
        "user_id": "cc134af9-b609-5b26-9bb7-bf00187e613d",
        "logo_id": null,
        "created_at": "2025-09-27T10:36:46.577962Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "b200",
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200",
          "b200"
        ]
      },
      "invocation_count": 4434,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [
        {
          "instance_id": "2267cb76-2701-4f08-9d8a-429a81ccab2d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T23:02:23.585592Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "36cd3003e1e2da982617e9c7ca94216b3d18ceaa",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "cf86f5b3-a764-54f7-9bba-ca75fadd77ee",
      "name": "koshak/Affine-world3",
      "tagline": "",
      "readme": "koshak/Affine-world3",
      "public": false,
      "version": "017a7182-2c02-5ccb-ba90-ceaff0737b28",
      "tool_description": null,
      "slug": "berlin01-koshak-affine-world3",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-08T06:58:31.065017Z",
      "updated_at": "2025-10-20T18:12:53.866540Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "berlin01",
        "user_id": "5a42b7a3-b6f6-52f5-affc-ba8c2546ec3f",
        "logo_id": null,
        "created_at": "2025-10-06T20:19:27.978837Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "b200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 4433,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [
        {
          "instance_id": "87161ee4-4d52-47c9-8565-ef66ec29d3bf",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T22:58:51.296576Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "d4e70f21bd3465425c57f028916d6da019677923",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "a3ad6bc4-8e00-5f22-bac4-a26a2ff8a1ae",
      "name": "SteveDDD/Affine-5EfM9exHnQVYBm5y4r6aSMyELgjCMpHw2oKpc2cT5nStVwVM",
      "tagline": "",
      "readme": "SteveDDD/Affine-5EfM9exHnQVYBm5y4r6aSMyELgjCMpHw2oKpc2cT5nStVwVM",
      "public": false,
      "version": "cffda845-a559-5343-bae9-358b3afaf231",
      "tool_description": null,
      "slug": "minmiss-steveddd-affine-5efm9exhnqvybm5y4r6asmyelgjcmphw2o",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-16T08:22:14.710638Z",
      "updated_at": "2025-10-20T18:13:43.989588Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "minmiss",
        "user_id": "71ac4861-2929-5382-86e2-8c262b5e968f",
        "logo_id": null,
        "created_at": "2025-09-28T06:16:58.547050Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "b200",
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200",
          "b200"
        ]
      },
      "invocation_count": 4432,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [
        {
          "instance_id": "69b7e112-1b3a-4fbc-a956-3f1890d5d7f2",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:52:52.119842Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "e1d2561e0ab341ecc45e14ebda09fded78556c91",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "fc50942a-058e-5e52-bc84-3aab14278d97",
      "name": "kishig/affine-totop",
      "tagline": "",
      "readme": "kishig/affine-totop",
      "public": false,
      "version": "ddda8307-e219-509a-a9f6-24e59b5b6796",
      "tool_description": null,
      "slug": "olympus-afworld-kishig-affine-totop",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-20T10:51:34.139842Z",
      "updated_at": "2025-10-20T10:51:34.139842Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "olympus_afworld",
        "user_id": "b785a860-1765-54c2-88db-6572a3117fef",
        "logo_id": null,
        "created_at": "2025-10-06T05:53:13.201978Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 4427,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "e4f2445c-8081-4968-9b6b-32088d6f80c9",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T23:08:35.182757Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "c935ad3cdb56da2cd1becacf98ecc53c7df8cc4e",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "f8188550-56d1-556a-88ca-49cd442ebf08",
      "name": "hO61qjpwxu/Affine_m4_ca_1457",
      "tagline": "",
      "readme": "hO61qjpwxu/Affine_m4_ca_1457",
      "public": false,
      "version": "064bbedf-855a-5bf2-822f-328f7f9b2083",
      "tool_description": null,
      "slug": "wang-d6-ho61qjpwxu-affine-m4-ca-1457",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "0315a7ff-bd8f-5415-a4f7-d0a367cfcfde",
      "created_at": "2025-10-20T06:12:24.956457Z",
      "updated_at": "2025-10-20T06:12:24.956457Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "wang_d6",
        "user_id": "2b8a6d2f-d82f-5529-b9ea-fa7098cb4877",
        "logo_id": null,
        "created_at": "2025-10-20T06:07:34.011544Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 4419,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "22bde38d-4819-4ae5-963f-de1b1a34c06b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T23:07:08.979963Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "4fe79903a1f5e02d828356e90f93476308efa692",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "e1d7286b-7c6d-587b-9905-b1187a5c833f",
      "name": "Dan-Carter/Affine-9",
      "tagline": "",
      "readme": "Dan-Carter/Affine-9",
      "public": false,
      "version": "e4442439-066f-5175-b6c7-b8c384ce1477",
      "tool_description": null,
      "slug": "king9-dan-carter-affine-9",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-08T07:41:26.731003Z",
      "updated_at": "2025-10-20T18:14:07.132030Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "king9",
        "user_id": "cd2cbdc7-d76f-5973-98e3-211fd63359ff",
        "logo_id": null,
        "created_at": "2025-09-08T00:32:40.561989Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200",
          "h100",
          "h100_sxm"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.397777777777778,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 4401,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.02,
            "tao": 0.00004967042431705
          },
          "output": {
            "usd": 0.1,
            "tao": 0.000248352121585251
          }
        },
        "usd": {
          "hour": 1.79,
          "second": 0.000497222222222222
        },
        "tao": {
          "hour": 0.004445502976376,
          "second": 0.000001234861937882
        }
      },
      "instances": [
        {
          "instance_id": "d313f79f-1e35-4ce7-b578-bae2c1fd98fe",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T23:02:23.766381Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "0828c18cb855ad6275c2d34db2007acf35a51be0",
      "concurrency": 20,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 18000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "ebe0a8fe-3c13-5d8f-bdd1-4404ef6cb17e",
      "name": "SteveDDD/Affine-5Fn4od93zK8p83NZKCWBRPkSxAsSZMtsgc669p4tbRuDAX1R",
      "tagline": "",
      "readme": "SteveDDD/Affine-5Fn4od93zK8p83NZKCWBRPkSxAsSZMtsgc669p4tbRuDAX1R",
      "public": false,
      "version": "9cd75cca-30b2-52be-a595-2ac455241caa",
      "tool_description": null,
      "slug": "mkopo-steveddd-affine-5fn4od93zk8p83nzkcwbrpksxasszmtsgc66",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-16T08:38:00.510389Z",
      "updated_at": "2025-10-20T18:14:14.818638Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "mkopo",
        "user_id": "cfd3cce0-e6c5-535d-b7bf-f9ceb6e01ec3",
        "logo_id": null,
        "created_at": "2025-09-28T06:21:14.682497Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "b200",
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200",
          "b200"
        ]
      },
      "invocation_count": 4391,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [
        {
          "instance_id": "a9a4e3f1-d390-4457-a59f-2c6c5daf0073",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T23:06:47.705920Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "71b218f7a127ab8ceccba6493342eb6526966bc8",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "8808662c-b214-5d42-b955-dde8f1db6932",
      "name": "carf07/affine-bee",
      "tagline": "",
      "readme": "carf07/affine-bee",
      "public": false,
      "version": "ca1c771a-a0b8-5961-ba24-63350ac2bce5",
      "tool_description": null,
      "slug": "carf0701-carf07-affine-bee",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-09T15:00:41.005647Z",
      "updated_at": "2025-10-20T18:13:28.590936Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "carf0701",
        "user_id": "2caffdcf-080a-5abf-a9a8-d16fa4781e3d",
        "logo_id": null,
        "created_at": "2025-10-09T14:54:31.245415Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 4354,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "006f6843-3a56-4c23-a187-d112fb2fba4f",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:46:59.238069Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "900afa061c07a0a851603b3ad5ec6c6b5a610f23",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "2b46a5e5-0a70-5cea-b2b4-e40bf88edd9d",
      "name": "GANGodfather/Affine-PESR04",
      "tagline": "",
      "readme": "GANGodfather/Affine-PESR04",
      "public": false,
      "version": "7eff9abe-68e0-52d6-ba1f-04c3f5303acb",
      "tool_description": null,
      "slug": "sonyx04-gangodfather-affine-pesr04",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-24T15:57:04.323775Z",
      "updated_at": "2025-10-20T18:13:09.089594Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "sonyx04",
        "user_id": "b7bb1570-efa0-5461-b230-222b1fc763eb",
        "logo_id": null,
        "created_at": "2025-08-29T03:00:56.239568Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 4351,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "3f8460b7-07da-4721-9ebf-6c6e0f69fc31",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:06:58.961172Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "e2113d3cf4d27138bb8f01820727295e500514b9",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "31ec7bf4-26a9-5333-adb8-c456b27d4e8d",
      "name": "void-818/Affine-star",
      "tagline": "",
      "readme": "void-818/Affine-star",
      "public": false,
      "version": "7498beba-3a5b-544e-b1dd-517fe5df82ff",
      "tool_description": null,
      "slug": "panda-003-void-818-affine-star",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-19T16:20:30.693268Z",
      "updated_at": "2025-10-19T16:20:30.693268Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "panda_003",
        "user_id": "5539d8de-9352-5500-9cec-58692f83f7a7",
        "logo_id": null,
        "created_at": "2025-10-13T04:20:41.773542Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 4327,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "c1c4fac5-3e66-46b6-957c-9e88ca752e50",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:08:20.798374Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "fb33e4bba210896010f31cb308edc73b701c555e",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.85,
      "shutdown_after_seconds": 36000,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "7d1992c2-ddc1-540f-966d-589f1e2ad3bb",
      "name": "Deval1004/Affine-v24.0.1",
      "tagline": "",
      "readme": "Deval1004/Affine-v24.0.1",
      "public": false,
      "version": "6f8b05a6-ac3a-5938-aefc-e46d526723ec",
      "tool_description": null,
      "slug": "affine-004-deval1004-affine-v24-0-1",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-06T08:54:13.675017Z",
      "updated_at": "2025-10-20T17:47:45.930202Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "affine_004",
        "user_id": "b23d9da7-9994-5ef5-a8a7-899fc92b746c",
        "logo_id": null,
        "created_at": "2025-09-01T13:38:23.995899Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 4321,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [
        {
          "instance_id": "592c06a3-66a8-4be0-bed5-896c94c7ac11",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:39:07.959816Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "49e01e89555a5be74127fc683e18c53f4c472799",
      "concurrency": 64,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "d05074f9-88a1-5c69-be2f-a6a7c27d0410",
      "name": "hO61qjpwxu/Affine_m2_5000",
      "tagline": "",
      "readme": "hO61qjpwxu/Affine_m2_5000",
      "public": false,
      "version": "3dbef7c1-6f50-54d2-9215-1f12dcb54942",
      "tool_description": null,
      "slug": "vk3lvxxpnn-ho61qjpwxu-affine-m2-5000",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-15T17:06:58.208372Z",
      "updated_at": "2025-10-20T18:13:51.594332Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "Vk3lVXxpnn",
        "user_id": "a5f862ee-0665-527d-a500-1843717374e1",
        "logo_id": null,
        "created_at": "2025-08-12T16:20:24.414133Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 4313,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "8d658c04-6ea0-4002-ab54-d76aced7526c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T22:58:47.212133Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "f708a5da6c5f5d05ec4bba0cd7372351448021f6",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "41e4d621-3ad7-57db-8473-760fad5f5cc4",
      "name": "Marco0/Affine-QQ",
      "tagline": "",
      "readme": "Marco0/Affine-QQ",
      "public": false,
      "version": "fb57c5c8-748a-5de3-bac7-36894296aba6",
      "tool_description": null,
      "slug": "affi4-marco0-affine-qq",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-04T00:59:07.369813Z",
      "updated_at": "2025-10-20T18:12:27.357612Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "affi4",
        "user_id": "97bbf6f7-949e-59c6-9c05-975e5422be33",
        "logo_id": null,
        "created_at": "2025-08-18T02:43:19.939692Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200",
          "h100",
          "h100_sxm"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.397777777777778,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 4299,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.02,
            "tao": 0.00004967042431705
          },
          "output": {
            "usd": 0.1,
            "tao": 0.000248352121585251
          }
        },
        "usd": {
          "hour": 1.79,
          "second": 0.000497222222222222
        },
        "tao": {
          "hour": 0.004445502976376,
          "second": 0.000001234861937882
        }
      },
      "instances": [
        {
          "instance_id": "44684451-b541-4cb0-b63d-385aa32147f5",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:13:01.308285Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "3be8484363db2b58ef8a8e705b4c2d4c3f19bd56",
      "concurrency": 20,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "93198b0f-5be0-5cb2-9b7e-a2e33e1ada80",
      "name": "GANGodfather/Affine-PESR01",
      "tagline": "",
      "readme": "GANGodfather/Affine-PESR01",
      "public": false,
      "version": "0745cd43-963a-5a7b-8d4d-72576317da89",
      "tool_description": null,
      "slug": "gangodfather-gangodfather-affine-pesr01",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-23T05:30:58.754095Z",
      "updated_at": "2025-10-20T17:49:25.188651Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "GANGodFather",
        "user_id": "a4e66cd0-d352-5be3-90e3-8e427195d2c5",
        "logo_id": null,
        "created_at": "2025-08-29T02:28:16.792283Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 4288,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "60f4ec0d-aa0b-42e9-bf25-6b78f13c1086",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:49:23.004850Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "aa3c6d9961ec55219fbebc2964c74165e40f4b41",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "6317dffe-5c19-5c62-b9bc-51a8ed5d9a7d",
      "name": "Miller777/Affine-5Ckqjq8Sskd2JNvG2NY1kKjF3ToDsvGY5FK5vTQZtrwwFrnR",
      "tagline": "",
      "readme": "Miller777/Affine-5Ckqjq8Sskd2JNvG2NY1kKjF3ToDsvGY5FK5vTQZtrwwFrnR",
      "public": false,
      "version": "b1d154ca-009f-5851-b9b2-0841886a0933",
      "tool_description": null,
      "slug": "hoo777-7-miller777-affine-5ckqjq8sskd2jnvg2ny1kkjf3todsvgy",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-19T13:59:40.562650Z",
      "updated_at": "2025-10-19T21:29:29.838944Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "Hoo777_7",
        "user_id": "5e5d9d98-cd67-5aa1-83a4-e050e2e24068",
        "logo_id": null,
        "created_at": "2025-09-25T21:40:46.236102Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "b200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 4275,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [
        {
          "instance_id": "8758ae24-a19b-4a82-a269-160d4a5865a3",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:35:22.467690Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "77e165338c18cca9f29b70d8738971520d33942d",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "e24f3d9e-e39e-5aa4-904e-ce843dd2b3cb",
      "name": "Dan-Carter/Affine-3",
      "tagline": "",
      "readme": "Dan-Carter/Affine-3",
      "public": false,
      "version": "fb14f437-d2ed-5f90-92cb-acd3247850d6",
      "tool_description": null,
      "slug": "king-33-dan-carter-affine-3",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-08T09:49:47.490903Z",
      "updated_at": "2025-10-20T18:14:10.999984Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "king_33",
        "user_id": "03332f72-bb3b-5997-87c4-eff8a185007b",
        "logo_id": null,
        "created_at": "2025-08-30T02:02:04.894331Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200",
          "h100",
          "h100_sxm"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.397777777777778,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 4269,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.02,
            "tao": 0.00004967042431705
          },
          "output": {
            "usd": 0.1,
            "tao": 0.000248352121585251
          }
        },
        "usd": {
          "hour": 1.79,
          "second": 0.000497222222222222
        },
        "tao": {
          "hour": 0.004445502976376,
          "second": 0.000001234861937882
        }
      },
      "instances": [
        {
          "instance_id": "69e6caff-b313-49d4-8358-7d5b7e5eb984",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T23:02:22.652691Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "777f297ee7af2ac90eb47f95b467a6f5e32e31e0",
      "concurrency": 20,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 18000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "31e46b31-5cd0-5d1d-bc17-0008bf3b4d62",
      "name": "SteveDDD/Affine-5Dyb4woQxanqgrHDMbQVHV5CSSdSFQN1HKvU7MR7ozgBxzzV",
      "tagline": "",
      "readme": "SteveDDD/Affine-5Dyb4woQxanqgrHDMbQVHV5CSSdSFQN1HKvU7MR7ozgBxzzV",
      "public": false,
      "version": "1f825ed8-4918-5f10-bc2b-d72f16e4a2c2",
      "tool_description": null,
      "slug": "fixkmiau-steveddd-affine-5dyb4woqxanqgrhdmbqvhv5cssdsfqn1h",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-08T09:29:33.379787Z",
      "updated_at": "2025-10-20T18:13:12.807539Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "fixkmiau",
        "user_id": "269f4a01-08b4-55ff-9457-20f8933c7288",
        "logo_id": null,
        "created_at": "2025-09-28T06:12:18.889452Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "b200",
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200",
          "b200"
        ]
      },
      "invocation_count": 4264,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [
        {
          "instance_id": "e9c114c2-2c7a-4747-859d-610c1d79adc4",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:08:29.899233Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "5d58b8e40f5bce19856b2e816f9dc519c245f70c",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "9f99ce29-3213-5bd4-a138-87f0350b41db",
      "name": "juhx/Affine-5",
      "tagline": "",
      "readme": "juhx/Affine-5",
      "public": false,
      "version": "32fa0420-bdfe-5c4f-937b-14c71188f6b0",
      "tool_description": null,
      "slug": "affi3-juhx-affine-5",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-09T14:26:34.849450Z",
      "updated_at": "2025-10-20T18:13:40.164868Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "affi3",
        "user_id": "a339d88e-737d-5b7c-b85f-fd9520c6b3a4",
        "logo_id": null,
        "created_at": "2025-08-17T21:39:48.747695Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200",
          "h100",
          "h100_sxm"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.397777777777778,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 4260,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.02,
            "tao": 0.00004967042431705
          },
          "output": {
            "usd": 0.1,
            "tao": 0.000248352121585251
          }
        },
        "usd": {
          "hour": 1.79,
          "second": 0.000497222222222222
        },
        "tao": {
          "hour": 0.004445502976376,
          "second": 0.000001234861937882
        }
      },
      "instances": [
        {
          "instance_id": "a704783b-d79f-46c9-beef-64537e4f0771",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:52:21.578283Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "2d71f07425e9c00063f6d39075245a6266fa0c99",
      "concurrency": 20,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "81dbe0ee-f2dc-57a0-b49b-b769c479c363",
      "name": "ebobo/Affine-5C8BkzxSJZvp5hhFUuEJaw3uMq9KKWvNjHo6koL8nbskgdAy",
      "tagline": "",
      "readme": "ebobo/Affine-5C8BkzxSJZvp5hhFUuEJaw3uMq9KKWvNjHo6koL8nbskgdAy",
      "public": false,
      "version": "ae2cc3d3-4244-57cd-8b6e-2b886b0f330a",
      "tool_description": null,
      "slug": "newall8-ebobo-affine-5c8bkzxsjzvp5hhfuuejaw3umq9kkwvnjho6k",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-29T15:16:35.819080Z",
      "updated_at": "2025-10-20T18:13:24.526151Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "newall8",
        "user_id": "e17ae1e7-11ba-560b-948b-1e1fa189f74c",
        "logo_id": null,
        "created_at": "2025-09-29T14:53:26.463756Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 4,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 2.44444444444444,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 4254,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          },
          "output": {
            "usd": 0.6,
            "tao": 0.00149011272951151
          }
        },
        "usd": {
          "hour": 11,
          "second": 0.00305555555555556
        },
        "tao": {
          "hour": 0.0273187333743777,
          "second": 0.000007588537048438
        }
      },
      "instances": [
        {
          "instance_id": "6f2f4cd9-b1b9-4996-94a7-5e693ace1207",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:41:24.610734Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "2c5e0b0cdd533bc4321788c9427ff751355dba6f",
      "concurrency": 24,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "efbecffe-9d22-5d2e-bfd1-aede2f391ddc",
      "name": "GANGodfather/Affine-PESR08",
      "tagline": "",
      "readme": "GANGodfather/Affine-PESR08",
      "public": false,
      "version": "443399b3-95bf-565f-bd69-55ea60c917b5",
      "tool_description": null,
      "slug": "sonyx08-gangodfather-affine-pesr08",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-25T13:05:09.770284Z",
      "updated_at": "2025-10-20T18:14:18.687490Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "sonyx08",
        "user_id": "ef01e8d9-2641-5d0d-8dfe-67f1ae2fda99",
        "logo_id": null,
        "created_at": "2025-08-28T23:52:04.089818Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 4243,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "aa667075-3ff7-4bb3-9efc-eaae43d8dc26",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T23:06:40.750528Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "99fc7a690831a5718461f9c0a3dfb1d96ed5b580",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "d0696198-4cac-5921-9c83-11145da92d76",
      "name": "acvbs23s/Affine-5Gq3MAWsiphMi17dwgcjGZETcRoQrbXWauwWqaEUbb6pVzZv",
      "tagline": "",
      "readme": "acvbs23s/Affine-5Gq3MAWsiphMi17dwgcjGZETcRoQrbXWauwWqaEUbb6pVzZv",
      "public": false,
      "version": "a0764987-51b0-5997-a671-6f2e466be451",
      "tool_description": null,
      "slug": "acvbs23s-acvbs23s-affine-5gq3mawsiphmi17dwgcjgzetcroqrbxwa",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-10T10:33:39.710707Z",
      "updated_at": "2025-10-20T17:49:53.935612Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "acvbs23s",
        "user_id": "66edcf58-2ce5-5096-b373-ea87713101dd",
        "logo_id": null,
        "created_at": "2025-10-06T08:15:57.748449Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200",
        "a100",
        "a5000",
        "h20",
        "a6000_ada",
        "h100",
        "h100_sxm",
        "l40"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "b200",
          "h200",
          "h20",
          "h100",
          "h100_sxm",
          "a100",
          "a6000_ada",
          "l40",
          "a5000"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "h200",
          "b200",
          "a100",
          "a5000",
          "h20",
          "a6000_ada",
          "h100",
          "h100_sxm",
          "l40"
        ]
      },
      "invocation_count": 4195,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "2165f31c-8e45-4dd1-ac4d-7ff51f99226b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T22:59:39.042363Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "9bd8b757b45f37c537d14abbd905ed579d45595d",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "f17fe3d8-9d5b-542e-ac0f-37ab88852533",
      "name": "GANGodfather/Affine-PESR03",
      "tagline": "",
      "readme": "GANGodfather/Affine-PESR03",
      "public": false,
      "version": "5cdb0f86-ae82-58a0-a9a7-c52765eb9f80",
      "tool_description": null,
      "slug": "sonyx03-gangodfather-affine-pesr03",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-24T15:53:28.438051Z",
      "updated_at": "2025-10-20T17:50:33.786254Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "sonyx03",
        "user_id": "5f442ce0-27cf-583e-b12c-9437119c3be5",
        "logo_id": null,
        "created_at": "2025-08-28T16:46:51.831884Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 4184,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "25ae7d40-bdb9-4c42-9952-746b074227fc",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T23:06:11.887109Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "a31f098f4ceafaa9afd33243adf49439d4ca6d95",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "f8574c7b-731f-5c55-9a5a-571e17bb92d8",
      "name": "juhx/Affine-4",
      "tagline": "",
      "readme": "juhx/Affine-4",
      "public": false,
      "version": "a16c6810-61a4-5da8-ba52-a9edd65023ec",
      "tool_description": null,
      "slug": "affi2-juhx-affine-4",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-09T13:14:00.807161Z",
      "updated_at": "2025-10-20T18:14:22.538540Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "affi2",
        "user_id": "f31a8bd6-213a-530f-b24b-3130ab960923",
        "logo_id": null,
        "created_at": "2025-08-10T06:05:57.307807Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200",
          "h100",
          "h100_sxm"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.397777777777778,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 4126,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.02,
            "tao": 0.00004967042431705
          },
          "output": {
            "usd": 0.1,
            "tao": 0.000248352121585251
          }
        },
        "usd": {
          "hour": 1.79,
          "second": 0.000497222222222222
        },
        "tao": {
          "hour": 0.004445502976376,
          "second": 0.000001234861937882
        }
      },
      "instances": [
        {
          "instance_id": "c2945315-98fd-4d1d-bafe-e996a4dcebbe",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T23:07:16.833506Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "1a84c9f7b0f53cb09bb820480617718863b87bf2",
      "concurrency": 20,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "b33bab14-92cf-5124-960f-c58666945e8a",
      "name": "hO61qjpwxu/Affine_m3_5066",
      "tagline": "",
      "readme": "hO61qjpwxu/Affine_m3_5066",
      "public": false,
      "version": "8380c7a6-ed22-5b22-b139-1be46ab5b56c",
      "tool_description": null,
      "slug": "silly-cow-ho61qjpwxu-affine-m3-5066",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-18T20:05:25.538579Z",
      "updated_at": "2025-10-20T17:49:37.619552Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "silly_cow",
        "user_id": "b2e36fa0-16e4-5212-9535-c2aa73e02738",
        "logo_id": null,
        "created_at": "2025-08-23T07:37:26.701271Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "b200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 4118,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [
        {
          "instance_id": "53385f49-28f8-470e-b626-3339f1e1f7d2",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:57:38.924790Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "a54b071de3f1e790f44c38d6749c504cecfab026",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "4fa2942f-acce-597f-973e-34d97ba034e4",
      "name": "koshak/Affine-world4",
      "tagline": "",
      "readme": "koshak/Affine-world4",
      "public": false,
      "version": "1f5767a1-26ea-5018-9977-e8e6fbf0d517",
      "tool_description": null,
      "slug": "lissabon-koshak-affine-world4",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-08T21:33:42.075542Z",
      "updated_at": "2025-10-20T18:13:20.596295Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "lissabon",
        "user_id": "129606a1-3609-51e2-8b55-6aa180df284c",
        "logo_id": null,
        "created_at": "2025-10-03T21:10:56.141690Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "b200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 4106,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [
        {
          "instance_id": "00e94dd8-47d2-4587-9d4e-fe089d499bea",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:16:41.562743Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "5e54211126b6effe6cd41d1107a61073a80185e5",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "80a94d59-1a3c-5b48-99b2-dcab362955f0",
      "name": "koshak/Affine-world7",
      "tagline": "",
      "readme": "koshak/Affine-world7",
      "public": false,
      "version": "8e27f6af-1eec-529e-b1da-1e1def37ce61",
      "tool_description": null,
      "slug": "palermo01-koshak-affine-world7",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-10T21:27:21.488556Z",
      "updated_at": "2025-10-20T17:49:12.400711Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "palermo01",
        "user_id": "2cf2300a-7517-53cf-b8b0-c25ed997829c",
        "logo_id": null,
        "created_at": "2025-10-01T22:03:55.146430Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "b200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 4098,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [
        {
          "instance_id": "ffa08376-2550-4b3a-a762-4e286001f275",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:41:08.953770Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "9924889e3068a1e2c45955b6543edcf1e0b4c0d9",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 86400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "24a2050b-86f2-5ac6-8bdf-e41a5e383c99",
      "name": "GangSingT/Affine-ganggang",
      "tagline": "",
      "readme": "GangSingT/Affine-ganggang",
      "public": false,
      "version": "1a50f1d7-2097-574f-a36e-dbc7d271b700",
      "tool_description": null,
      "slug": "gangsingt-gangsingt-affine-ganggang",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-20T13:11:12.245562Z",
      "updated_at": "2025-10-20T13:11:12.245562Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "GangSingT",
        "user_id": "ea6f4d5b-c21b-5b27-9b7b-53d2a423da3d",
        "logo_id": null,
        "created_at": "2025-09-15T16:25:47.811030Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 4091,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "c2515a2f-3eb5-40ed-9dff-e4e950a6627b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:05:19.162411Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "7c39069b1efde4dc376badef38c2d9bfc66e85e4",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "d5b7af66-9433-5d0b-a34b-3c1ffbc7ba51",
      "name": "juhx/Affine-10",
      "tagline": "",
      "readme": "juhx/Affine-10",
      "public": false,
      "version": "6f4dfd48-a28b-5feb-8de3-197ed17d8ea5",
      "tool_description": null,
      "slug": "affi5-juhx-affine-10",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-11T00:49:46.857632Z",
      "updated_at": "2025-10-20T17:50:11.306238Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "affi5",
        "user_id": "0df658c7-a621-5574-a179-c68dcc495425",
        "logo_id": null,
        "created_at": "2025-08-18T02:44:41.074469Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 4067,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [
        {
          "instance_id": "6c5832a1-a40d-4738-ace5-5549c9f0465c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T23:01:44.096490Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "26e70a19070946d86c4d4d569f52ade2f874a0b6",
      "concurrency": 20,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "3ba466f6-7e1a-511a-9a1d-c6ad8e7a7e6b",
      "name": "ibuki95/Affine-t1v1",
      "tagline": "",
      "readme": "ibuki95/Affine-t1v1",
      "public": false,
      "version": "b71e7371-37a2-5da3-89cf-9f25a5c6cc7e",
      "tool_description": null,
      "slug": "top-1-ibuki95-affine-t1v1",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-10T04:42:35.131311Z",
      "updated_at": "2025-10-20T17:48:20.146531Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "Top_1",
        "user_id": "05dfa67d-8fb6-5de2-9f64-15ae826145ba",
        "logo_id": null,
        "created_at": "2025-09-10T00:53:22.663942Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 4022,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.11,
            "tao": 0.000273187333743776
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [
        {
          "instance_id": "da38dfd5-cf3d-4267-afb7-ce7fd7a0988d",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:11:13.608538Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "15a3b80a5fb395cca294a470ef0ed99a441bcb1b",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 18000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "2a69814e-2ed2-5028-919a-9ee90c7ae338",
      "name": "koshak/Affine-world6",
      "tagline": "",
      "readme": "koshak/Affine-world6",
      "public": false,
      "version": "54f6652d-07bf-59a6-be23-6a855c767c25",
      "tool_description": null,
      "slug": "dubai04-koshak-affine-world6",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-10T10:25:09.106918Z",
      "updated_at": "2025-10-20T18:14:56.879485Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "dubai04",
        "user_id": "d7d84955-a20e-54ae-8b43-92bda33207a1",
        "logo_id": null,
        "created_at": "2025-10-10T10:10:20.194808Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "b200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 4004,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [
        {
          "instance_id": "26902b26-a696-4cde-8368-b6916c620b1b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:06:54.928213Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "4263da1992ec01b1a1c4b1707720e9588423e844",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 86400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "696423d4-338e-5430-a505-3eda8bdd73e9",
      "name": "EiMon724/Affine-5FEjGy6QaFDuhGvXMg2HuCZHsopTthTk8bKWV6VY2pxw6xBQ",
      "tagline": "",
      "readme": "EiMon724/Affine-5FEjGy6QaFDuhGvXMg2HuCZHsopTthTk8bKWV6VY2pxw6xBQ",
      "public": false,
      "version": "37f6083d-7976-5163-b57e-3d0f5a4bb8a6",
      "tool_description": null,
      "slug": "eimon725-eimon724-affine-5fejgy6qafduhgvxmg2huczhsoptthtk8",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-04T00:08:16.655849Z",
      "updated_at": "2025-10-20T18:12:31.177203Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "EiMon725",
        "user_id": "191fd401-4abf-5ea5-946e-c9ab2e8cbbf7",
        "logo_id": null,
        "created_at": "2025-10-03T02:49:06.267771Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 3968,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "7d0e8ec9-42d2-4d52-95bc-ec6783dd8502",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:36:30.062412Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "f19b83ec9c6bd23be595261185a6f4431651df36",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "6964d7d5-a5ea-508e-aec8-50f22e1d2bed",
      "name": "EiMon724/Affine-5DZGkVwqVWafefHT24WCeRRWz42NHhUVnc8rX9ddkckdTTGw",
      "tagline": "",
      "readme": "EiMon724/Affine-5DZGkVwqVWafefHT24WCeRRWz42NHhUVnc8rX9ddkckdTTGw",
      "public": false,
      "version": "e1556dce-c2d9-5685-82cb-1477364a7508",
      "tool_description": null,
      "slug": "eimon724-eimon724-affine-5dzgkvwqvwafefht24wcerrwz42nhhuvn",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-19T16:40:32.057628Z",
      "updated_at": "2025-10-20T17:50:54.870282Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "EiMon724",
        "user_id": "fb685fd1-2dce-5bbc-991b-2e96d73958d8",
        "logo_id": "86aeb80b-0096-449a-9bdd-7a9360ab540c",
        "created_at": "2025-09-18T07:20:32.915073Z",
        "logo": "https://logos.chutes.ai/logos/86aeb80b-0096-449a-9bdd-7a9360ab540c.webp"
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 3897,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "c03045b1-35a8-42a7-b69d-88a168483813",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:36:26.182895Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "f57cbbf909e54dff0854f71c7fb28cfedf3d75a0",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "8f5ec36a-f3ef-50a2-acff-f78d5a849bed",
      "name": "koshak/Affine-world9",
      "tagline": "",
      "readme": "koshak/Affine-world9",
      "public": false,
      "version": "30406897-2a62-564b-a165-33ef011eb054",
      "tool_description": null,
      "slug": "ibiza-koshak-affine-world9",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-14T10:36:52.504252Z",
      "updated_at": "2025-10-20T18:13:32.366536Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "ibiza",
        "user_id": "ad4dda97-645d-5619-a520-55ee3a7fe2de",
        "logo_id": null,
        "created_at": "2025-10-02T11:30:55.863582Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "b200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 3826,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [
        {
          "instance_id": "2fadb539-5a07-464b-bf30-4a603c61ddc6",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:49:22.765918Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "815c438186b2ceec3003950c3fc0128854673e60",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 86400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "4ea526a0-9de4-5cd3-ba0c-7fb938959af9",
      "name": "EiMon724/Affine-5HY6XuSFzMm49FbjBEbGSPnXo5vGoVUHy8HwYx5VXK5dC7Vn",
      "tagline": "",
      "readme": "EiMon724/Affine-5HY6XuSFzMm49FbjBEbGSPnXo5vGoVUHy8HwYx5VXK5dC7Vn",
      "public": false,
      "version": "0c46efaf-6f40-5420-87a8-3e662f7a9a3d",
      "tool_description": null,
      "slug": "eimon726-eimon724-affine-5hy6xusfzmm49fbjbebgspnxo5vgovuhy",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-19T07:05:08.610851Z",
      "updated_at": "2025-10-20T17:48:41.547578Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "EiMon726",
        "user_id": "7846bff8-5556-52b7-87a7-dbcfab09564d",
        "logo_id": null,
        "created_at": "2025-10-03T03:23:02.643245Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 3689,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "52172459-83af-4ba7-8eaf-953304ee4a58",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:14:22.278477Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "dd259165ec1188b3a28fdf025fc31e57abf6521d",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "1b371ee0-c14a-5a3f-9d83-c244b202ef05",
      "name": "anthrx/Affine-anthrx-gg",
      "tagline": "",
      "readme": "anthrx/Affine-anthrx-gg",
      "public": false,
      "version": "5d10c570-1037-556a-a2f7-011a8a219cdc",
      "tool_description": null,
      "slug": "zetty002-anthrx-affine-anthrx-gg",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-20T15:36:17.721502Z",
      "updated_at": "2025-10-20T15:36:17.721502Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "zetty002",
        "user_id": "10868e8d-e97f-5dc5-9c38-64dba176e640",
        "logo_id": null,
        "created_at": "2025-09-11T10:22:19.021966Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 3624,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "44b6c6bd-c540-42a2-976a-de492735fc29",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:03:33.744535Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "44744bce2013eda9ca46a926bda13f4aa6d9cce7",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "385aa551-6085-5c94-bda8-aa12609ef73b",
      "name": "deepseek-ai/DeepSeek-V3.1-turbo",
      "tagline": "",
      "readme": "deepseek-ai/DeepSeek-V3.1",
      "public": true,
      "version": "e236db16-85fd-57c7-9b47-3fd20bf4bc58",
      "tool_description": null,
      "slug": "chutes-deepseek-ai-deepseek-v3-1-turbo",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "56bf4f6f-06ef-5e08-a903-64e6ec96d5dc",
      "created_at": "2025-09-17T13:08:01.693825Z",
      "updated_at": "2025-10-19T11:24:26.563310Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 3623,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 1,
            "tao": 0.00248352121585251
          },
          "output": {
            "usd": 3,
            "tao": 0.00745056364755754
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "11e4ffa4-f877-4f5d-ba65-57489b1ea9ec",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:09:43.663924Z"
        },
        {
          "instance_id": "aa29f223-1337-4e31-92a0-d0cd382a33e5",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:09:43.663924Z"
        }
      ],
      "logo_id": "42090fef-c8e9-4d81-a8b9-fdde067adb41",
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "9e6c48c3fa6bb3e1cf684675dc02e813ca45d20f",
      "concurrency": 24,
      "boost": 3,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": false,
      "logo": "https://logos.chutes.ai/logos/42090fef-c8e9-4d81-a8b9-fdde067adb41.webp",
      "hot": true
    },
    {
      "chute_id": "2da3c94d-c58c-5c1f-a65f-b2acd105603b",
      "name": "chutesai/Ling-1T-FP8",
      "tagline": "",
      "readme": "chutesai/Ling-1T-FP8",
      "public": true,
      "version": "ab6b121d-5e51-562b-8ddf-6aa863c38e4b",
      "tool_description": null,
      "slug": "chutes-chutesai-ling-1t-fp8",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "b9784def-b796-57d7-888e-8fef54b2207e",
      "created_at": "2025-10-15T16:25:04.672861Z",
      "updated_at": "2025-10-19T14:42:10.154544Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "b200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "b200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 8,
        "supported_gpus": [
          "b200"
        ]
      },
      "invocation_count": 3426,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.4,
            "tao": 0.000993408486341005
          },
          "output": {
            "usd": 2,
            "tao": 0.00496704243170503
          }
        },
        "usd": {
          "hour": 36,
          "second": 0.01
        },
        "tao": {
          "hour": 0.0894067637706905,
          "second": 0.000024835212158525
        }
      },
      "instances": [
        {
          "instance_id": "22523e93-6ca1-4b3e-83d7-ebc08b4b82c6",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:08:49.296825Z"
        }
      ],
      "logo_id": "48943551-2412-4480-9c0f-5b9eae710327",
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "797172c9bc7e33e995e0d89d0b43b8984263098a",
      "concurrency": 32,
      "boost": 20,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/48943551-2412-4480-9c0f-5b9eae710327.webp",
      "hot": true
    },
    {
      "chute_id": "e7518f57-5336-5c1c-9ef9-f53248c618b9",
      "name": "anthrx/affine-3",
      "tagline": "",
      "readme": "anthrx/affine-3",
      "public": false,
      "version": "30ee2417-de7d-53fb-809a-3b67ddeaf1ee",
      "tool_description": null,
      "slug": "zetty003-anthrx-affine-3",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-20T11:25:49.463654Z",
      "updated_at": "2025-10-20T11:25:49.463654Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "zetty003",
        "user_id": "3fae6e0c-4939-515b-96c1-b467727591e1",
        "logo_id": null,
        "created_at": "2025-09-11T10:23:59.070352Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 3384,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "e6011378-260f-41f6-bc00-48c02cc23737",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T23:05:16.118842Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "9c4a5337f76d7ab939eecfc28d70211b6dee4c41",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "25f25a8a-7e77-548b-ba76-a592eab45233",
      "name": "Maziko/Affine-120abc",
      "tagline": "",
      "readme": "Maziko/Affine-120abc",
      "public": false,
      "version": "a04031ff-f418-5e62-a485-637c2e83e845",
      "tool_description": null,
      "slug": "mazikoo-maziko-affine-120abc",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "0315a7ff-bd8f-5415-a4f7-d0a367cfcfde",
      "created_at": "2025-10-20T15:40:08.379197Z",
      "updated_at": "2025-10-20T16:56:12.640512Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "mazikoo",
        "user_id": "4601e77d-7f7c-5657-91ac-9d76c680174c",
        "logo_id": null,
        "created_at": "2025-10-08T16:28:49.504883Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "b200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 3061,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [
        {
          "instance_id": "62751354-3114-440b-a24a-361d8067f3d4",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:05:19.262328Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "cb3e7ee7ae96a7b03e77fe0dfdd756a68d41a5ff",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 86400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "f53ae961-7dcd-576f-badd-098f907d9bd2",
      "name": "deepseek-ai/DeepSeek-V3-0324-turbo",
      "tagline": "",
      "readme": "deepseek-ai/DeepSeek-V3-0324",
      "public": true,
      "version": "584377c7-0a73-5ef6-b293-4dc84a825a7d",
      "tool_description": null,
      "slug": "chutes-deepseek-ai-deepseek-v3-0324-turbo",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "3fc9a9a4-04f1-515d-bad8-ccf3e093b22e",
      "created_at": "2025-09-17T12:56:33.368152Z",
      "updated_at": "2025-10-19T13:02:01.398814Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 2735,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 1,
            "tao": 0.00248352121585251
          },
          "output": {
            "usd": 3,
            "tao": 0.00745056364755754
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "d5943d93-1dcb-4b2d-a835-793c27557f90",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T03:06:08.682311Z"
        },
        {
          "instance_id": "1fcce2b9-0251-40b9-a56b-3b06024cd41b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T03:06:39.740731Z"
        },
        {
          "instance_id": "e014cc8a-0711-49cd-8ed4-688837ae7ca1",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T05:37:36.017574Z"
        },
        {
          "instance_id": "63350b8c-1bae-4a83-9169-0169d4fef629",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T03:11:25.725649Z"
        }
      ],
      "logo_id": "8a56d32d-4b77-4617-9045-a29096cb4d1c",
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "e9b33add76883f293d6bf61f6bd89b497e80e335",
      "concurrency": 24,
      "boost": 3,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/8a56d32d-4b77-4617-9045-a29096cb4d1c.webp",
      "hot": true
    },
    {
      "chute_id": "eaffac90-0cf6-5925-9685-c629d796f68b",
      "name": "Pavvav/Affine-world11",
      "tagline": "",
      "readme": "Pavvav/Affine-world11",
      "public": false,
      "version": "67457921-c336-572d-a6f6-2bced89273e9",
      "tool_description": null,
      "slug": "paris05-pavvav-affine-world11",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-20T19:08:27.641337Z",
      "updated_at": "2025-10-20T19:08:27.641337Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "paris05",
        "user_id": "84edadd6-72e8-57ab-9c24-109948dbcefd",
        "logo_id": null,
        "created_at": "2025-10-20T18:43:44.030425Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "b200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 2598,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [
        {
          "instance_id": "72fa202e-31f8-4f80-95c3-bf1508d528b9",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-20T23:05:51.976223Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "cd5c4e1deb190396e0cbe73c36d07f7877d89cd3",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 86400,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "64371741-a0a4-577c-923e-f545da8f6476",
      "name": "zai-org/GLM-4.5-turbo",
      "tagline": "",
      "readme": "zai-org/GLM-4.5-FP8",
      "public": true,
      "version": "d205000b-20e4-5a61-bf01-a5f2a1f023d6",
      "tool_description": null,
      "slug": "chutes-zai-org-glm-4-5-turbo",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "ec6cff99-787a-5f59-a4ed-c6890628d937",
      "created_at": "2025-09-17T13:39:21.215031Z",
      "updated_at": "2025-10-19T13:32:09.643314Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 1414,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 1,
            "tao": 0.00248352121585251
          },
          "output": {
            "usd": 3,
            "tao": 0.00745056364755754
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [
        {
          "instance_id": "255697f1-35b5-49ea-9baf-d17ece61f42a",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:37:34.070186Z"
        },
        {
          "instance_id": "5fff23e9-bd8d-4456-bd60-4d1c943ad2bb",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:37:34.070186Z"
        },
        {
          "instance_id": "a2f642c0-2480-4762-bce7-62467c57b2bc",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:37:34.070186Z"
        },
        {
          "instance_id": "0b9fc775-00db-499f-8858-e2777c4aa811",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:37:34.070186Z"
        }
      ],
      "logo_id": "120dc841-a82e-463f-a2e5-e69d674541b6",
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "a0f46d4df319ef3877e248e617035d4317729846",
      "concurrency": 24,
      "boost": 3,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/120dc841-a82e-463f-a2e5-e69d674541b6.webp",
      "hot": true
    },
    {
      "chute_id": "12d334b7-2f8e-5a7b-acf4-775e24f50c8a",
      "name": "hO61qjpwxu/Affine_ghs_2",
      "tagline": "",
      "readme": "hO61qjpwxu/Affine_ghs_2",
      "public": false,
      "version": "b2ced07c-9da8-5d2f-bab6-5bd51e51e0d7",
      "tool_description": null,
      "slug": "wang-d7-ho61qjpwxu-affine-ghs-2",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "0315a7ff-bd8f-5415-a4f7-d0a367cfcfde",
      "created_at": "2025-10-21T03:15:42.260770Z",
      "updated_at": "2025-10-21T03:15:42.260770Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "wang_d7",
        "user_id": "00c36609-44ec-5ced-a5ba-d4abbeb6c27d",
        "logo_id": null,
        "created_at": "2025-10-21T03:00:58.539800Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h100",
          "h200",
          "h100_sxm"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.397777777777778,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 1219,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.02,
            "tao": 0.00004967042431705
          },
          "output": {
            "usd": 0.1,
            "tao": 0.000248352121585251
          }
        },
        "usd": {
          "hour": 1.79,
          "second": 0.000497222222222222
        },
        "tao": {
          "hour": 0.004445502976376,
          "second": 0.000001234861937882
        }
      },
      "instances": [
        {
          "instance_id": "a1e37a14-b8a8-4147-bec9-fd8d419b46c2",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:49:25.490191Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "44f594b4e167fddd4981924aed7c652bee2b4d94",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "9bfd1912-a450-5c4f-95ed-eb7389fd2472",
      "name": "ebobo/Affine-5HWGnX9ndSwC1s76y66DWwasaiBWNsRBcJpVhHh4UyXq7PJq",
      "tagline": "",
      "readme": "ebobo/Affine-5HWGnX9ndSwC1s76y66DWwasaiBWNsRBcJpVhHh4UyXq7PJq",
      "public": false,
      "version": "85f7923a-524a-5474-84cc-cabb9e4e5144",
      "tool_description": null,
      "slug": "newall5-ebobo-affine-5hwgnx9ndswc1s76y66dwwasaibwnsrbcjpvh",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-28T11:55:07.727826Z",
      "updated_at": "2025-10-20T18:13:36.299310Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "newall5",
        "user_id": "18619dbd-a272-5caa-8e91-7f3e1c8cb7cc",
        "logo_id": null,
        "created_at": "2025-09-28T11:44:25.764023Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 1131,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "30d53313f08b42e0b5c2d3ee2334c91134b2983f",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 120000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "3d1b30a8-d5be-5ce5-99c7-4fc1ddc9becb",
      "name": "rednote-hilab/dots.ocr",
      "tagline": "dots.ocr is a 1.7B parameter vision-language model that parses and extracts text, formulas, tables and layout information from documents in multiple languages with state-of-the-art accuracy.",
      "readme": "\n\u003Cdiv align=\"center\"\u003E\n\n\u003Cp align=\"center\"\u003E\n    \u003Cimg src=\"https://raw.githubusercontent.com/rednote-hilab/dots.ocr/master/assets/logo.png\" width=\"300\"/\u003E\n\u003Cp\u003E\n\n\u003Ch1 align=\"center\"\u003E\ndots.ocr: Multilingual Document Layout Parsing in a Single Vision-Language Model\n\u003C/h1\u003E\n\n[![Blog](https://img.shields.io/badge/Blog-View_on_GitHub-333.svg?logo=github)](https://github.com/rednote-hilab/dots.ocr/blob/master/assets/blog.md)\n[![HuggingFace](https://img.shields.io/badge/HuggingFace%20Weights-black.svg?logo=HuggingFace)](https://huggingface.co/rednote-hilab/dots.ocr)\n\n\n\u003Cdiv align=\"center\"\u003E\n  \u003Ca href=\"https://dotsocr.xiaohongshu.com\" target=\"_blank\" rel=\"noopener noreferrer\"\u003E\u003Cstrong\u003EğŸ–¥ï¸ Live Demo\u003C/strong\u003E\u003C/a\u003E | \n  \u003Ca href=\"https://raw.githubusercontent.com/rednote-hilab/dots.ocr/master/assets/wechat.jpg\" target=\"_blank\" rel=\"noopener noreferrer\"\u003E\u003Cstrong\u003EğŸ’¬ WeChat\u003C/strong\u003E\u003C/a\u003E | \n  \u003Ca href=\"https://www.xiaohongshu.com/user/profile/683ffe42000000001d021a4c\" target=\"_blank\" rel=\"noopener noreferrer\"\u003E\u003Cstrong\u003EğŸ“• rednote\u003C/strong\u003E\u003C/a\u003E\n\u003C/div\u003E\n\n\u003C/div\u003E\n\n\n\n## Introduction\n\n**dots.ocr** is a powerful, multilingual document parser that unifies layout detection and content recognition within a single vision-language model while maintaining good reading order. Despite its compact 1.7B-parameter LLM foundation, it achieves state-of-the-art(SOTA) performance.\n\n1. **Powerful Performance:** **dots.ocr** achieves SOTA performance for text, tables, and reading order on [OmniDocBench](https://github.com/opendatalab/OmniDocBench), while delivering formula recognition results comparable to much larger models like Doubao-1.5 and gemini2.5-pro.\n2. **Multilingual Support:** **dots.ocr** demonstrates robust parsing capabilities for low-resource languages, achieving decisive advantages across both layout detection and content recognition on our in-house multilingual documents benchmark.\n3. **Unified and Simple Architecture:** By leveraging a single vision-language model, **dots.ocr** offers a significantly more streamlined architecture than conventional methods that rely on complex, multi-model pipelines. Switching between tasks is accomplished simply by altering the input prompt, proving that a VLM can achieve competitive detection results compared to traditional detection models like DocLayout-YOLO.\n4.  **Efficient and Fast Performance:** Built upon a compact 1.7B LLM, **dots.ocr** provides faster inference speeds than many other high-performing models based on larger foundations.\n\n\n## Usage with transformers\n\n```py\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoProcessor, AutoTokenizer\nfrom qwen_vl_utils import process_vision_info\nfrom dots_ocr.utils import dict_promptmode_to_prompt\n\nmodel_path = \"./weights/DotsOCR\"\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    attn_implementation=\"flash_attention_2\",\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\nprocessor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)\n\nimage_path = \"demo/demo_image1.jpg\"\nprompt = \"\"\"Please output the layout information from the PDF image, including each layout element's bbox, its category, and the corresponding text content within the bbox.\n\n1. Bbox format: [x1, y1, x2, y2]\n\n2. Layout Categories: The possible categories are ['Caption', 'Footnote', 'Formula', 'List-item', 'Page-footer', 'Page-header', 'Picture', 'Section-header', 'Table', 'Text', 'Title'].\n\n3. Text Extraction & Formatting Rules:\n    - Picture: For the 'Picture' category, the text field should be omitted.\n    - Formula: Format its text as LaTeX.\n    - Table: Format its text as HTML.\n    - All Others (Text, Title, etc.): Format their text as Markdown.\n\n4. Constraints:\n    - The output text must be the original text from the image, with no translation.\n    - All layout elements must be sorted according to human reading order.\n\n5. Final Output: The entire output must be a single JSON object.\n\"\"\"\n\nmessages = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"image\",\n                    \"image\": image_path\n                },\n                {\"type\": \"text\", \"text\": prompt}\n            ]\n        }\n    ]\n\n# Preparation for inference\ntext = processor.apply_chat_template(\n    messages, \n    tokenize=False, \n    add_generation_prompt=True\n)\nimage_inputs, video_inputs = process_vision_info(messages)\ninputs = processor(\n    text=[text],\n    images=image_inputs,\n    videos=video_inputs,\n    padding=True,\n    return_tensors=\"pt\",\n)\n\ninputs = inputs.to(\"cuda\")\n\n# Inference: Generation of the output\ngenerated_ids = model.generate(**inputs, max_new_tokens=24000)\ngenerated_ids_trimmed = [\n    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n]\noutput_text = processor.batch_decode(\n    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n)\nprint(output_text)\n```\n\n### Performance Comparison: dots.ocr vs. Competing Models\n\u003Cimg src=\"https://raw.githubusercontent.com/rednote-hilab/dots.ocr/master/assets/chart.png\" border=\"0\" /\u003E\n\n\u003E **Notes:** \n\u003E - The EN, ZH metrics are the end2end evaluation results of [OmniDocBench](https://github.com/opendatalab/OmniDocBench), and Multilingual metric is the end2end evaluation results of dots.ocr-bench.\n\n\n## News \n* ```2025.07.30 ``` ğŸš€ We release [dots.ocr](https://github.com/rednote-hilab/dots.ocr), â€” a multilingual documents parsing model based on 1.7b llm, with SOTA performance.\n\n\n\n## Benchmark Results\n\n### 1. OmniDocBench\n\n#### The end-to-end evaluation results of different tasks.\n\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth rowspan=\"2\"\u003E\u003Cstrong\u003EModel\u003Cbr\u003EType\u003C/strong\u003E\u003C/th\u003E\n\u003Cth rowspan=\"2\"\u003E\u003Cstrong\u003EMethods\u003C/strong\u003E\u003C/th\u003E\n\u003Cth colspan=\"2\"\u003E\u003Cstrong\u003EOverall\u003Csup\u003EEdit\u003C/sup\u003Eâ†“\u003C/strong\u003E\u003C/th\u003E\n\u003Cth colspan=\"2\"\u003E\u003Cstrong\u003EText\u003Csup\u003EEdit\u003C/sup\u003Eâ†“\u003C/strong\u003E\u003C/th\u003E\n\u003Cth colspan=\"2\"\u003E\u003Cstrong\u003EFormula\u003Csup\u003EEdit\u003C/sup\u003Eâ†“\u003C/strong\u003E\u003C/th\u003E\n\u003Cth colspan=\"2\"\u003E\u003Cstrong\u003ETable\u003Csup\u003ETEDS\u003C/sup\u003Eâ†‘\u003C/strong\u003E\u003C/th\u003E\n\u003Cth colspan=\"2\"\u003E\u003Cstrong\u003ETable\u003Csup\u003EEdit\u003C/sup\u003Eâ†“\u003C/strong\u003E\u003C/th\u003E\n\u003Cth colspan=\"2\"\u003E\u003Cstrong\u003ERead Order\u003Csup\u003EEdit\u003C/sup\u003Eâ†“\u003C/strong\u003E\u003C/th\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Cth\u003E\u003Cem\u003EEN\u003C/em\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cem\u003EZH\u003C/em\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cem\u003EEN\u003C/em\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cem\u003EZH\u003C/em\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cem\u003EEN\u003C/em\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cem\u003EZH\u003C/em\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cem\u003EEN\u003C/em\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cem\u003EZH\u003C/em\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cem\u003EEN\u003C/em\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cem\u003EZH\u003C/em\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cem\u003EEN\u003C/em\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cem\u003EZH\u003C/em\u003E\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd rowspan=\"8\"\u003E\u003Cstrong\u003EPipeline\u003Cbr\u003ETools\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003EMinerU\u003C/td\u003E\n\u003Ctd\u003E0.150\u003C/td\u003E\n\u003Ctd\u003E0.357\u003C/td\u003E\n\u003Ctd\u003E0.061\u003C/td\u003E\n\u003Ctd\u003E0.215\u003C/td\u003E\n\u003Ctd\u003E0.278\u003C/td\u003E\n\u003Ctd\u003E0.577\u003C/td\u003E\n\u003Ctd\u003E78.6\u003C/td\u003E\n\u003Ctd\u003E62.1\u003C/td\u003E\n\u003Ctd\u003E0.180\u003C/td\u003E\n\u003Ctd\u003E0.344\u003C/td\u003E\n\u003Ctd\u003E0.079\u003C/td\u003E\n\u003Ctd\u003E0.292\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EMarker\u003C/td\u003E\n\u003Ctd\u003E0.336\u003C/td\u003E\n\u003Ctd\u003E0.556\u003C/td\u003E\n\u003Ctd\u003E0.080\u003C/td\u003E\n\u003Ctd\u003E0.315\u003C/td\u003E\n\u003Ctd\u003E0.530\u003C/td\u003E\n\u003Ctd\u003E0.883\u003C/td\u003E\n\u003Ctd\u003E67.6\u003C/td\u003E\n\u003Ctd\u003E49.2\u003C/td\u003E\n\u003Ctd\u003E0.619\u003C/td\u003E\n\u003Ctd\u003E0.685\u003C/td\u003E\n\u003Ctd\u003E0.114\u003C/td\u003E\n\u003Ctd\u003E0.340\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EMathpix\u003C/td\u003E\n\u003Ctd\u003E0.191\u003C/td\u003E\n\u003Ctd\u003E0.365\u003C/td\u003E\n\u003Ctd\u003E0.105\u003C/td\u003E\n\u003Ctd\u003E0.384\u003C/td\u003E\n\u003Ctd\u003E0.306\u003C/td\u003E\n\u003Ctd\u003E0.454\u003C/td\u003E\n\u003Ctd\u003E77.0\u003C/td\u003E\n\u003Ctd\u003E67.1\u003C/td\u003E\n\u003Ctd\u003E0.243\u003C/td\u003E\n\u003Ctd\u003E0.320\u003C/td\u003E\n\u003Ctd\u003E0.108\u003C/td\u003E\n\u003Ctd\u003E0.304\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EDocling\u003C/td\u003E\n\u003Ctd\u003E0.589\u003C/td\u003E\n\u003Ctd\u003E0.909\u003C/td\u003E\n\u003Ctd\u003E0.416\u003C/td\u003E\n\u003Ctd\u003E0.987\u003C/td\u003E\n\u003Ctd\u003E0.999\u003C/td\u003E\n\u003Ctd\u003E1\u003C/td\u003E\n\u003Ctd\u003E61.3\u003C/td\u003E\n\u003Ctd\u003E25.0\u003C/td\u003E\n\u003Ctd\u003E0.627\u003C/td\u003E\n\u003Ctd\u003E0.810\u003C/td\u003E\n\u003Ctd\u003E0.313\u003C/td\u003E\n\u003Ctd\u003E0.837\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EPix2Text\u003C/td\u003E\n\u003Ctd\u003E0.320\u003C/td\u003E\n\u003Ctd\u003E0.528\u003C/td\u003E\n\u003Ctd\u003E0.138\u003C/td\u003E\n\u003Ctd\u003E0.356\u003C/td\u003E\n\u003Ctd\u003E0.276\u003C/td\u003E\n\u003Ctd\u003E0.611\u003C/td\u003E\n\u003Ctd\u003E73.6\u003C/td\u003E\n\u003Ctd\u003E66.2\u003C/td\u003E\n\u003Ctd\u003E0.584\u003C/td\u003E\n\u003Ctd\u003E0.645\u003C/td\u003E\n\u003Ctd\u003E0.281\u003C/td\u003E\n\u003Ctd\u003E0.499\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EUnstructured\u003C/td\u003E\n\u003Ctd\u003E0.586\u003C/td\u003E\n\u003Ctd\u003E0.716\u003C/td\u003E\n\u003Ctd\u003E0.198\u003C/td\u003E\n\u003Ctd\u003E0.481\u003C/td\u003E\n\u003Ctd\u003E0.999\u003C/td\u003E\n\u003Ctd\u003E1\u003C/td\u003E\n\u003Ctd\u003E0\u003C/td\u003E\n\u003Ctd\u003E0.06\u003C/td\u003E\n\u003Ctd\u003E1\u003C/td\u003E\n\u003Ctd\u003E0.998\u003C/td\u003E\n\u003Ctd\u003E0.145\u003C/td\u003E\n\u003Ctd\u003E0.387\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EOpenParse\u003C/td\u003E\n\u003Ctd\u003E0.646\u003C/td\u003E\n\u003Ctd\u003E0.814\u003C/td\u003E\n\u003Ctd\u003E0.681\u003C/td\u003E\n\u003Ctd\u003E0.974\u003C/td\u003E\n\u003Ctd\u003E0.996\u003C/td\u003E\n\u003Ctd\u003E1\u003C/td\u003E\n\u003Ctd\u003E64.8\u003C/td\u003E\n\u003Ctd\u003E27.5\u003C/td\u003E\n\u003Ctd\u003E0.284\u003C/td\u003E\n\u003Ctd\u003E0.639\u003C/td\u003E\n\u003Ctd\u003E0.595\u003C/td\u003E\n\u003Ctd\u003E0.641\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EPPStruct-V3\u003C/td\u003E\n\u003Ctd\u003E0.145\u003C/td\u003E\n\u003Ctd\u003E0.206\u003C/td\u003E\n\u003Ctd\u003E0.058\u003C/td\u003E\n\u003Ctd\u003E0.088\u003C/td\u003E\n\u003Ctd\u003E0.295\u003C/td\u003E\n\u003Ctd\u003E0.535\u003C/td\u003E\n\u003Ctd\u003E-\u003C/td\u003E\n\u003Ctd\u003E-\u003C/td\u003E\n\u003Ctd\u003E0.159\u003C/td\u003E\n\u003Ctd\u003E0.109\u003C/td\u003E\n\u003Ctd\u003E0.069\u003C/td\u003E\n\u003Ctd\u003E0.091\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd rowspan=\"9\"\u003E\u003Cstrong\u003EExpert\u003Cbr\u003EVLMs\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003EGOT-OCR\u003C/td\u003E\n\u003Ctd\u003E0.287\u003C/td\u003E\n\u003Ctd\u003E0.411\u003C/td\u003E\n\u003Ctd\u003E0.189\u003C/td\u003E\n\u003Ctd\u003E0.315\u003C/td\u003E\n\u003Ctd\u003E0.360\u003C/td\u003E\n\u003Ctd\u003E0.528\u003C/td\u003E\n\u003Ctd\u003E53.2\u003C/td\u003E\n\u003Ctd\u003E47.2\u003C/td\u003E\n\u003Ctd\u003E0.459\u003C/td\u003E\n\u003Ctd\u003E0.520\u003C/td\u003E\n\u003Ctd\u003E0.141\u003C/td\u003E\n\u003Ctd\u003E0.280\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ENougat\u003C/td\u003E\n\u003Ctd\u003E0.452\u003C/td\u003E\n\u003Ctd\u003E0.973\u003C/td\u003E\n\u003Ctd\u003E0.365\u003C/td\u003E\n\u003Ctd\u003E0.998\u003C/td\u003E\n\u003Ctd\u003E0.488\u003C/td\u003E\n\u003Ctd\u003E0.941\u003C/td\u003E\n\u003Ctd\u003E39.9\u003C/td\u003E\n\u003Ctd\u003E0\u003C/td\u003E\n\u003Ctd\u003E0.572\u003C/td\u003E\n\u003Ctd\u003E1.000\u003C/td\u003E\n\u003Ctd\u003E0.382\u003C/td\u003E\n\u003Ctd\u003E0.954\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EMistral OCR\u003C/td\u003E\n\u003Ctd\u003E0.268\u003C/td\u003E\n\u003Ctd\u003E0.439\u003C/td\u003E\n\u003Ctd\u003E0.072\u003C/td\u003E\n\u003Ctd\u003E0.325\u003C/td\u003E\n\u003Ctd\u003E0.318\u003C/td\u003E\n\u003Ctd\u003E0.495\u003C/td\u003E\n\u003Ctd\u003E75.8\u003C/td\u003E\n\u003Ctd\u003E63.6\u003C/td\u003E\n\u003Ctd\u003E0.600\u003C/td\u003E\n\u003Ctd\u003E0.650\u003C/td\u003E\n\u003Ctd\u003E0.083\u003C/td\u003E\n\u003Ctd\u003E0.284\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EOLMOCR-sglang\u003C/td\u003E\n\u003Ctd\u003E0.326\u003C/td\u003E\n\u003Ctd\u003E0.469\u003C/td\u003E\n\u003Ctd\u003E0.097\u003C/td\u003E\n\u003Ctd\u003E0.293\u003C/td\u003E\n\u003Ctd\u003E0.455\u003C/td\u003E\n\u003Ctd\u003E0.655\u003C/td\u003E\n\u003Ctd\u003E68.1\u003C/td\u003E\n\u003Ctd\u003E61.3\u003C/td\u003E\n\u003Ctd\u003E0.608\u003C/td\u003E\n\u003Ctd\u003E0.652\u003C/td\u003E\n\u003Ctd\u003E0.145\u003C/td\u003E\n\u003Ctd\u003E0.277\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ESmolDocling-256M\u003C/td\u003E\n\u003Ctd\u003E0.493\u003C/td\u003E\n\u003Ctd\u003E0.816\u003C/td\u003E\n\u003Ctd\u003E0.262\u003C/td\u003E\n\u003Ctd\u003E0.838\u003C/td\u003E\n\u003Ctd\u003E0.753\u003C/td\u003E\n\u003Ctd\u003E0.997\u003C/td\u003E\n\u003Ctd\u003E44.9\u003C/td\u003E\n\u003Ctd\u003E16.5\u003C/td\u003E\n\u003Ctd\u003E0.729\u003C/td\u003E\n\u003Ctd\u003E0.907\u003C/td\u003E\n\u003Ctd\u003E0.227\u003C/td\u003E\n\u003Ctd\u003E0.522\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EDolphin\u003C/td\u003E\n\u003Ctd\u003E0.206\u003C/td\u003E\n\u003Ctd\u003E0.306\u003C/td\u003E\n\u003Ctd\u003E0.107\u003C/td\u003E\n\u003Ctd\u003E0.197\u003C/td\u003E\n\u003Ctd\u003E0.447\u003C/td\u003E\n\u003Ctd\u003E0.580\u003C/td\u003E\n\u003Ctd\u003E77.3\u003C/td\u003E\n\u003Ctd\u003E67.2\u003C/td\u003E\n\u003Ctd\u003E0.180\u003C/td\u003E\n\u003Ctd\u003E0.285\u003C/td\u003E\n\u003Ctd\u003E0.091\u003C/td\u003E\n\u003Ctd\u003E0.162\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EMinerU 2\u003C/td\u003E\n\u003Ctd\u003E0.139\u003C/td\u003E\n\u003Ctd\u003E0.240\u003C/td\u003E\n\u003Ctd\u003E0.047\u003C/td\u003E\n\u003Ctd\u003E0.109\u003C/td\u003E\n\u003Ctd\u003E0.297\u003C/td\u003E\n\u003Ctd\u003E0.536\u003C/td\u003E\n\u003Ctd\u003E82.5\u003C/td\u003E\n\u003Ctd\u003E79.0\u003C/td\u003E\n\u003Ctd\u003E0.141\u003C/td\u003E\n\u003Ctd\u003E0.195\u003C/td\u003E\n\u003Ctd\u003E0.069\u003C\u003C/td\u003E\n\u003Ctd\u003E0.118\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EOCRFlux\u003C/td\u003E\n\u003Ctd\u003E0.195\u003C/td\u003E\n\u003Ctd\u003E0.281\u003C/td\u003E\n\u003Ctd\u003E0.064\u003C/td\u003E\n\u003Ctd\u003E0.183\u003C/td\u003E\n\u003Ctd\u003E0.379\u003C/td\u003E\n\u003Ctd\u003E0.613\u003C/td\u003E\n\u003Ctd\u003E71.6\u003C/td\u003E\n\u003Ctd\u003E81.3\u003C/td\u003E\n\u003Ctd\u003E0.253\u003C/td\u003E\n\u003Ctd\u003E0.139\u003C/td\u003E\n\u003Ctd\u003E0.086\u003C/td\u003E\n\u003Ctd\u003E0.187\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EMonkeyOCR-pro-3B\u003C/td\u003E\n\u003Ctd\u003E0.138\u003C/td\u003E\n\u003Ctd\u003E0.206\u003C/td\u003E\n\u003Ctd\u003E0.067\u003C/td\u003E\n\u003Ctd\u003E0.107\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E0.246\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E0.421\u003C/td\u003E\n\u003Ctd\u003E81.5\u003C/td\u003E\n\u003Ctd\u003E87.5\u003C/td\u003E\n\u003Ctd\u003E0.139\u003C/td\u003E\n\u003Ctd\u003E0.111\u003C/td\u003E\n\u003Ctd\u003E0.100\u003C/td\u003E\n\u003Ctd\u003E0.185\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\n\u003Ctd rowspan=\"5\"\u003E\u003Cstrong\u003EGeneral\u003Cbr\u003EVLMs\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003EGPT4o\u003C/td\u003E\n\u003Ctd\u003E0.233\u003C/td\u003E\n\u003Ctd\u003E0.399\u003C/td\u003E\n\u003Ctd\u003E0.144\u003C/td\u003E\n\u003Ctd\u003E0.409\u003C/td\u003E\n\u003Ctd\u003E0.425\u003C/td\u003E\n\u003Ctd\u003E0.606\u003C/td\u003E\n\u003Ctd\u003E72.0\u003C/td\u003E\n\u003Ctd\u003E62.9\u003C/td\u003E\n\u003Ctd\u003E0.234\u003C/td\u003E\n\u003Ctd\u003E0.329\u003C/td\u003E\n\u003Ctd\u003E0.128\u003C/td\u003E\n\u003Ctd\u003E0.251\u003C/td\u003E\n\u003C/tr\u003E\n    \u003Ctr\u003E\n      \u003Ctd\u003EQwen2-VL-72B\u003C/td\u003E\n      \u003Ctd\u003E0.252\u003C/td\u003E\n      \u003Ctd\u003E0.327\u003C/td\u003E\n      \u003Ctd\u003E0.096\u003C/td\u003E\n      \u003Ctd\u003E0.218\u003C/td\u003E\n      \u003Ctd\u003E0.404\u003C/td\u003E\n      \u003Ctd\u003E0.487\u003C/td\u003E\n      \u003Ctd\u003E76.8\u003C/td\u003E\n      \u003Ctd\u003E76.4\u003C/td\u003E\n      \u003Ctd\u003E0.387\u003C/td\u003E\n      \u003Ctd\u003E0.408\u003C/td\u003E\n      \u003Ctd\u003E0.119\u003C/td\u003E\n      \u003Ctd\u003E0.193\u003C/td\u003E\n    \u003C/tr\u003E\n    \u003Ctr\u003E\n      \u003Ctd\u003EQwen2.5-VL-72B\u003C/td\u003E\n      \u003Ctd\u003E0.214\u003C/td\u003E\n      \u003Ctd\u003E0.261\u003C/td\u003E\n      \u003Ctd\u003E0.092\u003C/td\u003E\n      \u003Ctd\u003E0.18\u003C/td\u003E\n      \u003Ctd\u003E0.315\u003C/td\u003E\n      \u003Ctd\u003E0.434\u003C/td\u003E\n      \u003Ctd\u003E82.9\u003C/td\u003E\n      \u003Ctd\u003E83.9\u003C/td\u003E\n      \u003Ctd\u003E0.341\u003C/td\u003E\n      \u003Ctd\u003E0.262\u003C/td\u003E\n      \u003Ctd\u003E0.106\u003C/td\u003E\n      \u003Ctd\u003E0.168\u003C/td\u003E\n    \u003C/tr\u003E\n    \u003Ctr\u003E\n      \u003Ctd\u003EGemini2.5-Pro\u003C/td\u003E\n      \u003Ctd\u003E0.148\u003C/td\u003E\n      \u003Ctd\u003E0.212\u003C/td\u003E\n      \u003Ctd\u003E0.055\u003C/td\u003E\n      \u003Ctd\u003E0.168\u003C/td\u003E\n      \u003Ctd\u003E0.356\u003C/td\u003E\n      \u003Ctd\u003E0.439\u003C/td\u003E\n      \u003Ctd\u003E85.8\u003C/td\u003E\n      \u003Ctd\u003E86.4\u003C/td\u003E\n      \u003Ctd\u003E0.13\u003C/td\u003E\n      \u003Ctd\u003E0.119\u003C/td\u003E\n      \u003Ctd\u003E0.049\u003C/td\u003E\n      \u003Ctd\u003E0.121\u003C/td\u003E\n    \u003C/tr\u003E\n    \u003Ctr\u003E\n      \u003Ctd\u003Edoubao-1-5-thinking-vision-pro-250428\u003C/td\u003E\n      \u003Ctd\u003E0.140\u003C/td\u003E\n      \u003Ctd\u003E0.162\u003C/td\u003E\n      \u003Ctd\u003E0.043\u003C/td\u003E\n      \u003Ctd\u003E0.085\u003C/td\u003E\n      \u003Ctd\u003E0.295\u003C/td\u003E\n      \u003Ctd\u003E\u003Cstrong\u003E0.384\u003C/strong\u003E\u003C/td\u003E\n      \u003Ctd\u003E83.3\u003C/td\u003E\n      \u003Ctd\u003E\u003Cstrong\u003E89.3\u003C/strong\u003E\u003C/td\u003E\n      \u003Ctd\u003E0.165\u003C/td\u003E\n      \u003Ctd\u003E\u003Cstrong\u003E0.085\u003C/strong\u003E\u003C/td\u003E\n      \u003Ctd\u003E0.058\u003C/td\u003E\n      \u003Ctd\u003E0.094\u003C/td\u003E\n    \u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd rowspan=\"1\"\u003E\u003Cstrong\u003EExpert VLMs\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003Edots.ocr\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E0.125\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E0.160\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E0.032\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E0.066\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E0.329\u003C/td\u003E\n\u003Ctd\u003E0.416\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E88.6\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E89.0\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E0.099\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E0.092\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E0.040\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E0.067\u003C/strong\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\n\n#### The end-to-end text recognition performance across 9 PDF page types.\n\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003E\u003Cstrong\u003EModel\u003Cbr\u003EType\u003C/strong\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cstrong\u003EModels\u003C/strong\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cstrong\u003EBook\u003C/strong\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cstrong\u003ESlides\u003C/strong\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cstrong\u003EFinancial\u003Cbr\u003EReport\u003C/strong\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cstrong\u003ETextbook\u003C/strong\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cstrong\u003EExam\u003Cbr\u003EPaper\u003C/strong\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cstrong\u003EMagazine\u003C/strong\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cstrong\u003EAcademic\u003Cbr\u003EPapers\u003C/strong\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cstrong\u003ENotes\u003C/strong\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cstrong\u003ENewspaper\u003C/strong\u003E\u003C/th\u003E\n\u003Cth\u003E\u003Cstrong\u003EOverall\u003C/strong\u003E\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd rowspan=\"3\"\u003E\u003Cstrong\u003EPipeline\u003Cbr\u003ETools\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003EMinerU\u003C/td\u003E\n\u003Ctd\u003E0.055\u003C/td\u003E\n\u003Ctd\u003E0.124\u003C/td\u003E\n\u003Ctd\u003E\u003Cu\u003E0.033\u003C/u\u003E\u003C/td\u003E\n\u003Ctd\u003E0.102\u003C/td\u003E\n\u003Ctd\u003E0.159\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E0.072\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Cu\u003E0.025\u003C/u\u003E\u003C/td\u003E\n\u003Ctd\u003E0.984\u003C/td\u003E\n\u003Ctd\u003E0.171\u003C/td\u003E\n\u003Ctd\u003E0.206\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EMarker\u003C/td\u003E\n\u003Ctd\u003E0.074\u003C/td\u003E\n\u003Ctd\u003E0.340\u003C/td\u003E\n\u003Ctd\u003E0.089\u003C/td\u003E\n\u003Ctd\u003E0.319\u003C/td\u003E\n\u003Ctd\u003E0.452\u003C/td\u003E\n\u003Ctd\u003E0.153\u003C/td\u003E\n\u003Ctd\u003E0.059\u003C/td\u003E\n\u003Ctd\u003E0.651\u003C/td\u003E\n\u003Ctd\u003E0.192\u003C/td\u003E\n\u003Ctd\u003E0.274\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EMathpix\u003C/td\u003E\n\u003Ctd\u003E0.131\u003C/td\u003E\n\u003Ctd\u003E0.220\u003C/td\u003E\n\u003Ctd\u003E0.202\u003C/td\u003E\n\u003Ctd\u003E0.216\u003C/td\u003E\n\u003Ctd\u003E0.278\u003C/td\u003E\n\u003Ctd\u003E0.147\u003C/td\u003E\n\u003Ctd\u003E0.091\u003C/td\u003E\n\u003Ctd\u003E0.634\u003C/td\u003E\n\u003Ctd\u003E0.690\u003C/td\u003E\n\u003Ctd\u003E0.300\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd rowspan=\"5\"\u003E\u003Cstrong\u003EExpert\u003Cbr\u003EVLMs\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003EGOT-OCR\u003C/td\u003E\n\u003Ctd\u003E0.111\u003C/td\u003E\n\u003Ctd\u003E0.222\u003C/td\u003E\n\u003Ctd\u003E0.067\u003C/td\u003E\n\u003Ctd\u003E0.132\u003C/td\u003E\n\u003Ctd\u003E0.204\u003C/td\u003E\n\u003Ctd\u003E0.198\u003C/td\u003E\n\u003Ctd\u003E0.179\u003C/td\u003E\n\u003Ctd\u003E0.388\u003C/td\u003E\n\u003Ctd\u003E0.771\u003C/td\u003E\n\u003Ctd\u003E0.267\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ENougat\u003C/td\u003E\n\u003Ctd\u003E0.734\u003C/td\u003E\n\u003Ctd\u003E0.958\u003C/td\u003E\n\u003Ctd\u003E1.000\u003C/td\u003E\n\u003Ctd\u003E0.820\u003C/td\u003E\n\u003Ctd\u003E0.930\u003C/td\u003E\n\u003Ctd\u003E0.830\u003C/td\u003E\n\u003Ctd\u003E0.214\u003C/td\u003E\n\u003Ctd\u003E0.991\u003C/td\u003E\n\u003Ctd\u003E0.871\u003C/td\u003E\n\u003Ctd\u003E0.806\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EDolphin\u003C/td\u003E\n\u003Ctd\u003E0.091\u003C/td\u003E\n\u003Ctd\u003E0.131\u003C/td\u003E\n\u003Ctd\u003E0.057\u003C/td\u003E\n\u003Ctd\u003E0.146\u003C/td\u003E\n\u003Ctd\u003E0.231\u003C/td\u003E\n\u003Ctd\u003E0.121\u003C/td\u003E\n\u003Ctd\u003E0.074\u003C/td\u003E\n\u003Ctd\u003E0.363\u003C/td\u003E\n\u003Ctd\u003E0.307\u003C/td\u003E\n\u003Ctd\u003E0.177\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EOCRFlux\u003C/td\u003E\n\u003Ctd\u003E0.068\u003C/td\u003E\n\u003Ctd\u003E0.125\u003C/td\u003E\n\u003Ctd\u003E0.092\u003C/td\u003E\n\u003Ctd\u003E0.102\u003C/td\u003E\n\u003Ctd\u003E0.119\u003C/td\u003E\n\u003Ctd\u003E0.083\u003C/td\u003E\n\u003Ctd\u003E0.047\u003C/td\u003E\n\u003Ctd\u003E0.223\u003C/td\u003E\n\u003Ctd\u003E0.536\u003C/td\u003E\n\u003Ctd\u003E0.149\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EMonkeyOCR-pro-3B\u003C/td\u003E\n\u003Ctd\u003E0.084\u003C/td\u003E\n\u003Ctd\u003E0.129\u003C/td\u003E\n\u003Ctd\u003E0.060\u003C/td\u003E\n\u003Ctd\u003E0.090\u003C/td\u003E\n\u003Ctd\u003E0.107\u003C/td\u003E\n\u003Ctd\u003E0.073\u003C/td\u003E\n\u003Ctd\u003E0.050\u003C/td\u003E\n\u003Ctd\u003E0.171\u003C/td\u003E\n\u003Ctd\u003E0.107\u003C/td\u003E\n\u003Ctd\u003E0.100\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd rowspan=\"4\"\u003E\u003Cstrong\u003EGeneral\u003Cbr\u003EVLMs\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003EGPT4o\u003C/td\u003E\n\u003Ctd\u003E0.157\u003C/td\u003E\n\u003Ctd\u003E0.163\u003C/td\u003E\n\u003Ctd\u003E0.348\u003C/td\u003E\n\u003Ctd\u003E0.187\u003C/td\u003E\n\u003Ctd\u003E0.281\u003C/td\u003E\n\u003Ctd\u003E0.173\u003C/td\u003E\n\u003Ctd\u003E0.146\u003C/td\u003E\n\u003Ctd\u003E0.607\u003C/td\u003E\n\u003Ctd\u003E0.751\u003C/td\u003E\n\u003Ctd\u003E0.316\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EQwen2.5-VL-7B\u003C/td\u003E\n\u003Ctd\u003E0.148\u003C/td\u003E\n\u003Ctd\u003E0.053\u003C/td\u003E\n\u003Ctd\u003E0.111\u003C/td\u003E\n\u003Ctd\u003E0.137\u003C/td\u003E\n\u003Ctd\u003E0.189\u003C/td\u003E\n\u003Ctd\u003E0.117\u003C/td\u003E\n\u003Ctd\u003E0.134\u003C/td\u003E\n\u003Ctd\u003E0.204\u003C/td\u003E\n\u003Ctd\u003E0.706\u003C/td\u003E\n\u003Ctd\u003E0.205\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EInternVL3-8B\u003C/td\u003E\n\u003Ctd\u003E0.163\u003C/td\u003E\n\u003Ctd\u003E0.056\u003C/td\u003E\n\u003Ctd\u003E0.107\u003C/td\u003E\n\u003Ctd\u003E0.109\u003C/td\u003E\n\u003Ctd\u003E0.129\u003C/td\u003E\n\u003Ctd\u003E0.100\u003C/td\u003E\n\u003Ctd\u003E0.159\u003C/td\u003E\n\u003Ctd\u003E0.150\u003C/td\u003E\n\u003Ctd\u003E0.681\u003C/td\u003E\n\u003Ctd\u003E0.188\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003Edoubao-1-5-thinking-vision-pro-250428\u003C/td\u003E\n\u003Ctd\u003E0.048\u003C/td\u003E\n\u003Ctd\u003E0.048\u003C/td\u003E\n\u003Ctd\u003E0.024\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E0.062\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E0.085\u003C/td\u003E\n\u003Ctd\u003E0.051\u003C/td\u003E\n\u003Ctd\u003E0.039\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E0.096\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E0.181\u003C/td\u003E\n\u003Ctd\u003E0.073\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd rowspan=\"1\"\u003E\u003Cstrong\u003EExpert VLMs\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003Edots.ocr\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E0.031\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E0.047\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E0.011\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E0.082\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E0.079\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E0.028\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E0.029\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E0.109\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E0.056\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E0.055\u003C/strong\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\n\u003C/tbody\u003E\n\u003C/table\u003E\n\n\u003E **Notes:** \n\u003E - The metrics are from [MonkeyOCR](https://github.com/Yuliang-Liu/MonkeyOCR), [OmniDocBench](https://github.com/opendatalab/OmniDocBench), and our own internal evaluations.\n\u003E - We delete the Page-header and Page-footer cells in the result markdown.\n\u003E - We use tikz_preprocess pipeline to upsample the images to dpi 200.\n\n\n### 2. **dots.ocr-bench**\n\nThis is an inhouse benchmark which contain 1493 pdf images with 100 languages.\n\n#### The end-to-end evaluation results of different tasks.\n\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth rowspan=\"1\"\u003E\u003Cstrong\u003EMethods\u003C/strong\u003E\u003C/th\u003E\n\u003Cth colspan=\"1\"\u003E\u003Cstrong\u003EOverall\u003Csup\u003EEdit\u003C/sup\u003Eâ†“\u003C/strong\u003E\u003C/th\u003E\n\u003Cth colspan=\"1\"\u003E\u003Cst",
      "public": true,
      "version": "0c320b89-5574-5ede-9610-29ff6b86dfb8",
      "tool_description": null,
      "slug": "chutes-rednote-hilab-dots-ocr",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "7e4c99c5-31f0-5254-869e-711c84e4423a",
      "created_at": "2025-10-02T11:32:10.005590Z",
      "updated_at": "2025-10-02T11:32:10.005590Z",
      "image": {
        "image_id": "7f8bd819-6d41-5d2c-aa8d-18d02f3a8391",
        "name": "vllm",
        "readme": "## vLLM - fast, flexible llm inference",
        "tag": "nightly-2025100201",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-02T11:03:47.066302Z",
        "build_started_at": "2025-10-02T11:03:48.683189Z",
        "build_completed_at": "2025-10-02T11:23:46.258327Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "948404928c07",
        "logo": null
      },
      "user": {
        "username": "chutes",
        "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
        "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
        "created_at": "2024-12-03T11:31:39.181725Z",
        "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "mi300x",
        "pro_6000",
        "a4000_ada",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "a4000",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": null,
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.0444444444444444,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "mi300x",
          "pro_6000",
          "a4000_ada",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "a4000",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 1055,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0,
            "tao": 0
          },
          "output": {
            "usd": 0,
            "tao": 0
          }
        },
        "usd": {
          "hour": 0,
          "second": 0
        },
        "tao": {
          "hour": 0,
          "second": 0
        }
      },
      "instances": [
        {
          "instance_id": "4bb0efc9-6fdf-43ff-ad38-db6db41ffe5f",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:11:33.069205Z"
        },
        {
          "instance_id": "4f2ceb93-5e16-4f97-92e7-cc511d092546",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:11:33.069205Z"
        },
        {
          "instance_id": "9e520ba8-d43a-4986-9e78-7ce7e22e95e3",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:11:33.069205Z"
        },
        {
          "instance_id": "be7bdc81-c562-4749-8d36-3d0f511ab1ea",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:11:33.069205Z"
        },
        {
          "instance_id": "c45e929c-5008-4e71-a81f-8041ac928f3b",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:11:33.069205Z"
        },
        {
          "instance_id": "cea81794-e74e-4dbd-86b4-6fc18a19b678",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:11:33.069205Z"
        }
      ],
      "logo_id": "80c6eeca-d15c-434b-9e30-6d2acf3d00d3",
      "openrouter": false,
      "chutes_version": "0.3.35",
      "revision": "ba670c5dcf03ff4e02015558c95b4042f5dce069",
      "concurrency": 8,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": true,
      "allow_external_egress": true,
      "logo": "https://logos.chutes.ai/logos/80c6eeca-d15c-434b-9e30-6d2acf3d00d3.webp",
      "hot": true
    },
    {
      "chute_id": "5a8276b5-0714-552c-9456-06eb8a1afbfa",
      "name": "bittensorflower/Affine-5D1suQXqNk4ZaHFadX4qAkbEWzrQPhNoPXdft7rjAD6LPa8m",
      "tagline": "",
      "readme": "bittensorflower/Affine-5D1suQXqNk4ZaHFadX4qAkbEWzrQPhNoPXdft7rjAD6LPa8m",
      "public": false,
      "version": "556727a7-c22b-5eef-ad02-926b5187746d",
      "tool_description": null,
      "slug": "tensorgardener-bittensorflower-affine-5d1suqxqnk4zahfadx4q",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-20T16:43:43.591846Z",
      "updated_at": "2025-10-20T16:43:43.591846Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "tensorgardener",
        "user_id": "17f0a410-9bb2-5e5d-a2ae-1bac6ffdda6d",
        "logo_id": null,
        "created_at": "2025-08-22T00:24:23.961086Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 963,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [
        {
          "instance_id": "1c925173-1c1f-45e3-b296-13b8eec599ae",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:34:31.867026Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "ec5d966c5c0561671d2aa12384eaf9089c63efcd",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "05bff694-d43e-5f1b-8cc8-13e21fd89e9d",
      "name": "bittensorflower/Affine-5HouHqpcouvhnVKrNhHfm4MmxVp9ZxSm1QyFNjjH3iBweQ1P",
      "tagline": "",
      "readme": "bittensorflower/Affine-5HouHqpcouvhnVKrNhHfm4MmxVp9ZxSm1QyFNjjH3iBweQ1P",
      "public": false,
      "version": "3f4d8092-8a39-5575-8dbe-9c46667d02b6",
      "tool_description": null,
      "slug": "affiner-bittensorflower-affine-5houhqpcouvhnvkrnhhfm4mmxvp",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-21T00:05:20.759907Z",
      "updated_at": "2025-10-21T00:05:20.759907Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "affiner",
        "user_id": "78bf2dbe-7270-5bf5-904d-1885a1d8346b",
        "logo_id": null,
        "created_at": "2025-08-22T19:41:15.889283Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 656,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [
        {
          "instance_id": "e351bb4b-a6c7-4efb-a89e-564a5f7464cf",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:41:58.085957Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "d1fa5cdbe7aab78c9139ba914323f8619fccc97c",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "055eee1e-31dc-523d-ae50-01619a7c87a4",
      "name": "NickDegollado0714/affine_roy_v2",
      "tagline": "",
      "readme": "NickDegollado0714/affine_roy_v2",
      "public": false,
      "version": "0ef2fe4f-47cb-5b0b-99d2-7d29915bc65d",
      "tool_description": null,
      "slug": "jason0309-nickdegollado0714-affine-roy-v2",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "0315a7ff-bd8f-5415-a4f7-d0a367cfcfde",
      "created_at": "2025-10-20T15:18:05.254888Z",
      "updated_at": "2025-10-21T08:39:45.777025Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "jason0309",
        "user_id": "fd1c8670-8d05-5fe0-a30a-9198b25b14ce",
        "logo_id": null,
        "created_at": "2025-10-20T13:49:41.342014Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "b200",
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200",
          "b200"
        ]
      },
      "invocation_count": 317,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [
        {
          "instance_id": "d8267c21-7d13-4888-8c7c-8bb7cf997258",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:41:57.214989Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "2744d2bd8092a38509a41a4d3964415f41c2c8c1",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 15000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "1b1ed3bf-63a0-5093-8ed9-e94049ae0b71",
      "name": "vonmises69/Affine-5G9XPx652tLC4GuWzHytWvj6mJm4YjsXcNucMuDG1ShFUZNS",
      "tagline": "",
      "readme": "",
      "public": false,
      "version": "668ab7f9-eb8a-5444-8bcc-f8e142788b61",
      "tool_description": null,
      "slug": "vonmises42069-vonmises69-affine-5g9xpx652tlc4guwzhytwvj6mj",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-21T02:28:07.461869Z",
      "updated_at": "2025-10-21T03:20:05.670877Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "vonmises42069",
        "user_id": "f74fb195-e3b2-51bf-97e3-0e474d0dc2bc",
        "logo_id": null,
        "created_at": "2025-10-20T23:30:16.654022Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 156,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "535dba0a4fcd622ef282211aa7c04c3d4f3a929e",
      "concurrency": 8,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "849f32f8-2802-51b3-bfaf-e3e7006d15e1",
      "name": "ALGODev/Affine-hot5-01",
      "tagline": "",
      "readme": "ALGODev/Affine-hot5-01",
      "public": false,
      "version": "efb5816c-cd84-512b-b50c-0f1b823c967e",
      "tool_description": null,
      "slug": "algo-aff-05-algodev-affine-hot5-01",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "0315a7ff-bd8f-5415-a4f7-d0a367cfcfde",
      "created_at": "2025-10-21T01:48:55.002882Z",
      "updated_at": "2025-10-21T02:51:44.687247Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "algo_aff_05",
        "user_id": "2674bd44-aa6c-5fdc-bd36-14d040ccacbc",
        "logo_id": null,
        "created_at": "2025-10-20T16:34:51.637073Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 149,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "60d81087-127d-4e34-b174-b5fe88c476ed",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T09:44:56.791747Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "c8980e5ebcb750b83c48e79fd95d22c486ef27ae",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 86400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "40a20667-befe-5ca9-83c3-951411e6d8b9",
      "name": "NickDegollado0714/affine_nick_v1",
      "tagline": "",
      "readme": "NickDegollado0714/affine_nick_v1",
      "public": false,
      "version": "dc48a3a7-0f26-5898-899f-29a2c15dbb39",
      "tool_description": null,
      "slug": "jason0309-nickdegollado0714-affine-nick-v1",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "0315a7ff-bd8f-5415-a4f7-d0a367cfcfde",
      "created_at": "2025-10-20T14:48:47.562224Z",
      "updated_at": "2025-10-21T08:40:01.731702Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "jason0309",
        "user_id": "fd1c8670-8d05-5fe0-a30a-9198b25b14ce",
        "logo_id": null,
        "created_at": "2025-10-20T13:49:41.342014Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "b200",
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200",
          "b200"
        ]
      },
      "invocation_count": 139,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [
        {
          "instance_id": "deddc9b4-bc09-45b0-9923-e06235ca3648",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:12:02.186825Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "812749b2ef7ab13e43d2a798b69c9a1fda9ce9bf",
      "concurrency": 48,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 24000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "0628467e-0ff4-54a2-bf3e-8d692450c538",
      "name": "bittensorflower/Affine-5DoCtYA7YRezivE6uKHvA8YmG4HzZtE326ZDMoHXsx84tRQb",
      "tagline": "",
      "readme": "bittensorflower/Affine-5DoCtYA7YRezivE6uKHvA8YmG4HzZtE326ZDMoHXsx84tRQb",
      "public": false,
      "version": "e6c5dcb0-3563-507d-9a5e-bf0658e5638d",
      "tool_description": null,
      "slug": "affiner7-bittensorflower-affine-5doctya7yrezive6ukhva8ymg4",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-20T17:46:53.322072Z",
      "updated_at": "2025-10-20T17:46:53.322072Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "affiner7",
        "user_id": "8f9e923c-48f9-5dc0-9128-1391d1feaf88",
        "logo_id": null,
        "created_at": "2025-08-26T02:36:18.134723Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 75,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "75fe90e877d11b4f7b9654708d05617a3f74546e",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "2e726e5f-8633-566f-a8b7-ed05f96b6770",
      "name": "Maziko/Affine-120.1",
      "tagline": "",
      "readme": "Maziko/Affine-120.1",
      "public": false,
      "version": "d02246d2-1188-5478-a722-90430c2c577f",
      "tool_description": null,
      "slug": "maziko1-maziko-affine-120-1",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "0315a7ff-bd8f-5415-a4f7-d0a367cfcfde",
      "created_at": "2025-10-21T09:58:05.499306Z",
      "updated_at": "2025-10-21T09:58:05.499306Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "maziko1",
        "user_id": "b1472ae1-a5b9-54aa-8c51-86d0856af38a",
        "logo_id": null,
        "created_at": "2025-10-21T08:03:30.827713Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "h100"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200",
          "h100"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.397777777777778,
        "supported_gpus": [
          "h200",
          "h100"
        ]
      },
      "invocation_count": 57,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.02,
            "tao": 0.00004967042431705
          },
          "output": {
            "usd": 0.1,
            "tao": 0.000248352121585251
          }
        },
        "usd": {
          "hour": 1.79,
          "second": 0.000497222222222222
        },
        "tao": {
          "hour": 0.004445502976376,
          "second": 0.000001234861937882
        }
      },
      "instances": [
        {
          "instance_id": "a0f335c8-45c0-432d-929d-6b0d2ef70828",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:08:30.037014Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "c650b67ec1c4d8ce11a227e2283328e2b7ddb6e0",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 86400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "d5856a60-feab-55c6-8c95-9ef866023cb0",
      "name": "ATL-Machine/affine-0003",
      "tagline": "",
      "readme": "ATL-Machine/affine-0003",
      "public": false,
      "version": "e5e62386-8124-56bb-88a8-2c2b1747a364",
      "tool_description": null,
      "slug": "atl2025-atl-machine-affine-0003",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-20T02:51:20.338614Z",
      "updated_at": "2025-10-20T02:51:20.338614Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "ATL2025",
        "user_id": "441ffcb9-563e-5368-abf1-1dc2d84054df",
        "logo_id": null,
        "created_at": "2025-10-16T15:38:47.325523Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "h100",
        "h100_sxm",
        "h800",
        "a100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 80,
        "compute_multiplier": 0.133333333333333,
        "supported_gpus": [
          "h200",
          "b200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "h100",
          "h100_sxm",
          "h800",
          "a100_sxm"
        ]
      },
      "invocation_count": 50,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.6,
          "second": 0.000166666666666666
        },
        "tao": {
          "hour": 0.00149011272951151,
          "second": 4.13920202642086e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "a7e1ed4a9b42a31830535ddf843264508746a63a",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "cbaaa43f-4549-5d4c-ba7b-d609d8b38438",
      "name": "affinefdn/Affine-gpt-oss-120",
      "tagline": "",
      "readme": "affinefdn/Affine-gpt-oss-120",
      "public": false,
      "version": "f0f86bf2-766e-54b1-b5e1-1319c16eb8ba",
      "tool_description": null,
      "slug": "maziko1-affinefdn-affine-gpt-oss-120",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "0315a7ff-bd8f-5415-a4f7-d0a367cfcfde",
      "created_at": "2025-10-21T09:49:24.306189Z",
      "updated_at": "2025-10-21T09:49:24.306189Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "maziko1",
        "user_id": "b1472ae1-a5b9-54aa-8c51-86d0856af38a",
        "logo_id": null,
        "created_at": "2025-10-21T08:03:30.827713Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 7,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [
        {
          "instance_id": "64a41b71-3df6-400b-866c-6d2e76a1d49c",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T10:15:43.334349Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "3c4ddf6e1e308558ee6c4c44faed855b9daf1484",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 86400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "fcc546ac-827a-5edc-9824-3614c46f156a",
      "name": "yonderjay/Affine-5CXZRqyaZcjEvDHjy16o2zgPuMi2mr632RknZfYWPpVjY1wPv",
      "tagline": "",
      "readme": "yonderjay/Affine-5CXZRqyaZcjEvDHjy16o2zgPuMi2mr632RknZfYWPpVjY1wPv",
      "public": false,
      "version": "0bbd8ba9-4f6e-5701-8acc-db639843e51b",
      "tool_description": null,
      "slug": "yonderjay001-yonderjay-affine-5cxzrqyazcjevdhjy16o2zgpumi2",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-21T00:22:38.924752Z",
      "updated_at": "2025-10-21T00:22:38.924752Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "yonderjay001",
        "user_id": "f7ed215a-7d1d-51ba-af28-4818b5737e65",
        "logo_id": null,
        "created_at": "2025-09-04T14:13:36.069014Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 4,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "a65e307b4a7b834b0e0a2cc548151595ddfb4366",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "350b4544-fbf9-5752-9e2d-16c6cb6344e4",
      "name": "ALGODev/Affine-hot6-01",
      "tagline": "",
      "readme": "ALGODev/Affine-hot6-01",
      "public": false,
      "version": "7b05f05a-74f6-561a-a0ca-acccf9e7ddb4",
      "tool_description": null,
      "slug": "algo-aff-06-algodev-affine-hot6-01",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "0315a7ff-bd8f-5415-a4f7-d0a367cfcfde",
      "created_at": "2025-10-21T05:08:04.815543Z",
      "updated_at": "2025-10-21T05:08:04.815543Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "algo_aff_06",
        "user_id": "fbfa95f9-6b17-5ddf-8547-be1b0c7bad6f",
        "logo_id": null,
        "created_at": "2025-10-21T04:10:48.255431Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 3,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [
        {
          "instance_id": "34c037ed-9e49-40b7-93fc-64852f28a28a",
          "region": "n/a",
          "active": true,
          "verified": true,
          "last_verified_at": "2025-10-21T11:09:27.033838Z"
        }
      ],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "443d9d13f5e4f5203188cbf4b1a491dd4a88957c",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 86400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": true
    },
    {
      "chute_id": "8260112a-ed03-5885-9ce9-7de7f0196693",
      "name": "hO61qjpwxu/Affine_qknt",
      "tagline": "",
      "readme": "hO61qjpwxu/Affine_qknt",
      "public": false,
      "version": "8f327723-cb30-5ecb-b2c6-035476270142",
      "tool_description": null,
      "slug": "wang-d8-ho61qjpwxu-affine-qknt",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "0315a7ff-bd8f-5415-a4f7-d0a367cfcfde",
      "created_at": "2025-10-21T04:06:41.446867Z",
      "updated_at": "2025-10-21T04:06:41.446867Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "wang_d8",
        "user_id": "e5eb5f44-5dee-58af-82a4-bc89aac8a61a",
        "logo_id": null,
        "created_at": "2025-10-21T03:10:25.702646Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h100",
          "h100_sxm",
          "h200"
        ],
        "gpu_count": 4,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 1.59111111111111,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 2,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.1,
            "tao": 0.000248352121585251
          },
          "output": {
            "usd": 0.39,
            "tao": 0.00096857327418248
          }
        },
        "usd": {
          "hour": 7.16,
          "second": 0.00198888888888889
        },
        "tao": {
          "hour": 0.017782011905504,
          "second": 0.000004939447751528
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "57a8f9afdf60a7206be8cf5419c45cb6e78507e5",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "36c3551a-f760-5c3c-ac30-b212a2c44f60",
      "name": "xaura/affine-543534",
      "tagline": "",
      "readme": "xaura/affine-543534",
      "public": false,
      "version": "1d441353-17ca-5beb-813b-2b99cb608f77",
      "tool_description": null,
      "slug": "vrooom-xaura-affine-543534",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-14T04:42:23.469968Z",
      "updated_at": "2025-10-20T18:15:34.513636Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "vrooom",
        "user_id": "ae35d280-8f9f-5edf-812a-8c534b0bd7ec",
        "logo_id": null,
        "created_at": "2025-08-03T08:48:33.202605Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "fac5caf2d19732e4f0d71ea389f371a787e58d8f",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 1200,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "9de5d255-8579-5898-af4a-6bb3bfd705d7",
      "name": "VitaG/Affine-5G3iDRRJz33Tjh3UD464xzUX6omA6Rr8s4j9bXuhrnFYRDVN",
      "tagline": "",
      "readme": "VitaG/Affine-5G3iDRRJz33Tjh3UD464xzUX6omA6Rr8s4j9bXuhrnFYRDVN",
      "public": false,
      "version": "0a1c05f1-8ea6-5b09-94a9-9be5d8bd39e8",
      "tool_description": null,
      "slug": "noganga1208-vitag-affine-5g3idrrjz33tjh3ud464xzux6oma6rr8s",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-28T16:27:49.394691Z",
      "updated_at": "2025-10-20T18:09:16.621183Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "NOganga1208",
        "user_id": "85c4a6a8-f749-5ab5-8bf9-5adda22eb84f",
        "logo_id": null,
        "created_at": "2025-09-17T21:39:09.260087Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "914bf68111256e04fa712ffebcfc736b562a9800",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 120000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "018b3d77-564a-5be4-b37a-86cde4e96bf4",
      "name": "xaura/affine-mkfhj",
      "tagline": "",
      "readme": "xaura/affine-mkfhj",
      "public": false,
      "version": "57c5026a-602a-5f03-bbcf-678fbb1846e6",
      "tool_description": null,
      "slug": "vrooom-xaura-affine-mkfhj",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-02T04:00:24.765553Z",
      "updated_at": "2025-10-20T18:11:18.334574Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "vrooom",
        "user_id": "ae35d280-8f9f-5edf-812a-8c534b0bd7ec",
        "logo_id": null,
        "created_at": "2025-08-03T08:48:33.202605Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "eb98b3d59da15d7e39f27c7ff475b9111c64be7a",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 1200,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "b4a4760c-4aa4-5b31-a62e-dfc0653d4cdb",
      "name": "Pavvav/Affine-Model-G",
      "tagline": "",
      "readme": "Pavvav/Affine-Model-G",
      "public": false,
      "version": "9e050355-2e67-53e3-9839-5e8e82e204d7",
      "tool_description": null,
      "slug": "melbourne-pavvav-affine-model-g",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-03T13:32:10.670374Z",
      "updated_at": "2025-10-20T18:10:17.686451Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "melbourne",
        "user_id": "dc7285f3-46ed-5eb4-a75a-3d89a43176dc",
        "logo_id": null,
        "created_at": "2025-10-02T14:55:56.119301Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 4,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 2.44444444444444,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          },
          "output": {
            "usd": 0.6,
            "tao": 0.00149011272951151
          }
        },
        "usd": {
          "hour": 11,
          "second": 0.00305555555555556
        },
        "tao": {
          "hour": 0.0273187333743777,
          "second": 0.000007588537048438
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "1352025c51a5ebba282aaed85bbfef0e349b62bc",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "06f27ddf-9d4e-571a-814f-c286096cf9c1",
      "name": "kesti/affine-gpt-01",
      "tagline": "",
      "readme": "kesti/affine-gpt-01",
      "public": false,
      "version": "31767d42-0a14-52b5-9337-0813e82b07fc",
      "tool_description": null,
      "slug": "kesti-0-kesti-affine-gpt-01",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-11T10:14:20.474362Z",
      "updated_at": "2025-10-20T18:08:17.176598Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "kesti_0",
        "user_id": "4b47975e-3b51-54c6-ba21-6e92821cd543",
        "logo_id": null,
        "created_at": "2025-08-24T05:43:26.758535Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "h100",
        "h100_sxm",
        "h800",
        "a100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "b200",
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 80,
        "compute_multiplier": 0.133333333333333,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "h100",
          "h100_sxm",
          "h800",
          "a100_sxm"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.6,
          "second": 0.000166666666666666
        },
        "tao": {
          "hour": 0.00149011272951151,
          "second": 4.13920202642086e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "874db7e835471b89583e5d3798d61b6cc7dec7eb",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 18000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "7f3ebea9-93ba-5c71-bdb9-78b06e6f3c96",
      "name": "zatup/Affine-5GLRh1xp2DAmnb63Bu83snbyZinecjheyscfBM5DdtoZPQ75",
      "tagline": "",
      "readme": "zatup/Affine-5GLRh1xp2DAmnb63Bu83snbyZinecjheyscfBM5DdtoZPQ75",
      "public": false,
      "version": "63d83bea-a7b1-5dd0-bceb-72479af88725",
      "tool_description": null,
      "slug": "jopaa107-zatup-affine-5glrh1xp2damnb63bu83snbyzinecjheyscf",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-18T14:55:39.085652Z",
      "updated_at": "2025-10-20T18:09:28.020485Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "JOPAa107",
        "user_id": "6bae7435-76d5-5ce2-80af-54256e9d9948",
        "logo_id": null,
        "created_at": "2025-09-17T16:41:10.864595Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "228121e5beb806f9bc70151f46d8b5cb2a34ad58",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 120000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "5b1d379e-a462-5e28-b2c5-76ed7ddd515e",
      "name": "xaura/affine-345563",
      "tagline": "",
      "readme": "xaura/affine-345563",
      "public": false,
      "version": "33ca6802-595c-595f-ba36-e3b5035950b8",
      "tool_description": null,
      "slug": "vrooom-xaura-affine-345563",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-16T16:41:36.575717Z",
      "updated_at": "2025-10-20T18:10:21.495108Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "vrooom",
        "user_id": "ae35d280-8f9f-5edf-812a-8c534b0bd7ec",
        "logo_id": null,
        "created_at": "2025-08-03T08:48:33.202605Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "e851b141ca4cc5cf4a2ec7e0cb03bb431321f1fc",
      "concurrency": 8,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 1200,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "84c0af2a-9f11-53dc-87cc-a351b112f08f",
      "name": "ATL-Machine/Affine-0001",
      "tagline": "",
      "readme": "ATL-Machine/Affine-0001",
      "public": false,
      "version": "a48ba48c-5093-5c14-a3b6-f425cdf8fdd6",
      "tool_description": null,
      "slug": "atl2025-atl-machine-affine-0001",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-17T17:59:11.710007Z",
      "updated_at": "2025-10-20T18:11:41.167969Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "ATL2025",
        "user_id": "441ffcb9-563e-5368-abf1-1dc2d84054df",
        "logo_id": null,
        "created_at": "2025-10-16T15:38:47.325523Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "h100",
        "h100_sxm",
        "h800",
        "a100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 80,
        "compute_multiplier": 0.133333333333333,
        "supported_gpus": [
          "h200",
          "b200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "h100",
          "h100_sxm",
          "h800",
          "a100_sxm"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.6,
          "second": 0.000166666666666666
        },
        "tao": {
          "hour": 0.00149011272951151,
          "second": 4.13920202642086e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "d47f8fa78c465f2c58ed4f8dfee1fec0e23a4a46",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "0d39d14d-a33b-5d08-bddc-9c9fcebf9fc3",
      "name": "duccd/Affine-5Hn6Ke9U6mv4XFw9gGP827reV38BCdDQN3RXx5ei4eaiuYHd",
      "tagline": "",
      "readme": "duccd/Affine-5Hn6Ke9U6mv4XFw9gGP827reV38BCdDQN3RXx5ei4eaiuYHd",
      "public": false,
      "version": "a9cd868f-aa7b-549d-b523-549f5417a266",
      "tool_description": null,
      "slug": "ontop-duccd-affine-5hn6ke9u6mv4xfw9ggp827rev38bcddqn3rxx5e",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-11T10:15:42.753821Z",
      "updated_at": "2025-10-20T18:08:28.703766Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "ontop",
        "user_id": "1868a1f0-ebcf-5298-b8f0-31c757c75504",
        "logo_id": null,
        "created_at": "2025-09-18T14:42:51.001782Z",
        "logo": null
      },
      "supported_gpus": [
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h100_sxm",
          "h100"
        ],
        "gpu_count": 4,
        "min_vram_gb_per_gpu": 80,
        "compute_multiplier": 1.59111111111111,
        "supported_gpus": [
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.1,
            "tao": 0.000248352121585251
          },
          "output": {
            "usd": 0.39,
            "tao": 0.00096857327418248
          }
        },
        "usd": {
          "hour": 7.16,
          "second": 0.00198888888888889
        },
        "tao": {
          "hour": 0.017782011905504,
          "second": 0.000004939447751528
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "f56cb3d4a10cfee74efc66636a07cf159d9e5857",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "f48b10bd-c3b5-52c1-9aec-6cf038c44958",
      "name": "supermanaff/Affine-5FC1Dq1kdHAGmrEkSCLwEKeNM7i9YY6rXtZKaLM2q4qaAE6b",
      "tagline": "",
      "readme": "supermanaff/Affine-5FC1Dq1kdHAGmrEkSCLwEKeNM7i9YY6rXtZKaLM2q4qaAE6b",
      "public": false,
      "version": "f23a0bcc-b76e-56b0-bf94-f2d6733564a2",
      "tool_description": null,
      "slug": "supermanaff-supermanaff-affine-5fc1dq1kdhagmreksclwekenm7i",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-23T11:21:56.523903Z",
      "updated_at": "2025-10-20T18:10:28.930121Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "supermanaff",
        "user_id": "0d1c0c96-c55b-5367-8645-9e8d12479289",
        "logo_id": null,
        "created_at": "2025-09-11T02:42:54.237522Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "pro_6000",
        "h20",
        "a6000_ada",
        "a40",
        "h100",
        "l40",
        "h800",
        "a100_sxm",
        "l40s"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h100_nvl",
          "pro_6000",
          "l40",
          "a40",
          "a100",
          "a100_sxm",
          "h800",
          "h100",
          "a6000_ada",
          "h20",
          "l40s",
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.888888888888889,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "pro_6000",
          "h20",
          "a6000_ada",
          "a40",
          "h100",
          "l40",
          "h800",
          "a100_sxm",
          "l40s"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.05,
            "tao": 0.000124176060792625
          },
          "output": {
            "usd": 0.22,
            "tao": 0.000546374667487553
          }
        },
        "usd": {
          "hour": 4,
          "second": 0.00111111111111111
        },
        "tao": {
          "hour": 0.00993408486341006,
          "second": 0.000002759468017613
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "0b685acbc4ebd082b287639199bb0cf0a194ad95",
      "concurrency": 24,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "058a55bd-5f45-5aca-8d66-8c8f4b0d366a",
      "name": "magicvec/Affine-5GQjgqKPGb76jY1MmmxCJTTaAkUEDXMAkX4h39v247bFnLph",
      "tagline": "",
      "readme": "magicvec/Affine-5GQjgqKPGb76jY1MmmxCJTTaAkUEDXMAkX4h39v247bFnLph",
      "public": false,
      "version": "baa1ed7b-e231-554b-9575-4a68b274bfec",
      "tool_description": null,
      "slug": "walwal-magicvec-affine-5gqjgqkpgb76jy1mmmxcjttaakuedxmakx4",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-10T23:09:48.717846Z",
      "updated_at": "2025-10-20T18:11:25.868251Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "walwal",
        "user_id": "7072445b-123f-5aef-a1f7-38f6bc821309",
        "logo_id": null,
        "created_at": "2025-10-10T20:53:28.972505Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "fc57bb38e7d090f6366c5fbeb970be0ccb139008",
      "concurrency": 20,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "9fa13d6b-c2db-5318-9f32-07761f586d45",
      "name": "ATL-Machine/affine-0002",
      "tagline": "",
      "readme": "ATL-Machine/affine-0002",
      "public": false,
      "version": "0e380c86-4950-50d6-8297-bf1000c0280e",
      "tool_description": null,
      "slug": "atl2025-atl-machine-affine-0002",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-18T14:12:07.197889Z",
      "updated_at": "2025-10-20T18:11:22.108415Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "ATL2025",
        "user_id": "441ffcb9-563e-5368-abf1-1dc2d84054df",
        "logo_id": null,
        "created_at": "2025-10-16T15:38:47.325523Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "h100",
        "h100_sxm",
        "h800",
        "a100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 80,
        "compute_multiplier": 0.133333333333333,
        "supported_gpus": [
          "h200",
          "b200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "h100",
          "h100_sxm",
          "h800",
          "a100_sxm"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.6,
          "second": 0.000166666666666666
        },
        "tao": {
          "hour": 0.00149011272951151,
          "second": 4.13920202642086e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "f32ab101ddd8d537992f9335888c22f1c4a88ed7",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "c0140fee-43a8-51fa-8d79-6c69b5275954",
      "name": "ibuki95/Affine-2",
      "tagline": "",
      "readme": "ibuki95/Affine-2",
      "public": false,
      "version": "5d3298b4-5f84-5d2b-b3fb-19ddace47884",
      "tool_description": null,
      "slug": "king-2-ibuki95-affine-2",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-08T10:12:31.423741Z",
      "updated_at": "2025-10-20T18:09:20.400261Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "king_2",
        "user_id": "a1e7d1ef-f0bc-5a5c-840b-bd45702c231a",
        "logo_id": null,
        "created_at": "2025-08-29T23:42:43.743495Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "exclude": [
          "mi300x",
          "b200"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.41,
            "tao": 0.00101824369849953
          },
          "output": {
            "usd": 1.64,
            "tao": 0.00407297479399812
          }
        },
        "usd": {
          "hour": 30.25,
          "second": 0.00840277777777778
        },
        "tao": {
          "hour": 0.0751265167795386,
          "second": 0.000020868476883205
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "04e9c3b59ab7ac7c59f7ea7d28b0c2605f03cffa",
      "concurrency": 32,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "1add00cc-e8d3-56f3-96e5-17503fd220a0",
      "name": "ebobo/Affine-5HWFmNtnrye2KFVC1YYuty17mFSANiZV7rsm5siFnmzdc9kc",
      "tagline": "",
      "readme": "ebobo/Affine-5HWFmNtnrye2KFVC1YYuty17mFSANiZV7rsm5siFnmzdc9kc",
      "public": false,
      "version": "f2eb1f66-8fa3-5d1e-89fd-ef1360431454",
      "tool_description": null,
      "slug": "newall4-ebobo-affine-5hwfmntnrye2kfvc1yyuty17mfsanizv7rsm5",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-26T19:32:42.556791Z",
      "updated_at": "2025-10-20T18:12:46.417858Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "newall4",
        "user_id": "61ab05c6-22dc-5427-83da-bf8164a0d469",
        "logo_id": null,
        "created_at": "2025-09-26T19:24:27.970668Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 2,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 1.22222222222222,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.07,
            "tao": 0.000173846485109676
          },
          "output": {
            "usd": 0.3,
            "tao": 0.000745056364755754
          }
        },
        "usd": {
          "hour": 5.5,
          "second": 0.00152777777777778
        },
        "tao": {
          "hour": 0.0136593666871888,
          "second": 0.000003794268524219
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "372ab80baad97227b41097437ebe3486388fb3f0",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 120000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "1398d2cb-ad71-5292-bf24-e7435123acd3",
      "name": "xaura/affine-s48484",
      "tagline": "",
      "readme": "xaura/affine-s48484",
      "public": false,
      "version": "1a809360-cf7f-50f5-bc27-0f92cda1b0a6",
      "tool_description": null,
      "slug": "vrooom-xaura-affine-s48484",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-17T10:06:42.691878Z",
      "updated_at": "2025-10-20T18:15:00.598252Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "vrooom",
        "user_id": "ae35d280-8f9f-5edf-812a-8c534b0bd7ec",
        "logo_id": null,
        "created_at": "2025-08-03T08:48:33.202605Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "8c31382f6434cff8453b20ceb056cc1126fb7ccf",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 1200,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "07f23959-7a98-56e4-a618-669a129305bc",
      "name": "ATL-Machine/Affine-5FvZXVAGSs2J5BtyUridFaHfB318GNAKNF6Zg1rMt1HJwA1A",
      "tagline": "",
      "readme": "ATL-Machine/Affine-5FvZXVAGSs2J5BtyUridFaHfB318GNAKNF6Zg1rMt1HJwA1A",
      "public": false,
      "version": "035718bb-431e-509f-9237-7b33e3c0d098",
      "tool_description": null,
      "slug": "atl2025-atl-machine-affine-5fvzxvagss2j5btyuridfahfb318gna",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-17T01:12:58.207346Z",
      "updated_at": "2025-10-20T18:15:08.111410Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "ATL2025",
        "user_id": "441ffcb9-563e-5368-abf1-1dc2d84054df",
        "logo_id": null,
        "created_at": "2025-10-16T15:38:47.325523Z",
        "logo": null
      },
      "supported_gpus": [
        "a100",
        "h100"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "a100",
          "h100"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.266666666666667,
        "supported_gpus": [
          "a100",
          "h100"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.02,
            "tao": 0.00004967042431705
          },
          "output": {
            "usd": 0.07,
            "tao": 0.000173846485109676
          }
        },
        "usd": {
          "hour": 1.2,
          "second": 0.000333333333333333
        },
        "tao": {
          "hour": 0.00298022545902302,
          "second": 8.27840405284171e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "33cd175ee31bd116f300e261a14b3757a4738f02",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 3600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "09245249-a8ee-5ca7-aaf3-145ed1f1382b",
      "name": "kleverer/Affine-new_round_11",
      "tagline": "",
      "readme": "kleverer/Affine-new_round_11",
      "public": false,
      "version": "5b67d47e-d200-5a39-a91b-8d14d4356541",
      "tool_description": null,
      "slug": "5cdbd124uc-kleverer-affine-new-round-11",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-29T01:31:15.066131Z",
      "updated_at": "2025-10-20T18:15:11.873503Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "5CDbD124uC",
        "user_id": "ed37ae33-a012-5942-87ec-ba24797799af",
        "logo_id": null,
        "created_at": "2025-09-28T13:10:17.543368Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "b21d0e267e0ef18341d8573a7cae4a117067e9da",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 3600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "714a09c6-7f72-5348-8e77-37074383243d",
      "name": "greeneggsandham/affine-alt",
      "tagline": "",
      "readme": "greeneggsandham/affine-alt",
      "public": false,
      "version": "e5d2d323-c74e-54f7-b70b-5a3336a01a18",
      "tool_description": null,
      "slug": "samiam-greeneggsandham-affine-alt",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-10-01T18:26:10.075327Z",
      "updated_at": "2025-10-20T17:50:47.997162Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "samiam",
        "user_id": "6d2a46cd-fe47-5860-b93e-a7b7b2bc77bc",
        "logo_id": null,
        "created_at": "2025-10-01T17:51:37.615250Z",
        "logo": null
      },
      "supported_gpus": [
        "3090"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "3090"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.444444444444444,
        "supported_gpus": [
          "3090"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          },
          "output": {
            "usd": 0.11,
            "tao": 0.000273187333743776
          }
        },
        "usd": {
          "hour": 2,
          "second": 0.000555555555555555
        },
        "tao": {
          "hour": 0.00496704243170503,
          "second": 0.000001379734008806
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "ac8b50088a15a77b836fd6cc9bc2a2ff0c63266b",
      "concurrency": 20,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "244c9aa7-71f2-5812-9fac-1d25a4c1031b",
      "name": "alecglover/Affine-v9",
      "tagline": "",
      "readme": "alecglover/Affine-v9",
      "public": false,
      "version": "5efb3c5e-b3bb-5bf4-b69b-f564828ffa8c",
      "tool_description": null,
      "slug": "upstation-alecglover-affine-v9",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-19T14:48:32.690233Z",
      "updated_at": "2025-10-20T18:15:15.612898Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "upstation",
        "user_id": "9721553c-e4d2-532f-951f-c7d47bec8ac3",
        "logo_id": null,
        "created_at": "2025-02-24T02:34:40.992868Z",
        "logo": null
      },
      "supported_gpus": [
        "3090"
      ],
      "node_selector": {
        "exclude": [
          "mi300x"
        ],
        "include": [
          "3090"
        ],
        "gpu_count": 2,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "3090"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "3a1d0448c4861dfebb7834ffa7f47e5693581f36",
      "concurrency": 20,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "90d3f6fa-4752-510a-a6f0-7055da76f367",
      "name": "ofloxacin/affine-qwen3-1b",
      "tagline": "",
      "readme": "ofloxacin/affine-qwen3-1b",
      "public": false,
      "version": "6283b784-59fa-5626-8b87-8f3645078ea3",
      "tool_description": null,
      "slug": "goeson-ofloxacin-affine-qwen3-1b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-19T06:58:48.024765Z",
      "updated_at": "2025-10-20T18:15:26.906103Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "goeson",
        "user_id": "1db05290-2bb9-52ed-a026-06bfefdd8ba1",
        "logo_id": null,
        "created_at": "2025-10-13T11:56:11.604829Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "l40"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "3090",
          "l40"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "l40"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "ebdf4fb296ca6807fa128677b2ac860f77386c8c",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 7200,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "86d01332-a42d-5e3d-b6d7-a414daaeaaaa",
      "name": "xaura/affine-665494",
      "tagline": "",
      "readme": "xaura/affine-665494",
      "public": false,
      "version": "c82dd89f-e42e-5078-9cb1-23ef92a8a41d",
      "tool_description": null,
      "slug": "vrooom-xaura-affine-665494",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-17T03:59:10.370360Z",
      "updated_at": "2025-10-20T18:15:38.289173Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "vrooom",
        "user_id": "ae35d280-8f9f-5edf-812a-8c534b0bd7ec",
        "logo_id": null,
        "created_at": "2025-08-03T08:48:33.202605Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "a4000_ada",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "h100_sxm",
        "4090",
        "5090",
        "a4000",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "exclude": [
          "b200",
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.0444444444444444,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "a4000_ada",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "h100_sxm",
          "4090",
          "5090",
          "a4000",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.2,
          "second": 0.000055555555555555
        },
        "tao": {
          "hour": 0.000496704243170502,
          "second": 1.37973400880695e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "b7817f97f524f3e3804c4df3a5de7f8499552e93",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 1200,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "27e29e6d-4b57-5f28-84da-d67901642221",
      "name": "Pavvav/Affine-GPT-OSS-120B",
      "tagline": "",
      "readme": "Pavvav/Affine-GPT-OSS-120B",
      "public": false,
      "version": "921c3fb5-eebc-52e2-9923-7ad8aafbb144",
      "tool_description": null,
      "slug": "palermo01-pavvav-affine-gpt-oss-120b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-02T21:23:07.965065Z",
      "updated_at": "2025-10-20T18:15:41.962116Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "palermo01",
        "user_id": "2cf2300a-7517-53cf-b8b0-c25ed997829c",
        "logo_id": null,
        "created_at": "2025-10-01T22:03:55.146430Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "b40dd0577b137d84861d5f3141d49e2a71bff7c4",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "4141a458-0c98-55ce-bceb-30ed4db4d9ca",
      "name": "kanoaal/Affine-top",
      "tagline": "",
      "readme": "kanoaal/Affine-top",
      "public": false,
      "version": "98a93f4a-9116-55d8-a5e6-a9dcccb9f2e3",
      "tool_description": null,
      "slug": "secret-000-kanoaal-affine-top",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-09T18:20:38.393764Z",
      "updated_at": "2025-10-20T18:15:45.666436Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "secret_000",
        "user_id": "d2cb75c1-d2a6-5db3-acb5-cc4c10c1f518",
        "logo_id": null,
        "created_at": "2025-10-09T17:59:15.115382Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "d4acd5a74499f649dec8515080fa49d3721442ce",
      "concurrency": 20,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "2578c5f3-aa47-5e72-b59d-3f5ff48738fb",
      "name": "Deval1004/Affine-v27.0.6",
      "tagline": "",
      "readme": "Deval1004/Affine-v27.0.6",
      "public": false,
      "version": "5e560f9b-2cdb-519e-a534-e191a94069d9",
      "tool_description": null,
      "slug": "affine-027-deval1004-affine-v27-0-6",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-25T12:00:15.259336Z",
      "updated_at": "2025-10-20T18:15:49.458539Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "affine_027",
        "user_id": "68ff04e6-feeb-5b82-96d9-a54b186a4b80",
        "logo_id": null,
        "created_at": "2025-09-03T18:02:15.073584Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200",
          "b200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200",
          "b200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "409a0928ed720ad94b5329759e6ba4e470892f1f",
      "concurrency": 64,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "94b1100b-64da-52f3-9be3-b9b7597ed47c",
      "name": "xaura/affine-444444",
      "tagline": "",
      "readme": "xaura/affine-444444",
      "public": false,
      "version": "be08ce3e-409d-5e5b-96cd-e4a42cca003c",
      "tool_description": null,
      "slug": "vrooom-xaura-affine-444444",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-14T04:11:44.414507Z",
      "updated_at": "2025-10-20T18:15:53.176491Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "vrooom",
        "user_id": "ae35d280-8f9f-5edf-812a-8c534b0bd7ec",
        "logo_id": null,
        "created_at": "2025-08-03T08:48:33.202605Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "4ca34d709f03c7de25ba63e0329fa251a0c0be0f",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 1200,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "43c7c79a-ebe1-50f3-918a-023bef74eb91",
      "name": "demonwizard0/affine-beta-1",
      "tagline": "",
      "readme": "demonwizard0/affine-beta-1",
      "public": false,
      "version": "dd60ba80-c7f2-5413-90bf-999f29ff6649",
      "tool_description": null,
      "slug": "affine-mantis-demonwizard0-affine-beta-1",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-19T13:03:27.595359Z",
      "updated_at": "2025-10-20T18:15:56.852358Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "affine_mantis",
        "user_id": "9ff1df41-ade1-57f5-ae9c-bbe5d29dc94e",
        "logo_id": null,
        "created_at": "2025-08-12T14:44:06.905655Z",
        "logo": null
      },
      "supported_gpus": [
        "h100_nvl",
        "h200",
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h100_nvl",
          "h100_sxm",
          "h100",
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.397777777777778,
        "supported_gpus": [
          "h100_nvl",
          "h200",
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.02,
            "tao": 0.00004967042431705
          },
          "output": {
            "usd": 0.1,
            "tao": 0.000248352121585251
          }
        },
        "usd": {
          "hour": 1.79,
          "second": 0.000497222222222222
        },
        "tao": {
          "hour": 0.004445502976376,
          "second": 0.000001234861937882
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "d8b4df53054e65bfcde534870f539e79b987704b",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 3600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "2c1de095-9683-549c-b71e-77a3fed83a2f",
      "name": "dsaddsaf/affine-1",
      "tagline": "",
      "readme": "dsaddsaf/affine-1",
      "public": false,
      "version": "f584eb8b-27fc-5c69-9749-fafcff0aa6cc",
      "tool_description": null,
      "slug": "affine0222-dsaddsaf-affine-1",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-01T14:35:57.030185Z",
      "updated_at": "2025-10-20T18:16:00.619429Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "affine0222",
        "user_id": "2d096276-3ce3-5437-85b1-d8a9503cce3a",
        "logo_id": null,
        "created_at": "2025-10-01T13:50:41.994456Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "ca3e30e590ea35926ac76f47fa7ab37df1e8a8b8",
      "concurrency": 8,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "1971f8cb-83aa-5c31-a278-551f15e92341",
      "name": "alecglover/Affine-v8",
      "tagline": "",
      "readme": "alecglover/Affine-v8",
      "public": false,
      "version": "64305aa2-fb01-5215-9339-589c506ae3a2",
      "tool_description": null,
      "slug": "upstation-alecglover-affine-v8",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-19T14:26:26.896435Z",
      "updated_at": "2025-10-20T18:16:04.323437Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "upstation",
        "user_id": "9721553c-e4d2-532f-951f-c7d47bec8ac3",
        "logo_id": null,
        "created_at": "2025-02-24T02:34:40.992868Z",
        "logo": null
      },
      "supported_gpus": [
        "3090"
      ],
      "node_selector": {
        "exclude": [
          "mi300x"
        ],
        "include": [
          "3090"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "314683106bb44e73f30f832fdcac1b05af6e1e15",
      "concurrency": 20,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "1beb19e5-6931-5112-a28a-34ab0eb65f26",
      "name": "iwbr/Affine-4b-a1",
      "tagline": "",
      "readme": "iwbr/Affine-4b-a1",
      "public": false,
      "version": "d37529b5-16a1-5b1d-b480-85e71b8d15cd",
      "tool_description": null,
      "slug": "iwbr-iwbr-affine-4b-a1",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-13T14:04:39.315865Z",
      "updated_at": "2025-10-20T18:16:08.044021Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "iwbr",
        "user_id": "7fade6ad-761e-5123-a83a-9c4a372c1fda",
        "logo_id": null,
        "created_at": "2025-10-13T12:50:59.947256Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "f33f608ffff6cad3162454c4c28e6f8a26a52442",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "25a24be3-2888-5fde-8674-9141fc331097",
      "name": "ebobo/Affine-5CDakZvEQ6tKSfQoPz8A611mcPKVim9SXVk4NNXEAw6y4DEb",
      "tagline": "",
      "readme": "ebobo/Affine-5CDakZvEQ6tKSfQoPz8A611mcPKVim9SXVk4NNXEAw6y4DEb",
      "public": false,
      "version": "db898a72-6e9d-5df9-9e38-83e1814bbedd",
      "tool_description": null,
      "slug": "newall3-ebobo-affine-5cdakzveq6tksfqopz8a611mcpkvim9sxvk4n",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-22T23:15:05.407516Z",
      "updated_at": "2025-10-20T18:09:35.802183Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "newall3",
        "user_id": "86dfe660-9fa1-5006-ae0e-6f11fe55facd",
        "logo_id": null,
        "created_at": "2025-09-22T23:02:56.397219Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "02a6ad91af99e7cadb9d2f5bfb28945fb84e1717",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 1200,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "f5bb50f0-1739-5cd1-9f6c-8a5a99e8b889",
      "name": "kesti/affine-120-2",
      "tagline": "",
      "readme": "kesti/affine-120-2",
      "public": false,
      "version": "0d51615d-18ac-5a95-980f-7f0e9c4f39f9",
      "tool_description": null,
      "slug": "kesti-2-kesti-affine-120-2",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-15T16:33:35.734356Z",
      "updated_at": "2025-10-20T18:14:41.784192Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "kesti_2",
        "user_id": "525683be-4fa9-5349-a646-eb57c884c5eb",
        "logo_id": null,
        "created_at": "2025-08-24T05:44:58.672061Z",
        "logo": null
      },
      "supported_gpus": [
        "h100_nvl",
        "h200",
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "exclude": [
          "mi300x",
          "b200"
        ],
        "include": [
          "h100_nvl",
          "h100_sxm",
          "h100",
          "h200"
        ],
        "gpu_count": 2,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.795555555555556,
        "supported_gpus": [
          "h100_nvl",
          "h200",
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.05,
            "tao": 0.000124176060792625
          },
          "output": {
            "usd": 0.19,
            "tao": 0.000471869031011977
          }
        },
        "usd": {
          "hour": 3.58,
          "second": 0.000994444444444444
        },
        "tao": {
          "hour": 0.008891005952752,
          "second": 0.000002469723875764
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "28f32409377008aa25eb7c9fcb42d07d8659e8c6",
      "concurrency": 64,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "a07e7c43-8a89-5c1e-8f4b-11aeada601c0",
      "name": "darkhorse0811/Affine-5DJ3hfEC6dMtrq6WFMnak79vGJjctYHPfPmaL1kSvE7eU6hX",
      "tagline": "",
      "readme": "darkhorse0811/Affine-5DJ3hfEC6dMtrq6WFMnak79vGJjctYHPfPmaL1kSvE7eU6hX",
      "public": false,
      "version": "608a9eb7-5872-59b9-b636-e9c4bc96fba4",
      "tool_description": null,
      "slug": "darkhorse888-darkhorse0811-affine-5dj3hfec6dmtrq6wfmnak79v",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-06T15:42:22.182531Z",
      "updated_at": "2025-10-20T18:09:47.352897Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "darkhorse888",
        "user_id": "c2401918-bb08-5d4a-8519-91837a59b921",
        "logo_id": null,
        "created_at": "2025-10-06T15:12:44.791323Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200",
          "h100",
          "h100_sxm"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.397777777777778,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.02,
            "tao": 0.00004967042431705
          },
          "output": {
            "usd": 0.1,
            "tao": 0.000248352121585251
          }
        },
        "usd": {
          "hour": 1.79,
          "second": 0.000497222222222222
        },
        "tao": {
          "hour": 0.004445502976376,
          "second": 0.000001234861937882
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "4ebc9edf2be86fcb1baef667f281cb0c39f1a835",
      "concurrency": 20,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "41aa107b-5b0f-5766-b1af-f7488234a46d",
      "name": "hO61qjpwxu/Affine_m3_5000",
      "tagline": "",
      "readme": "hO61qjpwxu/Affine_m3_5000",
      "public": false,
      "version": "442bb968-94a6-51e9-97d0-9299a2895e69",
      "tool_description": null,
      "slug": "m-d2-ho61qjpwxu-affine-m3-5000",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-18T20:02:43.995507Z",
      "updated_at": "2025-10-20T18:13:16.821264Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "m_d2",
        "user_id": "66451761-bf70-5dce-ac00-876f87a9348a",
        "logo_id": null,
        "created_at": "2025-08-29T16:58:18.035372Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "b200",
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200",
          "b200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "61f28e77bb7c11f5690eff0b311e404c04e13326",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "db3ec7bd-edab-51dd-a6a6-338ffff71309",
      "name": "xaura/affine-q6866666",
      "tagline": "",
      "readme": "xaura/affine-q6866666",
      "public": false,
      "version": "848b2c5d-0d27-51d3-9ff5-8f1bc97b29ba",
      "tool_description": null,
      "slug": "vrooom-xaura-affine-q6866666",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-29T18:09:52.256573Z",
      "updated_at": "2025-10-20T18:08:21.037371Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "vrooom",
        "user_id": "ae35d280-8f9f-5edf-812a-8c534b0bd7ec",
        "logo_id": null,
        "created_at": "2025-08-03T08:48:33.202605Z",
        "logo": null
      },
      "supported_gpus": [
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h100",
          "h100_sxm"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 3.18222222222222,
        "supported_gpus": [
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.19,
            "tao": 0.000471869031011977
          },
          "output": {
            "usd": 0.78,
            "tao": 0.00193714654836496
          }
        },
        "usd": {
          "hour": 14.32,
          "second": 0.00397777777777778
        },
        "tao": {
          "hour": 0.035564023811008,
          "second": 0.000009878895503057
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "b453b547a6c79c80ba8f9ebb02fa1220b49875be",
      "concurrency": 24,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "f5af46c7-55f4-5467-b95b-23530f1bd885",
      "name": "EiMon724/Affine-5EcXEX2hPdUbKEhyfJLMVKJHesaGYNshwL5wnrB2mZNu5dCR",
      "tagline": "",
      "readme": "EiMon724/Affine-5EcXEX2hPdUbKEhyfJLMVKJHesaGYNshwL5wnrB2mZNu5dCR",
      "public": false,
      "version": "913f7d02-104b-5cda-95ce-c4517e57857e",
      "tool_description": null,
      "slug": "eimon727-eimon724-affine-5ecxex2hpdubkehyfjlmvkjhesagynshw",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-19T15:49:33.889190Z",
      "updated_at": "2025-10-19T16:37:29.507009Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "EiMon727",
        "user_id": "5497a029-57c5-571a-91af-1cbb9c837719",
        "logo_id": null,
        "created_at": "2025-10-03T04:25:18.822934Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "9b7601e532180085c3168b8b76b27afbeb47b074",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "b6157ef2-b99b-5f73-a915-dfe978b1daa3",
      "name": "wanglongo/Affine-5FZg9eMgApwng8jhgeS3rrRw4r9PsqUNm8MiDCPQ5pfYEG65",
      "tagline": "",
      "readme": "wanglongo/Affine-5FZg9eMgApwng8jhgeS3rrRw4r9PsqUNm8MiDCPQ5pfYEG65",
      "public": false,
      "version": "b4ef398f-a148-5c4e-8b71-63945e91f749",
      "tool_description": null,
      "slug": "wiwtao-wanglongo-affine-5fzg9emgapwng8jhges3rrrw4r9psqunm8",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-13T13:54:17.154102Z",
      "updated_at": "2025-10-20T18:15:30.719542Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "wiwtao",
        "user_id": "0f0fd1d4-2d8d-5b13-9c3d-08146ea0360d",
        "logo_id": null,
        "created_at": "2025-10-13T13:12:32.045562Z",
        "logo": null
      },
      "supported_gpus": [
        "a6000",
        "l40"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "a6000",
          "l40"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "a6000",
          "l40"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "2cff8ed988f82a987cc3f8c98acc357972922fb4",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 18000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "58081677-3d61-5017-9b47-f70e84178c43",
      "name": "xaura/affine-gki",
      "tagline": "",
      "readme": "xaura/affine-gki",
      "public": false,
      "version": "fde65cd4-2d5b-512e-9138-354e96a9ca7c",
      "tool_description": null,
      "slug": "vrooom-xaura-affine-gki",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-02T13:11:23.132588Z",
      "updated_at": "2025-10-20T18:11:03.014077Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "vrooom",
        "user_id": "ae35d280-8f9f-5edf-812a-8c534b0bd7ec",
        "logo_id": null,
        "created_at": "2025-08-03T08:48:33.202605Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.3,
            "tao": 0.000745056364755754
          },
          "output": {
            "usd": 1.2,
            "tao": 0.00298022545902302
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "056b5ce12787d9fb709ad18178121d507f661782",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "60bb508c-e349-58f1-9d8e-d8d7982163b3",
      "name": "Dan-Carter/Affine-41",
      "tagline": "",
      "readme": "Dan-Carter/Affine-41",
      "public": false,
      "version": "3ae49413-fd90-585d-b9be-d692cb56baf7",
      "tool_description": null,
      "slug": "king-44-dan-carter-affine-41",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-10T05:20:34.300116Z",
      "updated_at": "2025-10-20T18:09:24.174076Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "king_44",
        "user_id": "8c90b5ab-d1b3-50b7-b408-1cd2411a415c",
        "logo_id": null,
        "created_at": "2025-08-30T02:32:35.021006Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "exclude": [
          "mi300x",
          "b200"
        ],
        "include": [
          "h200",
          "b200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.41,
            "tao": 0.00101824369849953
          },
          "output": {
            "usd": 1.64,
            "tao": 0.00407297479399812
          }
        },
        "usd": {
          "hour": 30.25,
          "second": 0.00840277777777778
        },
        "tao": {
          "hour": 0.0751265167795386,
          "second": 0.000020868476883205
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "f65044804a348ec2622560c0ed822779a8fb8caf",
      "concurrency": 32,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "a802cd89-84af-54df-9166-e0461b843780",
      "name": "kleverer/Affine-new_round_10",
      "tagline": "",
      "readme": "kleverer/Affine-new_round_10",
      "public": false,
      "version": "34363680-48ae-57c0-83ce-dd2f623e684d",
      "tool_description": null,
      "slug": "5fqtctmjtj-kleverer-affine-new-round-10",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-29T01:19:09.456435Z",
      "updated_at": "2025-10-20T18:14:53.147610Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "5FQtCtMJTJ",
        "user_id": "a6ae518c-fde0-5ff5-a120-796e55f87e94",
        "logo_id": null,
        "created_at": "2025-09-28T13:11:01.510885Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "d9ccdf4bc25dc81feaf8d5e7063de0f34639febf",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 3600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "ad4d20a3-c616-52d6-89df-e45217d5e51e",
      "name": "makeAffineGreatAgain/Affine-003",
      "tagline": "",
      "readme": "makeAffineGreatAgain/Affine-003",
      "public": false,
      "version": "a8290394-6cc5-56dd-a4db-76cbc6aec44a",
      "tool_description": null,
      "slug": "maga3-makeaffinegreatagain-affine-003",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-19T12:35:49.055044Z",
      "updated_at": "2025-10-20T18:12:19.846606Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "maga3",
        "user_id": "bd9f7b04-612c-5a32-ae25-939c2dbfa035",
        "logo_id": null,
        "created_at": "2025-09-18T15:27:09.549660Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "1e19fbbb24fab5773425b46008d7f15526045a5d",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 1200,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "8a1b9676-77fb-5825-ba80-23c5671c597d",
      "name": "Dan-Carter/Affine-102",
      "tagline": "",
      "readme": "Dan-Carter/Affine-102",
      "public": false,
      "version": "99ff73ac-c9b5-5e36-a28d-a6a8f26baef2",
      "tool_description": null,
      "slug": "king10-dan-carter-affine-102",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-08T14:01:03.933457Z",
      "updated_at": "2025-10-20T18:12:38.770594Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "king10",
        "user_id": "22836b87-77c7-58ca-ac3e-271f70988d06",
        "logo_id": null,
        "created_at": "2025-09-08T00:56:01.302666Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "exclude": [
          "mi300x",
          "b200"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.82,
            "tao": 0.00203648739699906
          },
          "output": {
            "usd": 3.29,
            "tao": 0.00817078480015477
          }
        },
        "usd": {
          "hour": 30.25,
          "second": 0.00840277777777778
        },
        "tao": {
          "hour": 0.0751265167795386,
          "second": 0.000020868476883205
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "374e4dee10a9b5175484c7c75077076fbf4b97dd",
      "concurrency": 8,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "531dc5b3-9450-510a-8b55-bfb8e97d703f",
      "name": "Dan-Carter/Affine-t4v3",
      "tagline": "",
      "readme": "Dan-Carter/Affine-t4v3",
      "public": false,
      "version": "425a5284-b157-5a10-bf65-e70e24a8879a",
      "tool_description": null,
      "slug": "top-4-dan-carter-affine-t4v3",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-17T16:59:15.089943Z",
      "updated_at": "2025-10-20T18:09:51.170350Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "Top_4",
        "user_id": "af9afba4-0fae-5c3d-b709-9ef83572aaab",
        "logo_id": null,
        "created_at": "2025-09-10T10:34:21.840697Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "adf994602dd806c3e3ac37f873182226612ae71b",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 86400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "8ce702cb-2d8d-54af-b637-e01183d33d9c",
      "name": "ebobo/Affine-5GxkLkomuy8XkrQ4sUA6hDmvY3sHJwjvgNeKw8cHAxUh8ngN",
      "tagline": "",
      "readme": "ebobo/Affine-5GxkLkomuy8XkrQ4sUA6hDmvY3sHJwjvgNeKw8cHAxUh8ngN",
      "public": false,
      "version": "280d1c40-298a-551f-b888-ae7ac4c0f2a6",
      "tool_description": null,
      "slug": "newall1-ebobo-affine-5gxklkomuy8xkrq4sua6hdmvy3shjwjvgnekw",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-22T22:29:17.726922Z",
      "updated_at": "2025-10-20T18:10:10.164384Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "newall1",
        "user_id": "929d8f06-55fa-5200-8052-5656519a6d07",
        "logo_id": null,
        "created_at": "2025-09-22T21:50:18.833310Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "6947f88e518690d6d37c21c22c760844cb1b799c",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 1200,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "9d577285-f094-54bb-a454-8d211b858340",
      "name": "kesti/affine-0016",
      "tagline": "",
      "readme": "kesti/affine-0016",
      "public": false,
      "version": "13e9a862-b6fa-5e45-9255-408fb9b84dbe",
      "tool_description": null,
      "slug": "kesti-5-kesti-affine-0016",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-09T17:39:24.674332Z",
      "updated_at": "2025-10-20T18:12:42.517855Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "kesti_5",
        "user_id": "7d65da0d-b5ae-5e6b-9a37-eaf8de01fa48",
        "logo_id": null,
        "created_at": "2025-08-27T07:59:40.631677Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a100_40gb",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x",
          "b200"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 40,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a100_40gb",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "9be2fd8365c68f21ebeb80abec4e455bb8687dfb",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 18000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "a84549af-8c8b-57c4-a909-0b200e373aff",
      "name": "kesti/affine-q4-a",
      "tagline": "",
      "readme": "kesti/affine-q4-a",
      "public": false,
      "version": "6f718057-5a40-5308-8dc6-c4119b9ee92f",
      "tool_description": null,
      "slug": "kesti-10-kesti-affine-q4-a",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-11T09:32:48.200993Z",
      "updated_at": "2025-10-20T18:15:19.360060Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "kesti_10",
        "user_id": "7305c11e-e19e-5bdb-88e5-da38c04de20c",
        "logo_id": null,
        "created_at": "2025-10-11T04:55:55.368625Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a100_40gb",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x",
          "b200"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 40,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a100_40gb",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "d6e8224574dbbf1aafa9facb3ddc2ed309720930",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 18000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "49e3380a-4517-5e37-809e-912701a24b15",
      "name": "GANGodfather/Affine-PESR07",
      "tagline": "",
      "readme": "GANGodfather/Affine-PESR07",
      "public": false,
      "version": "8be8c48c-8b81-534e-b88b-efd0b427fd40",
      "tool_description": null,
      "slug": "sonyx07-gangodfather-affine-pesr07",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-19T07:58:46.037662Z",
      "updated_at": "2025-10-20T18:15:23.107297Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "sonyx07",
        "user_id": "aa8eaeeb-8083-5acd-8d35-2ae869ec33a4",
        "logo_id": null,
        "created_at": "2025-08-29T11:42:56.755520Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "8d5f2ab74f5b22548e777b2558621fb3efc96438",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "7b2282fa-aac5-5fe0-ae41-fc4c26a10131",
      "name": "devrichard000/Affine-002",
      "tagline": "",
      "readme": "devrichard000/Affine-002",
      "public": false,
      "version": "293be13a-cea8-53f1-9e5d-d557f619fd0f",
      "tool_description": null,
      "slug": "vitaliidev-devrichard000-affine-002",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-01T13:09:11.876654Z",
      "updated_at": "2025-10-20T18:12:34.979920Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "vitaliidev",
        "user_id": "d7b55652-3a11-571a-8318-395b7132e836",
        "logo_id": null,
        "created_at": "2025-08-12T01:03:08.350035Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "12d51d95fd841c69bf9cdd3f0ca580e68340a561",
      "concurrency": 24,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 1200,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "4283617f-51c9-5407-94f7-46ba102c7a49",
      "name": "kesti/affine-0019",
      "tagline": "",
      "readme": "kesti/affine-0019",
      "public": false,
      "version": "60a9cd54-8630-5e2e-b0b5-5acd2ec86829",
      "tool_description": null,
      "slug": "kesti-7-kesti-affine-0019",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-15T02:12:52.830856Z",
      "updated_at": "2025-10-20T18:12:23.631965Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "kesti_7",
        "user_id": "f92ba067-55e7-5d06-a8b8-cf449fd4966a",
        "logo_id": null,
        "created_at": "2025-08-27T08:03:29.772303Z",
        "logo": null
      },
      "supported_gpus": [
        "5090",
        "3090",
        "l4",
        "a6000",
        "4090"
      ],
      "node_selector": {
        "exclude": [
          "b200",
          "mi300x"
        ],
        "include": [
          "3090",
          "4090",
          "5090",
          "a6000",
          "l4"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "5090",
          "3090",
          "l4",
          "a6000",
          "4090"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "616ea993e488d0ba0998056acc0650a18e0ec32b",
      "concurrency": 8,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 3600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "a958527d-654a-5f54-8abc-5fff0687b879",
      "name": "GANGodfather/Affine-PESR02",
      "tagline": "",
      "readme": "GANGodfather/Affine-PESR02",
      "public": false,
      "version": "ace71cbc-e1fb-52a9-a9cf-95729fb4a1cd",
      "tool_description": null,
      "slug": "sonyx02-gangodfather-affine-pesr02",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-23T04:26:36.981280Z",
      "updated_at": "2025-10-20T18:12:15.924816Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "sonyx02",
        "user_id": "3338daf1-0d4f-565a-a153-db499166bf0f",
        "logo_id": null,
        "created_at": "2025-08-29T11:04:48.190674Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "d8c7c1b76d4f631c706020a7b30d1f304cf8d34e",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "368e9303-909b-5d13-9397-5b397cfb67c4",
      "name": "makeAffineGreatAgain/Affine-A",
      "tagline": "",
      "readme": "makeAffineGreatAgain/Affine-A",
      "public": false,
      "version": "8f63671e-a1ac-565a-9de4-c10493ef10ce",
      "tool_description": null,
      "slug": "magaa-makeaffinegreatagain-affine-a",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-06T06:45:45.829507Z",
      "updated_at": "2025-10-20T18:10:13.886557Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "magaA",
        "user_id": "5c6f0cc3-dff4-540e-9378-77a26946180b",
        "logo_id": null,
        "created_at": "2025-10-06T05:36:03.942146Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "3a2242f6ad2d94b17bbb58a0a1deb3fc42d03703",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "58200156-b142-54d9-8bc5-6457e99ca6e5",
      "name": "kleverer/Affine-new_1",
      "tagline": "",
      "readme": "kleverer/Affine-new_1",
      "public": false,
      "version": "99e91b9c-25dc-5bac-bb09-315808f27d2c",
      "tool_description": null,
      "slug": "5fqtctmjtj-kleverer-affine-new-1",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "0315a7ff-bd8f-5415-a4f7-d0a367cfcfde",
      "created_at": "2025-10-20T16:44:09.372155Z",
      "updated_at": "2025-10-20T16:44:09.372155Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "5FQtCtMJTJ",
        "user_id": "a6ae518c-fde0-5ff5-a120-796e55f87e94",
        "logo_id": null,
        "created_at": "2025-09-28T13:11:01.510885Z",
        "logo": null
      },
      "supported_gpus": [
        "a100",
        "h100"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "a100",
          "h100"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.266666666666667,
        "supported_gpus": [
          "a100",
          "h100"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.02,
            "tao": 0.00004967042431705
          },
          "output": {
            "usd": 0.07,
            "tao": 0.000173846485109676
          }
        },
        "usd": {
          "hour": 1.2,
          "second": 0.000333333333333333
        },
        "tao": {
          "hour": 0.00298022545902302,
          "second": 8.27840405284171e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "fff48082230afcfe35456e9aaa62680008631b20",
      "concurrency": 20,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 3600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "c9bd9d67-dd12-5991-8d50-5a3fc895eb62",
      "name": "xuivgovne/affine-megapisun228",
      "tagline": "",
      "readme": "xuivgovne/affine-megapisun228",
      "public": false,
      "version": "5bfa9eec-7162-5b88-a7a5-0a3eb3ad97fc",
      "tool_description": null,
      "slug": "1lock001-xuivgovne-affine-megapisun228",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-01T10:13:28.309729Z",
      "updated_at": "2025-10-20T18:14:33.844260Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "1lock001",
        "user_id": "89f2801e-f3b8-57ba-b3b5-2d2945f141af",
        "logo_id": null,
        "created_at": "2025-09-07T13:45:47.079147Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "36308985b67477f0bdf4752edd807206c40eacd8",
      "concurrency": 8,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "0e5cc6a1-8de3-5afb-ad75-e5d8e429cb5a",
      "name": "alecglover/Affine-v2",
      "tagline": "",
      "readme": "alecglover/Affine-v2",
      "public": false,
      "version": "194bafe5-3b7c-5261-83b7-4ddb0643d524",
      "tool_description": null,
      "slug": "upstation-alecglover-affine-v2",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-09-22T16:41:34.309776Z",
      "updated_at": "2025-10-20T18:09:39.479549Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "upstation",
        "user_id": "9721553c-e4d2-532f-951f-c7d47bec8ac3",
        "logo_id": null,
        "created_at": "2025-02-24T02:34:40.992868Z",
        "logo": null
      },
      "supported_gpus": [
        "3090"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "3090"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.444444444444444,
        "supported_gpus": [
          "3090"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          },
          "output": {
            "usd": 0.11,
            "tao": 0.000273187333743776
          }
        },
        "usd": {
          "hour": 2,
          "second": 0.000555555555555555
        },
        "tao": {
          "hour": 0.00496704243170503,
          "second": 0.000001379734008806
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "f952105d736675c3f0a36f21fc1055f54b6712bc",
      "concurrency": 12,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "1e9eea22-7379-5ac7-8b57-eb4160d80c2a",
      "name": "GANGodfather/Affine-PESR06",
      "tagline": "",
      "readme": "GANGodfather/Affine-PESR06",
      "public": false,
      "version": "0034972a-1106-59e4-bf13-362e9a3b48f4",
      "tool_description": null,
      "slug": "sonyx06-gangodfather-affine-pesr06",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-24T17:12:32.168343Z",
      "updated_at": "2025-10-20T18:11:56.447627Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "sonyx06",
        "user_id": "0153f7bc-b73b-5c48-b1d2-d59bbc1f168c",
        "logo_id": null,
        "created_at": "2025-09-05T19:08:52.796864Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "deda5b159f528118798b25af90673b7f7bd712d4",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "21903468-9a7f-597f-bc16-da8acd6c5ddb",
      "name": "VitaG/Affine-5EPKBToKMa6MTeAAQEsN52RgbCemVYCgbwPcz4wgNrD3ENpY",
      "tagline": "",
      "readme": "VitaG/Affine-5EPKBToKMa6MTeAAQEsN52RgbCemVYCgbwPcz4wgNrD3ENpY",
      "public": false,
      "version": "b6b93823-ad2a-5e7e-ab45-8c6f68031ca2",
      "tool_description": null,
      "slug": "noganga1201-vitag-affine-5epkbtokma6mteaaqesn52rgbcemvycgb",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-18T17:29:45.167533Z",
      "updated_at": "2025-10-20T18:08:24.890844Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "NOganga1201",
        "user_id": "0d0d1e62-1356-52e3-be5f-50e6c0c67b96",
        "logo_id": null,
        "created_at": "2025-09-17T21:32:01.103694Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "327094cd3da95cf20391560ba7ed667fbba74bad",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 120000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "bfe6328a-17b2-5c4f-ba79-cb058c1d92bc",
      "name": "ebobo/Affine-5F4f41BGoiaAsLiBD5sGt5Qnt2Gm1cMqzWJdjp3DWwGfTURJ",
      "tagline": "",
      "readme": "ebobo/Affine-5F4f41BGoiaAsLiBD5sGt5Qnt2Gm1cMqzWJdjp3DWwGfTURJ",
      "public": false,
      "version": "21cecb93-1517-53e7-b178-96aca6c9bd0c",
      "tool_description": null,
      "slug": "newall7-ebobo-affine-5f4f41bgoiaaslibd5sgt5qnt2gm1cmqzwjdj",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-29T14:51:51.516006Z",
      "updated_at": "2025-10-20T18:09:31.962339Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "newall7",
        "user_id": "1c7ae779-4dab-5dea-9b32-9fe4a42207d4",
        "logo_id": null,
        "created_at": "2025-09-29T14:42:53.209831Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "5836d11dd8738094cca53d1f6b497348781f7458",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 120000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "9d604229-5ae8-58f8-a3d1-f4edff295ab3",
      "name": "xaura/affine-9575648",
      "tagline": "",
      "readme": "xaura/affine-9575648",
      "public": false,
      "version": "5221f7fe-aa5e-5995-b219-a2090fa75cc9",
      "tool_description": null,
      "slug": "vrooom-xaura-affine-9575648",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-04T11:31:28.541627Z",
      "updated_at": "2025-10-20T18:14:49.295755Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "vrooom",
        "user_id": "ae35d280-8f9f-5edf-812a-8c534b0bd7ec",
        "logo_id": null,
        "created_at": "2025-08-03T08:48:33.202605Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "exclude": [
          "b200",
          "mi300x"
        ],
        "include": [
          "h100",
          "h100_sxm",
          "h200",
          "b200"
        ],
        "gpu_count": 2,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.795555555555556,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.54,
            "tao": 0.00134110145656036
          },
          "output": {
            "usd": 2.14,
            "tao": 0.00531473540192438
          }
        },
        "usd": {
          "hour": 39.38,
          "second": 0.0109388888888889
        },
        "tao": {
          "hour": 0.097801065480272,
          "second": 0.000027166962633408
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "3f7bcd80b2d08f5796ff1be9627a74a930ca5b7f",
      "concurrency": 32,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "015f9844-9b29-58af-aded-926d805b3a71",
      "name": "makeAffineGreatAgain/Affine-001",
      "tagline": "",
      "readme": "makeAffineGreatAgain/Affine-001",
      "public": false,
      "version": "106b3472-1b35-527b-aa0c-995beca7616e",
      "tool_description": null,
      "slug": "maga1-makeaffinegreatagain-affine-001",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-19T12:42:46.303938Z",
      "updated_at": "2025-10-20T18:11:14.561802Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "maga1",
        "user_id": "b1db5772-97ec-5122-912c-52f9da994e8f",
        "logo_id": null,
        "created_at": "2025-09-18T15:20:21.974948Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "3d14a4c4f5f25bcdd606099aedee5449053828f5",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 1200,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "3a82e9d8-c085-5b47-9dfb-4b449791d981",
      "name": "Deval1004/Affine-v28.0.7",
      "tagline": "",
      "readme": "Deval1004/Affine-v28.0.7",
      "public": false,
      "version": "a8a7eec8-f604-5d7f-9ca8-3ce0311409eb",
      "tool_description": null,
      "slug": "affine-028-deval1004-affine-v28-0-7",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-26T23:18:46.641076Z",
      "updated_at": "2025-10-20T18:11:10.575865Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "affine_028",
        "user_id": "bf0d2093-0512-5e7c-b0a5-6aad9b2c3bb0",
        "logo_id": null,
        "created_at": "2025-09-03T18:03:00.679440Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200",
          "b200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200",
          "b200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "4785cfc7435a23068bf995e8a5d7e49c0bd4418e",
      "concurrency": 64,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "33c146d6-c1b4-5a2c-9b34-d3ce5e72632c",
      "name": "darkhorse0811/Affine-5H5p2h3WWErqojpGbqeCadr6o3sfTiKrFrfTwNGRsPih3zyb",
      "tagline": "",
      "readme": "darkhorse0811/Affine-5H5p2h3WWErqojpGbqeCadr6o3sfTiKrFrfTwNGRsPih3zyb",
      "public": false,
      "version": "ed02c7e8-56eb-5355-8b97-c2a3a26221c5",
      "tool_description": null,
      "slug": "darkhorse0811-darkhorse0811-affine-5h5p2h3wwerqojpgbqecadr",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-18T07:14:08.913038Z",
      "updated_at": "2025-10-20T18:10:55.511474Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "darkhorse0811",
        "user_id": "2764e04e-f683-5c2e-9219-bdef54bf6d0d",
        "logo_id": null,
        "created_at": "2025-09-14T15:47:29.203990Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "pro_6000",
        "h20",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "l40",
        "h800",
        "a6000",
        "h100",
        "a100_sxm",
        "l40s"
      ],
      "node_selector": {
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h100_nvl",
          "pro_6000",
          "l40",
          "h100_sxm",
          "a40",
          "a100",
          "a100_sxm",
          "h800",
          "a6000",
          "h100",
          "a6000_ada",
          "h20",
          "h200",
          "l40s"
        ],
        "gpu_count": 2,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.222222222222222,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "pro_6000",
          "h20",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "l40",
          "h800",
          "a6000",
          "h100",
          "a100_sxm",
          "l40s"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.05,
            "tao": 0.000124176060792625
          }
        },
        "usd": {
          "hour": 1,
          "second": 0.000277777777777777
        },
        "tao": {
          "hour": 0.00248352121585251,
          "second": 6.89867004403476e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "2d5925cb3d683d3f79668016a5297fb7f702161e",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 1200,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "898662e3-2dbd-522f-900b-07f26a16539b",
      "name": "xaura/affine-55555",
      "tagline": "",
      "readme": "xaura/affine-55555",
      "public": false,
      "version": "6fb03d33-ff60-54c4-9dc6-5209a8c50dff",
      "tool_description": null,
      "slug": "vrooom-xaura-affine-55555",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-20T15:45:21.525138Z",
      "updated_at": "2025-10-20T18:14:45.497529Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "vrooom",
        "user_id": "ae35d280-8f9f-5edf-812a-8c534b0bd7ec",
        "logo_id": null,
        "created_at": "2025-08-03T08:48:33.202605Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "f1fa491c6340a859de21cc103f5f76b58f4a26a8",
      "concurrency": 64,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 1200,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "cbec2300-c660-5e87-8cdd-c6ea4c600468",
      "name": "hO61qjpwxu/Affine_m3_5000_107",
      "tagline": "",
      "readme": "hO61qjpwxu/Affine_m3_5000_107",
      "public": false,
      "version": "97c4a114-fc8d-5aed-b8ec-59d1e8759aff",
      "tool_description": null,
      "slug": "silly-cow-ho61qjpwxu-affine-m3-5000-107",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-19T11:48:55.088179Z",
      "updated_at": "2025-10-20T18:11:37.386888Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "silly_cow",
        "user_id": "b2e36fa0-16e4-5212-9535-c2aa73e02738",
        "logo_id": null,
        "created_at": "2025-08-23T07:37:26.701271Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 48,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "b200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "36f21b3bf22d17c6852624cd25608688ca0340e2",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "c8ea1026-6e7e-5c1a-b362-b8fe2cc65fb3",
      "name": "tarabukinivan/Affine-2025",
      "tagline": "",
      "readme": "tarabukinivan/Affine-2025",
      "public": false,
      "version": "c9952c4a-7e57-5618-9736-790eb234322e",
      "tool_description": null,
      "slug": "tarab-tarabukinivan-affine-2025",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-18T00:45:47.121089Z",
      "updated_at": "2025-10-20T18:13:05.377240Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "tarab",
        "user_id": "a4ad5ddd-e88c-52a5-b928-578ad591a8e5",
        "logo_id": null,
        "created_at": "2025-10-16T12:25:13.703683Z",
        "logo": null
      },
      "supported_gpus": [
        "a100",
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h100",
          "a100",
          "h100_sxm"
        ],
        "gpu_count": 3,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.8,
        "supported_gpus": [
          "a100",
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.05,
            "tao": 0.000124176060792625
          },
          "output": {
            "usd": 0.2,
            "tao": 0.000496704243170502
          }
        },
        "usd": {
          "hour": 3.6,
          "second": 0.001
        },
        "tao": {
          "hour": 0.00894067637706905,
          "second": 0.000002483521215852
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "79ac0fb2f3b45df1021c3370dbf3a01e57a234d3",
      "concurrency": 20,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 3600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "27310b7d-038c-5f86-b297-83ed3191d1c4",
      "name": "darkhorse0811/Affine-5FpjxPXBTE6NH8qBAbeMK3msvHvuptKXS8pXUqjeLmxqwRCT",
      "tagline": "",
      "readme": "darkhorse0811/Affine-5FpjxPXBTE6NH8qBAbeMK3msvHvuptKXS8pXUqjeLmxqwRCT",
      "public": false,
      "version": "dc585e0a-1e96-5566-a308-5c54fb542d5a",
      "tool_description": null,
      "slug": "ryan888-darkhorse0811-affine-5fpjxpxbte6nh8qbabemk3msvhvup",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-01T12:19:25.322694Z",
      "updated_at": "2025-10-20T18:11:52.523135Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "ryan888",
        "user_id": "a193f8c4-c49b-5dca-97d4-2ff2796a5a9c",
        "logo_id": null,
        "created_at": "2025-09-18T10:07:18.712108Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 2,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 1.22222222222222,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.07,
            "tao": 0.000173846485109676
          },
          "output": {
            "usd": 0.3,
            "tao": 0.000745056364755754
          }
        },
        "usd": {
          "hour": 5.5,
          "second": 0.00152777777777778
        },
        "tao": {
          "hour": 0.0136593666871888,
          "second": 0.000003794268524219
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "787b251a906c427dbb2c84dbf50917b6b7836bf6",
      "concurrency": 64,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 1200,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "cc95f732-0632-5e57-8ebf-a8949e6d5871",
      "name": "matt0xdev/Affine-5FeEYe467qmBicd2ZuS2BWkYZt71zhwDRwog1h7zodEzP48p",
      "tagline": "",
      "readme": "matt0xdev/Affine-5FeEYe467qmBicd2ZuS2BWkYZt71zhwDRwog1h7zodEzP48p",
      "public": false,
      "version": "a6b74bcd-7be0-52b9-8c20-de6e1eac285a",
      "tool_description": null,
      "slug": "ryan1-matt0xdev-affine-5feeye467qmbicd2zus2bwkyzt71zhwdrwo",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-01T21:00:16.673419Z",
      "updated_at": "2025-10-20T18:09:54.928763Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "ryan1",
        "user_id": "f1505801-94ae-5c31-a71c-1b25dba75dd3",
        "logo_id": null,
        "created_at": "2025-10-01T20:38:17.282584Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "pro_6000",
        "h20",
        "a6000_ada",
        "a4000_ada",
        "a40",
        "h100_sxm",
        "h100",
        "h800",
        "a6000"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h100_nvl",
          "pro_6000",
          "h100_sxm",
          "a40",
          "a100",
          "h800",
          "a4000_ada",
          "h100",
          "a6000",
          "a6000_ada",
          "h20",
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.373333333333333,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "pro_6000",
          "h20",
          "a6000_ada",
          "a4000_ada",
          "a40",
          "h100_sxm",
          "h100",
          "h800",
          "a6000"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.02,
            "tao": 0.00004967042431705
          },
          "output": {
            "usd": 0.09,
            "tao": 0.000223516909426726
          }
        },
        "usd": {
          "hour": 1.68,
          "second": 0.000466666666666666
        },
        "tao": {
          "hour": 0.00417231564263222,
          "second": 0.000001158976567397
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "943327bebda14875d759d842ec2685be3067756f",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 120000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "2fba384f-6765-5a9d-9728-ae3193e7c943",
      "name": "trenden/Affine-10-20-01",
      "tagline": "",
      "readme": "trenden/Affine-10-20-01",
      "public": false,
      "version": "7ad3b349-3772-5cb7-9b65-91700f1a7ccf",
      "tool_description": null,
      "slug": "af02-trenden-affine-10-20-01",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-19T23:29:03.363355Z",
      "updated_at": "2025-10-19T23:29:03.363355Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "af02",
        "user_id": "8373ae40-34aa-58d4-a920-c752fe4155c3",
        "logo_id": null,
        "created_at": "2025-08-25T16:54:16.321091Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "6e02287876a131ffd84147a1e45140567bd65422",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "8e7e242f-1a1e-5c7e-b8a8-d41081296e84",
      "name": "xaura/affine-23424",
      "tagline": "",
      "readme": "xaura/affine-23424",
      "public": false,
      "version": "a4f90f11-43bf-58b2-9449-9c2f416ec45d",
      "tool_description": null,
      "slug": "unconst-xaura-affine-23424",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-08-04T12:32:33.142863Z",
      "updated_at": "2025-10-20T18:13:01.554778Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "unconst",
        "user_id": "e422c407-3326-5d7d-88a5-b28e09de0990",
        "logo_id": null,
        "created_at": "2025-03-05T18:21:52.749839Z",
        "logo": null
      },
      "supported_gpus": [
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "h100",
        "h100_sxm",
        "h800",
        "a100_sxm"
      ],
      "node_selector": {
        "exclude": [
          "mi300x",
          "b200",
          "h200"
        ],
        "include": null,
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 80,
        "compute_multiplier": 1.06666666666667,
        "supported_gpus": [
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "h100",
          "h100_sxm",
          "h800",
          "a100_sxm"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.72,
            "tao": 0.00178813527541381
          },
          "output": {
            "usd": 2.87,
            "tao": 0.00712770588949672
          }
        },
        "usd": {
          "hour": 52.8,
          "second": 0.0146666666666667
        },
        "tao": {
          "hour": 0.131129920197013,
          "second": 0.000036424977832503
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "26137b017ead0e19f597982099cc8714f549f062",
      "concurrency": 16,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "9011d9e5-6630-5029-865f-eac4c4507d2b",
      "name": "makeAffineGreatAgain/Affine-B",
      "tagline": "",
      "readme": "makeAffineGreatAgain/Affine-B",
      "public": false,
      "version": "18f2cbd8-bac3-54ac-9fbd-13ee07b0fabb",
      "tool_description": null,
      "slug": "magab-makeaffinegreatagain-affine-b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-06T06:55:28.225303Z",
      "updated_at": "2025-10-20T18:11:33.570208Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "magaB",
        "user_id": "b65f7d5a-e9cd-59c5-806b-84388d1f89b5",
        "logo_id": null,
        "created_at": "2025-10-06T05:47:12.096430Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "55a033bc235c9427abf223c4e3e6973c55ff9c16",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1800,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "89a8d0d7-c9b0-5ddc-a345-1cb3f170be7e",
      "name": "alecglover/Affine-v1",
      "tagline": "",
      "readme": "alecglover/Affine-v1",
      "public": false,
      "version": "a701b870-6c6b-558b-8895-36f9f7d24162",
      "tool_description": null,
      "slug": "upstation-alecglover-affine-v1",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-09-22T15:20:14.047379Z",
      "updated_at": "2025-10-20T18:11:44.995994Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "upstation",
        "user_id": "9721553c-e4d2-532f-951f-c7d47bec8ac3",
        "logo_id": null,
        "created_at": "2025-02-24T02:34:40.992868Z",
        "logo": null
      },
      "supported_gpus": [
        "3090"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "3090"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.444444444444444,
        "supported_gpus": [
          "3090"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          },
          "output": {
            "usd": 0.11,
            "tao": 0.000273187333743776
          }
        },
        "usd": {
          "hour": 2,
          "second": 0.000555555555555555
        },
        "tao": {
          "hour": 0.00496704243170503,
          "second": 0.000001379734008806
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "de83017571fcbe02252c8263cb11ecd7956af860",
      "concurrency": 12,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "034e710e-a01b-5977-8804-5c17d17d4d49",
      "name": "kesti/affine-108-1",
      "tagline": "",
      "readme": "kesti/affine-108-1",
      "public": false,
      "version": "aa37ff98-5540-5965-893d-98420bbc37f5",
      "tool_description": null,
      "slug": "kesti-1-kesti-affine-108-1",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-08T09:14:18.009725Z",
      "updated_at": "2025-10-20T18:10:06.328497Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "kesti_1",
        "user_id": "e410dbf0-ad0c-531f-b00a-a79e929dc279",
        "logo_id": null,
        "created_at": "2025-08-24T05:44:06.401291Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a100_40gb",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "b200",
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 40,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a100_40gb",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "a4d9677adda773005b10053ea6a520257d8e8f51",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 18000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "e8a0489f-ee9f-5df9-b97a-e20eb5b96d3b",
      "name": "GANGodfather/Affine-5HMkezj9CE9X1LpCybtCfvRUNYP1e3x8PBnG4WF1yBr64n8N",
      "tagline": "",
      "readme": "GANGodfather/Affine-5HMkezj9CE9X1LpCybtCfvRUNYP1e3x8PBnG4WF1yBr64n8N",
      "public": false,
      "version": "e01df93c-3ade-5ad6-94f7-ad9e17f1e24f",
      "tool_description": null,
      "slug": "sonyx07-gangodfather-affine-5hmkezj9ce9x1lpcybtcfvrunyp1e3",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-29T15:00:22.568242Z",
      "updated_at": "2025-10-20T18:10:59.239084Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "sonyx07",
        "user_id": "aa8eaeeb-8083-5acd-8d35-2ae869ec33a4",
        "logo_id": null,
        "created_at": "2025-08-29T11:42:56.755520Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "8e546d9e9020d6fc8c11a1ca0073f4624b799076",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "175019bb-32a5-5909-b6d6-6956475d666b",
      "name": "dasLOL/Affine-5FTZtXJnYj3sMLacezr4kqYkJzRgyDZTKvxmV28jZ4PSVNWY",
      "tagline": "",
      "readme": "dasLOL/Affine-5FTZtXJnYj3sMLacezr4kqYkJzRgyDZTKvxmV28jZ4PSVNWY",
      "public": false,
      "version": "0d8d28d8-d50e-5a6a-8d12-31a259c5e4d1",
      "tool_description": null,
      "slug": "bots5-1-daslol-affine-5ftztxjnyj3smlacezr4kqykjzrgydztkvxm",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-30T11:37:20.569394Z",
      "updated_at": "2025-10-20T18:10:02.466497Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "bots5_1",
        "user_id": "22a96c85-e926-5b2e-b2d9-5fdf2316aa51",
        "logo_id": null,
        "created_at": "2025-09-16T11:46:33.437993Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 4.88888888888889,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.3,
            "tao": 0.000745056364755754
          },
          "output": {
            "usd": 1.2,
            "tao": 0.00298022545902302
          }
        },
        "usd": {
          "hour": 22,
          "second": 0.00611111111111111
        },
        "tao": {
          "hour": 0.0546374667487553,
          "second": 0.000015177074096876
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "5f085e16b33de721c6a513170aef7c8858b19273",
      "concurrency": 64,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "1522cb06-eb06-5762-8517-f6dc6ce9ef13",
      "name": "kesti/affine-108-4",
      "tagline": "",
      "readme": "kesti/affine-108-4",
      "public": false,
      "version": "b2040706-5329-5ef9-83d4-e0b43d7a645f",
      "tool_description": null,
      "slug": "kesti-4-kesti-affine-108-4",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-08T09:31:00.362542Z",
      "updated_at": "2025-10-20T17:47:25.810829Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "kesti_4",
        "user_id": "67155904-5e38-5460-b20e-3514db5e89c2",
        "logo_id": null,
        "created_at": "2025-08-27T01:44:50.961079Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a100_40gb",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x",
          "b200"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 40,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a100_40gb",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "35d7c2117cc4289f3504e316f46cd318fc987da9",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 18000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "a99c3381-48be-5f3b-b642-6f311687a455",
      "name": "kishig/Affine-5HowRb3CdVoMYrsLSfkB5ySHSEMAUnJRZ52YmkRZFAMoFTJr",
      "tagline": "",
      "readme": "kishig/Affine-5HowRb3CdVoMYrsLSfkB5ySHSEMAUnJRZ52YmkRZFAMoFTJr",
      "public": false,
      "version": "45f60465-c163-50ec-bdda-03c9ade79efc",
      "tool_description": null,
      "slug": "olympus001-kishig-affine-5howrb3cdvomyrslsfkb5yshsemaunjrz",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-29T12:47:27.192351Z",
      "updated_at": "2025-10-20T18:10:36.480754Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "olympus001",
        "user_id": "2d783edc-595f-5eb2-873e-292ef8f2f53b",
        "logo_id": null,
        "created_at": "2025-09-11T14:08:04.336107Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "bf79e5fa58081565818cfd8f73f1fd001634bec5",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 1200,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "34b9e0a3-3f6d-592e-ac70-9317db8fe915",
      "name": "kesti/affine-q4-c",
      "tagline": "",
      "readme": "kesti/affine-q4-c",
      "public": false,
      "version": "63621c5c-c637-5083-964f-40161c1f2665",
      "tool_description": null,
      "slug": "kesti-12-kesti-affine-q4-c",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-11T09:45:50.350653Z",
      "updated_at": "2025-10-20T18:11:48.736505Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "kesti_12",
        "user_id": "33388e37-31ea-5efd-aa17-38a639dd77f9",
        "logo_id": null,
        "created_at": "2025-10-11T05:40:19.241811Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a100_40gb",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "b200",
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 40,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a100_40gb",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "a01b1d5cac85a9d4634d36936c72c1bbd07947aa",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 18000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "3e380bcc-c840-5175-b92c-a7306ecfc935",
      "name": "kesti/affine-q4-b",
      "tagline": "",
      "readme": "kesti/affine-q4-b",
      "public": false,
      "version": "e268cb88-150f-5cae-97d5-9529d55f8e5b",
      "tool_description": null,
      "slug": "kesti-11-kesti-affine-q4-b",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-11T09:35:56.386792Z",
      "updated_at": "2025-10-20T18:09:58.690106Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "kesti_11",
        "user_id": "cea17777-5864-5a23-a231-254d7d543996",
        "logo_id": null,
        "created_at": "2025-10-11T04:59:37.324029Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a100_40gb",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x",
          "b200"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 40,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a100_40gb",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "f9c2a84e0ce14d7b947d15139fb65dd389aba3c8",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 18000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "35a841f4-1f39-5988-8b82-e796b9ea5638",
      "name": "Dan-Carter/Affine-t3",
      "tagline": "",
      "readme": "Dan-Carter/Affine-t3",
      "public": false,
      "version": "dd5fa57d-e720-5044-ae2f-a31ab7aae8ef",
      "tool_description": null,
      "slug": "top3-dan-carter-affine-t3",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-10T08:36:50.519211Z",
      "updated_at": "2025-10-20T18:10:40.278284Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "top3",
        "user_id": "7f84d9bc-27d8-50fd-abb0-707c2940a6f0",
        "logo_id": null,
        "created_at": "2025-09-10T08:32:48.185858Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "exclude": [
          "b200",
          "mi300x"
        ],
        "include": [
          "h200",
          "b200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.41,
            "tao": 0.00101824369849953
          },
          "output": {
            "usd": 1.64,
            "tao": 0.00407297479399812
          }
        },
        "usd": {
          "hour": 30.25,
          "second": 0.00840277777777778
        },
        "tao": {
          "hour": 0.0751265167795386,
          "second": 0.000020868476883205
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "85e432aa16e6a7ae22e4b08b303645b9f06f8787",
      "concurrency": 32,
      "boost": null,
      "max_instances": null,
      "scaling_threshold": null,
      "shutdown_after_seconds": null,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "d450dbde-1b08-5e7a-a05e-6563ad2f2e78",
      "name": "kleverer/Affine-new_round_12",
      "tagline": "",
      "readme": "kleverer/Affine-new_round_12",
      "public": false,
      "version": "d3fb6593-b478-5c6f-803e-2b56388d61e4",
      "tool_description": null,
      "slug": "5fqtctmjtj-kleverer-affine-new-round-12",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-29T14:36:05.937959Z",
      "updated_at": "2025-10-20T18:10:47.760524Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "5FQtCtMJTJ",
        "user_id": "a6ae518c-fde0-5ff5-a120-796e55f87e94",
        "logo_id": null,
        "created_at": "2025-09-28T13:11:01.510885Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "905c517f1143c35d99c2795ddbed677c00b45bc4",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 3600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "78613e65-de1e-50ee-9758-bebd05b158f9",
      "name": "Deval1004/Affine-v25.0.1",
      "tagline": "",
      "readme": "Deval1004/Affine-v25.0.1",
      "public": false,
      "version": "82a80d66-2f0d-54a8-aefa-a544c92dd361",
      "tool_description": null,
      "slug": "affine-025-deval1004-affine-v25-0-1",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-07T15:03:55.681119Z",
      "updated_at": "2025-10-20T18:12:57.705216Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "affine_025",
        "user_id": "ca3b23e4-89bc-5d3f-b36c-7711521f20d8",
        "logo_id": null,
        "created_at": "2025-09-02T13:34:20.684695Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "08fa3b4317e70053ecd0ef40f813cdd857453b5a",
      "concurrency": 64,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "562b103e-9023-5b26-b454-fecf535c4976",
      "name": "affineprozz/Affine-newzzz",
      "tagline": "",
      "readme": "affineprozz/Affine-newzzz",
      "public": false,
      "version": "5b6fa4ab-8f90-551e-924f-d1e455970bbe",
      "tool_description": null,
      "slug": "affineprozz-affineprozz-affine-newzzz",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-30T07:59:33.654776Z",
      "updated_at": "2025-10-20T18:10:32.710508Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "affineprozz",
        "user_id": "8a5f366d-6c69-52de-bef7-5e66efa1fa0e",
        "logo_id": "3b043138-4555-4c68-a0dc-4e61f558809d",
        "created_at": "2025-09-05T06:25:42.497502Z",
        "logo": "https://logos.chutes.ai/logos/3b043138-4555-4c68-a0dc-4e61f558809d.webp"
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "pro_6000",
        "h20",
        "a6000_ada",
        "a4000_ada",
        "a40",
        "h100_sxm",
        "h100",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h100_nvl",
          "pro_6000",
          "h100_sxm",
          "a40",
          "a100",
          "h800",
          "a4000_ada",
          "h100",
          "a6000_ada",
          "h20",
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.0466666666666667,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "pro_6000",
          "h20",
          "a6000_ada",
          "a4000_ada",
          "a40",
          "h100_sxm",
          "h100",
          "h800"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.21,
          "second": 0.000058333333333333
        },
        "tao": {
          "hour": 0.000521539455329028,
          "second": 1.4487207092473e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "7e8fdbbcfec821f63eeeb4e95afa0ab020c0522f",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 1600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "3e0d6a32-5731-5bf8-b892-21d01f0b6c1b",
      "name": "ebobo/Affine-5DocUf3iHnrWhYJQ2CCYrPvHyk9UiaXsZ7Nsy5xRKVtmmWSG",
      "tagline": "",
      "readme": "ebobo/Affine-5DocUf3iHnrWhYJQ2CCYrPvHyk9UiaXsZ7Nsy5xRKVtmmWSG",
      "public": false,
      "version": "aae1d2cb-f320-5fb1-a3d9-751a423bdf13",
      "tool_description": null,
      "slug": "newall6-ebobo-affine-5docuf3ihnrwhyjq2ccyrpvhyk9uiaxsz7nsy",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-28T12:33:04.353902Z",
      "updated_at": "2025-10-20T18:10:44.052305Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "newall6",
        "user_id": "6170a1f3-7694-53f4-b98a-a9b4883ec1cd",
        "logo_id": null,
        "created_at": "2025-09-28T12:27:02.488577Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "f05fe68d4a6ff189cd54792933bc086ec9f0f62a",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 120000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "0194a1a4-1e3a-5564-b6a4-2ed56487a1e2",
      "name": "ebobo/Affine-5EJ7GF16uNfKY5c1s9xzSwqw2vAPUVaMVrpoi8QcNdk3bVTN",
      "tagline": "",
      "readme": "ebobo/Affine-5EJ7GF16uNfKY5c1s9xzSwqw2vAPUVaMVrpoi8QcNdk3bVTN",
      "public": false,
      "version": "5781f752-ee6a-531c-aae9-29f0614bd957",
      "tool_description": null,
      "slug": "newall2-ebobo-affine-5ej7gf16unfky5c1s9xzswqw2vapuvamvrpoi",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-22T22:45:56.705521Z",
      "updated_at": "2025-10-20T18:14:37.831347Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "newall2",
        "user_id": "9b281b8e-815b-5fc9-8070-cd0ee1c3cc46",
        "logo_id": null,
        "created_at": "2025-09-22T22:36:05.153085Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "5e5e5483193f257f98324a8dbeb2b5292ff312b3",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 120000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "a727dfd9-af05-54d8-8c38-fa9d3e085e83",
      "name": "makeAffineGreatAgain/Affine-002",
      "tagline": "",
      "readme": "makeAffineGreatAgain/Affine-002",
      "public": false,
      "version": "a0367c8d-1914-56dd-96d1-ccbcf69a5b34",
      "tool_description": null,
      "slug": "maga2-makeaffinegreatagain-affine-002",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-19T12:06:01.768325Z",
      "updated_at": "2025-10-20T18:15:04.400228Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "maga2",
        "user_id": "24f6e68c-a259-57ba-9fb5-cf9f3a040511",
        "logo_id": null,
        "created_at": "2025-09-18T15:25:37.872280Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "3f333736766db4926e4b80eb693f42b3d30c32e8",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 1200,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "b8aef539-5b7e-5f7e-b3f8-14c0cd5618a8",
      "name": "carf07/affine-bee",
      "tagline": "",
      "readme": "EiMon724/Affine-5EcXEX2hPdUbKEhyfJLMVKJHesaGYNshwL5wnrB2mZNu5dCR",
      "public": false,
      "version": "401b8b33-86c8-589c-b62b-ed61004d560e",
      "tool_description": null,
      "slug": "eimon727-carf07-affine-bee",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "76d0779b-030c-5efa-82a3-110d709844cd",
      "created_at": "2025-10-20T12:10:44.367040Z",
      "updated_at": "2025-10-20T12:14:00.193053Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "EiMon727",
        "user_id": "5497a029-57c5-571a-91af-1cbb9c837719",
        "logo_id": null,
        "created_at": "2025-10-03T04:25:18.822934Z",
        "logo": null
      },
      "supported_gpus": [
        "3090",
        "h20",
        "a100_40gb",
        "a100_sxm",
        "h200",
        "a100",
        "pro_6000",
        "h100",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "a10",
        "l40s",
        "b200",
        "h100_sxm",
        "4090",
        "5090",
        "h100_nvl",
        "a5000",
        "l4",
        "a6000_ada",
        "a40",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 24,
        "compute_multiplier": 0.0555555555555556,
        "supported_gpus": [
          "3090",
          "h20",
          "a100_40gb",
          "a100_sxm",
          "h200",
          "a100",
          "pro_6000",
          "h100",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "a10",
          "l40s",
          "b200",
          "h100_sxm",
          "4090",
          "5090",
          "h100_nvl",
          "a5000",
          "l4",
          "a6000_ada",
          "a40",
          "h800"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          }
        },
        "usd": {
          "hour": 0.25,
          "second": 0.000069444444444444
        },
        "tao": {
          "hour": 0.000620880303963128,
          "second": 1.72466751100869e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "900afa061c07a0a851603b3ad5ec6c6b5a610f23",
      "concurrency": 32,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 2400,
      "preemptible": false,
      "allow_external_egress": false,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "5fdd8538-ca1c-57e1-acf1-c7dc99918d69",
      "name": "kesti/affine-108-3",
      "tagline": "",
      "readme": "kesti/affine-108-3",
      "public": false,
      "version": "9f4f105b-9bca-570a-a0bd-3c912011dbfd",
      "tool_description": null,
      "slug": "kesti-3-kesti-affine-108-3",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-08T09:28:44.076409Z",
      "updated_at": "2025-10-20T17:48:47.659995Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "kesti_3",
        "user_id": "63916d2e-212a-5e38-a333-5a2f1c99f1a7",
        "logo_id": null,
        "created_at": "2025-08-24T05:45:30.601367Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a100_40gb",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x",
          "b200"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 40,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a100_40gb",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "739e76a64b3ab2f3d735b4a6751d2289cbab343d",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 18000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "3c9eea53-0e35-5a16-8fe8-cf9b94ca61ef",
      "name": "alecglover/Affine-v11",
      "tagline": "",
      "readme": "alecglover/Affine-v11",
      "public": false,
      "version": "c4c40c43-dabf-5ab6-aaf7-edc53d17dde5",
      "tool_description": null,
      "slug": "upstation-alecglover-affine-v11",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "a251c166-2e46-55cf-93d7-08aaea2069c7",
      "created_at": "2025-09-22T14:06:41.756730Z",
      "updated_at": "2025-10-20T18:14:30.033797Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "upstation",
        "user_id": "9721553c-e4d2-532f-951f-c7d47bec8ac3",
        "logo_id": null,
        "created_at": "2025-02-24T02:34:40.992868Z",
        "logo": null
      },
      "supported_gpus": [
        "3090"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "3090"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.444444444444444,
        "supported_gpus": [
          "3090"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          },
          "output": {
            "usd": 0.11,
            "tao": 0.000273187333743776
          }
        },
        "usd": {
          "hour": 2,
          "second": 0.000555555555555555
        },
        "tao": {
          "hour": 0.00496704243170503,
          "second": 0.000001379734008806
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "6bb28f0b99afc74ca747fdd6260ed6eaf81c037a",
      "concurrency": 1,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "0eee0766-620a-53af-b1e4-d676c32eaafb",
      "name": "matt0xdev/Affine-lfg",
      "tagline": "",
      "readme": "matt0xdev/Affine-lfg",
      "public": false,
      "version": "3db0e910-e8b9-53c8-8d5d-6c41e3297134",
      "tool_description": null,
      "slug": "ryan0x1-matt0xdev-affine-lfg",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-01T23:20:43.108229Z",
      "updated_at": "2025-10-20T18:14:26.327498Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "ryan0x1",
        "user_id": "a166709f-3612-548e-8882-7d0958dc8349",
        "logo_id": null,
        "created_at": "2025-10-01T21:17:39.182567Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 2,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 1.22222222222222,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.07,
            "tao": 0.000173846485109676
          },
          "output": {
            "usd": 0.3,
            "tao": 0.000745056364755754
          }
        },
        "usd": {
          "hour": 5.5,
          "second": 0.00152777777777778
        },
        "tao": {
          "hour": 0.0136593666871888,
          "second": 0.000003794268524219
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "8a9ca7839281a9b859a04a4c7c2350718fe89975",
      "concurrency": 16,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 120000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "ddd47e1a-5b8d-59d4-bf0f-1cb857bb99e1",
      "name": "xaura/affine-krikr9",
      "tagline": "",
      "readme": "xaura/affine-krikr9",
      "public": false,
      "version": "d53d5c27-acfe-59c2-ad3b-1ede32e33967",
      "tool_description": null,
      "slug": "vrooom-xaura-affine-krikr9",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-02T05:51:29.807496Z",
      "updated_at": "2025-10-20T18:11:29.782368Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "vrooom",
        "user_id": "ae35d280-8f9f-5edf-812a-8c534b0bd7ec",
        "logo_id": null,
        "created_at": "2025-08-03T08:48:33.202605Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "9bff40887d6870cf5a4da30d20b44d9df0556d04",
      "concurrency": 16,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 1200,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "774f7936-cbbe-536a-9b54-67485e9e84ed",
      "name": "Deval1004/Affine-v31.0.1",
      "tagline": "",
      "readme": "Deval1004/Affine-v31.0.1",
      "public": false,
      "version": "0e76b6b5-1dbb-50a1-bf2b-a8554e88e1e6",
      "tool_description": null,
      "slug": "affine-031-deval1004-affine-v31-0-1",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-23T00:39:01.761765Z",
      "updated_at": "2025-10-20T18:10:25.199137Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "affine_031",
        "user_id": "bcef3ae6-0791-565a-afbd-c222067bafc1",
        "logo_id": null,
        "created_at": "2025-09-10T00:06:01.306876Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200",
          "b200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200",
          "b200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "393176e1b4f874c521537c85086a9ad8e7ccbbb8",
      "concurrency": 64,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "21572df8-7589-5404-a5a2-32b960407cfd",
      "name": "xaura/affine-9575845",
      "tagline": "",
      "readme": "xaura/affine-9575845",
      "public": false,
      "version": "face1322-a4a4-5d0c-8360-2ec91af269fb",
      "tool_description": null,
      "slug": "vrooom-xaura-affine-9575845",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-12T07:06:20.404047Z",
      "updated_at": "2025-10-20T18:12:50.147407Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "vrooom",
        "user_id": "ae35d280-8f9f-5edf-812a-8c534b0bd7ec",
        "logo_id": null,
        "created_at": "2025-08-03T08:48:33.202605Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "h100",
        "h100_sxm"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h100",
          "h100_sxm",
          "h200"
        ],
        "gpu_count": 8,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 3.18222222222222,
        "supported_gpus": [
          "h200",
          "h100",
          "h100_sxm"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.19,
            "tao": 0.000471869031011977
          },
          "output": {
            "usd": 0.78,
            "tao": 0.00193714654836496
          }
        },
        "usd": {
          "hour": 14.32,
          "second": 0.00397777777777778
        },
        "tao": {
          "hour": 0.035564023811008,
          "second": 0.000009878895503057
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "1c537bba5e395d21dd5742290f4580a5b388584c",
      "concurrency": 24,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "3ad24bee-f80e-51cc-a57b-322572dbb097",
      "name": "VitaG/Affine-5FWu3UzvL6Mk7sE6UmMZwrhVRfPSW2oV6kZSjbeb2QjvJWo4",
      "tagline": "",
      "readme": "VitaG/Affine-5FWu3UzvL6Mk7sE6UmMZwrhVRfPSW2oV6kZSjbeb2QjvJWo4",
      "public": false,
      "version": "f2f54a1b-347a-5c80-bf49-0ae8c5796bfa",
      "tool_description": null,
      "slug": "noganga1209-vitag-affine-5fwu3uzvl6mk7se6ummzwrhvrfpsw2ov6",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-28T15:34:28.206161Z",
      "updated_at": "2025-10-20T18:10:51.643156Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "NOganga1209",
        "user_id": "b2478a1e-c5a5-5ab9-8eaa-28787544a743",
        "logo_id": null,
        "created_at": "2025-09-17T21:36:45.658164Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "54f85c99012f482794aea225fc2918cdc39873dc",
      "concurrency": 8,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 120000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "dccec6f7-68f6-5f8f-8fe8-b4787755586f",
      "name": "r2911/Affine-a41",
      "tagline": "",
      "readme": "r2911/Affine-a41",
      "public": false,
      "version": "65e56765-1d65-567b-88a6-a9a160ca0e74",
      "tool_description": null,
      "slug": "shak41-r2911-affine-a41",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "0315a7ff-bd8f-5415-a4f7-d0a367cfcfde",
      "created_at": "2025-10-20T19:28:28.354861Z",
      "updated_at": "2025-10-20T19:28:28.354861Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "shak41",
        "user_id": "af7e23fa-c920-52bb-b3b9-b8180765fe76",
        "logo_id": null,
        "created_at": "2025-10-20T16:38:15.733997Z",
        "logo": null
      },
      "supported_gpus": [
        "a100",
        "h100"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "a100",
          "h100"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.266666666666667,
        "supported_gpus": [
          "a100",
          "h100"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.02,
            "tao": 0.00004967042431705
          },
          "output": {
            "usd": 0.07,
            "tao": 0.000173846485109676
          }
        },
        "usd": {
          "hour": 1.2,
          "second": 0.000333333333333333
        },
        "tao": {
          "hour": 0.00298022545902302,
          "second": 8.27840405284171e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "e1b96fce26ac86f5119153bdad485f5f92d68e7e",
      "concurrency": 20,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.5,
      "shutdown_after_seconds": 3600,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "6b2427fa-f1d9-580b-8942-8fdc7e2f1121",
      "name": "zatup/Affine-5F7NCk265tH34kmuVR3243jNswH8wKvxRbHBVAmhXmvFQr2f",
      "tagline": "",
      "readme": "zatup/Affine-5F7NCk265tH34kmuVR3243jNswH8wKvxRbHBVAmhXmvFQr2f",
      "public": false,
      "version": "6a4559fb-a32b-59ec-a4d8-d5b02c894cae",
      "tool_description": null,
      "slug": "jopaa1010-zatup-affine-5f7nck265th34kmuvr3243jnswh8wkvxrbh",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-03T13:03:42.718884Z",
      "updated_at": "2025-10-20T18:09:43.565112Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "JOPAa1010",
        "user_id": "481ec8e3-707c-5cae-890b-db248e11bd15",
        "logo_id": null,
        "created_at": "2025-09-17T16:47:26.829742Z",
        "logo": null
      },
      "supported_gpus": [
        "h200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "884a8e67bad0ca8f71c234987eb8799824db9de5",
      "concurrency": 24,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 1200,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "ca9e41d6-7f89-58b1-b633-03f623463d86",
      "name": "kesti/affine-108-2",
      "tagline": "",
      "readme": "kesti/affine-108-2",
      "public": false,
      "version": "d0b4f8a1-ff9c-5510-a29a-4285f0cc5318",
      "tool_description": null,
      "slug": "kesti-2-kesti-affine-108-2",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-10-08T09:26:25.032647Z",
      "updated_at": "2025-10-20T18:11:06.911835Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "kesti_2",
        "user_id": "525683be-4fa9-5349-a646-eb57c884c5eb",
        "logo_id": null,
        "created_at": "2025-08-24T05:44:58.672061Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "a100",
        "h100_nvl",
        "h20",
        "pro_6000",
        "a6000_ada",
        "a100_40gb",
        "a40",
        "h100_sxm",
        "a6000",
        "l40",
        "a100_40gb_sxm",
        "h100",
        "a100_sxm",
        "l40s",
        "h800"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x",
          "b200"
        ],
        "include": null,
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 40,
        "compute_multiplier": 0.111111111111111,
        "supported_gpus": [
          "h200",
          "a100",
          "h100_nvl",
          "h20",
          "pro_6000",
          "a6000_ada",
          "a100_40gb",
          "a40",
          "h100_sxm",
          "a6000",
          "l40",
          "a100_40gb_sxm",
          "h100",
          "a100_sxm",
          "l40s",
          "h800"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.01,
            "tao": 0.000024835212158525
          },
          "output": {
            "usd": 0.03,
            "tao": 0.000074505636475575
          }
        },
        "usd": {
          "hour": 0.5,
          "second": 0.000138888888888888
        },
        "tao": {
          "hour": 0.00124176060792626,
          "second": 3.44933502201738e-7
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "56dc11d52d31ad50f6a95d0156381a4bf314edb3",
      "concurrency": 32,
      "boost": null,
      "max_instances": 2,
      "scaling_threshold": 0.95,
      "shutdown_after_seconds": 18000,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    },
    {
      "chute_id": "c81bb46a-7579-5d46-aeac-7d6caca91286",
      "name": "Deval1004/Affine-v30.0.1",
      "tagline": "",
      "readme": "Deval1004/Affine-v30.0.1",
      "public": false,
      "version": "b9bcfa52-ed83-5dd9-86fc-c5c1c024a5d0",
      "tool_description": null,
      "slug": "affin-029-deval1004-affine-v30-0-1",
      "standard_template": "vllm",
      "cords": null,
      "jobs": [],
      "cord_ref_id": "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825",
      "created_at": "2025-09-28T16:11:23.991941Z",
      "updated_at": "2025-10-20T18:12:00.289273Z",
      "image": {
        "image_id": "b004c99b-175f-58ee-819d-42e69c7b620a",
        "name": "sglang",
        "readme": "SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language.",
        "tag": "nightly-2025101900",
        "public": true,
        "status": "built and pushed",
        "created_at": "2025-10-19T10:32:57.397619Z",
        "build_started_at": "2025-10-19T10:32:59.290715Z",
        "build_completed_at": "2025-10-19T11:09:25.867902Z",
        "user": {
          "username": "chutes",
          "user_id": "dff3e6bb-3a6b-5a2b-9c48-da3abcd5ca5f",
          "logo_id": "24ef9084-7739-400c-aab6-135463a8c2d9",
          "created_at": "2024-12-03T11:31:39.181725Z",
          "logo": "https://logos.chutes.ai/logos/24ef9084-7739-400c-aab6-135463a8c2d9.webp"
        },
        "logo_id": null,
        "patch_version": "3161f5aabcb9",
        "logo": null
      },
      "user": {
        "username": "affin_029",
        "user_id": "c743f7f8-346f-56f4-851f-e59976970807",
        "logo_id": null,
        "created_at": "2025-09-03T18:06:09.448451Z",
        "logo": null
      },
      "supported_gpus": [
        "h200",
        "b200"
      ],
      "node_selector": {
        "dynamic": false,
        "exclude": [
          "mi300x"
        ],
        "include": [
          "h200",
          "b200"
        ],
        "gpu_count": 1,
        "min_vram_gb_per_gpu": 16,
        "compute_multiplier": 0.611111111111111,
        "supported_gpus": [
          "h200",
          "b200"
        ]
      },
      "invocation_count": 0,
      "current_estimated_price": {
        "per_million_tokens": {
          "input": {
            "usd": 0.04,
            "tao": 0.0000993408486341
          },
          "output": {
            "usd": 0.15,
            "tao": 0.000372528182377877
          }
        },
        "usd": {
          "hour": 2.75,
          "second": 0.000763888888888888
        },
        "tao": {
          "hour": 0.00682968334359442,
          "second": 0.000001897134262109
        }
      },
      "instances": [],
      "logo_id": null,
      "openrouter": false,
      "chutes_version": "0.3.46",
      "revision": "ec30ec6c773cd8a1f10d83282ec26a79fc3342f4",
      "concurrency": 64,
      "boost": null,
      "max_instances": 1,
      "scaling_threshold": 0.75,
      "shutdown_after_seconds": 300,
      "preemptible": false,
      "allow_external_egress": true,
      "logo": null,
      "hot": false
    }
  ],
  "cord_refs": {
    "39298a95-dfa9-5370-8d14-8d45715bcfbf": [
      {
        "path": "/chat_stream",
        "method": "POST",
        "stream": true,
        "function": "chat_stream",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion_stream",
        "method": "POST",
        "stream": true,
        "function": "completion_stream",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/chat",
        "method": "POST",
        "stream": false,
        "function": "chat",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion",
        "method": "POST",
        "stream": false,
        "function": "completion",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/get_models",
        "method": "GET",
        "stream": false,
        "function": "get_models",
        "passthrough": true,
        "public_api_path": "/v1/models",
        "public_api_method": "GET",
        "output_content_type": null
      }
    ],
    "a251c166-2e46-55cf-93d7-08aaea2069c7": [
      {
        "path": "/chat_stream",
        "method": "POST",
        "stream": true,
        "function": "chat_stream",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion_stream",
        "method": "POST",
        "stream": true,
        "function": "completion_stream",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/chat",
        "method": "POST",
        "stream": false,
        "function": "chat",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion",
        "method": "POST",
        "stream": false,
        "function": "completion",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/get_models",
        "method": "GET",
        "stream": false,
        "function": "get_models",
        "passthrough": true,
        "public_api_path": "/v1/models",
        "public_api_method": "GET",
        "output_content_type": null
      }
    ],
    "b9784def-b796-57d7-888e-8fef54b2207e": [
      {
        "path": "/chat_stream",
        "method": "POST",
        "stream": true,
        "function": "chat_stream",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion_stream",
        "method": "POST",
        "stream": true,
        "function": "completion_stream",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/chat",
        "method": "POST",
        "stream": false,
        "function": "chat",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion",
        "method": "POST",
        "stream": false,
        "function": "completion",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/get_models",
        "method": "GET",
        "stream": false,
        "function": "get_models",
        "passthrough": true,
        "public_api_path": "/v1/models",
        "public_api_method": "GET",
        "output_content_type": null
      }
    ],
    "bcc7eb3b-d9ea-5892-b6ce-97ae9dc8e825": [
      {
        "path": "/chat_stream",
        "method": "POST",
        "stream": true,
        "function": "chat_stream",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion_stream",
        "method": "POST",
        "stream": true,
        "function": "completion_stream",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/chat",
        "method": "POST",
        "stream": false,
        "function": "chat",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion",
        "method": "POST",
        "stream": false,
        "function": "completion",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/get_models",
        "method": "GET",
        "stream": false,
        "function": "get_models",
        "passthrough": true,
        "public_api_path": "/v1/models",
        "public_api_method": "GET",
        "output_content_type": null
      }
    ],
    "7e4c99c5-31f0-5254-869e-711c84e4423a": [
      {
        "path": "/chat_stream",
        "method": "POST",
        "stream": true,
        "function": "chat_stream",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion_stream",
        "method": "POST",
        "stream": true,
        "function": "completion_stream",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/chat",
        "method": "POST",
        "stream": false,
        "function": "chat",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/do_tokenize",
        "method": "POST",
        "stream": false,
        "function": "do_tokenize",
        "passthrough": true,
        "public_api_path": "/tokenize",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/do_detokenize",
        "method": "POST",
        "stream": false,
        "function": "do_detokenize",
        "passthrough": true,
        "public_api_path": "/detokenize",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion",
        "method": "POST",
        "stream": false,
        "function": "completion",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/get_models",
        "method": "GET",
        "stream": false,
        "function": "get_models",
        "passthrough": true,
        "public_api_path": "/v1/models",
        "public_api_method": "GET",
        "output_content_type": null
      }
    ],
    "9821e394-028a-5870-a29d-d29d32ac464c": [
      {
        "path": "/chat_stream",
        "method": "POST",
        "stream": true,
        "function": "chat_stream",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion_stream",
        "method": "POST",
        "stream": true,
        "function": "completion_stream",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/chat",
        "method": "POST",
        "stream": false,
        "function": "chat",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion",
        "method": "POST",
        "stream": false,
        "function": "completion",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/get_models",
        "method": "GET",
        "stream": false,
        "function": "get_models",
        "passthrough": true,
        "public_api_path": "/v1/models",
        "public_api_method": "GET",
        "output_content_type": null
      }
    ],
    "0315a7ff-bd8f-5415-a4f7-d0a367cfcfde": [
      {
        "path": "/chat_stream",
        "method": "POST",
        "stream": true,
        "function": "chat_stream",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion_stream",
        "method": "POST",
        "stream": true,
        "function": "completion_stream",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/chat",
        "method": "POST",
        "stream": false,
        "function": "chat",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion",
        "method": "POST",
        "stream": false,
        "function": "completion",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/get_models",
        "method": "GET",
        "stream": false,
        "function": "get_models",
        "passthrough": true,
        "public_api_path": "/v1/models",
        "public_api_method": "GET",
        "output_content_type": null
      }
    ],
    "56bf4f6f-06ef-5e08-a903-64e6ec96d5dc": [
      {
        "path": "/chat_stream",
        "method": "POST",
        "stream": true,
        "function": "chat_stream",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion_stream",
        "method": "POST",
        "stream": true,
        "function": "completion_stream",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/chat",
        "method": "POST",
        "stream": false,
        "function": "chat",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion",
        "method": "POST",
        "stream": false,
        "function": "completion",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/get_models",
        "method": "GET",
        "stream": false,
        "function": "get_models",
        "passthrough": true,
        "public_api_path": "/v1/models",
        "public_api_method": "GET",
        "output_content_type": null
      }
    ],
    "3fc9a9a4-04f1-515d-bad8-ccf3e093b22e": [
      {
        "path": "/chat_stream",
        "method": "POST",
        "stream": true,
        "function": "chat_stream",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion_stream",
        "method": "POST",
        "stream": true,
        "function": "completion_stream",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/chat",
        "method": "POST",
        "stream": false,
        "function": "chat",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion",
        "method": "POST",
        "stream": false,
        "function": "completion",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/get_models",
        "method": "GET",
        "stream": false,
        "function": "get_models",
        "passthrough": true,
        "public_api_path": "/v1/models",
        "public_api_method": "GET",
        "output_content_type": null
      }
    ],
    "ec6cff99-787a-5f59-a4ed-c6890628d937": [
      {
        "path": "/chat_stream",
        "method": "POST",
        "stream": true,
        "function": "chat_stream",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion_stream",
        "method": "POST",
        "stream": true,
        "function": "completion_stream",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/chat",
        "method": "POST",
        "stream": false,
        "function": "chat",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion",
        "method": "POST",
        "stream": false,
        "function": "completion",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/get_models",
        "method": "GET",
        "stream": false,
        "function": "get_models",
        "passthrough": true,
        "public_api_path": "/v1/models",
        "public_api_method": "GET",
        "output_content_type": null
      }
    ],
    "76d0779b-030c-5efa-82a3-110d709844cd": [
      {
        "path": "/chat_stream",
        "method": "POST",
        "stream": true,
        "function": "chat_stream",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion_stream",
        "method": "POST",
        "stream": true,
        "function": "completion_stream",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/chat",
        "method": "POST",
        "stream": false,
        "function": "chat",
        "passthrough": true,
        "public_api_path": "/v1/chat/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/completion",
        "method": "POST",
        "stream": false,
        "function": "completion",
        "passthrough": true,
        "public_api_path": "/v1/completions",
        "public_api_method": "POST",
        "output_content_type": "application/json"
      },
      {
        "path": "/get_models",
        "method": "GET",
        "stream": false,
        "function": "get_models",
        "passthrough": true,
        "public_api_path": "/v1/models",
        "public_api_method": "GET",
        "output_content_type": null
      }
    ]
  }
}
