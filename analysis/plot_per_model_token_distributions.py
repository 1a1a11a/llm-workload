#!/usr/bin/env python3
"""Token usage distribution analysis script
This requires the per-model CSV files, which are generated by the plot_user.py script.

Plot the number of input and output token distributions.
Input is one or more CSV files, each representing a model's data.
Uses parallel processing for reading multiple CSV files and generating plots.

Example:
    traces=$(wc -l data/metrics_30day/per_model/*.csv | grep -v "total" | sort -nr | head -n 10 | awk '{print $2}')
    echo "Top 10 models by number of requests:"
    echo "$traces"
    python3 plot_token_distributions.py $traces

"""

import argparse
import csv
import os
import sys
from concurrent.futures import ProcessPoolExecutor, as_completed
from pathlib import Path
from typing import Dict, List, Optional, Tuple

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import matplotlib.pyplot as plt
import numpy as np

from utils.plot import setup_plot_style


def _read_tokens_from_csv(csv_path: str) -> Dict[str, Dict[int, int]]:
    """Read input_tokens and output_tokens from CSV as frequency maps.

    Returns:
        Dict with 'input_tokens' and 'output_tokens' keys, each containing
        a frequency map {token_count: num_requests}
    """
    input_token_counts = {}
    output_token_counts = {}
    ratio_counts = {}

    with open(csv_path, "r") as f:
        reader = csv.DictReader(f)
        for row in reader:
            if not row.get("input_tokens") or not row.get("output_tokens"):
                continue

            input_tok = int(row["input_tokens"])
            output_tok = int(row["output_tokens"])

            # Update frequency maps
            input_token_counts[input_tok] = input_token_counts.get(input_tok, 0) + 1
            output_token_counts[output_tok] = output_token_counts.get(output_tok, 0) + 1

            # Store ratio as well (for positive input tokens)
            if input_tok > 0:
                ratio = output_tok / input_tok
                ratio_counts[ratio] = ratio_counts.get(ratio, 0) + 1

    return {
        "input_tokens": input_token_counts,
        "output_tokens": output_token_counts,
        "ratio": ratio_counts,
    }


def _frequency_map_to_cdf(freq_map: Dict[float, int]) -> Tuple[np.ndarray, np.ndarray]:
    """Convert frequency map to CDF coordinates for plotting.

    Args:
        freq_map: Dict mapping value to frequency {value: count}

    Returns:
        Tuple of (sorted_values, cdf_values)
    """
    if not freq_map:
        return np.array([]), np.array([])

    # Sort by value
    sorted_items = sorted(freq_map.items())
    values = np.array([item[0] for item in sorted_items])
    counts = np.array([item[1] for item in sorted_items])

    # Calculate cumulative counts and normalize to [0, 1]
    cumulative = np.cumsum(counts)
    cdf = cumulative / cumulative[-1]

    return values, cdf


def _plot_single_model(args: Tuple[str, Dict[float, int], str, str, str, bool]) -> str:
    """Plot a single model's CDF from frequency map. Used for parallel processing.

    Returns:
        Path to the saved plot
    """
    model_name, freq_map, title, xlabel, output_dir, logx = args

    if freq_map is None or len(freq_map) == 0:
        return ""

    values, cdf = _frequency_map_to_cdf(freq_map)
    num_samples = sum(freq_map.values())

    plt.figure(figsize=(12, 8))
    plt.plot(
        values,
        cdf,
        label=f"{model_name} (n={num_samples:,})",
        linewidth=3,
        alpha=0.8,
        linestyle="-",
        color=plt.cm.tab10.colors[0],
    )

    plt.title(f"{title} - {model_name}", pad=20)
    plt.xlabel(xlabel)
    plt.ylabel("Cumulative Probability Distribution (CDF)")
    if logx:
        plt.xscale("log")
    plt.grid(True, alpha=0.3)
    plt.legend(bbox_to_anchor=(1.05, 1), loc="upper left")

    output_file = os.path.join(output_dir, f"{model_name.replace('/', '_')}_cdf.png")
    plt.savefig(output_file, dpi=300, bbox_inches="tight")
    plt.close()
    return output_file


def plot_cdf(
    data_dict: Dict[str, Dict[float, int]],
    title: str,
    xlabel: str,
    output_file: str,
    logx: bool = True,
) -> None:
    """Plot the CDF for each dataset from frequency maps and save the figure."""
    plt.figure(figsize=(12, 8))
    line_styles = ["-", "--", "-.", ":", "-", "--", "-.", ":", "-", "--", "-.", ":"]
    colors = tuple(plt.cm.tab10.colors + plt.cm.Set1.colors)

    for index, (label, freq_map) in enumerate(data_dict.items()):
        if freq_map is None or len(freq_map) == 0:
            continue

        values, cdf = _frequency_map_to_cdf(freq_map)
        num_samples = sum(freq_map.values())

        line_style = line_styles[index % len(line_styles)]
        color = colors[index % len(colors)]
        plt.plot(
            values,
            cdf,
            label=f"{label} (n={num_samples:,})",
            linewidth=3,
            alpha=0.8,
            linestyle=line_style,
            color=color,
        )

    plt.title(title, pad=20)
    plt.xlabel(xlabel)
    plt.ylabel("Cumulative Probability Distribution (CDF)")
    if logx:
        plt.xscale("log")
    plt.grid(True, alpha=0.3)
    plt.legend(bbox_to_anchor=(1.05, 1), loc="upper left")
    plt.savefig(output_file, dpi=300, bbox_inches="tight")
    plt.close()
    print(f"Saved: {output_file}")


def plot_cdf_individual(
    data_dict: Dict[str, Dict[float, int]],
    title: str,
    xlabel: str,
    output_dir: str,
    logx: bool = True,
) -> None:
    """Plot individual CDFs from frequency maps for each model in separate figures (parallelized)."""
    # Prepare arguments for parallel processing
    plot_args = [
        (model_name, freq_map, title, xlabel, output_dir, logx)
        for model_name, freq_map in data_dict.items()
        if freq_map is not None and len(freq_map) > 0
    ]

    if not plot_args:
        return

    # Plot in parallel
    with ProcessPoolExecutor() as executor:
        futures = [executor.submit(_plot_single_model, args) for args in plot_args]
        for future in as_completed(futures):
            output_file = future.result()
            if output_file:
                print(f"Saved individual plot: {output_file}")


def main(
    csv_files: List[str], model_names: Optional[List[str]], output_dir: str
) -> None:
    if len(csv_files) == 0:
        raise RuntimeError("No CSV files provided")

    # Prepare model names - use provided names or derive from filenames
    if model_names is None:
        model_names = []
        for csv_file in csv_files:
            base_name = os.path.basename(csv_file)
            model_name = os.path.splitext(base_name)[0]
            model_names.append(model_name)
    elif len(model_names) != len(csv_files):
        raise RuntimeError(
            f"Number of model names ({len(model_names)}) must match number of CSV files ({len(csv_files)})"
        )

    # Store frequency maps
    input_tokens_freq: Dict[str, Dict[int, int]] = {}
    output_tokens_freq: Dict[str, Dict[int, int]] = {}
    ratio_freq: Dict[str, Dict[float, int]] = {}

    total_records = 0

    # Read files in parallel
    print(f"Reading {len(csv_files)} file(s) in parallel...")
    with ProcessPoolExecutor() as executor:
        # Submit all CSV reading jobs
        future_to_info = {
            executor.submit(_read_tokens_from_csv, csv_file): (csv_file, model_name)
            for csv_file, model_name in zip(csv_files, model_names)
        }

        # Collect results as they complete
        for future in as_completed(future_to_info):
            csv_file, model_name = future_to_info[future]
            token_data = future.result()

            input_freq = token_data["input_tokens"]
            output_freq = token_data["output_tokens"]
            ratio_freq_data = token_data["ratio"]

            if len(input_freq) == 0:
                print(f"  -> No token data found in {csv_file}")
                continue

            # Calculate total records from frequency map
            num_samples = sum(input_freq.values())
            total_records += num_samples

            input_tokens_freq[model_name] = input_freq
            output_tokens_freq[model_name] = output_freq
            ratio_freq[model_name] = ratio_freq_data

            print(
                f"  -> {model_name}: {num_samples:,} samples from {os.path.basename(csv_file)}"
            )

    if not input_tokens_freq:
        raise RuntimeError("No token data available from any file")

    print(f"Loaded {total_records:,} total records from {len(csv_files)} file(s)")
    print("Models to plot: " + ", ".join(input_tokens_freq.keys()))

    # Create output directory based on the first file name or a combined name
    if len(csv_files) == 1:
        trace_name = os.path.basename(csv_files[0]).split(".")[0]
    else:
        trace_name = "combined_models"

    output_path = Path(f"{output_dir}/figures/per_model_token_distributions/{trace_name}")
    output_path.mkdir(parents=True, exist_ok=True)

    # Create combined plots for all models (directly from frequency maps)
    print("\nCreating combined input tokens CDF plot...")
    plot_cdf(
        input_tokens_freq,
        "Input Tokens Distribution (All Models)",
        "Input Tokens",
        str(output_path / "input_tokens_cdf_combined.png"),
    )

    print("Creating combined output tokens CDF plot...")
    plot_cdf(
        output_tokens_freq,
        "Output Tokens Distribution (All Models)",
        "Output Tokens",
        str(output_path / "output_tokens_cdf_combined.png"),
    )

    print("Creating combined output/input ratio CDF plot...")
    plot_cdf(
        ratio_freq,
        "Output/Input Token Distribution (All Models)",
        "Output/Input Ratio",
        str(output_path / "input_output_ratio_cdf_combined.png"),
    )

    # Create individual plots for each model (directly from frequency maps)
    print("\nCreating individual plots for each model...")
    individual_output_path = output_path / "individual"
    individual_output_path.mkdir(exist_ok=True)

    plot_cdf_individual(
        input_tokens_freq,
        "Input Tokens Distribution",
        "Input Tokens",
        str(individual_output_path),
    )

    plot_cdf_individual(
        output_tokens_freq,
        "Output Tokens Distribution",
        "Output Tokens",
        str(individual_output_path),
    )

    plot_cdf_individual(
        ratio_freq,
        "Output/Input Token Distribution",
        "Output/Input Ratio",
        str(individual_output_path),
    )

    print("\nPlotting complete! Outputs saved to:")
    for filename in (
        "input_tokens_cdf_combined.png",
        "output_tokens_cdf_combined.png",
        "input_output_ratio_cdf_combined.png",
    ):
        print(f"- {output_path / filename}")

    print("Individual plots saved to:")
    print(f"- {individual_output_path}")


if __name__ == "__main__":
    setup_plot_style()
    parser = argparse.ArgumentParser(
        description="Plot token distributions for metrics traces (each file represents one model)"
    )
    parser.add_argument(
        "csv_files",
        nargs="+",
        help="Path to one or more metrics CSV files (each file represents one model)",
    )
    parser.add_argument(
        "--output-dir",
        default=".",
        help="Directory for saving the generated plots",
    )
    parser.add_argument(
        "--model-names",
        nargs="+",
        help="Model names corresponding to each CSV file (defaults to filename without extension)",
    )
    arguments = parser.parse_args()
    main(arguments.csv_files, arguments.model_names, arguments.output_dir)
